{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npObmTx3XCna"
      },
      "outputs": [],
      "source": [
        "!pip install neuralforecast\n",
        "!pip install feature-engine"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from neuralforecast import NeuralForecast\n",
        "from neuralforecast.auto import AutoNHITS\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from neuralforecast.losses.numpy import mase as mase_numpy\n",
        "from utilsforecast.losses import mase\n",
        "from ray import tune\n",
        "from ray.tune.search.hyperopt import HyperOptSearch\n",
        "from neuralforecast.losses.pytorch import MAE\n",
        "import sklearn\n",
        "import neuralforecast\n",
        "import feature_engine"
      ],
      "metadata": {
        "id": "hWmEps0FZT1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Versões\n",
        "print('Versões:')\n",
        "print('Python: %s' % sys.version)\n",
        "print('Pandas: %s' % pd.__version__)\n",
        "print('Numpy: %s' % np.__version__)\n",
        "print('Sklearn: %s' % sklearn.__version__)\n",
        "print('NeuralForecast: %s' % neuralforecast.__version__)\n",
        "print('Feature-Engine: %s' % feature_engine.__version__)"
      ],
      "metadata": {
        "id": "Hk4Y8G2vcbDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = \"/content/drive/MyDrive/dl-project\"\n",
        "\n",
        "FEATURES = [\n",
        "    'pressure_1',\n",
        "    'pressure_2',\n",
        "    'pressure_3',\n",
        "    'pressure_4',\n",
        "    'pressure_5',\n",
        "    'pressure_6',\n",
        "    'pressure_7'\n",
        "]\n",
        "SEED = 78\n",
        "\n",
        "horizon = 187\n",
        "input_size = 187"
      ],
      "metadata": {
        "id": "rw3Ii1CjZrMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(f\"{ROOT}/data/train_data_scaled.csv\")\n",
        "test = pd.read_csv(f\"{ROOT}/data/test_data_scaled.csv\")"
      ],
      "metadata": {
        "id": "PHyIkQdEaH8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Requrimento do nixtla\n",
        "train['unique_id'] = 'slug_flow'\n",
        "train['ds'] = train['time']\n",
        "train['y'] = train['liquid_flow_rate']\n",
        "\n",
        "\n",
        "test['unique_id'] = 'slug_flow'\n",
        "test['ds'] = test['time']\n",
        "test['y'] = test['liquid_flow_rate']"
      ],
      "metadata": {
        "id": "rtJ67wFqaLhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nhits_config = AutoNHITS.get_default_config(h = horizon, backend=\"ray\")\n",
        "nhits_config.update(\n",
        "    {\n",
        "        'input_size': input_size,\n",
        "        'exclude_insample_y': True,\n",
        "        'hist_exog_list': FEATURES,\n",
        "        'early_stop_patience_steps': 10,\n",
        "        'val_check_steps': 100,\n",
        "        'random_seed': SEED\n",
        "    }\n",
        ")\n",
        "nhits_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC5dvEz95BtH",
        "outputId": "8339038d-c32e-454c-983b-4473050581fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'h': None,\n",
              " 'n_pool_kernel_size': <ray.tune.search.sample.Categorical at 0x7f7bd0508ed0>,\n",
              " 'n_freq_downsample': <ray.tune.search.sample.Categorical at 0x7f7bd0509150>,\n",
              " 'learning_rate': <ray.tune.search.sample.Float at 0x7f7bd0509210>,\n",
              " 'scaler_type': <ray.tune.search.sample.Categorical at 0x7f7bd0509310>,\n",
              " 'max_steps': <ray.tune.search.sample.Float at 0x7f7bd0509090>,\n",
              " 'batch_size': <ray.tune.search.sample.Categorical at 0x7f7bd0509510>,\n",
              " 'windows_batch_size': <ray.tune.search.sample.Categorical at 0x7f7bd0509610>,\n",
              " 'loss': None,\n",
              " 'random_seed': 78,\n",
              " 'input_size': <ray.tune.search.sample.Categorical at 0x7f7bd0573f90>,\n",
              " 'step_size': <ray.tune.search.sample.Categorical at 0x7f7bd258fa10>,\n",
              " 'exclude_insample_y': True,\n",
              " 'hist_exog_list': ['pressure_1',\n",
              "  'pressure_2',\n",
              "  'pressure_3',\n",
              "  'pressure_4',\n",
              "  'pressure_5',\n",
              "  'pressure_6',\n",
              "  'pressure_7'],\n",
              " 'early_stop_patience_steps': 10,\n",
              " 'val_check_steps': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "wX4rf3LNa4mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    AutoNHITS(\n",
        "        h=horizon,\n",
        "        loss=MAE(),\n",
        "        config=nhits_config,\n",
        "        search_alg=HyperOptSearch(),\n",
        "        backend='ray',\n",
        "        num_samples=30\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "WjRIPCRgaQWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nf = NeuralForecast(\n",
        "    models=models,\n",
        "    freq=1\n",
        ")\n",
        "nf.fit(\n",
        "    df=train, val_size=horizon\n",
        ")"
      ],
      "metadata": {
        "id": "StldPXZvcR9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3abb8dc-7e5b-4078-9f69-01d2d0406219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 17:27:59,797\tINFO worker.py:1917 -- Started a local Ray instance.\n",
            "2025-06-15 17:28:01,541\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     _train_tune_2025-06-15_17-27-55   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 SearchGenerator                   |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 30                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/_train_tune_2025-06-15_17-27-55\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2025-06-15_17-27-55_986760_192/artifacts/2025-06-15_17-28-01/_train_tune_2025-06-15_17-27-55/driver_artifacts`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=1422)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 2025-06-15 17:28:15.749325: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m E0000 00:00:1750008496.035796    1515 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m E0000 00:00:1750008496.112943    1515 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 2025-06-15 17:28:16.735240: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 3 | blocks       | ModuleList    | 5.1 M  | train\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 5.1 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 5.1 M     Total params\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 20.233    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\n",
            "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.141, train_loss_epoch=0.141]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.123, train_loss_epoch=0.123]\n",
            "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0938, train_loss_epoch=0.0938]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.100, train_loss_epoch=0.100]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0855, train_loss_epoch=0.0855]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0826, train_loss_epoch=0.0826]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.077]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0743, train_loss_epoch=0.0743]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0634, train_loss_epoch=0.0634]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0564, train_loss_epoch=0.0564]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0592, train_loss_epoch=0.0592]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0524, train_loss_epoch=0.0524]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0528, train_loss_epoch=0.0528]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.054, train_loss_epoch=0.054]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0541, train_loss_epoch=0.0541]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0507, train_loss_epoch=0.0507]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.051]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0489, train_loss_epoch=0.0489]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426]\n",
            "Epoch 41: 100%|██████████| 1/1 [00:00<00:00,  7.02it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0435, train_loss_epoch=0.0435]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0427, train_loss_epoch=0.0427]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0432, train_loss_epoch=0.0432]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0441, train_loss_epoch=0.0441]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0441, train_loss_epoch=0.0441]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.048, train_loss_epoch=0.048]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.81it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0372]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.32it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.00933]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.00933]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.00933]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.00933]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.00933]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=0.00933]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=0.00933]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.00933]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.00933]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.00933]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.00933]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=0.00933]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.00933]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.00933]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.00933]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.00933]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.00933]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.00933]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.00933]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.00933]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.00933]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=0.00933]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.00933]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.00933]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.00933]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=0.00933]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.00933]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.00933]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=0.00933]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.00933]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.00933]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.00933]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.00933]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=0.00933]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=0.00933]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=0.00933]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.00933]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.00933]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0364, train_loss_epoch=0.0364, valid_loss=0.00933]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.00933]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=0.00933]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:00<00:00,  7.09it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=0.00933]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=0.00933]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=0.00933]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.00933]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.00933]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.00933]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.00933]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.00933]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.00933]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.00933]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.00933]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.00933]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.00933]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=0.00933]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.00933]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.00933]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.00933]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.00933]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.00933]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.00933]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.00933]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=0.00933]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.00933]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=0.00933]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0346, valid_loss=0.00933]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.00933]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.00933]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=0.00933]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.00933]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.00933]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.00933]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.00933]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=0.00933]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.00933]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.00933]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.00933]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.00933]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.00933]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.00933]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.00933]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=0.00933]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.00933]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.00933]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.00933]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.00933]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.00933]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.00933]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.00933]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=0.00933]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.00933]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=0.00933]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=0.00933]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=0.00933]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=0.00933]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=0.00933]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.00933]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.00933]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.00933]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.00933]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.00933]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=0.00933]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0292, valid_loss=0.00933]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 150.29it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=0.00836]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=0.00836]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.00836]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=0.00836]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=0.00836]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.00836]\n",
            "Epoch 205: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.00836]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.00836]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=0.00836]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.00836]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.00836]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.00836]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=0.00836]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.00836]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.00836]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=0.00836]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=0.00836]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.00836]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=0.00836]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.00836]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.00836]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.00836]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.00836]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=0.00836]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.00836]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.00836]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.00836]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.00836]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.00836]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.00836]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.00836]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=0.00836]        \n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=0.00836]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.00836]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=0.00836]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.00836]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00836]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.00836]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.00836]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.00836]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.00836]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.00836]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=0.00836]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.00836]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.00836]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=0.00836]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.00836]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=0.00836]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.00836]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.00836]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.00836]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=0.00836]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.00836]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.00836]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.00836]\n",
            "Epoch 252: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0263, valid_loss=0.00836]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.00836]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.00836]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=0.00836]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=0.00836]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.00836]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=0.00836]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.00836]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.00836]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.00836]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.00836]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.00836]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.00836]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.00836]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.00836]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.00836]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.00836]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.00836]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.00836]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.00836]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.00836]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00836]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.00836]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.00836]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.00836]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.00836]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=0.00836]\n",
            "Epoch 278: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=0.00836]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.00836]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.00836]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.00836]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.00836]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.00836]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.00836]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.00836]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.00836]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.00836]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.00836]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246, valid_loss=0.00836]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.00836]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=0.00836]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.00836]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=0.00836]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=0.00836]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=0.00836]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=0.00836]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=0.00836]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.00836]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=0.00836]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.76it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.022, valid_loss=0.00836]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.38it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.00696]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=0.00696]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.00696]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.00696]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=0.00696]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.00696]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=0.00696]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.00696]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=0.00696]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0219, train_loss_epoch=0.0219, valid_loss=0.00696]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.00696]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=0.00696]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.00696]\n",
            "Epoch 312: 100%|██████████| 1/1 [00:00<00:00,  6.97it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.00696]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=0.00696]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.00696]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=0.00696]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00696]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=0.00696]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.00696]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204, valid_loss=0.00696]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212, valid_loss=0.00696]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=0.00696]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=0.00696]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=0.00696]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=0.00696]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0236, train_loss_epoch=0.0236, valid_loss=0.00696]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=0.00696]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=0.00696]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.00696]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  5.79it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=0.00696]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=0.00696]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0219, train_loss_epoch=0.0219, valid_loss=0.00696]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.00696]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211, valid_loss=0.00696]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=0.00696]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.00696]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=0.00696]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=0.00696]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=0.00696]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=0.00696]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=0.00696]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.00696]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=0.00696]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.00696]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=0.00696]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=0.00696]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0205, train_loss_epoch=0.0205, valid_loss=0.00696]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.00696]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.00696]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212, valid_loss=0.00696]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204, valid_loss=0.00696]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00696]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00696]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0196, train_loss_epoch=0.0196, valid_loss=0.00696]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192, valid_loss=0.00696]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=0.00696]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=0.00696]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211, valid_loss=0.00696]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.00696]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.00696]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203, valid_loss=0.00696]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=0.00696]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=0.00696]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=0.00696]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204, valid_loss=0.00696]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00696]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203, valid_loss=0.00696]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00696]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0193, train_loss_epoch=0.0193, valid_loss=0.00696]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203, valid_loss=0.00696]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.00696]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00696]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.00696]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00696]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192, valid_loss=0.00696]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0193, train_loss_epoch=0.0193, valid_loss=0.00696]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00696]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.00696]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.00696]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018, valid_loss=0.00696]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.00696]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.00696]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214, valid_loss=0.00696]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.00696]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.00696]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0212, train_loss_epoch=0.0212, valid_loss=0.00696]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=0.00696]\n",
            "Epoch 385: 100%|██████████| 1/1 [00:00<00:00,  6.89it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.00696]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.00696]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=0.00696]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=0.00696]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.00696]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.00696]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.00696]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=0.00696]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=0.00696]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=0.00696]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=0.00696]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0219, train_loss_epoch=0.0219, valid_loss=0.00696]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=0.00696]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.00696]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.00696]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.86it/s, v_num=0, train_loss_step=0.0199, train_loss_epoch=0.0198, valid_loss=0.00696]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.90it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0199, train_loss_epoch=0.0199, valid_loss=0.00775]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211, valid_loss=0.00775]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=0.00775]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=0.00775]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.00775]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00775]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=0.00775]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.00775]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.00775]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0199, train_loss_epoch=0.0199, valid_loss=0.00775]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0193, train_loss_epoch=0.0193, valid_loss=0.00775]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.00775]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.00775]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.00775]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.00775]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=0.00775]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=0.00775]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=0.00775]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00775]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=0.00775]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=0.00775]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.00775]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.00775]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.00775]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00775]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.00775]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.00775]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=0.00775]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00775]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.00775]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.00775]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.00775]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=0.00775]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0174, train_loss_epoch=0.0174, valid_loss=0.00775]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.00775]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.00775]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.00775]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=0.00775]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.00775]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.00775]\n",
            "Epoch 439: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.00775]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.00775]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.00775]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.00775]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.00775]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00775]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.00775]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.00775]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.00775]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.00775]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00775]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0171, train_loss_epoch=0.0171, valid_loss=0.00775]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.00775]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.00775]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.00775]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00775]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00775]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=0.00775]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.00775]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.00775]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00775]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00775]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.00775]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.00775]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.00775]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.00775]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.00775]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.00775]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.00775]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.00775]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163, valid_loss=0.00775]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.00775]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.00775]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.00775]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00775]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.00775]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.00775]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.00775]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.00775]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00775]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.00775]\n",
            "Epoch 479: 100%|██████████| 1/1 [00:00<00:00,  6.88it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.00775]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.00775]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00775]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.00775]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.00775]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00775]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00775]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00775]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00775]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00775]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.00775]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00775]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00775]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00775]\n",
            "Epoch 492: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0144, valid_loss=0.00775]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00775]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00775]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00775]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.00775]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00775]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00775]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.00775]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0148, valid_loss=0.00775]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 156.07it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00415]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00415]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.00415]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.00415]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  6.60it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.00415]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00415]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00415]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  6.79it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.00415]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.00415]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00415]\n",
            "Epoch 507: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0142, valid_loss=0.00415]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.00415]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00415]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00415]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.00415]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.00415]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00415]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00415]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00415]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00415]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.00415]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00415]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.00415]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00415]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00415]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.00415]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00415]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00415]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00415]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00415]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00415]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00415]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.00415]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00415]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00415]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00415]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00415]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.00415]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.00415]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.00415]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00415]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.00415]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.00415]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.00415]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.00415]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.00415]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.00415]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00415]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.00415]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00415]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0165, train_loss_epoch=0.0165, valid_loss=0.00415]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=0.00415]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.00415]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00415]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.00415]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00415]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00415]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00415]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=0.00415]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00415]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00415]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00415]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00415]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00415]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00415]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00415]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00415]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00415]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00415]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00415]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00415]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00415]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00415]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00415]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00415]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00415]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00415]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00415]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00415]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00415]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00415]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00415]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00415]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00415]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00415]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00415]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00415]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00415]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00415]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00415]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00415]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00415]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00415]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00415]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00415]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00415]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00415]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00415]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00415]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.00415]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00415]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00415]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00415]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0141, valid_loss=0.00415]\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.44it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00454]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00454]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00454]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00454]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00454]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00454]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00454]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00454]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00454]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00454]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.00454]\n",
            "Epoch 610: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0153, valid_loss=0.00454]\n",
            "Epoch 610: 100%|██████████| 1/1 [00:00<00:00,  4.19it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00454]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00454]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00454]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00454]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00454]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.00454]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00454]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00454]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00454]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00454]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00454]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00454]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00454]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00454]\n",
            "Epoch 623: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.013, valid_loss=0.00454]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00454]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00454]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00454]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00454]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00454]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00454]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00454]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00454]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00454]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00454]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00454]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00454]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00454]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00454]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.00454]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00454]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00454]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00454]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00454]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.00454]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00454]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00454]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00454]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00454]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00454]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00454]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00454]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00454]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00454]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00454]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00454]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00454]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00454]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00454]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00454]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00454]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00454]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00454]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00454]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00454]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00454]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00454]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00454]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00454]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00454]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00454]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00454]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00454]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00454]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00454]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00454]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00454]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00454]\n",
            "Epoch 676: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00454]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00454]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00454]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00454]\n",
            "Epoch 679: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00454]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00454]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00454]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00454]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00454]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00454]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00454]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00454]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00454]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00454]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00454]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00454]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00454]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00454]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00454]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00454]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00454]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00454]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00454]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00454]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00454]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0138, valid_loss=0.00454]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.69it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00447]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00447]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00447]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00447]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00447]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00447]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.00447]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00447]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.00447]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00447]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.00447]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00447]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00447]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00447]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00447]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00447]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.00447]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00447]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00447]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00447]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00447]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00447]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00447]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00447]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00447]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00447]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00447]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00447]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00447]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00447]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.00447]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00447]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00447]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00447]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00447]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00447]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00447]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00447]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00447]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00447]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00447]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00447]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00447]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00447]\n",
            "Epoch 745: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00447]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00447]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00447]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00447]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00447]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00447]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00447]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00447]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00447]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00447]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00447]\n",
            "Epoch 757: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00447]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00447]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00447]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00447]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00447]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00447]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00447]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00447]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00447]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00447]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00447]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00447]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00447]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00447]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00447]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00447]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00447]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00447]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00447]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00447]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00447]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00447]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00447]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.00447]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00447]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00447]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00447]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00447]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00447]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00447]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00447]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00447]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00447]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00447]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00447]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00447]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00447]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00447]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.00447]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00447]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00447]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  4.83it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0119, valid_loss=0.00447]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.26it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00446]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00446]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00446]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00446]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00446]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00446]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00446]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00446]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00446]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00446]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00446]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00446]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.00446]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00446]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00446]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00446]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00446]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00446]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00962, train_loss_epoch=0.00962, valid_loss=0.00446]\n",
            "Epoch 818: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446] \n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 819: 100%|██████████| 1/1 [00:00<00:00,  3.27it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00446]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00446]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00446]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00446]\n",
            "Epoch 823: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00446]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00446]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00446]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00446]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00446]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00446]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00446]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00446]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00446]\n",
            "Epoch 831: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0142, valid_loss=0.00446]\n",
            "Epoch 831: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00446]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00446]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00446]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00446]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00446]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00446]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00446]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00446]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00446]\n",
            "Epoch 840: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.0126, valid_loss=0.00446] \n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00446]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00446]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00446]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00446]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00446]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00446]\n",
            "Epoch 846: 100%|██████████| 1/1 [00:00<00:00,  5.25it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00446]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00446]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00446]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00446]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00446]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00446]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00446]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00446]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00446]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00446]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00446]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.00446]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00446]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00446]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00446]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00446]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00446]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00446]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00995, train_loss_epoch=0.00995, valid_loss=0.00446]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00446]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00446]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.00446]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00446]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00446]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00446]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00446]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00446]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00446]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00446]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.00446]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00446]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.00446]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00446]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.00446]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00446]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00446]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00446]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=0.00446]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00446]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.00446]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00446]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00446]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00446]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00446]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00991, train_loss_epoch=0.00991, valid_loss=0.00446]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.00446]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00446]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00446]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00446]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00446]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00446]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00446]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  5.46it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.011, valid_loss=0.00446]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 152.15it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.00997, valid_loss=0.00612]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00612]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00612]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.00612]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00612]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.00612]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00612]\n",
            "Epoch 906: 100%|██████████| 1/1 [00:00<00:00,  5.43it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00612]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00927, train_loss_epoch=0.00927, valid_loss=0.00612]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.00612]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00612]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00612]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.00612]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.00612]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.00612]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00612]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00612]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00612]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00992, train_loss_epoch=0.00992, valid_loss=0.00612]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00612]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00612]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00612]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00612]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00949, train_loss_epoch=0.00949, valid_loss=0.00612]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.00612]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00612]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00612]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00612]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00612]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00612]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00612]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00612]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00612]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00612]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00612]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00612]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00612]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=0.00612]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00884, train_loss_epoch=0.00884, valid_loss=0.00612]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.00612]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00932, train_loss_epoch=0.00932, valid_loss=0.00612]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.00612]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00992, train_loss_epoch=0.00992, valid_loss=0.00612]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00962, train_loss_epoch=0.00962, valid_loss=0.00612]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00612]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00612]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00938, train_loss_epoch=0.00938, valid_loss=0.00612]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00939, train_loss_epoch=0.00939, valid_loss=0.00612]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00612]\n",
            "Epoch 947: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00612] \n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00612]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00842, train_loss_epoch=0.00842, valid_loss=0.00612]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00946, train_loss_epoch=0.00946, valid_loss=0.00612]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0098, train_loss_epoch=0.0098, valid_loss=0.00612]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00919, train_loss_epoch=0.00919, valid_loss=0.00612]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00992, train_loss_epoch=0.00992, valid_loss=0.00612]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00948, train_loss_epoch=0.00948, valid_loss=0.00612]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00612]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00612]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00612]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=0.00612]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00994, train_loss_epoch=0.00994, valid_loss=0.00612]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00944, train_loss_epoch=0.00944, valid_loss=0.00612]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0097, valid_loss=0.00612]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00967, train_loss_epoch=0.00967, valid_loss=0.00612]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00914, train_loss_epoch=0.00914, valid_loss=0.00612]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00994, train_loss_epoch=0.00994, valid_loss=0.00612]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00827, train_loss_epoch=0.00827, valid_loss=0.00612]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00898, train_loss_epoch=0.00898, valid_loss=0.00612]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00877, train_loss_epoch=0.00877, valid_loss=0.00612]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00949, train_loss_epoch=0.00949, valid_loss=0.00612]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0087, train_loss_epoch=0.0087, valid_loss=0.00612]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00974, train_loss_epoch=0.00974, valid_loss=0.00612]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=0.00612]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0099, train_loss_epoch=0.0099, valid_loss=0.00612]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0095, train_loss_epoch=0.0095, valid_loss=0.00612]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00863, train_loss_epoch=0.00863, valid_loss=0.00612]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00916, train_loss_epoch=0.00916, valid_loss=0.00612]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.009, train_loss_epoch=0.009, valid_loss=0.00612]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00867, train_loss_epoch=0.00867, valid_loss=0.00612]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00912, valid_loss=0.00612]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00896, train_loss_epoch=0.00896, valid_loss=0.00612]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00935, train_loss_epoch=0.00935, valid_loss=0.00612]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0095, train_loss_epoch=0.0095, valid_loss=0.00612]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00965, train_loss_epoch=0.00965, valid_loss=0.00612]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00801, train_loss_epoch=0.00801, valid_loss=0.00612]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00893, train_loss_epoch=0.00893, valid_loss=0.00612]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00923, train_loss_epoch=0.00923, valid_loss=0.00612]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00911, train_loss_epoch=0.00911, valid_loss=0.00612]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00955, train_loss_epoch=0.00955, valid_loss=0.00612]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0087, train_loss_epoch=0.0087, valid_loss=0.00612]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=0.00612]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0092, train_loss_epoch=0.0092, valid_loss=0.00612]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00852, train_loss_epoch=0.00852, valid_loss=0.00612]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00956, train_loss_epoch=0.00956, valid_loss=0.00612]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082, valid_loss=0.00612]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00881, train_loss_epoch=0.00881, valid_loss=0.00612]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00922, train_loss_epoch=0.00922, valid_loss=0.00612]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00954, train_loss_epoch=0.00954, valid_loss=0.00612]\n",
            "Epoch 996: 100%|██████████| 1/1 [00:00<00:00,  5.09it/s, v_num=0, train_loss_step=0.00898, train_loss_epoch=0.00954, valid_loss=0.00612]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00898, train_loss_epoch=0.00898, valid_loss=0.00612]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00947, train_loss_epoch=0.00947, valid_loss=0.00612]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.008, train_loss_epoch=0.008, valid_loss=0.00612]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.008, valid_loss=0.00612]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 155.41it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.00871, valid_loss=0.00359]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00857, train_loss_epoch=0.00857, valid_loss=0.00359]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=0.00359]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00886, train_loss_epoch=0.00886, valid_loss=0.00359]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=0.00359]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00838, train_loss_epoch=0.00838, valid_loss=0.00359]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00969, train_loss_epoch=0.00969, valid_loss=0.00359]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00889, train_loss_epoch=0.00889, valid_loss=0.00359]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00931, train_loss_epoch=0.00931, valid_loss=0.00359]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00841, train_loss_epoch=0.00841, valid_loss=0.00359]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00965, train_loss_epoch=0.00965, valid_loss=0.00359]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00807, train_loss_epoch=0.00807, valid_loss=0.00359]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00359]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00919, train_loss_epoch=0.00919, valid_loss=0.00359]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0095, train_loss_epoch=0.0095, valid_loss=0.00359]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00844, train_loss_epoch=0.00844, valid_loss=0.00359]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00902, train_loss_epoch=0.00902, valid_loss=0.00359]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00899, train_loss_epoch=0.00899, valid_loss=0.00359]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00927, train_loss_epoch=0.00927, valid_loss=0.00359]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00359]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00872, train_loss_epoch=0.00872, valid_loss=0.00359]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=0.00359]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00891, train_loss_epoch=0.00891, valid_loss=0.00359]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00884, train_loss_epoch=0.00884, valid_loss=0.00359]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=0.00359]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848, valid_loss=0.00359]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00825, train_loss_epoch=0.00825, valid_loss=0.00359]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00779, train_loss_epoch=0.00779, valid_loss=0.00359]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00825, train_loss_epoch=0.00825, valid_loss=0.00359]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00839, train_loss_epoch=0.00839, valid_loss=0.00359]\n",
            "Epoch 1029: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00359]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00359]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00815, train_loss_epoch=0.00815, valid_loss=0.00359]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.00871, valid_loss=0.00359]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=0.00359]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=0.00359]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00875, train_loss_epoch=0.00875, valid_loss=0.00359]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=0.00359]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00881, train_loss_epoch=0.00881, valid_loss=0.00359]\n",
            "Epoch 1037: 100%|██████████| 1/1 [00:00<00:00,  4.90it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00359]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00359]        \n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00359]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00809, train_loss_epoch=0.00809, valid_loss=0.00359]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00836, train_loss_epoch=0.00836, valid_loss=0.00359]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00741, train_loss_epoch=0.00741, valid_loss=0.00359]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00752, train_loss_epoch=0.00752, valid_loss=0.00359]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00827, train_loss_epoch=0.00827, valid_loss=0.00359]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00797, train_loss_epoch=0.00797, valid_loss=0.00359]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00896, train_loss_epoch=0.00896, valid_loss=0.00359]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00828, train_loss_epoch=0.00828, valid_loss=0.00359]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00894, train_loss_epoch=0.00894, valid_loss=0.00359]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848, valid_loss=0.00359]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.009, train_loss_epoch=0.009, valid_loss=0.00359]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00836, train_loss_epoch=0.00836, valid_loss=0.00359]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0096, train_loss_epoch=0.0096, valid_loss=0.00359]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00814, train_loss_epoch=0.00814, valid_loss=0.00359]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00821, train_loss_epoch=0.00821, valid_loss=0.00359]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0086, train_loss_epoch=0.0086, valid_loss=0.00359]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00866, train_loss_epoch=0.00866, valid_loss=0.00359]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00891, train_loss_epoch=0.00891, valid_loss=0.00359]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00897, train_loss_epoch=0.00897, valid_loss=0.00359]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00861, train_loss_epoch=0.00861, valid_loss=0.00359]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00872, train_loss_epoch=0.00872, valid_loss=0.00359]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00853, train_loss_epoch=0.00853, valid_loss=0.00359]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00868, train_loss_epoch=0.00868, valid_loss=0.00359]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00907, train_loss_epoch=0.00907, valid_loss=0.00359]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00875, train_loss_epoch=0.00875, valid_loss=0.00359]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00841, train_loss_epoch=0.00841, valid_loss=0.00359]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00879, train_loss_epoch=0.00879, valid_loss=0.00359]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00973, train_loss_epoch=0.00973, valid_loss=0.00359]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00926, train_loss_epoch=0.00926, valid_loss=0.00359]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00897, train_loss_epoch=0.00897, valid_loss=0.00359]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00858, train_loss_epoch=0.00858, valid_loss=0.00359]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00995, train_loss_epoch=0.00995, valid_loss=0.00359]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00359]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.00359]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.00359]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00854, train_loss_epoch=0.00854, valid_loss=0.00359]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00945, train_loss_epoch=0.00945, valid_loss=0.00359]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00852, train_loss_epoch=0.00852, valid_loss=0.00359]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783, valid_loss=0.00359]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00802, train_loss_epoch=0.00802, valid_loss=0.00359]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00919, train_loss_epoch=0.00919, valid_loss=0.00359]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00896, train_loss_epoch=0.00896, valid_loss=0.00359]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00359]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=0.00359]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00956, train_loss_epoch=0.00956, valid_loss=0.00359]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00763, train_loss_epoch=0.00763, valid_loss=0.00359]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00852, train_loss_epoch=0.00852, valid_loss=0.00359]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783, valid_loss=0.00359]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00938, train_loss_epoch=0.00938, valid_loss=0.00359]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00359]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=0.00359]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00833, train_loss_epoch=0.00833, valid_loss=0.00359]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=0.00359]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00919, train_loss_epoch=0.00919, valid_loss=0.00359]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00807, train_loss_epoch=0.00807, valid_loss=0.00359]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00359]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00836, train_loss_epoch=0.00836, valid_loss=0.00359]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00804, train_loss_epoch=0.00804, valid_loss=0.00359]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082, valid_loss=0.00359]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00844, train_loss_epoch=0.00844, valid_loss=0.00359]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00805, train_loss_epoch=0.00805, valid_loss=0.00359]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=0, train_loss_step=0.0086, train_loss_epoch=0.00805, valid_loss=0.00359] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.38it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0086, train_loss_epoch=0.0086, valid_loss=0.00359]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00906, train_loss_epoch=0.00906, valid_loss=0.00359]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00916, train_loss_epoch=0.00916, valid_loss=0.00359]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00885, train_loss_epoch=0.00885, valid_loss=0.00359]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00842, train_loss_epoch=0.00842, valid_loss=0.00359]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00795, train_loss_epoch=0.00795, valid_loss=0.00359]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.00359]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00899, train_loss_epoch=0.00899, valid_loss=0.00359]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=0.00359]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=0.00359]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00823, train_loss_epoch=0.00823, valid_loss=0.00359]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00925, train_loss_epoch=0.00925, valid_loss=0.00359]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00796, train_loss_epoch=0.00796, valid_loss=0.00359]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00878, train_loss_epoch=0.00878, valid_loss=0.00359]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00791, train_loss_epoch=0.00791, valid_loss=0.00359]\n",
            "Epoch 1114: 100%|██████████| 1/1 [00:00<00:00,  5.48it/s, v_num=0, train_loss_step=0.00795, train_loss_epoch=0.00795, valid_loss=0.00359]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00795, train_loss_epoch=0.00795, valid_loss=0.00359]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00821, train_loss_epoch=0.00821, valid_loss=0.00359]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00839, train_loss_epoch=0.00839, valid_loss=0.00359]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=0.00359]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00897, train_loss_epoch=0.00897, valid_loss=0.00359]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0087, train_loss_epoch=0.0087, valid_loss=0.00359]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00851, train_loss_epoch=0.00851, valid_loss=0.00359]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00904, train_loss_epoch=0.00904, valid_loss=0.00359]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00907, train_loss_epoch=0.00907, valid_loss=0.00359]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=0.00359]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0085, train_loss_epoch=0.0085, valid_loss=0.00359]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00855, train_loss_epoch=0.00855, valid_loss=0.00359]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.00359]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=0.00359]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00828, train_loss_epoch=0.00828, valid_loss=0.00359]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00831, train_loss_epoch=0.00831, valid_loss=0.00359]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00806, train_loss_epoch=0.00806, valid_loss=0.00359]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00966, train_loss_epoch=0.00966, valid_loss=0.00359]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0093, train_loss_epoch=0.0093, valid_loss=0.00359]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00886, train_loss_epoch=0.00886, valid_loss=0.00359]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.00359]\n",
            "Epoch 1135: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.00882, train_loss_epoch=0.00822, valid_loss=0.00359]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00882, train_loss_epoch=0.00882, valid_loss=0.00359]        \n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00882, train_loss_epoch=0.00882, valid_loss=0.00359]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848, valid_loss=0.00359]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00884, train_loss_epoch=0.00884, valid_loss=0.00359]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00814, train_loss_epoch=0.00814, valid_loss=0.00359]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00838, train_loss_epoch=0.00838, valid_loss=0.00359]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0094, train_loss_epoch=0.0094, valid_loss=0.00359]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00825, train_loss_epoch=0.00825, valid_loss=0.00359]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00782, train_loss_epoch=0.00782, valid_loss=0.00359]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00823, train_loss_epoch=0.00823, valid_loss=0.00359]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00808, train_loss_epoch=0.00808, valid_loss=0.00359]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=0.00359]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00885, train_loss_epoch=0.00885, valid_loss=0.00359]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00855, train_loss_epoch=0.00855, valid_loss=0.00359]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=0.00359]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00802, train_loss_epoch=0.00802, valid_loss=0.00359]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00798, train_loss_epoch=0.00798, valid_loss=0.00359]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848, valid_loss=0.00359]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.00871, valid_loss=0.00359]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00818, train_loss_epoch=0.00818, valid_loss=0.00359]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00929, train_loss_epoch=0.00929, valid_loss=0.00359]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00816, train_loss_epoch=0.00816, valid_loss=0.00359]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00856, train_loss_epoch=0.00856, valid_loss=0.00359]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0095, train_loss_epoch=0.0095, valid_loss=0.00359]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00814, train_loss_epoch=0.00814, valid_loss=0.00359]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00819, train_loss_epoch=0.00819, valid_loss=0.00359]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00812, train_loss_epoch=0.00812, valid_loss=0.00359]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00861, train_loss_epoch=0.00861, valid_loss=0.00359]\n",
            "Epoch 1162: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=0, train_loss_step=0.00835, train_loss_epoch=0.00861, valid_loss=0.00359]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00835, train_loss_epoch=0.00835, valid_loss=0.00359]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00784, train_loss_epoch=0.00784, valid_loss=0.00359]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00806, train_loss_epoch=0.00806, valid_loss=0.00359]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=0.00359]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00743, train_loss_epoch=0.00743, valid_loss=0.00359]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00821, train_loss_epoch=0.00821, valid_loss=0.00359]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00772, train_loss_epoch=0.00772, valid_loss=0.00359]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=0.00359]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00825, train_loss_epoch=0.00825, valid_loss=0.00359]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00936, train_loss_epoch=0.00936, valid_loss=0.00359]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.00359]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00809, train_loss_epoch=0.00809, valid_loss=0.00359]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00731, train_loss_epoch=0.00731, valid_loss=0.00359]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00884, train_loss_epoch=0.00884, valid_loss=0.00359]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00761, train_loss_epoch=0.00761, valid_loss=0.00359]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0083, train_loss_epoch=0.0083, valid_loss=0.00359]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.00359]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00919, train_loss_epoch=0.00919, valid_loss=0.00359]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00869, train_loss_epoch=0.00869, valid_loss=0.00359]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00797, train_loss_epoch=0.00797, valid_loss=0.00359]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00798, train_loss_epoch=0.00798, valid_loss=0.00359]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00857, train_loss_epoch=0.00857, valid_loss=0.00359]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00879, train_loss_epoch=0.00879, valid_loss=0.00359]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00841, train_loss_epoch=0.00841, valid_loss=0.00359]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00857, train_loss_epoch=0.00857, valid_loss=0.00359]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00762, train_loss_epoch=0.00762, valid_loss=0.00359]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00857, train_loss_epoch=0.00857, valid_loss=0.00359]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=0.00359]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00858, train_loss_epoch=0.00858, valid_loss=0.00359]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00737, train_loss_epoch=0.00737, valid_loss=0.00359]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00824, train_loss_epoch=0.00824, valid_loss=0.00359]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00826, train_loss_epoch=0.00826, valid_loss=0.00359]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00803, train_loss_epoch=0.00803, valid_loss=0.00359]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00789, train_loss_epoch=0.00789, valid_loss=0.00359]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00765, train_loss_epoch=0.00765, valid_loss=0.00359]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848, valid_loss=0.00359]\n",
            "Epoch 1198: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.00792, train_loss_epoch=0.00792, valid_loss=0.00359]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00792, train_loss_epoch=0.00792, valid_loss=0.00359]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.00898, train_loss_epoch=0.00792, valid_loss=0.00359]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.27it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \n",
            "Epoch 1200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00898, train_loss_epoch=0.00898, valid_loss=0.00349]\n",
            "Epoch 1201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00796, train_loss_epoch=0.00796, valid_loss=0.00349]\n",
            "Epoch 1202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00836, train_loss_epoch=0.00836, valid_loss=0.00349]\n",
            "Epoch 1203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.00871, valid_loss=0.00349]\n",
            "Epoch 1204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00796, train_loss_epoch=0.00796, valid_loss=0.00349]\n",
            "Epoch 1205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00893, train_loss_epoch=0.00893, valid_loss=0.00349]\n",
            "Epoch 1206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756, valid_loss=0.00349]\n",
            "Epoch 1207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00827, train_loss_epoch=0.00827, valid_loss=0.00349]\n",
            "Epoch 1208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=0.00349]\n",
            "Epoch 1209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00855, train_loss_epoch=0.00855, valid_loss=0.00349]\n",
            "Epoch 1210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00744, train_loss_epoch=0.00744, valid_loss=0.00349]\n",
            "Epoch 1211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00758, train_loss_epoch=0.00758, valid_loss=0.00349]\n",
            "Epoch 1212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00802, train_loss_epoch=0.00802, valid_loss=0.00349]\n",
            "Epoch 1213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00763, train_loss_epoch=0.00763, valid_loss=0.00349]\n",
            "Epoch 1214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00825, train_loss_epoch=0.00825, valid_loss=0.00349]\n",
            "Epoch 1215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00854, train_loss_epoch=0.00854, valid_loss=0.00349]\n",
            "Epoch 1216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756, valid_loss=0.00349]\n",
            "Epoch 1217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.00349]\n",
            "Epoch 1218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00805, train_loss_epoch=0.00805, valid_loss=0.00349]\n",
            "Epoch 1219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00766, train_loss_epoch=0.00766, valid_loss=0.00349]\n",
            "Epoch 1220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00766, train_loss_epoch=0.00766, valid_loss=0.00349]\n",
            "Epoch 1221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00745, train_loss_epoch=0.00745, valid_loss=0.00349]\n",
            "Epoch 1222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00849, train_loss_epoch=0.00849, valid_loss=0.00349]\n",
            "Epoch 1223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00829, train_loss_epoch=0.00829, valid_loss=0.00349]\n",
            "Epoch 1224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=0.00349]\n",
            "Epoch 1225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=0.00349]\n",
            "Epoch 1226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00851, train_loss_epoch=0.00851, valid_loss=0.00349]\n",
            "Epoch 1227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00892, train_loss_epoch=0.00892, valid_loss=0.00349]\n",
            "Epoch 1228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00829, train_loss_epoch=0.00829, valid_loss=0.00349]\n",
            "Epoch 1229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=0.00349]\n",
            "Epoch 1230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00789, train_loss_epoch=0.00789, valid_loss=0.00349]\n",
            "Epoch 1231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00737, train_loss_epoch=0.00737, valid_loss=0.00349]\n",
            "Epoch 1232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00789, train_loss_epoch=0.00789, valid_loss=0.00349]\n",
            "Epoch 1233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00795, train_loss_epoch=0.00795, valid_loss=0.00349]\n",
            "Epoch 1233: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=0, train_loss_step=0.00795, train_loss_epoch=0.00795, valid_loss=0.00349]\n",
            "Epoch 1234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00801, train_loss_epoch=0.00801, valid_loss=0.00349]\n",
            "Epoch 1235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00758, train_loss_epoch=0.00758, valid_loss=0.00349]\n",
            "Epoch 1236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00763, train_loss_epoch=0.00763, valid_loss=0.00349]\n",
            "Epoch 1237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00778, train_loss_epoch=0.00778, valid_loss=0.00349]\n",
            "Epoch 1238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=0.00349]\n",
            "Epoch 1239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00896, train_loss_epoch=0.00896, valid_loss=0.00349]\n",
            "Epoch 1240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.00871, valid_loss=0.00349]\n",
            "Epoch 1241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00808, train_loss_epoch=0.00808, valid_loss=0.00349]\n",
            "Epoch 1242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=0.00349]\n",
            "Epoch 1243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00794, train_loss_epoch=0.00794, valid_loss=0.00349]\n",
            "Epoch 1244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00791, train_loss_epoch=0.00791, valid_loss=0.00349]\n",
            "Epoch 1245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00782, train_loss_epoch=0.00782, valid_loss=0.00349]\n",
            "Epoch 1246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00819, train_loss_epoch=0.00819, valid_loss=0.00349]\n",
            "Epoch 1247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00901, train_loss_epoch=0.00901, valid_loss=0.00349]\n",
            "Epoch 1248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=0.00349]\n",
            "Epoch 1249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0079, train_loss_epoch=0.0079, valid_loss=0.00349]\n",
            "Epoch 1250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00875, train_loss_epoch=0.00875, valid_loss=0.00349]\n",
            "Epoch 1251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.009, train_loss_epoch=0.009, valid_loss=0.00349]\n",
            "Epoch 1252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00777, train_loss_epoch=0.00777, valid_loss=0.00349]\n",
            "Epoch 1253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00881, train_loss_epoch=0.00881, valid_loss=0.00349]\n",
            "Epoch 1254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00855, train_loss_epoch=0.00855, valid_loss=0.00349]\n",
            "Epoch 1255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=0.00349]\n",
            "Epoch 1256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00803, train_loss_epoch=0.00803, valid_loss=0.00349]\n",
            "Epoch 1257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00864, train_loss_epoch=0.00864, valid_loss=0.00349]\n",
            "Epoch 1258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.00349]\n",
            "Epoch 1259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=0.00349]\n",
            "Epoch 1260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00834, train_loss_epoch=0.00834, valid_loss=0.00349]\n",
            "Epoch 1261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=0.00349]\n",
            "Epoch 1262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00839, train_loss_epoch=0.00839, valid_loss=0.00349]\n",
            "Epoch 1263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00945, train_loss_epoch=0.00945, valid_loss=0.00349]\n",
            "Epoch 1264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00808, train_loss_epoch=0.00808, valid_loss=0.00349]\n",
            "Epoch 1265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00936, train_loss_epoch=0.00936, valid_loss=0.00349]\n",
            "Epoch 1266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00894, train_loss_epoch=0.00894, valid_loss=0.00349]\n",
            "Epoch 1267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0092, train_loss_epoch=0.0092, valid_loss=0.00349]\n",
            "Epoch 1268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00789, train_loss_epoch=0.00789, valid_loss=0.00349]\n",
            "Epoch 1269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00854, train_loss_epoch=0.00854, valid_loss=0.00349]\n",
            "Epoch 1270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00883, train_loss_epoch=0.00883, valid_loss=0.00349]\n",
            "Epoch 1271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00802, train_loss_epoch=0.00802, valid_loss=0.00349]\n",
            "Epoch 1272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00795, train_loss_epoch=0.00795, valid_loss=0.00349]\n",
            "Epoch 1273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00927, train_loss_epoch=0.00927, valid_loss=0.00349]\n",
            "Epoch 1274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00851, train_loss_epoch=0.00851, valid_loss=0.00349]\n",
            "Epoch 1275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00739, train_loss_epoch=0.00739, valid_loss=0.00349]\n",
            "Epoch 1276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00851, train_loss_epoch=0.00851, valid_loss=0.00349]\n",
            "Epoch 1277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00833, train_loss_epoch=0.00833, valid_loss=0.00349]\n",
            "Epoch 1278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00833, train_loss_epoch=0.00833, valid_loss=0.00349]\n",
            "Epoch 1279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00878, train_loss_epoch=0.00878, valid_loss=0.00349]\n",
            "Epoch 1280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00853, train_loss_epoch=0.00853, valid_loss=0.00349]\n",
            "Epoch 1281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00892, train_loss_epoch=0.00892, valid_loss=0.00349]\n",
            "Epoch 1282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00896, train_loss_epoch=0.00896, valid_loss=0.00349]\n",
            "Epoch 1283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00769, train_loss_epoch=0.00769, valid_loss=0.00349]\n",
            "Epoch 1284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00806, train_loss_epoch=0.00806, valid_loss=0.00349]\n",
            "Epoch 1285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00904, train_loss_epoch=0.00904, valid_loss=0.00349]\n",
            "Epoch 1286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848, valid_loss=0.00349]\n",
            "Epoch 1287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00779, train_loss_epoch=0.00779, valid_loss=0.00349]\n",
            "Epoch 1288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00804, train_loss_epoch=0.00804, valid_loss=0.00349]\n",
            "Epoch 1289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=0.00349]\n",
            "Epoch 1290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0085, train_loss_epoch=0.0085, valid_loss=0.00349]\n",
            "Epoch 1290: 100%|██████████| 1/1 [00:00<00:00,  5.19it/s, v_num=0, train_loss_step=0.0094, train_loss_epoch=0.0094, valid_loss=0.00349]\n",
            "Epoch 1291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0094, train_loss_epoch=0.0094, valid_loss=0.00349]\n",
            "Epoch 1292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082, valid_loss=0.00349]\n",
            "Epoch 1293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.00349]\n",
            "Epoch 1294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0083, train_loss_epoch=0.0083, valid_loss=0.00349]\n",
            "Epoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00895, train_loss_epoch=0.00895, valid_loss=0.00349]\n",
            "Epoch 1296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=0.00349]\n",
            "Epoch 1297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00885, train_loss_epoch=0.00885, valid_loss=0.00349]\n",
            "Epoch 1298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00836, train_loss_epoch=0.00836, valid_loss=0.00349]\n",
            "Epoch 1299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0086, train_loss_epoch=0.0086, valid_loss=0.00349]\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=0, train_loss_step=0.00823, train_loss_epoch=0.0086, valid_loss=0.00349]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 121.23it/s]\u001b[A\n",
            "Epoch 1300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00823, train_loss_epoch=0.00823, valid_loss=0.00391]\n",
            "Epoch 1301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=0.00391]\n",
            "Epoch 1302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=0.00391]\n",
            "Epoch 1303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00826, train_loss_epoch=0.00826, valid_loss=0.00391]\n",
            "Epoch 1304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00767, train_loss_epoch=0.00767, valid_loss=0.00391]\n",
            "Epoch 1305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=0.00391]\n",
            "Epoch 1306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00804, train_loss_epoch=0.00804, valid_loss=0.00391]\n",
            "Epoch 1307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00869, train_loss_epoch=0.00869, valid_loss=0.00391]\n",
            "Epoch 1308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00815, train_loss_epoch=0.00815, valid_loss=0.00391]\n",
            "Epoch 1309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0077, train_loss_epoch=0.0077, valid_loss=0.00391]\n",
            "Epoch 1310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=0.00391]\n",
            "Epoch 1311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00806, train_loss_epoch=0.00806, valid_loss=0.00391]\n",
            "Epoch 1312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00946, train_loss_epoch=0.00946, valid_loss=0.00391]\n",
            "Epoch 1313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0083, train_loss_epoch=0.0083, valid_loss=0.00391]\n",
            "Epoch 1314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00876, train_loss_epoch=0.00876, valid_loss=0.00391]\n",
            "Epoch 1315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00889, train_loss_epoch=0.00889, valid_loss=0.00391]\n",
            "Epoch 1316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00734, train_loss_epoch=0.00734, valid_loss=0.00391]\n",
            "Epoch 1317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082, valid_loss=0.00391]\n",
            "Epoch 1318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00803, train_loss_epoch=0.00803, valid_loss=0.00391]\n",
            "Epoch 1319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0093, train_loss_epoch=0.0093, valid_loss=0.00391]\n",
            "Epoch 1320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00706, train_loss_epoch=0.00706, valid_loss=0.00391]\n",
            "Epoch 1321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00815, train_loss_epoch=0.00815, valid_loss=0.00391]\n",
            "Epoch 1322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00786, train_loss_epoch=0.00786, valid_loss=0.00391]\n",
            "Epoch 1323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=0.00391]\n",
            "Epoch 1324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00764, train_loss_epoch=0.00764, valid_loss=0.00391]\n",
            "Epoch 1325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00743, train_loss_epoch=0.00743, valid_loss=0.00391]\n",
            "Epoch 1326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=0.00391]\n",
            "Epoch 1327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00778, train_loss_epoch=0.00778, valid_loss=0.00391]\n",
            "Epoch 1328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00859, train_loss_epoch=0.00859, valid_loss=0.00391]\n",
            "Epoch 1329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00762, train_loss_epoch=0.00762, valid_loss=0.00391]\n",
            "Epoch 1330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00858, train_loss_epoch=0.00858, valid_loss=0.00391]\n",
            "Epoch 1331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00799, train_loss_epoch=0.00799, valid_loss=0.00391]\n",
            "Epoch 1332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00787, train_loss_epoch=0.00787, valid_loss=0.00391]\n",
            "Epoch 1333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00837, train_loss_epoch=0.00837, valid_loss=0.00391]\n",
            "Epoch 1334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0072, train_loss_epoch=0.0072, valid_loss=0.00391]\n",
            "Epoch 1335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00806, train_loss_epoch=0.00806, valid_loss=0.00391]\n",
            "Epoch 1336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00769, train_loss_epoch=0.00769, valid_loss=0.00391]\n",
            "Epoch 1337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00741, train_loss_epoch=0.00741, valid_loss=0.00391]\n",
            "Epoch 1338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00721, train_loss_epoch=0.00721, valid_loss=0.00391]\n",
            "Epoch 1339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00747, train_loss_epoch=0.00747, valid_loss=0.00391]\n",
            "Epoch 1340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00777, train_loss_epoch=0.00777, valid_loss=0.00391]\n",
            "Epoch 1341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00824, train_loss_epoch=0.00824, valid_loss=0.00391]\n",
            "Epoch 1342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00777, train_loss_epoch=0.00777, valid_loss=0.00391]\n",
            "Epoch 1343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00706, train_loss_epoch=0.00706, valid_loss=0.00391]\n",
            "Epoch 1344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00758, train_loss_epoch=0.00758, valid_loss=0.00391]\n",
            "Epoch 1345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.00391]\n",
            "Epoch 1346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.008, train_loss_epoch=0.008, valid_loss=0.00391]\n",
            "Epoch 1347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=0.00391]\n",
            "Epoch 1348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0073, train_loss_epoch=0.0073, valid_loss=0.00391]\n",
            "Epoch 1349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00753, train_loss_epoch=0.00753, valid_loss=0.00391]\n",
            "Epoch 1350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00702, train_loss_epoch=0.00702, valid_loss=0.00391]\n",
            "Epoch 1351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00778, train_loss_epoch=0.00778, valid_loss=0.00391]\n",
            "Epoch 1352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00708, train_loss_epoch=0.00708, valid_loss=0.00391]\n",
            "Epoch 1353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00717, train_loss_epoch=0.00717, valid_loss=0.00391]\n",
            "Epoch 1354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00735, train_loss_epoch=0.00735, valid_loss=0.00391]\n",
            "Epoch 1355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00829, train_loss_epoch=0.00829, valid_loss=0.00391]\n",
            "Epoch 1356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00735, train_loss_epoch=0.00735, valid_loss=0.00391]\n",
            "Epoch 1357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=0.00391]\n",
            "Epoch 1358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00835, train_loss_epoch=0.00835, valid_loss=0.00391]\n",
            "Epoch 1359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.00391]\n",
            "Epoch 1360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00765, train_loss_epoch=0.00765, valid_loss=0.00391]\n",
            "Epoch 1361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00766, train_loss_epoch=0.00766, valid_loss=0.00391]\n",
            "Epoch 1362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00797, train_loss_epoch=0.00797, valid_loss=0.00391]\n",
            "Epoch 1363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00825, train_loss_epoch=0.00825, valid_loss=0.00391]\n",
            "Epoch 1364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00798, train_loss_epoch=0.00798, valid_loss=0.00391]\n",
            "Epoch 1365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00681, train_loss_epoch=0.00681, valid_loss=0.00391]\n",
            "Epoch 1366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00857, train_loss_epoch=0.00857, valid_loss=0.00391]\n",
            "Epoch 1367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00757, train_loss_epoch=0.00757, valid_loss=0.00391]\n",
            "Epoch 1368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0077, train_loss_epoch=0.0077, valid_loss=0.00391]\n",
            "Epoch 1369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00741, train_loss_epoch=0.00741, valid_loss=0.00391]\n",
            "Epoch 1370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00821, train_loss_epoch=0.00821, valid_loss=0.00391]\n",
            "Epoch 1371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00729, train_loss_epoch=0.00729, valid_loss=0.00391]\n",
            "Epoch 1372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00781, train_loss_epoch=0.00781, valid_loss=0.00391]\n",
            "Epoch 1373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00807, train_loss_epoch=0.00807, valid_loss=0.00391]\n",
            "Epoch 1374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0079, train_loss_epoch=0.0079, valid_loss=0.00391]\n",
            "Epoch 1375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0076, train_loss_epoch=0.0076, valid_loss=0.00391]\n",
            "Epoch 1376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00801, train_loss_epoch=0.00801, valid_loss=0.00391]\n",
            "Epoch 1377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00679, train_loss_epoch=0.00679, valid_loss=0.00391]\n",
            "Epoch 1377: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s, v_num=0, train_loss_step=0.00852, train_loss_epoch=0.00852, valid_loss=0.00391]\n",
            "Epoch 1378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00852, train_loss_epoch=0.00852, valid_loss=0.00391]\n",
            "Epoch 1379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00878, train_loss_epoch=0.00878, valid_loss=0.00391]\n",
            "Epoch 1380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.00391]\n",
            "Epoch 1381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00909, train_loss_epoch=0.00909, valid_loss=0.00391]\n",
            "Epoch 1382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0078, train_loss_epoch=0.0078, valid_loss=0.00391]\n",
            "Epoch 1383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00749, train_loss_epoch=0.00749, valid_loss=0.00391]\n",
            "Epoch 1384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0079, train_loss_epoch=0.0079, valid_loss=0.00391]\n",
            "Epoch 1385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00719, train_loss_epoch=0.00719, valid_loss=0.00391]\n",
            "Epoch 1386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00878, train_loss_epoch=0.00878, valid_loss=0.00391]\n",
            "Epoch 1386: 100%|██████████| 1/1 [00:00<00:00,  5.05it/s, v_num=0, train_loss_step=0.00819, train_loss_epoch=0.00819, valid_loss=0.00391]\n",
            "Epoch 1387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00819, train_loss_epoch=0.00819, valid_loss=0.00391]\n",
            "Epoch 1388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00728, train_loss_epoch=0.00728, valid_loss=0.00391]\n",
            "Epoch 1389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00777, train_loss_epoch=0.00777, valid_loss=0.00391]\n",
            "Epoch 1390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00777, train_loss_epoch=0.00777, valid_loss=0.00391]\n",
            "Epoch 1391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0069, train_loss_epoch=0.0069, valid_loss=0.00391]\n",
            "Epoch 1392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00799, train_loss_epoch=0.00799, valid_loss=0.00391]\n",
            "Epoch 1393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00754, train_loss_epoch=0.00754, valid_loss=0.00391]\n",
            "Epoch 1394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00731, train_loss_epoch=0.00731, valid_loss=0.00391]\n",
            "Epoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00802, train_loss_epoch=0.00802, valid_loss=0.00391]\n",
            "Epoch 1396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.00391]\n",
            "Epoch 1397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=0.00391]\n",
            "Epoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00754, train_loss_epoch=0.00754, valid_loss=0.00391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 17:33:01,763\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00,  4.78it/s, v_num=0, train_loss_step=0.00754, train_loss_epoch=0.00754, valid_loss=0.00391]\rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00,  4.77it/s, v_num=0, train_loss_step=0.00755, train_loss_epoch=0.00754, valid_loss=0.00391]\rEpoch 1398: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s, v_num=0, train_loss_step=0.00755, train_loss_epoch=0.00755, valid_loss=0.00391]\rEpoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00755, train_loss_epoch=0.00755, valid_loss=0.00391]        \rEpoch 1399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00755, train_loss_epoch=0.00755, valid_loss=0.00391]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=1422)\u001b[0m `Trainer.fit` stopped: `max_steps=1400.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  5.50it/s, v_num=0, train_loss_step=0.00755, train_loss_epoch=0.00755, valid_loss=0.00391]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  5.49it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00755, valid_loss=0.00391]\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.16it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=1422)\u001b[0m \r                                                                       \u001b[A\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00755, valid_loss=0.00356]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756, valid_loss=0.00356]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756, valid_loss=0.00356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=2744)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 2025-06-15 17:33:14.647871: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m E0000 00:00:1750008794.677098    2833 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m E0000 00:00:1750008794.686944    2833 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 2025-06-15 17:33:14.719104: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 3 | blocks       | ModuleList    | 8.2 M  | train\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 8.2 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 8.2 M     Total params\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 32.849    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.119, train_loss_epoch=0.119]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0961, train_loss_epoch=0.0961]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.111, train_loss_epoch=0.111]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0488, train_loss_epoch=0.0488]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0859, train_loss_epoch=0.0859]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0535, train_loss_epoch=0.0535]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0562, train_loss_epoch=0.0562]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0455, train_loss_epoch=0.0455]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0553, train_loss_epoch=0.0553]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0501, train_loss_epoch=0.0501]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, v_num=0, train_loss_step=0.0219, train_loss_epoch=0.0219]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0219, train_loss_epoch=0.0219]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0177, train_loss_epoch=0.0177]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0219, train_loss_epoch=0.0219]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0177, train_loss_epoch=0.0177]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0172]\n",
            "Epoch 69: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0392]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0124]\n",
            "Epoch 80: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0211, train_loss_epoch=0.0211]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142]\n",
            "Epoch 97: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0138]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.93it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0387]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0387]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0387]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.0387]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0387]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0387]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0387]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0097, valid_loss=0.0387]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0387]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00885, train_loss_epoch=0.00885, valid_loss=0.0387]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00882, train_loss_epoch=0.00882, valid_loss=0.0387]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0387]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0387]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0096, train_loss_epoch=0.0096, valid_loss=0.0387]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0387]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00853, train_loss_epoch=0.00853, valid_loss=0.0387]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00818, train_loss_epoch=0.00818, valid_loss=0.0387]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00912, valid_loss=0.0387]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0387]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.0387]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0387]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0387]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.0387]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0387]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0236, train_loss_epoch=0.0236, valid_loss=0.0387]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.0387]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.0387]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0165, train_loss_epoch=0.0165, valid_loss=0.0387]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271, valid_loss=0.0387]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.0387]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=0.0387]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=0.0387]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0387]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.0387]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0219, train_loss_epoch=0.0219, valid_loss=0.0387]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.0387]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=0.0387]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.0387]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=0.0387]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0387]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=0.0387]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.0387]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=0.0387]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.0387]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0387]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.0387]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.0387]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00878, train_loss_epoch=0.00878, valid_loss=0.0387]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.0387]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0387]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00953, train_loss_epoch=0.00953, valid_loss=0.0387]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.0387]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0387]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0387]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0387]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00929, train_loss_epoch=0.00929, valid_loss=0.0387]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0387]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=0.0387]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0387]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0387]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0387]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0387]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0387]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.0387]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.0387]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00881, train_loss_epoch=0.00881, valid_loss=0.0387]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.0387]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=0.0387]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0387]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0387]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0387]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.0387]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783, valid_loss=0.0387]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0387]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00781, train_loss_epoch=0.00781, valid_loss=0.0387]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.005, train_loss_epoch=0.005, valid_loss=0.0387]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00962, train_loss_epoch=0.00962, valid_loss=0.0387]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0387]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=0.0387]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0387]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00833, train_loss_epoch=0.00833, valid_loss=0.0387]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00729, train_loss_epoch=0.00729, valid_loss=0.0387]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0387]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00944, train_loss_epoch=0.00944, valid_loss=0.0387]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00672, train_loss_epoch=0.00672, valid_loss=0.0387]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00969, train_loss_epoch=0.00969, valid_loss=0.0387]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0387]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0076, train_loss_epoch=0.0076, valid_loss=0.0387]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.0387]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00883, train_loss_epoch=0.00883, valid_loss=0.0387]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00664, train_loss_epoch=0.00664, valid_loss=0.0387]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0387]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00809, train_loss_epoch=0.00809, valid_loss=0.0387]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=0.0387]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0387]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00838, train_loss_epoch=0.00838, valid_loss=0.0387]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00606, train_loss_epoch=0.00606, valid_loss=0.0387]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0068, train_loss_epoch=0.0068, valid_loss=0.0387]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0387]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00751, train_loss_epoch=0.00751, valid_loss=0.0387]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.00751, valid_loss=0.0387] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.58it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.0249]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00907, train_loss_epoch=0.00907, valid_loss=0.0249]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0249]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.007, train_loss_epoch=0.007, valid_loss=0.0249]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00931, train_loss_epoch=0.00931, valid_loss=0.0249]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0082, train_loss_epoch=0.0082, valid_loss=0.0249]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00744, train_loss_epoch=0.00744, valid_loss=0.0249]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00748, train_loss_epoch=0.00748, valid_loss=0.0249]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00709, train_loss_epoch=0.00709, valid_loss=0.0249]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00778, train_loss_epoch=0.00778, valid_loss=0.0249]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00526, train_loss_epoch=0.00526, valid_loss=0.0249]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00613, train_loss_epoch=0.00613, valid_loss=0.0249]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=0.0249]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00403, train_loss_epoch=0.00403, valid_loss=0.0249]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00613, train_loss_epoch=0.00613, valid_loss=0.0249]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00438, valid_loss=0.0249]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00555, train_loss_epoch=0.00555, valid_loss=0.0249]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0249]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00439, train_loss_epoch=0.00439, valid_loss=0.0249]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00612, train_loss_epoch=0.00612, valid_loss=0.0249]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00452, train_loss_epoch=0.00452, valid_loss=0.0249]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00583, train_loss_epoch=0.00583, valid_loss=0.0249]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0037, train_loss_epoch=0.0037, valid_loss=0.0249]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00536, train_loss_epoch=0.00536, valid_loss=0.0249]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=0.0249]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00364, train_loss_epoch=0.00364, valid_loss=0.0249]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00493, train_loss_epoch=0.00493, valid_loss=0.0249]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0249]\n",
            "Epoch 227: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0249]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0249]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00566, train_loss_epoch=0.00566, valid_loss=0.0249]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00334, train_loss_epoch=0.00334, valid_loss=0.0249]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00458, train_loss_epoch=0.00458, valid_loss=0.0249]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00553, train_loss_epoch=0.00553, valid_loss=0.0249]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00421, train_loss_epoch=0.00421, valid_loss=0.0249]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00708, train_loss_epoch=0.00708, valid_loss=0.0249]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00447, train_loss_epoch=0.00447, valid_loss=0.0249]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00724, valid_loss=0.0249]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00426, train_loss_epoch=0.00426, valid_loss=0.0249]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00681, train_loss_epoch=0.00681, valid_loss=0.0249]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00471, valid_loss=0.0249]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00581, train_loss_epoch=0.00581, valid_loss=0.0249]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=0.0249]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.004, train_loss_epoch=0.004, valid_loss=0.0249]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=0.0249]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00441, train_loss_epoch=0.00441, valid_loss=0.0249]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00411, train_loss_epoch=0.00411, valid_loss=0.0249]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00323, train_loss_epoch=0.00323, valid_loss=0.0249]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=0, train_loss_step=0.00362, train_loss_epoch=0.00362, valid_loss=0.0249]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00362, train_loss_epoch=0.00362, valid_loss=0.0249]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0041, train_loss_epoch=0.0041, valid_loss=0.0249]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=0.0249]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00414, train_loss_epoch=0.00414, valid_loss=0.0249]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00411, train_loss_epoch=0.00411, valid_loss=0.0249]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00296, train_loss_epoch=0.00296, valid_loss=0.0249]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00374, train_loss_epoch=0.00374, valid_loss=0.0249]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00349, train_loss_epoch=0.00349, valid_loss=0.0249]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.0027, valid_loss=0.0249]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00481, train_loss_epoch=0.00481, valid_loss=0.0249]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00516, train_loss_epoch=0.00516, valid_loss=0.0249]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=0.0249]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0047, train_loss_epoch=0.0047, valid_loss=0.0249]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00546, train_loss_epoch=0.00546, valid_loss=0.0249]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00337, train_loss_epoch=0.00337, valid_loss=0.0249]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00456, train_loss_epoch=0.00456, valid_loss=0.0249]\n",
            "Epoch 262: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=0.0249]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=0.0249]        \n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=0.0249]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00381, train_loss_epoch=0.00381, valid_loss=0.0249]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00406, train_loss_epoch=0.00406, valid_loss=0.0249]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00352, train_loss_epoch=0.00352, valid_loss=0.0249]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00383, train_loss_epoch=0.00383, valid_loss=0.0249]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00304, train_loss_epoch=0.00304, valid_loss=0.0249]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00316, train_loss_epoch=0.00316, valid_loss=0.0249]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00343, train_loss_epoch=0.00343, valid_loss=0.0249]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0249]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00365, train_loss_epoch=0.00365, valid_loss=0.0249]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00298, train_loss_epoch=0.00298, valid_loss=0.0249]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00317, train_loss_epoch=0.00317, valid_loss=0.0249]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=0.0249]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00377, train_loss_epoch=0.00377, valid_loss=0.0249]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00302, train_loss_epoch=0.00302, valid_loss=0.0249]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00367, train_loss_epoch=0.00367, valid_loss=0.0249]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00353, train_loss_epoch=0.00353, valid_loss=0.0249]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=0.0249]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00367, train_loss_epoch=0.00367, valid_loss=0.0249]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0039, train_loss_epoch=0.0039, valid_loss=0.0249]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00427, train_loss_epoch=0.00427, valid_loss=0.0249]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0249]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00336, train_loss_epoch=0.00336, valid_loss=0.0249]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00326, train_loss_epoch=0.00326, valid_loss=0.0249]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00355, train_loss_epoch=0.00355, valid_loss=0.0249]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00511, train_loss_epoch=0.00511, valid_loss=0.0249]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00484, train_loss_epoch=0.00484, valid_loss=0.0249]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00318, train_loss_epoch=0.00318, valid_loss=0.0249]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00319, train_loss_epoch=0.00319, valid_loss=0.0249]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=0.0249]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00464, train_loss_epoch=0.00464, valid_loss=0.0249]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00356, train_loss_epoch=0.00356, valid_loss=0.0249]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0249]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00511, train_loss_epoch=0.00511, valid_loss=0.0249]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0249]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00586, train_loss_epoch=0.00586, valid_loss=0.0249]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00365, train_loss_epoch=0.00365, valid_loss=0.0249]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, v_num=0, train_loss_step=0.00564, train_loss_epoch=0.00365, valid_loss=0.0249]\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.58it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00564, train_loss_epoch=0.00564, valid_loss=0.0321]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00551, train_loss_epoch=0.00551, valid_loss=0.0321]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00549, train_loss_epoch=0.00549, valid_loss=0.0321]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, v_num=0, train_loss_step=0.00549, train_loss_epoch=0.00549, valid_loss=0.0321]\n",
            "Epoch 302: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00549, valid_loss=0.0321]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=0.0321]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00463, train_loss_epoch=0.00463, valid_loss=0.0321]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=0.0321]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00524, train_loss_epoch=0.00524, valid_loss=0.0321]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00397, train_loss_epoch=0.00397, valid_loss=0.0321]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00469, train_loss_epoch=0.00469, valid_loss=0.0321]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00561, train_loss_epoch=0.00561, valid_loss=0.0321]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00461, train_loss_epoch=0.00461, valid_loss=0.0321]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.0321]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0043, train_loss_epoch=0.0043, valid_loss=0.0321]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.00435, valid_loss=0.0321]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0321]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00504, train_loss_epoch=0.00504, valid_loss=0.0321]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.0321]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00433, train_loss_epoch=0.00433, valid_loss=0.0321]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=0.0321]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00469, train_loss_epoch=0.00469, valid_loss=0.0321]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00405, train_loss_epoch=0.00405, valid_loss=0.0321]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00437, train_loss_epoch=0.00437, valid_loss=0.0321]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00359, train_loss_epoch=0.00359, valid_loss=0.0321]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00349, train_loss_epoch=0.00349, valid_loss=0.0321]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00453, train_loss_epoch=0.00453, valid_loss=0.0321]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00389, train_loss_epoch=0.00389, valid_loss=0.0321]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00349, train_loss_epoch=0.00349, valid_loss=0.0321]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00367, train_loss_epoch=0.00367, valid_loss=0.0321]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00296, train_loss_epoch=0.00296, valid_loss=0.0321]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=0.0321]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=0.0321]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00459, train_loss_epoch=0.00459, valid_loss=0.0321]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00571, train_loss_epoch=0.00571, valid_loss=0.0321]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00451, train_loss_epoch=0.00451, valid_loss=0.0321]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00472, train_loss_epoch=0.00472, valid_loss=0.0321]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=0.0321]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00563, train_loss_epoch=0.00563, valid_loss=0.0321]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00814, train_loss_epoch=0.00814, valid_loss=0.0321]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00505, train_loss_epoch=0.00505, valid_loss=0.0321]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0321]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.0321]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00693, train_loss_epoch=0.00693, valid_loss=0.0321]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=0.0321]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00441, train_loss_epoch=0.00441, valid_loss=0.0321]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00409, train_loss_epoch=0.00409, valid_loss=0.0321]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00407, train_loss_epoch=0.00407, valid_loss=0.0321]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00417, train_loss_epoch=0.00417, valid_loss=0.0321]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0037, train_loss_epoch=0.0037, valid_loss=0.0321]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00392, train_loss_epoch=0.00392, valid_loss=0.0321]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00649, train_loss_epoch=0.00649, valid_loss=0.0321]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00541, train_loss_epoch=0.00541, valid_loss=0.0321]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=0.0321]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00496, train_loss_epoch=0.00496, valid_loss=0.0321]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00401, train_loss_epoch=0.00401, valid_loss=0.0321]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0037, train_loss_epoch=0.0037, valid_loss=0.0321]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00308, train_loss_epoch=0.00308, valid_loss=0.0321]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00452, train_loss_epoch=0.00452, valid_loss=0.0321]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00448, train_loss_epoch=0.00448, valid_loss=0.0321]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0034, train_loss_epoch=0.0034, valid_loss=0.0321]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=0.0321]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0039, train_loss_epoch=0.0039, valid_loss=0.0321]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00347, train_loss_epoch=0.00347, valid_loss=0.0321]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00303, train_loss_epoch=0.00303, valid_loss=0.0321]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00372, train_loss_epoch=0.00372, valid_loss=0.0321]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00406, train_loss_epoch=0.00406, valid_loss=0.0321]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=0.0321]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00312, train_loss_epoch=0.00312, valid_loss=0.0321]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00343, train_loss_epoch=0.00343, valid_loss=0.0321]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0034, train_loss_epoch=0.0034, valid_loss=0.0321]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00435, train_loss_epoch=0.00435, valid_loss=0.0321]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00418, train_loss_epoch=0.00418, valid_loss=0.0321]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0321]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=0.0321]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=0.0321]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=0.0321]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0038, train_loss_epoch=0.0038, valid_loss=0.0321]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0321]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0321]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00584, train_loss_epoch=0.00584, valid_loss=0.0321]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00471, valid_loss=0.0321]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00372, train_loss_epoch=0.00372, valid_loss=0.0321]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00469, train_loss_epoch=0.00469, valid_loss=0.0321]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00531, train_loss_epoch=0.00531, valid_loss=0.0321]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00378, train_loss_epoch=0.00378, valid_loss=0.0321]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=0.0321]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00503, train_loss_epoch=0.00503, valid_loss=0.0321]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0034, train_loss_epoch=0.0034, valid_loss=0.0321]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00476, train_loss_epoch=0.00476, valid_loss=0.0321]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00364, train_loss_epoch=0.00364, valid_loss=0.0321]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00369, train_loss_epoch=0.00369, valid_loss=0.0321]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00377, train_loss_epoch=0.00377, valid_loss=0.0321]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=0.0321]\n",
            "Epoch 391: 100%|██████████| 1/1 [00:01<00:00,  0.96it/s, v_num=0, train_loss_step=0.00393, train_loss_epoch=0.00393, valid_loss=0.0321]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00393, train_loss_epoch=0.00393, valid_loss=0.0321]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00274, train_loss_epoch=0.00274, valid_loss=0.0321]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00353, train_loss_epoch=0.00353, valid_loss=0.0321]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0045, train_loss_epoch=0.0045, valid_loss=0.0321]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00522, train_loss_epoch=0.00522, valid_loss=0.0321]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00406, train_loss_epoch=0.00406, valid_loss=0.0321]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0048, train_loss_epoch=0.0048, valid_loss=0.0321]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00492, train_loss_epoch=0.00492, valid_loss=0.0321]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, v_num=0, train_loss_step=0.00461, train_loss_epoch=0.00492, valid_loss=0.0321]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 122.69it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00461, train_loss_epoch=0.00461, valid_loss=0.0298]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00346, train_loss_epoch=0.00346, valid_loss=0.0298]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=0.0298]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00216, train_loss_epoch=0.00216, valid_loss=0.0298]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00294, train_loss_epoch=0.00294, valid_loss=0.0298]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=0.0298]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0298]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=0.0298]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0298]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00196, train_loss_epoch=0.00196, valid_loss=0.0298]\n",
            "Epoch 409: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00196, valid_loss=0.0298]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0298]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00245, train_loss_epoch=0.00245, valid_loss=0.0298]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0298]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00207, train_loss_epoch=0.00207, valid_loss=0.0298]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0298]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0298]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00227, valid_loss=0.0298]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0298]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=0.0298]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0298]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00182, train_loss_epoch=0.00182, valid_loss=0.0298]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00199, train_loss_epoch=0.00199, valid_loss=0.0298]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00216, train_loss_epoch=0.00216, valid_loss=0.0298]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=0.0298]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0298]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0298]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0025, train_loss_epoch=0.0025, valid_loss=0.0298]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00186, train_loss_epoch=0.00186, valid_loss=0.0298]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00416, train_loss_epoch=0.00416, valid_loss=0.0298]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00293, train_loss_epoch=0.00293, valid_loss=0.0298]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0042, train_loss_epoch=0.0042, valid_loss=0.0298]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00339, train_loss_epoch=0.00339, valid_loss=0.0298]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00466, train_loss_epoch=0.00466, valid_loss=0.0298]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00318, train_loss_epoch=0.00318, valid_loss=0.0298]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00418, train_loss_epoch=0.00418, valid_loss=0.0298]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00265, train_loss_epoch=0.00265, valid_loss=0.0298]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00533, train_loss_epoch=0.00533, valid_loss=0.0298]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00393, train_loss_epoch=0.00393, valid_loss=0.0298]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00509, train_loss_epoch=0.00509, valid_loss=0.0298]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00482, train_loss_epoch=0.00482, valid_loss=0.0298]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00351, train_loss_epoch=0.00351, valid_loss=0.0298]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.004, train_loss_epoch=0.004, valid_loss=0.0298]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00353, train_loss_epoch=0.00353, valid_loss=0.0298]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0298]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00419, train_loss_epoch=0.00419, valid_loss=0.0298]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0298]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0053, train_loss_epoch=0.0053, valid_loss=0.0298]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00396, train_loss_epoch=0.00396, valid_loss=0.0298]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00458, train_loss_epoch=0.00458, valid_loss=0.0298]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00415, train_loss_epoch=0.00415, valid_loss=0.0298]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00436, train_loss_epoch=0.00436, valid_loss=0.0298]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0298]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0298]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00458, train_loss_epoch=0.00458, valid_loss=0.0298]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00225, train_loss_epoch=0.00225, valid_loss=0.0298]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00255, train_loss_epoch=0.00255, valid_loss=0.0298]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0298]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=0.0298]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0036, train_loss_epoch=0.0036, valid_loss=0.0298]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00194, train_loss_epoch=0.00194, valid_loss=0.0298]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00338, train_loss_epoch=0.00338, valid_loss=0.0298]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=0.0298]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0029, train_loss_epoch=0.0029, valid_loss=0.0298]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00306, train_loss_epoch=0.00306, valid_loss=0.0298]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=0.0298]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00356, train_loss_epoch=0.00356, valid_loss=0.0298]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0298]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00375, train_loss_epoch=0.00375, valid_loss=0.0298]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00204, train_loss_epoch=0.00204, valid_loss=0.0298]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00181, train_loss_epoch=0.00181, valid_loss=0.0298]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00338, train_loss_epoch=0.00338, valid_loss=0.0298]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0022, train_loss_epoch=0.0022, valid_loss=0.0298]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00317, train_loss_epoch=0.00317, valid_loss=0.0298]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0298]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=0.0298]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0038, train_loss_epoch=0.0038, valid_loss=0.0298]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=0.0298]\n",
            "Epoch 476: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, v_num=0, train_loss_step=0.00357, train_loss_epoch=0.00357, valid_loss=0.0298]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00357, train_loss_epoch=0.00357, valid_loss=0.0298]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00204, train_loss_epoch=0.00204, valid_loss=0.0298]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=0.0298]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0298]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00296, train_loss_epoch=0.00296, valid_loss=0.0298]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=0.0298]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=0.0298]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0298]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0298]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=0.0298]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00209, train_loss_epoch=0.00209, valid_loss=0.0298]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=0.0298]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0298]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0298]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00259, train_loss_epoch=0.00259, valid_loss=0.0298]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00216, train_loss_epoch=0.00216, valid_loss=0.0298]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0298]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0298]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0298]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0298]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00154, train_loss_epoch=0.00154, valid_loss=0.0298]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00246, train_loss_epoch=0.00246, valid_loss=0.0298]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0298]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00235, valid_loss=0.0298]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 97.86it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=0.0277]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0277]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0277]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  1.04it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0277]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0277]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0277]\n",
            "Epoch 503: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0277]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0277]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00217, train_loss_epoch=0.00217, valid_loss=0.0277]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=0.0277]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=0.0277]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0277]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=0.0277]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0277]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00211, train_loss_epoch=0.00211, valid_loss=0.0277]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0018, train_loss_epoch=0.0018, valid_loss=0.0277]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00169, train_loss_epoch=0.00169, valid_loss=0.0277]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=0.0277]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0277]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00193, train_loss_epoch=0.00193, valid_loss=0.0277]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00208, train_loss_epoch=0.00208, valid_loss=0.0277]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00252, train_loss_epoch=0.00252, valid_loss=0.0277]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00194, train_loss_epoch=0.00194, valid_loss=0.0277]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0277]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00177, train_loss_epoch=0.00177, valid_loss=0.0277]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00189, train_loss_epoch=0.00189, valid_loss=0.0277]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0277]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00305, train_loss_epoch=0.00305, valid_loss=0.0277]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=0.0277]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00397, train_loss_epoch=0.00397, valid_loss=0.0277]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00165, train_loss_epoch=0.00165, valid_loss=0.0277]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=0.0277]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00293, train_loss_epoch=0.00293, valid_loss=0.0277]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00471, valid_loss=0.0277]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=0.0277]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00566, train_loss_epoch=0.00566, valid_loss=0.0277]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0061, train_loss_epoch=0.0061, valid_loss=0.0277]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00288, train_loss_epoch=0.00288, valid_loss=0.0277]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0277]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00315, train_loss_epoch=0.00315, valid_loss=0.0277]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00676, train_loss_epoch=0.00676, valid_loss=0.0277]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0277]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00494, train_loss_epoch=0.00494, valid_loss=0.0277]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00545, valid_loss=0.0277]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=0.0277]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00554, train_loss_epoch=0.00554, valid_loss=0.0277]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00298, train_loss_epoch=0.00298, valid_loss=0.0277]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00593, train_loss_epoch=0.00593, valid_loss=0.0277]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=0.0277]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00305, train_loss_epoch=0.00305, valid_loss=0.0277]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00654, train_loss_epoch=0.00654, valid_loss=0.0277]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00343, train_loss_epoch=0.00343, valid_loss=0.0277]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00593, train_loss_epoch=0.00593, valid_loss=0.0277]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00555, train_loss_epoch=0.00555, valid_loss=0.0277]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0045, train_loss_epoch=0.0045, valid_loss=0.0277]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00576, train_loss_epoch=0.00576, valid_loss=0.0277]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0019, train_loss_epoch=0.0019, valid_loss=0.0277]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=0.0277]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00312, train_loss_epoch=0.00312, valid_loss=0.0277]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00565, train_loss_epoch=0.00565, valid_loss=0.0277]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00414, train_loss_epoch=0.00414, valid_loss=0.0277]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00462, train_loss_epoch=0.00462, valid_loss=0.0277]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00559, train_loss_epoch=0.00559, valid_loss=0.0277]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0277]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0277]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, v_num=0, train_loss_step=0.0036, train_loss_epoch=0.0031, valid_loss=0.0277]\n",
            "Epoch 560: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, v_num=0, train_loss_step=0.0036, train_loss_epoch=0.0036, valid_loss=0.0277]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0036, train_loss_epoch=0.0036, valid_loss=0.0277]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=0.0277]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0037, train_loss_epoch=0.0037, valid_loss=0.0277]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0277]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0277]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=0.0277]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00192, train_loss_epoch=0.00192, valid_loss=0.0277]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0277]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00185, train_loss_epoch=0.00185, valid_loss=0.0277]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00211, train_loss_epoch=0.00211, valid_loss=0.0277]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=0.0277]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=0.0277]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00177, train_loss_epoch=0.00177, valid_loss=0.0277]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=0.0277]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0277]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00214, train_loss_epoch=0.00214, valid_loss=0.0277]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00326, train_loss_epoch=0.00326, valid_loss=0.0277]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=0.0277]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00362, train_loss_epoch=0.00362, valid_loss=0.0277]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00251, train_loss_epoch=0.00251, valid_loss=0.0277]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00354, train_loss_epoch=0.00354, valid_loss=0.0277]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0277]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00406, train_loss_epoch=0.00406, valid_loss=0.0277]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0277]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00377, train_loss_epoch=0.00377, valid_loss=0.0277]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00204, train_loss_epoch=0.00204, valid_loss=0.0277]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00276, train_loss_epoch=0.00276, valid_loss=0.0277]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=0.0277]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=0.0277]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0028, train_loss_epoch=0.0028, valid_loss=0.0277]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0277]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00322, train_loss_epoch=0.00322, valid_loss=0.0277]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00265, train_loss_epoch=0.00265, valid_loss=0.0277]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00256, valid_loss=0.0277]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0277]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=0.0277]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0277]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.0017, valid_loss=0.0277]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=0.0277]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 17:40:26,918\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m `Trainer.fit` stopped: `max_steps=600.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=0.0277]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00206, valid_loss=0.0277]\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.32it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=2744)\u001b[0m \r                                                                       \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00206, valid_loss=0.030] \rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.030]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.030]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=4657)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 2025-06-15 17:40:41.117658: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m E0000 00:00:1750009241.167755    4751 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m E0000 00:00:1750009241.182259    4751 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 2025-06-15 17:40:41.235245: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 3 | blocks       | ModuleList    | 8.5 M  | train\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 8.5 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 8.5 M     Total params\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 33.857    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.649, train_loss_epoch=0.649]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=587.0, train_loss_epoch=587.0]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=120.0, train_loss_epoch=120.0]\n",
            "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=120.0]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=51.30, train_loss_epoch=51.30]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.10, train_loss_epoch=42.10]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.20, train_loss_epoch=32.20]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.80, train_loss_epoch=32.80]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.40, train_loss_epoch=68.40]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.570, train_loss_epoch=9.570]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.450, train_loss_epoch=9.450]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.690, train_loss_epoch=9.690]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.40, train_loss_epoch=21.40]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.780, train_loss_epoch=4.780]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  3.49it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=4.780]\n",
            "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.490]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.490]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.761, train_loss_epoch=0.761]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.675, train_loss_epoch=0.675]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.613, train_loss_epoch=0.613]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.632, train_loss_epoch=0.632]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.579, train_loss_epoch=0.579]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.540, train_loss_epoch=0.540]\n",
            "Epoch 32: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.540]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.496, train_loss_epoch=0.496]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.457, train_loss_epoch=0.457]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415]\n",
            "Epoch 58: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.409, train_loss_epoch=0.409]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.406, train_loss_epoch=0.406]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423]\n",
            "Epoch 62: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.392, train_loss_epoch=0.392]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.391, train_loss_epoch=0.391]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.362]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.50it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.00938]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.00938]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.00938]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.00938]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.00938]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.00938]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.00938]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.00938]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.00938]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.00938]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.00938]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.343, train_loss_epoch=0.343, valid_loss=0.00938]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.00938]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.00938]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.00938]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.00938]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.00938]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.00938]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.00938]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.00938]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.00938]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.00938]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.00938]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.00938]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.00938]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.00938]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.00938]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.00938]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.00938]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.00938]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.00938]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.00938]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.00938]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.00938]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.00938]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.00938]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.00938]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.00938]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.00938]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.00938]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.00938]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.00938]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.00938]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.00938]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.00938]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.00938]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.00938]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.00938]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.00938]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.00938]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.00938]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.00938]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.00938]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.00938]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.00938]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.00938]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.00938]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.00938]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.00938]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.00938]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.00938]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.00938]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.00938]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.351, train_loss_epoch=0.351, valid_loss=0.00938]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.00938]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.00938]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.00938]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.00938]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.00938]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.00938]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.00938]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.00938]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.00938]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.00938]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.00938]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.00938]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.00938]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.00938]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.00938]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.00938]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.00938]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.00938]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.00938]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.00938]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.00938]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.00938]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.00938]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.00938]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.00938]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.00938]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.00938]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.00938]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.00938]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.00938]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.00938]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.00938]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.00938]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.00938]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.00938]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.00938]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.271, valid_loss=0.00938]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.03it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.00727]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=0.00727]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.00727]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.00727]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.00727]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.00727]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.00727]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.00727]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.00727]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.00727]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.00727]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.00727]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.00727]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.00727]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.00727]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.00727]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.00727]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.00727]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.00727]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.00727]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.00727]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.00727]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.00727]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.00727]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.00727]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.00727]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.00727]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.00727]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.00727]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.00727]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.00727]\n",
            "Epoch 229: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.00727]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.00727]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.00727]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.00727]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.00727]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.00727]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.00727]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.00727]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.00727]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.00727]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.00727]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.00727]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.00727]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.00727]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.00727]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.00727]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.00727]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.00727]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.00727]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.00727]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.00727]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.00727]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.00727]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.00727]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.00727]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.00727]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.00727]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.00727]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.00727]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.00727]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.00727]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.00727]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.00727]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.00727]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.00727]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.00727]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.00727]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.00727]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.00727]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.00727]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.00727]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.00727]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.00727]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.00727]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.00727]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.00727]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.00727]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.00727]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.00727]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.00727]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.00727]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.00727]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.00727]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.00727]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.00727]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.00727]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.00727]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.232, valid_loss=0.00727]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.00727]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.00727]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.00727]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.00727]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.00727]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.00727]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.00727]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.00727]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.00727]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.00727]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.00727]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.00727]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.00727]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.00727]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.215, valid_loss=0.00727]\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 116.05it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.00605]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.00605]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.00605]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.00605]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.00605]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.00605]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.217, valid_loss=0.00605]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:00<00:00,  3.51it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.00605]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.00605]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.00605]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.00605]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.00605]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.00605]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.00605]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.00605]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.00605]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.00605]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.00605]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.00605]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.00605]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.00605]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.00605]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.00605]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.00605]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.00605]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.00605]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.00605]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.00605]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.00605]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.00605]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.00605]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.00605]\n",
            "Epoch 329: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.204, valid_loss=0.00605]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.00605]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.00605]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.00605]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.00605]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.00605]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.00605]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.00605]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.00605]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.00605]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.00605]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.00605]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.00605]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.00605]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.00605]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.00605]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.00605]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.00605]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.00605]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.00605]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.00605]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.00605]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.00605]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.00605]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.00605]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.00605]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.00605]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.00605]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.00605]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00605]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.00605]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.00605]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.00605]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.00605]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.00605]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.00605]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.00605]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.00605]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.00605]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.00605]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.00605]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.00605]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.176, valid_loss=0.00605]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.00605]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.00605]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.00605]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.00605]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.00605]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.00605]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.00605]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.00605]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.00605]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.00605]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.00605]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.00605]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.00605]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.00605]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.00605]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.00605]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00605]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.00605]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.00605]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.00605]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.00605]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.00605]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.00605]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.00605]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.00605]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.00605]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.00605]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.00605]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.00605]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.195, valid_loss=0.00605]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.41it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.00512]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.00512]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.00512]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.00512]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.00512]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.00512]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.00512]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.00512]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.00512]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.00512]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.00512]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.00512]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.00512]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00512]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.00512]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.00512]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.00512]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.00512]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.00512]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00512]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.00512]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.00512]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00512]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.00512]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.00512]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.00512]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.00512]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.00512]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.00512]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.00512]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.00512]\n",
            "Epoch 432: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.00512]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.00512]\n",
            "Epoch 433: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00512]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00512]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.00512]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.00512]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.00512]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.00512]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.00512]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.00512]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.00512]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.00512]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.00512]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.00512]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.00512]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.00512]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.00512]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.00512]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.00512]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.00512]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.00512]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00512]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.00512]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.00512]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.00512]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.00512]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.00512]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.00512]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.00512]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.00512]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.00512]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.00512]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.00512]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.00512]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.00512]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.00512]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.00512]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.00512]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.00512]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.00512]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.00512]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.00512]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.00512]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.00512]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.00512]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.00512]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.00512]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.00512]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.00512]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.00512]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.00512]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.00512]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.00512]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.00512]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.00512]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.00512]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.00512]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.00512]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.00512]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.00512]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.00512]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.00512]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.00512]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.00512]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.00512]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 17:43:24,381\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (60, 8, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \rEpoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.00512]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.166, valid_loss=0.00512]\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 67.79it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=4657)\u001b[0m \r                                                                      \u001b[A\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.166, valid_loss=0.00523]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.00523]\rEpoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.33it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.00523]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=4657)\u001b[0m `Trainer.fit` stopped: `max_steps=500.0` reached.\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 2025-06-15 17:43:39.011984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m E0000 00:00:1750009419.039775    5567 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m E0000 00:00:1750009419.051355    5567 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 2025-06-15 17:43:39.087491: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 3 | blocks       | ModuleList    | 9.7 M  | train\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 9.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 9.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 38.987    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.30, train_loss_epoch=27.30]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.90, train_loss_epoch=27.90]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.50, train_loss_epoch=27.50]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.30, train_loss_epoch=27.30]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.60, train_loss_epoch=26.60]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.10, train_loss_epoch=26.10]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.20, train_loss_epoch=25.20]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.20, train_loss_epoch=24.20]\n",
            "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 18: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=14.30]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:03<00:00,  0.25it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]\n",
            "Epoch 22: 100%|██████████| 1/1 [00:02<00:00,  0.48it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.690, train_loss_epoch=9.690]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.050, train_loss_epoch=9.050]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.100, train_loss_epoch=8.100]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=8.100]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.610, train_loss_epoch=6.610]        \n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.610, train_loss_epoch=6.610]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.140, train_loss_epoch=6.140]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.170, train_loss_epoch=6.170]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.380, train_loss_epoch=5.380]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.050, train_loss_epoch=5.050]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.550, train_loss_epoch=4.550]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.300, train_loss_epoch=4.300]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]        \n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.350, train_loss_epoch=1.350]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]\n",
            "Epoch 64: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.760]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.270, train_loss_epoch=1.270]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.590]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
            "Epoch 88: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.100, train_loss_epoch=1.100]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.40it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.010]\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 63.94it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.0148]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.927, train_loss_epoch=0.927, valid_loss=0.0148]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.0148]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.0148]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0148]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.0148]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.0148]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.0148]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.0148]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0148]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.769, train_loss_epoch=0.769, valid_loss=0.0148]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.990, train_loss_epoch=0.990, valid_loss=0.0148]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.0148]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.0148]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875, valid_loss=0.0148]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.0148]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0148]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.949, train_loss_epoch=0.949, valid_loss=0.0148]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.0148]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0148]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.808, train_loss_epoch=0.808, valid_loss=0.0148]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.0148]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.748, train_loss_epoch=0.748, valid_loss=0.0148]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.0148]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.0148]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.0148]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.0148]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.0148]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=0.0148]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.0148]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.0148]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=0.0148]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.0148]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.982, train_loss_epoch=0.982, valid_loss=0.0148]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.721, train_loss_epoch=0.721, valid_loss=0.0148]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.0148]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0148]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.0148]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.0148]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.0148]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.0148]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.0148]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.0148]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.883, train_loss_epoch=0.883, valid_loss=0.0148]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.0148]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.0148]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.938, train_loss_epoch=0.938, valid_loss=0.0148]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.0148]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.0148]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.940, train_loss_epoch=0.940, valid_loss=0.0148]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0148]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0148]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.0148]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.980, train_loss_epoch=0.980, valid_loss=0.0148]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0148]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0148]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=0.0148]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.0148]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.985, train_loss_epoch=0.985, valid_loss=0.0148]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.0148]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=0.0148]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=0.771, valid_loss=0.0148]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.0148]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.763, train_loss_epoch=0.763, valid_loss=0.0148]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.0148]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=1.030, valid_loss=0.0148]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0148]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0148]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=0.0148]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0148]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.903, train_loss_epoch=0.903, valid_loss=0.0148]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.0148]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.867, train_loss_epoch=0.867, valid_loss=0.0148]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.933, train_loss_epoch=0.933, valid_loss=0.0148]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.873, train_loss_epoch=0.873, valid_loss=0.0148]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.912, train_loss_epoch=0.912, valid_loss=0.0148]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.0148]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0148]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972, valid_loss=0.0148]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.0148]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.871, train_loss_epoch=0.871, valid_loss=0.0148]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.0148]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0148]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.905, train_loss_epoch=0.905, valid_loss=0.0148]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.891, train_loss_epoch=0.891, valid_loss=0.0148]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.758, train_loss_epoch=0.758, valid_loss=0.0148]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.0148]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.0148]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.673, train_loss_epoch=0.673, valid_loss=0.0148]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.0148]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.0148]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.0148]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.0148]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=0.0148]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.0148]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.0148]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0148]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.0148]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=0.0148]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.030, train_loss_epoch=1.030, valid_loss=0.0148]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0148]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.0148]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.951, train_loss_epoch=0.951, valid_loss=0.0148]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=0.951, valid_loss=0.0148]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.42it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0147]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0147]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.900, train_loss_epoch=0.900, valid_loss=0.0147]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.852, train_loss_epoch=0.852, valid_loss=0.0147]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=0.0147]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.853, train_loss_epoch=0.853, valid_loss=0.0147]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0147]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.670, train_loss_epoch=0.670, valid_loss=0.0147]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.0147]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.0147]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.0147]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.957, train_loss_epoch=0.957, valid_loss=0.0147]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.865, train_loss_epoch=0.865, valid_loss=0.0147]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.0147]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.0147]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.0147]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.0147]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.936, train_loss_epoch=0.936, valid_loss=0.0147]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.882, train_loss_epoch=0.882, valid_loss=0.0147]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.0147]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.0147]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.0147]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.695, train_loss_epoch=0.695, valid_loss=0.0147]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.0147]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.0147]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.0147]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.0147]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.0147]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.815, train_loss_epoch=0.815, valid_loss=0.0147]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=0.0147]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.909, train_loss_epoch=0.909, valid_loss=0.0147]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.751, train_loss_epoch=0.751, valid_loss=0.0147]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.911, train_loss_epoch=0.911, valid_loss=0.0147]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.0147]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.756, train_loss_epoch=0.756, valid_loss=0.0147]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.0147]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=0.0147]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.885, train_loss_epoch=0.885, valid_loss=0.0147]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0147]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.959, train_loss_epoch=0.959, valid_loss=0.0147]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.863, train_loss_epoch=0.863, valid_loss=0.0147]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.833, train_loss_epoch=0.833, valid_loss=0.0147]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.918, train_loss_epoch=0.918, valid_loss=0.0147]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.0147]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0147]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=0.0147]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958, valid_loss=0.0147]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.855, train_loss_epoch=0.855, valid_loss=0.0147]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=0.0147]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.932, train_loss_epoch=0.932, valid_loss=0.0147]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.792, train_loss_epoch=0.792, valid_loss=0.0147]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.0147]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0147]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.774, train_loss_epoch=0.774, valid_loss=0.0147]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.652, train_loss_epoch=0.652, valid_loss=0.0147]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.786, train_loss_epoch=0.786, valid_loss=0.0147]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.796, train_loss_epoch=0.796, valid_loss=0.0147]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=0.0147]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0147]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.914, train_loss_epoch=0.914, valid_loss=0.0147]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.943, train_loss_epoch=0.943, valid_loss=0.0147]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.930, train_loss_epoch=0.930, valid_loss=0.0147]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.0147]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772, valid_loss=0.0147]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0147]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0147]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.0147]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.679, train_loss_epoch=0.679, valid_loss=0.0147]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000, valid_loss=0.0147]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.950, train_loss_epoch=0.950, valid_loss=0.0147]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.0147]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.0147]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.755, train_loss_epoch=0.755, valid_loss=0.0147]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=0.0147]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.894, train_loss_epoch=0.894, valid_loss=0.0147]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.777, train_loss_epoch=0.777, valid_loss=0.0147]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.923, train_loss_epoch=0.923, valid_loss=0.0147]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.916, train_loss_epoch=0.916, valid_loss=0.0147]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.0147]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=0.0147]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.861, train_loss_epoch=0.861, valid_loss=0.0147]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.686, train_loss_epoch=0.686, valid_loss=0.0147]\n",
            "Epoch 281: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.686, valid_loss=0.0147]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.0147]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.0147]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.801, train_loss_epoch=0.801, valid_loss=0.0147]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.0147]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.839, train_loss_epoch=0.839, valid_loss=0.0147]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.745, train_loss_epoch=0.745, valid_loss=0.0147]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=0.0147]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.0147]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0147]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.802, train_loss_epoch=0.802, valid_loss=0.0147]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759, valid_loss=0.0147]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0147]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.658, train_loss_epoch=0.658, valid_loss=0.0147]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0147]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.757, train_loss_epoch=0.757, valid_loss=0.0147]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.651, train_loss_epoch=0.651, valid_loss=0.0147]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.831, train_loss_epoch=0.831, valid_loss=0.0147]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.607, train_loss_epoch=0.607, valid_loss=0.0147]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:01<00:00,  0.57it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.607, valid_loss=0.0147]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.47it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.971, train_loss_epoch=0.971, valid_loss=0.0148]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.663, train_loss_epoch=0.663, valid_loss=0.0148]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.0148]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.0148]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.0148]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.945, train_loss_epoch=0.945, valid_loss=0.0148]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.657, train_loss_epoch=0.657, valid_loss=0.0148]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.899, train_loss_epoch=0.899, valid_loss=0.0148]\n",
            "Epoch 307: 100%|██████████| 1/1 [00:04<00:00,  0.21it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.899, valid_loss=0.0148]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.704, train_loss_epoch=0.704, valid_loss=0.0148]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.0148]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.999, train_loss_epoch=0.999, valid_loss=0.0148]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.0148]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0148]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.817, train_loss_epoch=0.817, valid_loss=0.0148]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.747, train_loss_epoch=0.747, valid_loss=0.0148]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.0148]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0148]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.842, train_loss_epoch=0.842, valid_loss=0.0148]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0148]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.681, train_loss_epoch=0.681, valid_loss=0.0148]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.781, train_loss_epoch=0.781, valid_loss=0.0148]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.662, train_loss_epoch=0.662, valid_loss=0.0148]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.785, train_loss_epoch=0.785, valid_loss=0.0148]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=0.0148]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.776, train_loss_epoch=0.776, valid_loss=0.0148]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0148]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.754, train_loss_epoch=0.754, valid_loss=0.0148]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0148]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.0148]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.791, train_loss_epoch=0.791, valid_loss=0.0148]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=0.0148]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.807, train_loss_epoch=0.807, valid_loss=0.0148]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0148]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857, valid_loss=0.0148]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0148]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.0148]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.765, train_loss_epoch=0.765, valid_loss=0.0148]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.0148]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0148]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.0148]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.711, train_loss_epoch=0.711, valid_loss=0.0148]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.598, train_loss_epoch=0.598, valid_loss=0.0148]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.578, train_loss_epoch=0.578, valid_loss=0.0148]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:02<00:00,  0.35it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.578, valid_loss=0.0148]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.644, train_loss_epoch=0.644, valid_loss=0.0148]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.635, train_loss_epoch=0.635, valid_loss=0.0148]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.583, train_loss_epoch=0.583, valid_loss=0.0148]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0148]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.783, train_loss_epoch=0.783, valid_loss=0.0148]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0148]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.788, train_loss_epoch=0.788, valid_loss=0.0148]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.656, train_loss_epoch=0.656, valid_loss=0.0148]\n",
            "Epoch 350: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.656, valid_loss=0.0148]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.645, train_loss_epoch=0.645, valid_loss=0.0148]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.687, train_loss_epoch=0.687, valid_loss=0.0148]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.638, train_loss_epoch=0.638, valid_loss=0.0148]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.514, train_loss_epoch=0.514, valid_loss=0.0148]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.674, train_loss_epoch=0.674, valid_loss=0.0148]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0148]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.0148]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.692, train_loss_epoch=0.692, valid_loss=0.0148]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.0148]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.841, train_loss_epoch=0.841, valid_loss=0.0148]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505, valid_loss=0.0148]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.0148]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.917, train_loss_epoch=0.917, valid_loss=0.0148]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.661, train_loss_epoch=0.661, valid_loss=0.0148]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.967, train_loss_epoch=0.967, valid_loss=0.0148]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.601, train_loss_epoch=0.601, valid_loss=0.0148]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.805, train_loss_epoch=0.805, valid_loss=0.0148]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=0.0148]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:01<00:00,  0.57it/s, v_num=0, train_loss_step=0.764, train_loss_epoch=0.764, valid_loss=0.0148]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.551, train_loss_epoch=0.551, valid_loss=0.0148]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.706, train_loss_epoch=0.706, valid_loss=0.0148]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.631, train_loss_epoch=0.631, valid_loss=0.0148]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.809, train_loss_epoch=0.809, valid_loss=0.0148]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.735, train_loss_epoch=0.735, valid_loss=0.0148]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.0148]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.691, train_loss_epoch=0.691, valid_loss=0.0148]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712, valid_loss=0.0148]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.580, train_loss_epoch=0.580, valid_loss=0.0148]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.880, train_loss_epoch=0.880, valid_loss=0.0148]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.760, train_loss_epoch=0.760, valid_loss=0.0148]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.750, train_loss_epoch=0.750, valid_loss=0.0148]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.746, train_loss_epoch=0.746, valid_loss=0.0148]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.800, train_loss_epoch=0.800, valid_loss=0.0148]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.829, train_loss_epoch=0.829, valid_loss=0.0148]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.680, train_loss_epoch=0.680, valid_loss=0.0148]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.0148]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.664, train_loss_epoch=0.664, valid_loss=0.0148]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.797, train_loss_epoch=0.797, valid_loss=0.0148]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.0148]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.806, train_loss_epoch=0.806, valid_loss=0.0148]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.847, train_loss_epoch=0.847, valid_loss=0.0148]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.0148]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.798, train_loss_epoch=0.798, valid_loss=0.0148]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.666, train_loss_epoch=0.666, valid_loss=0.0148]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.726, train_loss_epoch=0.726, valid_loss=0.0148]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.597, train_loss_epoch=0.597, valid_loss=0.0148]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.682, train_loss_epoch=0.682, valid_loss=0.0148]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.637, train_loss_epoch=0.637, valid_loss=0.0148]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.0148]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.0148]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.821, valid_loss=0.0148]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.67it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.708, train_loss_epoch=0.708, valid_loss=0.0149]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.715, train_loss_epoch=0.715, valid_loss=0.0149]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.854, train_loss_epoch=0.854, valid_loss=0.0149]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.684, train_loss_epoch=0.684, valid_loss=0.0149]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.896, train_loss_epoch=0.896, valid_loss=0.0149]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.722, train_loss_epoch=0.722, valid_loss=0.0149]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.872, train_loss_epoch=0.872, valid_loss=0.0149]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.859, train_loss_epoch=0.859, valid_loss=0.0149]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.856, train_loss_epoch=0.856, valid_loss=0.0149]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.810, train_loss_epoch=0.810, valid_loss=0.0149]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.766, train_loss_epoch=0.766, valid_loss=0.0149]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0149]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0149]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.771, train_loss_epoch=0.771, valid_loss=0.0149]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.689, train_loss_epoch=0.689, valid_loss=0.0149]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.0149]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.773, train_loss_epoch=0.773, valid_loss=0.0149]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744, valid_loss=0.0149]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.744, train_loss_epoch=0.744, valid_loss=0.0149]\n",
            "Epoch 418: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730, valid_loss=0.0149]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.730, train_loss_epoch=0.730, valid_loss=0.0149]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.688, train_loss_epoch=0.688, valid_loss=0.0149]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.828, train_loss_epoch=0.828, valid_loss=0.0149]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.834, train_loss_epoch=0.834, valid_loss=0.0149]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.876, train_loss_epoch=0.876, valid_loss=0.0149]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.741, train_loss_epoch=0.741, valid_loss=0.0149]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=0.0149]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.698, train_loss_epoch=0.698, valid_loss=0.0149]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.667, train_loss_epoch=0.667, valid_loss=0.0149]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.693, train_loss_epoch=0.693, valid_loss=0.0149]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0149]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.707, train_loss_epoch=0.707, valid_loss=0.0149]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.563, train_loss_epoch=0.563, valid_loss=0.0149]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.502, train_loss_epoch=0.502, valid_loss=0.0149]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.589, train_loss_epoch=0.589, valid_loss=0.0149]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0149]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.497, train_loss_epoch=0.497, valid_loss=0.0149]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0149]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0149]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0149]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0149]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0149]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0149]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0149]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0149]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0149]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.309, train_loss_epoch=0.309, valid_loss=0.0149]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.0149]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0149]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0149]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0149]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0149]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0149]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0149]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0149]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0149]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0149]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.311, valid_loss=0.0149]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0149]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0149]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0149]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0149]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0149]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0149]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0149]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0149]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0149]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0149]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0149]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0149]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0149]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0149]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0149]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0149]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.0149]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.0149]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0149]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0149]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0149]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0149]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0149]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.262, train_loss_epoch=0.262, valid_loss=0.0149]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.322, train_loss_epoch=0.322, valid_loss=0.0149]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.0149]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0149]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.0149]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0149]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.0149]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.0149]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0149]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0149]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0149]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0149]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0149]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0149]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0149]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0149]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0149]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0149]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0149]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0149]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.0149]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.255, valid_loss=0.0149]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.30it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0148]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0148]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0148]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0148]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.0148]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0148]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0148]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0148]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.0148]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.347, train_loss_epoch=0.347, valid_loss=0.0148]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0148]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0148]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0148]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.271, train_loss_epoch=0.271, valid_loss=0.0148]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0148]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0148]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0148]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0148]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0148]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0148]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.0148]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0148]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0148]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0148]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0148]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0148]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0148]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0148]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0148]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0148]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0148]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0148]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0148]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0148]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0148]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0148]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0148]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0148]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0148]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0148]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0148]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0148]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0148]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327, valid_loss=0.0148]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0148]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0148]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.0148]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0148]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.268, train_loss_epoch=0.268, valid_loss=0.0148]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0148]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0148]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0148]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0148]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0148]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0148]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0148]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0148]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0148]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.344, train_loss_epoch=0.344, valid_loss=0.0148]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0148]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0148]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0148]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0148]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0148]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.466, train_loss_epoch=0.466, valid_loss=0.0148]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0148]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0148]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0148]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0148]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0148]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0148]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0148]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0148]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0148]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0148]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0148]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0148]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0148]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0148]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0148]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.0148]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.359, train_loss_epoch=0.359, valid_loss=0.0148]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0148]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0148]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.471, train_loss_epoch=0.471, valid_loss=0.0148]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0148]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0148]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0148]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0148]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0148]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.323, train_loss_epoch=0.323, valid_loss=0.0148]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.0148]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0148]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0148]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.0148]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0148]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.376, train_loss_epoch=0.376, valid_loss=0.0148]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0148]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0148]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0148]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.432, valid_loss=0.0148]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.52it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.381, train_loss_epoch=0.381, valid_loss=0.0149]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0149]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0149]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0149]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0149]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0149]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0149]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0149]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0149]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0149]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0149]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0149]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0149]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0149]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0149]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0149]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.0149]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.393, train_loss_epoch=0.393, valid_loss=0.0149]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0149]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0149]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0149]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0149]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0149]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0149]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0149]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0149]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0149]\n",
            "Epoch 626: 100%|██████████| 1/1 [00:02<00:00,  0.49it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.301, valid_loss=0.0149]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0149]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0149]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0149]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0149]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0149]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.0149]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.341, train_loss_epoch=0.341, valid_loss=0.0149]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0149]\n",
            "Epoch 634: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0149]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0149]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0149]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0149]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0149]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0149]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0149]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0149]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0149]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0149]\n",
            "Epoch 642: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.318, valid_loss=0.0149]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0149]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0149]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.340, train_loss_epoch=0.340, valid_loss=0.0149]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.0149]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0149]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0149]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0149]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0149]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.372, train_loss_epoch=0.372, valid_loss=0.0149]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0149]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0149]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0149]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0149]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.368, train_loss_epoch=0.368, valid_loss=0.0149]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0149]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.335, train_loss_epoch=0.335, valid_loss=0.0149]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0149]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0149]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.300, train_loss_epoch=0.300, valid_loss=0.0149]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0149]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0149]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0149]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0149]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0149]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.377, train_loss_epoch=0.377, valid_loss=0.0149]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.294, train_loss_epoch=0.294, valid_loss=0.0149]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0149]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.0149]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.316, train_loss_epoch=0.316, valid_loss=0.0149]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0149]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.0149]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0149]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0149]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.0149]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0149]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0149]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0149]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.302, train_loss_epoch=0.302, valid_loss=0.0149]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310, valid_loss=0.0149]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0149]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0149]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.296, train_loss_epoch=0.296, valid_loss=0.0149]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0149]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.0149]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.0149]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0149]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0149]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0149]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0149]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319, valid_loss=0.0149]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0149]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0149]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0149]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0149]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0149]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0149]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.303, train_loss_epoch=0.303, valid_loss=0.0149]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:02<00:00,  0.38it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.303, valid_loss=0.0149]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.11it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0149]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0149]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0149]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0149]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.311, train_loss_epoch=0.311, valid_loss=0.0149]\n",
            "Epoch 704: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.311, valid_loss=0.0149]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0149]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0149]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330, valid_loss=0.0149]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317, valid_loss=0.0149]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0149]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291, valid_loss=0.0149]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0149]\n",
            "Epoch 711: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.364, valid_loss=0.0149]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.334, train_loss_epoch=0.334, valid_loss=0.0149]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0149]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.0149]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0149]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326, valid_loss=0.0149]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.365, train_loss_epoch=0.365, valid_loss=0.0149]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438, valid_loss=0.0149]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307, valid_loss=0.0149]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0149]\n",
            "Epoch 720: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.454, valid_loss=0.0149]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0149]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0149]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0149]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0149]\n",
            "Epoch 724: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.329, valid_loss=0.0149]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0149]\n",
            "Epoch 725: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.356, valid_loss=0.0149]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.375, train_loss_epoch=0.375, valid_loss=0.0149]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0149]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.354, train_loss_epoch=0.354, valid_loss=0.0149]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.0149]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0149]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0149]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0149]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.378, train_loss_epoch=0.378, valid_loss=0.0149]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.0149]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.373, train_loss_epoch=0.373, valid_loss=0.0149]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0149]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0149]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0149]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0149]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0149]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0149]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0149]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0149]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.362, train_loss_epoch=0.362, valid_loss=0.0149]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0149]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.475, train_loss_epoch=0.475, valid_loss=0.0149]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0149]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.314, train_loss_epoch=0.314, valid_loss=0.0149]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412, valid_loss=0.0149]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.299, train_loss_epoch=0.299, valid_loss=0.0149]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0149]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.346, train_loss_epoch=0.346, valid_loss=0.0149]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.494, train_loss_epoch=0.494, valid_loss=0.0149]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0149]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0149]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0149]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0149]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0149]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0149]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0149]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.353, train_loss_epoch=0.353, valid_loss=0.0149]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.333, train_loss_epoch=0.333, valid_loss=0.0149]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0149]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.324, train_loss_epoch=0.324, valid_loss=0.0149]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361, valid_loss=0.0149]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.370, train_loss_epoch=0.370, valid_loss=0.0149]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342, valid_loss=0.0149]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.374, train_loss_epoch=0.374, valid_loss=0.0149]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.318, train_loss_epoch=0.318, valid_loss=0.0149]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.278, train_loss_epoch=0.278, valid_loss=0.0149]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.331, train_loss_epoch=0.331, valid_loss=0.0149]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0149]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0149]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0149]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339, valid_loss=0.0149]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0149]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0149]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0149]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0149]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.400, train_loss_epoch=0.400, valid_loss=0.0149]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413, valid_loss=0.0149]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0149]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0149]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0149]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0149]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0149]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0149]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0149]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0149]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.379, train_loss_epoch=0.379, valid_loss=0.0149]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0149]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0149]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0149]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0149]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.355, train_loss_epoch=0.355, valid_loss=0.0149]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0149]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0149]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.313, train_loss_epoch=0.313, valid_loss=0.0149]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0149]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:02<00:00,  0.46it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.499, valid_loss=0.0149]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.14it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.453, train_loss_epoch=0.453, valid_loss=0.0149]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.384, train_loss_epoch=0.384, valid_loss=0.0149]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0149]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.345, train_loss_epoch=0.345, valid_loss=0.0149]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.451, train_loss_epoch=0.451, valid_loss=0.0149]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.332, train_loss_epoch=0.332, valid_loss=0.0149]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0149]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0149]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0149]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.277, train_loss_epoch=0.277, valid_loss=0.0149]\n",
            "Epoch 809: 100%|██████████| 1/1 [00:02<00:00,  0.43it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.277, valid_loss=0.0149]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.408, train_loss_epoch=0.408, valid_loss=0.0149]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0149]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0149]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0149]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.321, train_loss_epoch=0.321, valid_loss=0.0149]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.0149]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337, valid_loss=0.0149]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0149]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0149]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.306, train_loss_epoch=0.306, valid_loss=0.0149]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.287, train_loss_epoch=0.287, valid_loss=0.0149]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.286, train_loss_epoch=0.286, valid_loss=0.0149]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.325, train_loss_epoch=0.325, valid_loss=0.0149]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0149]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0149]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0149]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297, valid_loss=0.0149]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0149]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.308, train_loss_epoch=0.308, valid_loss=0.0149]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0149]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.405, train_loss_epoch=0.405, valid_loss=0.0149]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.348, train_loss_epoch=0.348, valid_loss=0.0149]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0149]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.320, train_loss_epoch=0.320, valid_loss=0.0149]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0149]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.285, train_loss_epoch=0.285, valid_loss=0.0149]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0149]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0149]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0149]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.0149]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0149]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0149]\n",
            "Epoch 841: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0149]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0149]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.336, train_loss_epoch=0.336, valid_loss=0.0149]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.329, train_loss_epoch=0.329, valid_loss=0.0149]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0149]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0149]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304, valid_loss=0.0149]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.305, train_loss_epoch=0.305, valid_loss=0.0149]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.289, train_loss_epoch=0.289, valid_loss=0.0149]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0149]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0149]\n",
            "Epoch 851: 100%|██████████| 1/1 [00:03<00:00,  0.31it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.242, valid_loss=0.0149]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0149]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.0149]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.0149]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273, valid_loss=0.0149]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.0149]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.312, train_loss_epoch=0.312, valid_loss=0.0149]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0149]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.290, train_loss_epoch=0.290, valid_loss=0.0149]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0149]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.0149]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.350, train_loss_epoch=0.350, valid_loss=0.0149]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0149]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0149]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.369, train_loss_epoch=0.369, valid_loss=0.0149]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.293, train_loss_epoch=0.293, valid_loss=0.0149]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.356, train_loss_epoch=0.356, valid_loss=0.0149]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0149]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0149]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301, valid_loss=0.0149]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.0149]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0149]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0149]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0149]\n",
            "Epoch 874: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0149]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0149]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0149]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0149]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0149]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0149]\n",
            "Epoch 880: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.174, valid_loss=0.0149]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0149]\n",
            "Epoch 881: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0149]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0149]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0149]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0149]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0149]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0149]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0149]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0149]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0149]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=0.0149]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0149]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.140, train_loss_epoch=0.140, valid_loss=0.0149]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0149]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0149]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0149]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0149]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.42it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0149]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0149]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0149]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0149]\n",
            "Epoch 903: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0149]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0149]\n",
            "Epoch 904: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.179, valid_loss=0.0149]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0149]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0149]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0149]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0149]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0149]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0149]\n",
            "Epoch 911: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0149]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0149]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0149]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0149]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0149]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0149]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.0149]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0149]\n",
            "Epoch 920: 100%|██████████| 1/1 [00:03<00:00,  0.33it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.181, valid_loss=0.0149]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.249, train_loss_epoch=0.249, valid_loss=0.0149]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0149]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0149]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0149]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.0149]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.0149]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0149]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0149]\n",
            "Epoch 928: 100%|██████████| 1/1 [00:02<00:00,  0.49it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.195, valid_loss=0.0149]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0149]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0149]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0149]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0149]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0149]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 934: 100%|██████████| 1/1 [00:03<00:00,  0.33it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0149]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0149]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0149]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0149]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0149]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0149]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0149]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0149]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0149]\n",
            "Epoch 951: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0149]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0149]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.0149]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0149]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0149]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0149]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0149]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.0149]\n",
            "Epoch 960: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0149]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0149]\n",
            "Epoch 961: 100%|██████████| 1/1 [00:02<00:00,  0.35it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.218, valid_loss=0.0149]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.0149]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0149]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0149]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.0149]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0149]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0149]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.328, train_loss_epoch=0.328, valid_loss=0.0149]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0149]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0149]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.0149]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0149]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0149]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0149]\n",
            "Epoch 974: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.265, valid_loss=0.0149]\n",
            "Epoch 974: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0149]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0149]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0149]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0149]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.196, train_loss_epoch=0.196, valid_loss=0.0149]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0149]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0149]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0149]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0149]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0149]\n",
            "Epoch 983: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0149]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0149]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0149]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0149]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0149]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0149]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.0149]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0149]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0149]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.0149]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0149]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0149]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0149]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0149]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.0149]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.219, valid_loss=0.0149]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.68it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.0149]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.0149]\n",
            "Epoch 1001: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.205, valid_loss=0.0149]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0149]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0149]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0149]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0149]\n",
            "Epoch 1005: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.173, valid_loss=0.0149]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.0149]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0149]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0149]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0149]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.0149]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0149]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0149]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0149]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0149]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0149]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0149]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.0149]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0149]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.128, train_loss_epoch=0.128, valid_loss=0.0149]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0149]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0149]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.122, train_loss_epoch=0.122, valid_loss=0.0149]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0149]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0149]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0149]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0149]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0149]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.0149]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0149]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0149]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.164, train_loss_epoch=0.164, valid_loss=0.0149]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0149]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0149]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.142, train_loss_epoch=0.142, valid_loss=0.0149]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]        \n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0149]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0149]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155, valid_loss=0.0149]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.158, train_loss_epoch=0.158, valid_loss=0.0149]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=0.0149]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.144, train_loss_epoch=0.144, valid_loss=0.0149]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0149]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0149]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0149]\n",
            "Epoch 1051: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.151, valid_loss=0.0149]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.0149]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0149]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0149]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0149]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.0149]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0149]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.135, train_loss_epoch=0.135, valid_loss=0.0149]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.255, train_loss_epoch=0.255, valid_loss=0.0149]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0149]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0149]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0149]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0149]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0149]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0149]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0149]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0149]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0149]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0149]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0149]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.0149]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0149]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.0149]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0149]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.0149]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0149]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0149]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0149]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0149]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0149]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251, valid_loss=0.0149]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0149]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0149]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0149]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.200, train_loss_epoch=0.200, valid_loss=0.0149]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0149]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0149]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.0149]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0149]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139, valid_loss=0.0149]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0149]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0149]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.0149]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0149]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:03<00:00,  0.33it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.170, valid_loss=0.0149]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 34.15it/s]\u001b[A\n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0149]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.0149]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0149]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.147, train_loss_epoch=0.147, valid_loss=0.0149]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132, valid_loss=0.0149]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0149]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0149]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178, valid_loss=0.0149]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157, valid_loss=0.0149]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0149]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0149]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0149]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0149]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0149]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.151, train_loss_epoch=0.151, valid_loss=0.0149]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0149]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126, valid_loss=0.0149]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0149]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0149]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.131, train_loss_epoch=0.131, valid_loss=0.0149]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0149]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.146, train_loss_epoch=0.146, valid_loss=0.0149]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0149]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.136, train_loss_epoch=0.136, valid_loss=0.0149]\n",
            "Epoch 1125: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.136, valid_loss=0.0149]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0149]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0149]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0149]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0149]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0149]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150, valid_loss=0.0149]\n",
            "Epoch 1131: 100%|██████████| 1/1 [00:02<00:00,  0.49it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.150, valid_loss=0.0149]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.0149]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0149]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0149]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0149]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0149]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0149]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0149]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0149]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0149]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0149]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.183, train_loss_epoch=0.183, valid_loss=0.0149]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0149]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0149]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1145: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0149]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0149]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0149]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.0149]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 1150: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0149]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0149]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.217, train_loss_epoch=0.217, valid_loss=0.0149]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170, valid_loss=0.0149]\n",
            "Epoch 1154: 100%|██████████| 1/1 [00:03<00:00,  0.32it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.170, valid_loss=0.0149]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0149]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.154, train_loss_epoch=0.154, valid_loss=0.0149]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120, valid_loss=0.0149]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0149]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0149]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177, valid_loss=0.0149]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.0149]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148, valid_loss=0.0149]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0149]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130, valid_loss=0.0149]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.0149]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.0149]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.165, train_loss_epoch=0.165, valid_loss=0.0149]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.161, train_loss_epoch=0.161, valid_loss=0.0149]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.176, train_loss_epoch=0.176, valid_loss=0.0149]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0149]\n",
            "Epoch 1173: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.175, valid_loss=0.0149]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0149]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.175, train_loss_epoch=0.175, valid_loss=0.0149]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.173, train_loss_epoch=0.173, valid_loss=0.0149]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0149]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0149]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0149]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0149]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0149]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171, valid_loss=0.0149]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0149]\n",
            "Epoch 1183: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.212, valid_loss=0.0149]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159, valid_loss=0.0149]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0149]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.152, train_loss_epoch=0.152, valid_loss=0.0149]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.198, train_loss_epoch=0.198, valid_loss=0.0149]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0149]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0149]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0149]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0149]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 1192: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 1192: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.201, valid_loss=0.0149]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153, valid_loss=0.0149]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0149]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.145, train_loss_epoch=0.145, valid_loss=0.0149]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.174, train_loss_epoch=0.174, valid_loss=0.0149]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.143, train_loss_epoch=0.143, valid_loss=0.0149]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0149]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0149]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 18:26:52,699\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=0.168, train_loss_epoch=0.168, valid_loss=0.0149]\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.168, valid_loss=0.0149]\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 71.00it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=5472)\u001b[0m \r                                                                      \u001b[A\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.168, valid_loss=0.0149]\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0149]\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162, valid_loss=0.0149]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=16289)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 2025-06-15 18:27:07.817615: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m E0000 00:00:1750012027.869396   16388 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m E0000 00:00:1750012027.885267   16388 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 2025-06-15 18:27:07.944405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 3 | blocks       | ModuleList    | 9.7 M  | train\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 9.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 9.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 38.977    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.339, train_loss_epoch=0.339]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.40, train_loss_epoch=95.40]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=67.30, train_loss_epoch=67.30]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=398.0, train_loss_epoch=398.0]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.640, train_loss_epoch=3.640]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.60, train_loss_epoch=76.60]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.600, train_loss_epoch=4.600]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.250, train_loss_epoch=5.250]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.120, train_loss_epoch=4.120]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.000, train_loss_epoch=1.000]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.301, train_loss_epoch=0.301]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.20, train_loss_epoch=21.20]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.972, train_loss_epoch=0.972]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.439, train_loss_epoch=0.439]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.464, train_loss_epoch=0.464]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.958, train_loss_epoch=0.958]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.983, train_loss_epoch=0.983]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.505, train_loss_epoch=0.505]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.857, train_loss_epoch=0.857]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.557, train_loss_epoch=0.557]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.772, train_loss_epoch=0.772]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.921, train_loss_epoch=0.921]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.531, train_loss_epoch=0.531]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.759, train_loss_epoch=0.759]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.875, train_loss_epoch=0.875]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.548, train_loss_epoch=0.548]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.887, train_loss_epoch=0.887]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.120, train_loss_epoch=0.120]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.544, train_loss_epoch=0.544]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.178, train_loss_epoch=0.178]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0935, train_loss_epoch=0.0935]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.170, train_loss_epoch=0.170]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.155, train_loss_epoch=0.155]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.304, train_loss_epoch=0.304]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.310, train_loss_epoch=0.310]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.412, train_loss_epoch=0.412]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.413, train_loss_epoch=0.413]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.134, train_loss_epoch=0.134]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.134]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.33it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.530]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.562, train_loss_epoch=0.562, valid_loss=0.530]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.530]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.530]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.530]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.363, train_loss_epoch=0.363, valid_loss=0.530]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.349, train_loss_epoch=0.349, valid_loss=0.530]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.530]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.156, train_loss_epoch=0.156, valid_loss=0.530]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.275, train_loss_epoch=0.275, valid_loss=0.530]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.530]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.116, train_loss_epoch=0.116, valid_loss=0.530]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.160, train_loss_epoch=0.160, valid_loss=0.530]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.530]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.163, train_loss_epoch=0.163, valid_loss=0.530]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0894, train_loss_epoch=0.0894, valid_loss=0.530]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.167, train_loss_epoch=0.167, valid_loss=0.530]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.530]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.530]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=0.530]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.530]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.149, train_loss_epoch=0.149, valid_loss=0.530]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.127, train_loss_epoch=0.127, valid_loss=0.530]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=0.530]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110, valid_loss=0.530]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.129, train_loss_epoch=0.129, valid_loss=0.530]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114, valid_loss=0.530]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.106, train_loss_epoch=0.106, valid_loss=0.530]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.530]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0878, train_loss_epoch=0.0878, valid_loss=0.530]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.113, train_loss_epoch=0.113, valid_loss=0.530]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0768, train_loss_epoch=0.0768, valid_loss=0.530]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804, valid_loss=0.530]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0754, train_loss_epoch=0.0754, valid_loss=0.530]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.530]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.108, train_loss_epoch=0.108, valid_loss=0.530]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0959, train_loss_epoch=0.0959, valid_loss=0.530]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774, valid_loss=0.530]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0958, train_loss_epoch=0.0958, valid_loss=0.530]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0823, train_loss_epoch=0.0823, valid_loss=0.530]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0847, train_loss_epoch=0.0847, valid_loss=0.530]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0872, train_loss_epoch=0.0872, valid_loss=0.530]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0776, train_loss_epoch=0.0776, valid_loss=0.530]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0856, train_loss_epoch=0.0856, valid_loss=0.530]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.072, train_loss_epoch=0.072, valid_loss=0.530]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0812, train_loss_epoch=0.0812, valid_loss=0.530]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0722, train_loss_epoch=0.0722, valid_loss=0.530]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=0.530]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0678, train_loss_epoch=0.0678, valid_loss=0.530]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0828, train_loss_epoch=0.0828, valid_loss=0.530]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=0.530]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=0.530]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.078, train_loss_epoch=0.078, valid_loss=0.530]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=0.530]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=0.530]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0761, train_loss_epoch=0.0761, valid_loss=0.530]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0745, train_loss_epoch=0.0745, valid_loss=0.530]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.530]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.530]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0691, train_loss_epoch=0.0691, valid_loss=0.530]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s, v_num=0, train_loss_step=0.0777, train_loss_epoch=0.0691, valid_loss=0.530]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0777, train_loss_epoch=0.0777, valid_loss=0.530]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=0.530]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0921, train_loss_epoch=0.0921, valid_loss=0.530]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.077, train_loss_epoch=0.077, valid_loss=0.530]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0966, train_loss_epoch=0.0966, valid_loss=0.530]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107, valid_loss=0.530]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0939, train_loss_epoch=0.0939, valid_loss=0.530]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0711, train_loss_epoch=0.0711, valid_loss=0.530]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0798, train_loss_epoch=0.0798, valid_loss=0.530]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0796, train_loss_epoch=0.0796, valid_loss=0.530]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0837, train_loss_epoch=0.0837, valid_loss=0.530]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655, valid_loss=0.530]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0837, train_loss_epoch=0.0837, valid_loss=0.530]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.530]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=0.530]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=0.530]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0707, train_loss_epoch=0.0707, valid_loss=0.530]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.530]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0775, train_loss_epoch=0.0775, valid_loss=0.530]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0716, train_loss_epoch=0.0716, valid_loss=0.530]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0689, train_loss_epoch=0.0689, valid_loss=0.530]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0829, train_loss_epoch=0.0829, valid_loss=0.530]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.530]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0857, train_loss_epoch=0.0857, valid_loss=0.530]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914, valid_loss=0.530]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.072, train_loss_epoch=0.072, valid_loss=0.530]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.104, train_loss_epoch=0.104, valid_loss=0.530]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105, valid_loss=0.530]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.530]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0923, train_loss_epoch=0.0923, valid_loss=0.530]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0986, train_loss_epoch=0.0986, valid_loss=0.530]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0838, train_loss_epoch=0.0838, valid_loss=0.530]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0813, train_loss_epoch=0.0813, valid_loss=0.530]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0845, train_loss_epoch=0.0845, valid_loss=0.530]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=0.530]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0809, train_loss_epoch=0.0809, valid_loss=0.530]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=0.530]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0887, train_loss_epoch=0.0887, valid_loss=0.530]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0795, train_loss_epoch=0.0795, valid_loss=0.530]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0827, train_loss_epoch=0.0827, valid_loss=0.530]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s, v_num=0, train_loss_step=0.0901, train_loss_epoch=0.0827, valid_loss=0.530]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.64it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0901, train_loss_epoch=0.0901, valid_loss=0.0349]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0858, train_loss_epoch=0.0858, valid_loss=0.0349]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0731, train_loss_epoch=0.0731, valid_loss=0.0349]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0758, train_loss_epoch=0.0758, valid_loss=0.0349]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0823, train_loss_epoch=0.0823, valid_loss=0.0349]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0722, train_loss_epoch=0.0722, valid_loss=0.0349]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0737, train_loss_epoch=0.0737, valid_loss=0.0349]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0815, train_loss_epoch=0.0815, valid_loss=0.0349]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0829, train_loss_epoch=0.0829, valid_loss=0.0349]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726, valid_loss=0.0349]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0723, train_loss_epoch=0.0723, valid_loss=0.0349]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0757, train_loss_epoch=0.0757, valid_loss=0.0349]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=0.0349]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0715, train_loss_epoch=0.0715, valid_loss=0.0349]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0793, train_loss_epoch=0.0793, valid_loss=0.0349]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=0.0349]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0349]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0729, train_loss_epoch=0.0729, valid_loss=0.0349]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0349]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=0.0349]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735, valid_loss=0.0349]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=0.0349]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0716, train_loss_epoch=0.0716, valid_loss=0.0349]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709, valid_loss=0.0349]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0349]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0701, train_loss_epoch=0.0701, valid_loss=0.0349]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=0.0349]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=0.0349]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0683, train_loss_epoch=0.0683, valid_loss=0.0349]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0722, train_loss_epoch=0.0722, valid_loss=0.0349]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0714, train_loss_epoch=0.0714, valid_loss=0.0349]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.0349]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0721, train_loss_epoch=0.0721, valid_loss=0.0349]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0694, train_loss_epoch=0.0694, valid_loss=0.0349]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.069, train_loss_epoch=0.069, valid_loss=0.0349]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0718, train_loss_epoch=0.0718, valid_loss=0.0349]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0349]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0732, train_loss_epoch=0.0732, valid_loss=0.0349]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0708, train_loss_epoch=0.0708, valid_loss=0.0349]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0726, train_loss_epoch=0.0726, valid_loss=0.0349]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.072, train_loss_epoch=0.072, valid_loss=0.0349]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655, valid_loss=0.0349]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0733, train_loss_epoch=0.0733, valid_loss=0.0349]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=0.0349]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=0.0349]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=0.0349]\n",
            "Epoch 245: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0349]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0349]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688, valid_loss=0.0349]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0699, train_loss_epoch=0.0699, valid_loss=0.0349]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=0.0349]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=0.0349]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=0.0349]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702, valid_loss=0.0349]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0349]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0675, train_loss_epoch=0.0675, valid_loss=0.0349]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0713, train_loss_epoch=0.0713, valid_loss=0.0349]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.0349]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0698, train_loss_epoch=0.0698, valid_loss=0.0349]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=0.0349]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0678, train_loss_epoch=0.0678, valid_loss=0.0349]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.0349]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.0349]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0712, train_loss_epoch=0.0712, valid_loss=0.0349]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.065, train_loss_epoch=0.065, valid_loss=0.0349]\n",
            "Epoch 263: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s, v_num=0, train_loss_step=0.0708, train_loss_epoch=0.0708, valid_loss=0.0349]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0708, train_loss_epoch=0.0708, valid_loss=0.0349]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=0.0349]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=0.0349]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.0349]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.0349]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0349]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0686, train_loss_epoch=0.0686, valid_loss=0.0349]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.065, train_loss_epoch=0.065, valid_loss=0.0349]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=0.0349]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.0349]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0675, train_loss_epoch=0.0675, valid_loss=0.0349]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.0349]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=0.0349]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0621, train_loss_epoch=0.0621, valid_loss=0.0349]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.0349]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.0349]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=0.0349]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.0349]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0349]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679, valid_loss=0.0349]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.0349]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.0349]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687, valid_loss=0.0349]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.0349]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.0349]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.0349]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0349]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0349]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.0349]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=0.0349]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0349]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=0.0349]\n",
            "Epoch 295: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0349]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0349]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0349]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=0.0349]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0349]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0653, valid_loss=0.0349]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.14it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0653, valid_loss=0.0199]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0199]        \n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0199]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.0199]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=0.0199]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655, valid_loss=0.0199]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=0.0199]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0199]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=0.0199]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=0.0199]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.0199]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0199]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.0199]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0199]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0199]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.0199]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0199]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=0.0199]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0199]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.0199]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=0.0199]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0199]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.0199]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=0.0199]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.0199]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=0.0199]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0199]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.0199]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=0.0199]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0199]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0199]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0199]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.0199]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=0.0199]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.0199]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0199]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=0.0199]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=0.0199]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0199]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0652, train_loss_epoch=0.0652, valid_loss=0.0199]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=0.0199]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=0.0199]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.0199]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.0199]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0199]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=0.0199]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=0.0199]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0199]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0199]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.0199]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.0199]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0199]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684, valid_loss=0.0199]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=0.0199]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=0.0199]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0199]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0199]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=0.0199]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.065, train_loss_epoch=0.065, valid_loss=0.0199]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.0199]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=0.0199]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.0199]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0199]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=0.0199]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.0199]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.0199]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=0.0199]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=0.0199]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=0.0199]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0199]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.0199]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0676, train_loss_epoch=0.0676, valid_loss=0.0199]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0199]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.0199]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=0.0199]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=0.0199]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0682, train_loss_epoch=0.0682, valid_loss=0.0199]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=0.0199]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0199]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=0.0199]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.0199]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.0199]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=0.0199]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0199]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0199]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0199]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=0.0199]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0199]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0678, train_loss_epoch=0.0678, valid_loss=0.0199]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668, valid_loss=0.0199]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.0199]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=0.0199]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0199]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=0.0199]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0698, train_loss_epoch=0.0698, valid_loss=0.0199]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0199]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.0199]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.0199]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0199]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0199]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.067, train_loss_epoch=0.067, valid_loss=0.0199]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=0.0199]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0631, valid_loss=0.0199]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.49it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617, valid_loss=0.021]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.021]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.021]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=0.021]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.021]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=0.021]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.021]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.021]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=0.021]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=0.021]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.021]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.021]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.021]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.021]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.021]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.021]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.021]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655, valid_loss=0.021]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=0.021]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.021]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=0.021]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.021]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0625, train_loss_epoch=0.0625, valid_loss=0.021]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.021]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=0.021]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.021]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.021]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=0.021]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.021]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.021]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.021]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.021]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.021]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=0.021]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=0.021]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.021]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.021]\n",
            "Epoch 434: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0636, valid_loss=0.021]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.021]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.021]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.021]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=0.021]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=0.021]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0697, train_loss_epoch=0.0697, valid_loss=0.021]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.021]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.021]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.021]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=0.021]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.021]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=0.021]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=0.021]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.021]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.021]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0693, train_loss_epoch=0.0693, valid_loss=0.021]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=0.021]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.021]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.021]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.021]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=0.021]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.021]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=0.021]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.021]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.021]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.021]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0643, train_loss_epoch=0.0643, valid_loss=0.021]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=0.021]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.021]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.063, train_loss_epoch=0.063, valid_loss=0.021]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.021]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0619, train_loss_epoch=0.0619, valid_loss=0.021]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=0.021]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.021]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.021]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642, valid_loss=0.021]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.021]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672, valid_loss=0.021]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=0.021]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.021]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.021]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=0.021]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0663, train_loss_epoch=0.0663, valid_loss=0.021]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=0.021]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s, v_num=0, train_loss_step=0.065, train_loss_epoch=0.065, valid_loss=0.021] \n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.065, train_loss_epoch=0.065, valid_loss=0.021]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.021]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=0.021]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0629, train_loss_epoch=0.0629, valid_loss=0.021]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607, valid_loss=0.021]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.021]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=0.021]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679, valid_loss=0.021]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.021]\n",
            "Epoch 487: 100%|██████████| 1/1 [00:00<00:00,  2.36it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.021]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.021]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=0.021]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0632, train_loss_epoch=0.0632, valid_loss=0.021]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.021]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0625, train_loss_epoch=0.0625, valid_loss=0.021]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.021]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=0.021]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=0.021]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.021]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.021]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.021]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.021]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0639, valid_loss=0.021]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.39it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.0174]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0677, train_loss_epoch=0.0677, valid_loss=0.0174]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=0.0174]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0659, train_loss_epoch=0.0659, valid_loss=0.0174]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0174]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=0.0174]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0635, train_loss_epoch=0.0635, valid_loss=0.0174]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.0174]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=0.0174]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0174]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0174]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.063, train_loss_epoch=0.063, valid_loss=0.0174]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0174]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0613, train_loss_epoch=0.0613, valid_loss=0.0174]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.0174]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.0174]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=0.0174]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0649, train_loss_epoch=0.0649, valid_loss=0.0174]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704, valid_loss=0.0174]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0622, train_loss_epoch=0.0622, valid_loss=0.0174]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.0174]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0174]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644, valid_loss=0.0174]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.066, train_loss_epoch=0.066, valid_loss=0.0174]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.0174]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0646, train_loss_epoch=0.0646, valid_loss=0.0174]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0655, train_loss_epoch=0.0655, valid_loss=0.0174]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.0174]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0174]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0174]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.0174]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0174]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=0.0174]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0174]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0638, train_loss_epoch=0.0638, valid_loss=0.0174]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0174]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0681, train_loss_epoch=0.0681, valid_loss=0.0174]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0174]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0641, train_loss_epoch=0.0641, valid_loss=0.0174]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0174]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=0.0174]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662, valid_loss=0.0174]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0174]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0647, train_loss_epoch=0.0647, valid_loss=0.0174]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0174]\n",
            "Epoch 544: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=0.0174]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=0.0174]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.0174]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.0174]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0174]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0664, train_loss_epoch=0.0664, valid_loss=0.0174]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.0174]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0628, train_loss_epoch=0.0628, valid_loss=0.0174]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0671, train_loss_epoch=0.0671, valid_loss=0.0174]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673, valid_loss=0.0174]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0174]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.0174]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.0174]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.0174]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719, valid_loss=0.0174]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0174]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064, valid_loss=0.0174]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0605, train_loss_epoch=0.0605, valid_loss=0.0174]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0634, train_loss_epoch=0.0634, valid_loss=0.0174]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0174]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651, valid_loss=0.0174]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656, valid_loss=0.0174]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648, valid_loss=0.0174]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0685, train_loss_epoch=0.0685, valid_loss=0.0174]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.0174]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0637, train_loss_epoch=0.0637, valid_loss=0.0174]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.063, train_loss_epoch=0.063, valid_loss=0.0174]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.068, train_loss_epoch=0.068, valid_loss=0.0174]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.0174]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0661, train_loss_epoch=0.0661, valid_loss=0.0174]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0674, train_loss_epoch=0.0674, valid_loss=0.0174]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0174]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=0.0174]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0631, train_loss_epoch=0.0631, valid_loss=0.0174]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0658, train_loss_epoch=0.0658, valid_loss=0.0174]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0665, train_loss_epoch=0.0665, valid_loss=0.0174]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0627, train_loss_epoch=0.0627, valid_loss=0.0174]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0667, train_loss_epoch=0.0667, valid_loss=0.0174]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0616, train_loss_epoch=0.0616, valid_loss=0.0174]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0666, train_loss_epoch=0.0666, valid_loss=0.0174]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636, valid_loss=0.0174]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0695, train_loss_epoch=0.0695, valid_loss=0.0174]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0669, train_loss_epoch=0.0669, valid_loss=0.0174]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639, valid_loss=0.0174]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.0174]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0653, train_loss_epoch=0.0653, valid_loss=0.0174]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0611, train_loss_epoch=0.0611, valid_loss=0.0174]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0623, train_loss_epoch=0.0623, valid_loss=0.0174]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0645, train_loss_epoch=0.0645, valid_loss=0.0174]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0657, train_loss_epoch=0.0657, valid_loss=0.0174]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.0174]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0625, train_loss_epoch=0.0625, valid_loss=0.0174]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062, valid_loss=0.0174]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0625, train_loss_epoch=0.0625, valid_loss=0.0174]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0624, train_loss_epoch=0.0624, valid_loss=0.0174]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.0174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 18:32:14,958\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (168, 24, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m `Trainer.fit` stopped: `max_steps=600.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654, valid_loss=0.0174]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0654, valid_loss=0.0174]\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.56it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=16289)\u001b[0m \r                                                                       \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0654, valid_loss=0.0155]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.0155]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.0633, train_loss_epoch=0.0633, valid_loss=0.0155]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=17701)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 2025-06-15 18:32:29.153569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m E0000 00:00:1750012349.186292   17788 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m E0000 00:00:1750012349.195610   17788 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 2025-06-15 18:32:29.226006: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 3 | blocks       | ModuleList    | 5.2 M  | train\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 5.2 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 5.2 M     Total params\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 20.997    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 42.82it/s]\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \r                                                                           \n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.297, train_loss_epoch=0.297]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.157, train_loss_epoch=0.157]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.148, train_loss_epoch=0.148]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0865, train_loss_epoch=0.0865]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0987, train_loss_epoch=0.0987]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0914, train_loss_epoch=0.0914]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0867, train_loss_epoch=0.0867]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0922, train_loss_epoch=0.0922]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0922, train_loss_epoch=0.0922]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0819, train_loss_epoch=0.0819]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0784, train_loss_epoch=0.0784]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0821, train_loss_epoch=0.0821]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0808, train_loss_epoch=0.0808]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0742, train_loss_epoch=0.0742]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.073, train_loss_epoch=0.073]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0755, train_loss_epoch=0.0755]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0737, train_loss_epoch=0.0737]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0708, train_loss_epoch=0.0708]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0687, train_loss_epoch=0.0687]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.070, train_loss_epoch=0.070]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=0.0668, train_loss_epoch=0.0668]\n",
            "Epoch 29: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0656, train_loss_epoch=0.0656]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0679, train_loss_epoch=0.0679]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0654, train_loss_epoch=0.0654]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0651, train_loss_epoch=0.0651]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0648, train_loss_epoch=0.0648]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0636, train_loss_epoch=0.0636]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0626, train_loss_epoch=0.0626]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.062, train_loss_epoch=0.062]\n",
            "Epoch 38: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.062]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0617, train_loss_epoch=0.0617]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0613, train_loss_epoch=0.0613]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0604, train_loss_epoch=0.0604]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0607, train_loss_epoch=0.0607]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.060, train_loss_epoch=0.060]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.059, train_loss_epoch=0.059]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0592, train_loss_epoch=0.0592]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0597, train_loss_epoch=0.0597]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0594, train_loss_epoch=0.0594]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0576, train_loss_epoch=0.0576]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0574, train_loss_epoch=0.0574]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0576, train_loss_epoch=0.0576]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0552, train_loss_epoch=0.0552]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0559, train_loss_epoch=0.0559]\n",
            "Epoch 54: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=0.0562, train_loss_epoch=0.0562]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0562, train_loss_epoch=0.0562]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0534, train_loss_epoch=0.0534]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0521, train_loss_epoch=0.0521]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0551, train_loss_epoch=0.0551]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0526, train_loss_epoch=0.0526]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0508, train_loss_epoch=0.0508]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0494, train_loss_epoch=0.0494]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0482, train_loss_epoch=0.0482]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0475, train_loss_epoch=0.0475]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0477, train_loss_epoch=0.0477]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0476, train_loss_epoch=0.0476]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0475, train_loss_epoch=0.0475]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0466, train_loss_epoch=0.0466]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0454, train_loss_epoch=0.0454]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0446, train_loss_epoch=0.0446]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.045, train_loss_epoch=0.045]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0442, train_loss_epoch=0.0442]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0449, train_loss_epoch=0.0449]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0427, train_loss_epoch=0.0427]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0423]\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.00it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433, valid_loss=0.00943]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=0.00943]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=0.00943]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416, valid_loss=0.00943]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=0.00943]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=0.00943]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424, valid_loss=0.00943]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=0.00943]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=0.00943]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=0.00943]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0423, train_loss_epoch=0.0423, valid_loss=0.00943]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.00943]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=0.00943]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=0.00943]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0421, train_loss_epoch=0.0421, valid_loss=0.00943]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=0.00943]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=0.00943]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=0.00943]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.00943]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=0.00943]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=0.00943]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=0.00943]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.00943]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=0.00943]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403, valid_loss=0.00943]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=0.00943]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=0.00943]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.00943]\n",
            "Epoch 126: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0401, valid_loss=0.00943]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=0.00943]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=0.00943]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=0.00943]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=0.00943]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=0.00943]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.00943]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=0.00943]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=0.00943]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=0.00943]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=0.00943]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.00943]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=0.00943]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=0.00943]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=0.00943]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.00943]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=0.00943]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.00943]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=0.00943]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=0.00943]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=0.00943]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=0.00943]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=0.00943]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0369, train_loss_epoch=0.0369, valid_loss=0.00943]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.00943]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.00943]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=0.00943]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=0.00943]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371, valid_loss=0.00943]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.00943]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=0.00943]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0364, train_loss_epoch=0.0364, valid_loss=0.00943]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.00943]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.00943]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=0.00943]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.00943]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.00943]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.00943]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.00943]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=0.00943]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.00943]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.00943]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.00943]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.00943]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.00943]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=0.00943]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.00943]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.00943]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.00943]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.00943]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.00943]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.00943]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.00943]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.00943]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.00943]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=0.00943]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=0.00943]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.00943]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.00943]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.00943]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=0.00943]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.00943]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.00943]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=0.00943]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.00943]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.00943]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.00943]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.00943]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.00943]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.00943]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.00943]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.00943]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.00943]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=0.00943]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0333, valid_loss=0.00943]\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.54it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.00732]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.00732]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.00732]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.00732]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.00732]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.00732]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.00732]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.00732]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=0.00732]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.00732]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=0.00732]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.00732]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=0.00732]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.00732]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.00732]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=0.00732]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.00732]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=0.00732]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=0.00732]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=0.00732]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=0.00732]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=0.00732]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.00732]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.00732]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=0.00732]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=0.00732]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=0.00732]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.00732]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.00732]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.00732]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.00732]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=0.00732]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=0.00732]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=0.00732]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=0.00732]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=0.00732]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.00732]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.00732]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=0.00732]\n",
            "Epoch 238: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0283, valid_loss=0.00732]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.00732]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.00732]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0289, train_loss_epoch=0.0289, valid_loss=0.00732]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.00732]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.00732]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=0.00732]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=0.00732]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.00732]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.00732]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.00732]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.00732]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=0.00732]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=0.00732]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.00732]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.00732]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.00732]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.00732]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.00732]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.00732]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.00732]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.00732]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.00732]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=0.00732]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.00732]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.00732]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.00732]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.00732]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.00732]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.00732]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.00732]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.00732]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.00732]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256, valid_loss=0.00732]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.00732]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.00732]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.00732]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.00732]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.00732]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264, valid_loss=0.00732]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.00732]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.00732]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.00732]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.00732]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256, valid_loss=0.00732]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.00732]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247, valid_loss=0.00732]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.00732]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.00732]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.00732]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.00732]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.00732]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.00732]\n",
            "Epoch 290: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.00732]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.00732]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.00732]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00732]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00732]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=0.00732]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0243, train_loss_epoch=0.0243, valid_loss=0.00732]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.025, train_loss_epoch=0.025, valid_loss=0.00732]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=0.00732]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238, valid_loss=0.00732]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00732]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00732]\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.52it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245, valid_loss=0.00708]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.00708]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242, valid_loss=0.00708]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=0.00708]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.00708]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.00708]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.024, train_loss_epoch=0.024, valid_loss=0.00708]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0229, train_loss_epoch=0.0229, valid_loss=0.00708]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237, valid_loss=0.00708]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0241, train_loss_epoch=0.0241, valid_loss=0.00708]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0236, train_loss_epoch=0.0236, valid_loss=0.00708]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=0.00708]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=0.00708]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=0.00708]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=0.00708]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=0.00708]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=0.00708]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=0.00708]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=0.00708]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.00708]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0225, train_loss_epoch=0.0225, valid_loss=0.00708]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=0.00708]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.00708]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=0.00708]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=0.00708]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=0.00708]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=0.00708]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=0.00708]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.00708]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=0.00708]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=0.00708]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=0.00708]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=0.00708]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=0.00708]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=0.00708]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=0.00708]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=0.00708]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=0.00708]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0218, train_loss_epoch=0.0218, valid_loss=0.00708]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=0.00708]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=0.00708]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=0.00708]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208, valid_loss=0.00708]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.00708]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.00708]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0215, train_loss_epoch=0.0215, valid_loss=0.00708]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=0.00708]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0205, train_loss_epoch=0.0205, valid_loss=0.00708]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021, valid_loss=0.00708]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203, valid_loss=0.00708]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203, valid_loss=0.00708]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.00708]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.00708]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.00708]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.00708]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0199, train_loss_epoch=0.0199, valid_loss=0.00708]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.00708]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0199, train_loss_epoch=0.0199, valid_loss=0.00708]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=0.00708]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.00708]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=0.00708]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0196, train_loss_epoch=0.0196, valid_loss=0.00708]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00708]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.00708]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.00708]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.00708]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=0.00708]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192, valid_loss=0.00708]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0196, train_loss_epoch=0.0196, valid_loss=0.00708]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0193, train_loss_epoch=0.0193, valid_loss=0.00708]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.00708]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00708]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00708]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.00708]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.00708]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00708]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.00708]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00708]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192, valid_loss=0.00708]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.00708]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192, valid_loss=0.00708]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00708]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=0.00708]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00708]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0191, train_loss_epoch=0.0191, valid_loss=0.00708]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.00708]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=0.00708]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.00708]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.00708]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.00708]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019, valid_loss=0.00708]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.00708]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.00708]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.00708]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.00708]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0181, train_loss_epoch=0.0181, valid_loss=0.00708]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=0.00708]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.00708]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=0.00708]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=0.00708]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0183, valid_loss=0.00708]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.03it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.0046]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.0046]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.0046]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=0.0046]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0181, train_loss_epoch=0.0181, valid_loss=0.0046]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.0046]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.0046]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=0.0046]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.0046]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.0046]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.0046]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=0.0046]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.0046]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.0046]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0183, train_loss_epoch=0.0183, valid_loss=0.0046]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018, valid_loss=0.0046]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018, valid_loss=0.0046]\n",
            "Epoch 415: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.018, valid_loss=0.0046]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.0046]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.0046]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018, valid_loss=0.0046]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.0046]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.0046]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0181, train_loss_epoch=0.0181, valid_loss=0.0046]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.0046]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.0046]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.0046]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.0046]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.0046]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.0046]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.0046]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018, valid_loss=0.0046]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0177, train_loss_epoch=0.0177, valid_loss=0.0046]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0177, train_loss_epoch=0.0177, valid_loss=0.0046]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=0.0046]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.0046]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0174, train_loss_epoch=0.0174, valid_loss=0.0046]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.0046]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0174, train_loss_epoch=0.0174, valid_loss=0.0046]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.0046]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.0046]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.0046]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.0046]\n",
            "Epoch 440: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.017, valid_loss=0.0046]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.0046]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.0046]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.0046]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=0.0046]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.0046]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.0046]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.0046]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.0046]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.0046]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.0046]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.0046]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.0046]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.0046]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.0046]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.0046]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0046]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0165, train_loss_epoch=0.0165, valid_loss=0.0046]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0165, train_loss_epoch=0.0165, valid_loss=0.0046]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.0046]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.0046]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.0046]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0046]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.0046]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.0046]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0046]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.0046]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.0046]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.0046]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163, valid_loss=0.0046]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0046]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0046]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0046]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=0.0046]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0046]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.0046]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0046]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0046]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.0046]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0046]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0046]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0046]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0046]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.0046]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=0.0046]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.0046]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0046]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.0046]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=0.0046]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.0046]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.0046]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.0046]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.0046]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0046]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0157, valid_loss=0.0046]\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.40it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.00525]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.00525]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00525]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00525]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.00525]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00525]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00525]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00525]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00525]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00525]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.00525]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00525]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00525]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00525]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00525]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00525]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.00525]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00525]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00525]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00525]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00525]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00525]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00525]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.00525]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=0.00525]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.00525]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00525]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00525]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00525]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00525]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00525]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00525]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.00525]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.00525]\n",
            "Epoch 533: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00525]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00525]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00525]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00525]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.00525]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00525]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00525]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00525]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00525]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00525]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00525]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.00525]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.00525]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00525]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00525]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00525]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00525]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.00525]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00525]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00525]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.00525]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00525]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00525]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00525]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00525]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00525]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00525]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00525]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00525]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.00525]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00525]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.00525]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00525]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00525]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00525]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00525]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00525]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00525]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00525]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00525]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.00525]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00525]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00525]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00525]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00525]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00525]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00525]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00525]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00525]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00525]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00525]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00525]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00525]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0133, valid_loss=0.00525]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.32it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00499]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00499]\n",
            "Epoch 601: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00499]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00499]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.00499]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00499]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00499]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.00499]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00499]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00499]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.00499]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00499]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00499]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.00499]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00499]\n",
            "Epoch 618: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00499]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.00499]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00499]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.00499]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00499]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00499]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.00499]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00499]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.00499]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00499]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00499]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00499]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00499]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00499]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00499]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00499]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.00499]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00499]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00499]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00499]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00499]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00499]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00499]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.00499]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00499]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00499]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00499]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00499]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.00499]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.00499]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00499]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.00499]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.00499]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00499]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00499]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.00499]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.00499]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00499]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.00499]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.00499]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.00499]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.00499]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00499]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.00499]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00499]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.00499]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00499]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.00499]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.00499]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.00499]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.00499]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.00499]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00499]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00499]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.00499]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00499]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00499]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00499]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00499]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00499]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00499]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00499]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00499]\n",
            "Epoch 690: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00499]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00499]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00499]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.00499]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00499]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.00499]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00499]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.00499]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.00499]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.00499]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0111, valid_loss=0.00499]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 141.06it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.004]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.004]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.004]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.004]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.004]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.004]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 715: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.004] \n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.004]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.004]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.004]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.004]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.004]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.004]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.004]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.004]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.004]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.004]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.004]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.004]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0105, valid_loss=0.004]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 147.83it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00393]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00393]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00393]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00991, train_loss_epoch=0.00991, valid_loss=0.00393]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00393]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.00393]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.00393]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00393]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.00997, valid_loss=0.00393]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.00393]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00981, train_loss_epoch=0.00981, valid_loss=0.00393]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00393]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00995, train_loss_epoch=0.00995, valid_loss=0.00393]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00393]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00393]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988, valid_loss=0.00393]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00998, train_loss_epoch=0.00998, valid_loss=0.00393]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.00997, valid_loss=0.00393]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00991, train_loss_epoch=0.00991, valid_loss=0.00393]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00393]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00993, train_loss_epoch=0.00993, valid_loss=0.00393]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00991, train_loss_epoch=0.00991, valid_loss=0.00393]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=0.00393]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00999, train_loss_epoch=0.00999, valid_loss=0.00393]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00975, train_loss_epoch=0.00975, valid_loss=0.00393]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00393]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00393]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00393]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00393]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00979, train_loss_epoch=0.00979, valid_loss=0.00393]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00999, train_loss_epoch=0.00999, valid_loss=0.00393]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988, valid_loss=0.00393]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0098, train_loss_epoch=0.0098, valid_loss=0.00393]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=0.00973, train_loss_epoch=0.0098, valid_loss=0.00393]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.21it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00973, train_loss_epoch=0.00973, valid_loss=0.00382]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00382]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00382]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00382]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00382]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00971, train_loss_epoch=0.00971, valid_loss=0.00382]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00979, train_loss_epoch=0.00979, valid_loss=0.00382]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00981, train_loss_epoch=0.00981, valid_loss=0.00382]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00382]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00382]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00984, train_loss_epoch=0.00984, valid_loss=0.00382]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00991, train_loss_epoch=0.00991, valid_loss=0.00382]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00962, train_loss_epoch=0.00962, valid_loss=0.00382]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.00382]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00382]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00999, train_loss_epoch=0.00999, valid_loss=0.00382]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00993, train_loss_epoch=0.00993, valid_loss=0.00382]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00981, train_loss_epoch=0.00981, valid_loss=0.00382]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00981, train_loss_epoch=0.00981, valid_loss=0.00382]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.00382]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00963, train_loss_epoch=0.00963, valid_loss=0.00382]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00977, train_loss_epoch=0.00977, valid_loss=0.00382]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00999, train_loss_epoch=0.00999, valid_loss=0.00382]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00972, train_loss_epoch=0.00972, valid_loss=0.00382]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00382]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00987, train_loss_epoch=0.00987, valid_loss=0.00382]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00996, train_loss_epoch=0.00996, valid_loss=0.00382]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00996, train_loss_epoch=0.00996, valid_loss=0.00382]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00382]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00975, train_loss_epoch=0.00975, valid_loss=0.00382]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00955, train_loss_epoch=0.00955, valid_loss=0.00382]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00951, train_loss_epoch=0.00951, valid_loss=0.00382]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00959, train_loss_epoch=0.00959, valid_loss=0.00382]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0096, train_loss_epoch=0.0096, valid_loss=0.00382]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00989, train_loss_epoch=0.00989, valid_loss=0.00382]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00967, train_loss_epoch=0.00967, valid_loss=0.00382]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00967, train_loss_epoch=0.00967, valid_loss=0.00382]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00976, train_loss_epoch=0.00976, valid_loss=0.00382]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00983, train_loss_epoch=0.00983, valid_loss=0.00382]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00382]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00991, train_loss_epoch=0.00991, valid_loss=0.00382]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.00997, valid_loss=0.00382]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00986, train_loss_epoch=0.00986, valid_loss=0.00382]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00971, train_loss_epoch=0.00971, valid_loss=0.00382]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0097, valid_loss=0.00382]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00968, train_loss_epoch=0.00968, valid_loss=0.00382]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00957, train_loss_epoch=0.00957, valid_loss=0.00382]\n",
            "Epoch 946: 100%|██████████| 1/1 [00:00<00:00,  1.48it/s, v_num=0, train_loss_step=0.00967, train_loss_epoch=0.00967, valid_loss=0.00382]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00967, train_loss_epoch=0.00967, valid_loss=0.00382]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00382]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00965, train_loss_epoch=0.00965, valid_loss=0.00382]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00969, train_loss_epoch=0.00969, valid_loss=0.00382]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00945, train_loss_epoch=0.00945, valid_loss=0.00382]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00968, train_loss_epoch=0.00968, valid_loss=0.00382]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00975, train_loss_epoch=0.00975, valid_loss=0.00382]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00382]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.00382]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00972, train_loss_epoch=0.00972, valid_loss=0.00382]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00949, train_loss_epoch=0.00949, valid_loss=0.00382]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00966, train_loss_epoch=0.00966, valid_loss=0.00382]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00952, train_loss_epoch=0.00952, valid_loss=0.00382]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00965, train_loss_epoch=0.00965, valid_loss=0.00382]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00974, train_loss_epoch=0.00974, valid_loss=0.00382]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00971, train_loss_epoch=0.00971, valid_loss=0.00382]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00965, train_loss_epoch=0.00965, valid_loss=0.00382]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0096, train_loss_epoch=0.0096, valid_loss=0.00382]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00962, train_loss_epoch=0.00962, valid_loss=0.00382]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00382]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.00382]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0097, valid_loss=0.00382]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00965, train_loss_epoch=0.00965, valid_loss=0.00382]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00966, train_loss_epoch=0.00966, valid_loss=0.00382]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00966, train_loss_epoch=0.00966, valid_loss=0.00382]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00951, train_loss_epoch=0.00951, valid_loss=0.00382]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00944, train_loss_epoch=0.00944, valid_loss=0.00382]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00948, train_loss_epoch=0.00948, valid_loss=0.00382]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00962, train_loss_epoch=0.00962, valid_loss=0.00382]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00963, train_loss_epoch=0.00963, valid_loss=0.00382]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0098, train_loss_epoch=0.0098, valid_loss=0.00382]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00382]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00977, train_loss_epoch=0.00977, valid_loss=0.00382]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00963, train_loss_epoch=0.00963, valid_loss=0.00382]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00938, train_loss_epoch=0.00938, valid_loss=0.00382]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00947, train_loss_epoch=0.00947, valid_loss=0.00382]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00969, train_loss_epoch=0.00969, valid_loss=0.00382]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0095, train_loss_epoch=0.0095, valid_loss=0.00382]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00973, train_loss_epoch=0.00973, valid_loss=0.00382]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00951, train_loss_epoch=0.00951, valid_loss=0.00382]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00972, train_loss_epoch=0.00972, valid_loss=0.00382]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00965, train_loss_epoch=0.00965, valid_loss=0.00382]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00942, train_loss_epoch=0.00942, valid_loss=0.00382]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00959, train_loss_epoch=0.00959, valid_loss=0.00382]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00951, train_loss_epoch=0.00951, valid_loss=0.00382]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0096, train_loss_epoch=0.0096, valid_loss=0.00382]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00954, train_loss_epoch=0.00954, valid_loss=0.00382]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0095, train_loss_epoch=0.0095, valid_loss=0.00382]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00927, train_loss_epoch=0.00927, valid_loss=0.00382]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00953, train_loss_epoch=0.00953, valid_loss=0.00382]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00963, train_loss_epoch=0.00963, valid_loss=0.00382]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00977, train_loss_epoch=0.00977, valid_loss=0.00382]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00382]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 18:41:44,645\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (4, 4, 4), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m `Trainer.fit` stopped: `max_steps=1000.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=0.00961, train_loss_epoch=0.00961, valid_loss=0.00382]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00961, valid_loss=0.00382]\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.35it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=17701)\u001b[0m \r                                                                      \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00961, valid_loss=0.00346]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988, valid_loss=0.00346]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988, valid_loss=0.00346]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=20119)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 2025-06-15 18:41:58.432440: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m E0000 00:00:1750012918.464780   20211 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m E0000 00:00:1750012918.474276   20211 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 2025-06-15 18:41:58.504878: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 3 | blocks       | ModuleList    | 9.7 M  | train\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 9.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 9.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 38.969    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.30, train_loss_epoch=27.30]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.11e+5, train_loss_epoch=5.11e+5]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.93e+8, train_loss_epoch=7.93e+8]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.47e+8, train_loss_epoch=6.47e+8]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+8, train_loss_epoch=2.93e+8]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+8, train_loss_epoch=1.35e+8]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.28e+5, train_loss_epoch=8.28e+5]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2e+7, train_loss_epoch=2e+7]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.79e+7, train_loss_epoch=1.79e+7]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+9, train_loss_epoch=1.16e+9]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+8, train_loss_epoch=1.68e+8]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+7, train_loss_epoch=1.31e+7]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.18e+8, train_loss_epoch=1.18e+8]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+7, train_loss_epoch=2.43e+7]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:01<00:00,  0.59it/s, v_num=0, train_loss_step=4.02e+8, train_loss_epoch=2.43e+7]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.02e+8, train_loss_epoch=4.02e+8]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.39e+7, train_loss_epoch=8.39e+7]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.04e+7, train_loss_epoch=2.04e+7]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.56e+6, train_loss_epoch=5.56e+6]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+8, train_loss_epoch=1.08e+8]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+8, train_loss_epoch=1.68e+8]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.47e+7, train_loss_epoch=8.47e+7]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.79e+7, train_loss_epoch=1.79e+7]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.75e+7, train_loss_epoch=1.75e+7]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.12e+6, train_loss_epoch=9.12e+6]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+7, train_loss_epoch=1.13e+7]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+7, train_loss_epoch=2.54e+7]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=9.89e+6, train_loss_epoch=2.54e+7]\n",
            "Epoch 26: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=9.89e+6, train_loss_epoch=9.89e+6]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.89e+6, train_loss_epoch=9.89e+6]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+7, train_loss_epoch=1.14e+7]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.61e+6, train_loss_epoch=4.61e+6]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.97e+6, train_loss_epoch=2.97e+6]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.69e+3, train_loss_epoch=1.69e+3]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.04e+3, train_loss_epoch=2.04e+3]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+3, train_loss_epoch=3.62e+3]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.19e+3, train_loss_epoch=5.19e+3]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.28e+3, train_loss_epoch=4.28e+3]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.5e+3, train_loss_epoch=3.5e+3]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.66e+3, train_loss_epoch=4.66e+3]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.43e+3, train_loss_epoch=6.43e+3]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.63e+3, train_loss_epoch=9.63e+3]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.82e+3, train_loss_epoch=6.82e+3]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.19e+3, train_loss_epoch=6.19e+3]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.65e+3, train_loss_epoch=9.65e+3]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.62e+3, train_loss_epoch=8.62e+3]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.61e+3, train_loss_epoch=5.61e+3]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.29e+3, train_loss_epoch=5.29e+3]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.63e+3, train_loss_epoch=7.63e+3]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.56e+3, train_loss_epoch=3.56e+3]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+3, train_loss_epoch=2.82e+3]\n",
            "Epoch 49: 100%|██████████| 1/1 [00:02<00:00,  0.35it/s, v_num=0, train_loss_step=6.06e+3, train_loss_epoch=2.82e+3]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.06e+3, train_loss_epoch=6.06e+3]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.04e+3, train_loss_epoch=8.04e+3]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.97e+3, train_loss_epoch=7.97e+3]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+3, train_loss_epoch=2.64e+3]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.74e+5, train_loss_epoch=5.74e+5]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.29e+5, train_loss_epoch=5.29e+5]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.77e+4, train_loss_epoch=4.77e+4]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+4, train_loss_epoch=1.34e+4]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.53e+5, train_loss_epoch=1.53e+5]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+3, train_loss_epoch=3.09e+3]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=404.0, train_loss_epoch=404.0]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=357.0, train_loss_epoch=357.0]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=297.0, train_loss_epoch=297.0]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=237.0, train_loss_epoch=237.0]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=175.0]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=111.0, train_loss_epoch=111.0]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=57.00, train_loss_epoch=57.00]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=392.0, train_loss_epoch=392.0]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+8, train_loss_epoch=1.05e+8]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+4, train_loss_epoch=1.42e+4]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+3, train_loss_epoch=3.07e+3]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+3, train_loss_epoch=2.16e+3]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+4, train_loss_epoch=2.95e+4]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=693.0, train_loss_epoch=693.0]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+3, train_loss_epoch=1.64e+3]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.52e+3, train_loss_epoch=3.52e+3]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.37e+3, train_loss_epoch=6.37e+3]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+3, train_loss_epoch=2.98e+3]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:02<00:00,  0.38it/s, v_num=0, train_loss_step=2.98e+3, train_loss_epoch=2.98e+3]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=433.0, train_loss_epoch=433.0]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=484.0, train_loss_epoch=484.0]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.9e+3, train_loss_epoch=1.9e+3]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3]\n",
            "Epoch 85: 100%|██████████| 1/1 [00:02<00:00,  0.37it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=128.0, train_loss_epoch=128.0]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.87e+3, train_loss_epoch=3.87e+3]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.7e+3, train_loss_epoch=4.7e+3]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.94e+3, train_loss_epoch=1.94e+3]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=326.0, train_loss_epoch=326.0]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.78e+3, train_loss_epoch=3.78e+3]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+3, train_loss_epoch=3.25e+3]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+3, train_loss_epoch=1.29e+3]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.88e+3, train_loss_epoch=1.88e+3]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=0, train_loss_step=3.29e+3, train_loss_epoch=1.88e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.78it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.29e+3, train_loss_epoch=3.29e+3, valid_loss=1.880]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+3, train_loss_epoch=2.96e+3, valid_loss=1.880]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+3, train_loss_epoch=1.56e+3, valid_loss=1.880]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.23e+3, train_loss_epoch=1.23e+3, valid_loss=1.880]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=1.880]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.14e+3, train_loss_epoch=2.14e+3, valid_loss=1.880]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+3, train_loss_epoch=1.27e+3, valid_loss=1.880]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=744.0, train_loss_epoch=744.0, valid_loss=1.880]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=1.32e+3, train_loss_epoch=744.0, valid_loss=1.880]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+3, train_loss_epoch=1.32e+3, valid_loss=1.880]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=814.0, train_loss_epoch=814.0, valid_loss=1.880]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=601.0, train_loss_epoch=601.0, valid_loss=1.880]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=926.0, train_loss_epoch=926.0, valid_loss=1.880]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=226.0, train_loss_epoch=226.0, valid_loss=1.880]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+3, train_loss_epoch=1.38e+3, valid_loss=1.880]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.57e+3, train_loss_epoch=1.57e+3, valid_loss=1.880]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=1.22e+3, train_loss_epoch=1.57e+3, valid_loss=1.880]\n",
            "Epoch 114: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=1.22e+3, train_loss_epoch=1.22e+3, valid_loss=1.880]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+3, train_loss_epoch=1.22e+3, valid_loss=1.880]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=214.0, train_loss_epoch=214.0, valid_loss=1.880]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=574.0, train_loss_epoch=574.0, valid_loss=1.880]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=134.0, train_loss_epoch=134.0, valid_loss=1.880]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=1.880]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+3, train_loss_epoch=1.33e+3, valid_loss=1.880]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=851.0, train_loss_epoch=851.0, valid_loss=1.880]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=396.0, train_loss_epoch=396.0, valid_loss=1.880]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=674.0, train_loss_epoch=674.0, valid_loss=1.880]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=243.0, train_loss_epoch=243.0, valid_loss=1.880]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=967.0, train_loss_epoch=967.0, valid_loss=1.880]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+3, train_loss_epoch=1.2e+3, valid_loss=1.880]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=795.0, train_loss_epoch=795.0, valid_loss=1.880]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=366.0, train_loss_epoch=795.0, valid_loss=1.880]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=366.0, train_loss_epoch=366.0, valid_loss=1.880]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=652.0, train_loss_epoch=652.0, valid_loss=1.880]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=244.0, train_loss_epoch=244.0, valid_loss=1.880]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=738.0, train_loss_epoch=738.0, valid_loss=1.880]\n",
            "Epoch 131: 100%|██████████| 1/1 [00:01<00:00,  0.58it/s, v_num=0, train_loss_step=1e+3, train_loss_epoch=738.0, valid_loss=1.880] \n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+3, train_loss_epoch=1e+3, valid_loss=1.880]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=697.0, train_loss_epoch=697.0, valid_loss=1.880]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=441.0, train_loss_epoch=441.0, valid_loss=1.880]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=734.0, train_loss_epoch=734.0, valid_loss=1.880]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=282.0, train_loss_epoch=282.0, valid_loss=1.880]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=681.0, train_loss_epoch=681.0, valid_loss=1.880]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+3, train_loss_epoch=1e+3, valid_loss=1.880]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=598.0, train_loss_epoch=598.0, valid_loss=1.880]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=304.0, train_loss_epoch=304.0, valid_loss=1.880]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=581.0, train_loss_epoch=581.0, valid_loss=1.880]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=313.0, train_loss_epoch=313.0, valid_loss=1.880]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=364.0, train_loss_epoch=364.0, valid_loss=1.880]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=446.0, train_loss_epoch=446.0, valid_loss=1.880]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=121.0, train_loss_epoch=121.0, valid_loss=1.880]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=127.0, train_loss_epoch=127.0, valid_loss=1.880]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=460.0, train_loss_epoch=460.0, valid_loss=1.880]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=451.0, train_loss_epoch=451.0, valid_loss=1.880]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=179.0, train_loss_epoch=179.0, valid_loss=1.880]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=194.0, train_loss_epoch=194.0, valid_loss=1.880]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=331.0, train_loss_epoch=331.0, valid_loss=1.880]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=294.0, train_loss_epoch=294.0, valid_loss=1.880]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=205.0, train_loss_epoch=205.0, valid_loss=1.880]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=209.0, train_loss_epoch=209.0, valid_loss=1.880]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=359.0, train_loss_epoch=359.0, valid_loss=1.880]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=371.0, train_loss_epoch=371.0, valid_loss=1.880]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=166.0, train_loss_epoch=166.0, valid_loss=1.880]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=156.0, train_loss_epoch=156.0, valid_loss=1.880]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=346.0, train_loss_epoch=346.0, valid_loss=1.880]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=378.0, train_loss_epoch=378.0, valid_loss=1.880]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=141.0, train_loss_epoch=141.0, valid_loss=1.880]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=118.0, train_loss_epoch=118.0, valid_loss=1.880]        \n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=118.0, train_loss_epoch=118.0, valid_loss=1.880]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=309.0, train_loss_epoch=309.0, valid_loss=1.880]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=238.0, train_loss_epoch=238.0, valid_loss=1.880]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=370.0, train_loss_epoch=370.0, valid_loss=1.880]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=332.0, train_loss_epoch=332.0, valid_loss=1.880]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=257.0, train_loss_epoch=257.0, valid_loss=1.880]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=304.0, train_loss_epoch=304.0, valid_loss=1.880]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=83.20, train_loss_epoch=83.20, valid_loss=1.880]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=504.0, train_loss_epoch=504.0, valid_loss=1.880]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=494.0, train_loss_epoch=494.0, valid_loss=1.880]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=175.0, valid_loss=1.880]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=666.0, train_loss_epoch=666.0, valid_loss=1.880]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=918.0, train_loss_epoch=918.0, valid_loss=1.880]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=677.0, train_loss_epoch=677.0, valid_loss=1.880]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=197.0, train_loss_epoch=197.0, valid_loss=1.880]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=380.0, train_loss_epoch=380.0, valid_loss=1.880]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=326.0, train_loss_epoch=326.0, valid_loss=1.880]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=178.0, train_loss_epoch=178.0, valid_loss=1.880]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=322.0, train_loss_epoch=322.0, valid_loss=1.880]\n",
            "Epoch 180: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=0, train_loss_step=83.40, train_loss_epoch=322.0, valid_loss=1.880]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=83.40, train_loss_epoch=83.40, valid_loss=1.880]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=515.0, train_loss_epoch=515.0, valid_loss=1.880]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=505.0, train_loss_epoch=505.0, valid_loss=1.880]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.70, train_loss_epoch=36.70, valid_loss=1.880]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=303.0, train_loss_epoch=303.0, valid_loss=1.880]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=173.0, train_loss_epoch=173.0, valid_loss=1.880]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=394.0, train_loss_epoch=394.0, valid_loss=1.880]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=535.0, train_loss_epoch=535.0, valid_loss=1.880]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=261.0, train_loss_epoch=261.0, valid_loss=1.880]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=406.0, train_loss_epoch=406.0, valid_loss=1.880]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=565.0, train_loss_epoch=565.0, valid_loss=1.880]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=311.0, train_loss_epoch=311.0, valid_loss=1.880]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=374.0, train_loss_epoch=374.0, valid_loss=1.880]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=468.0, train_loss_epoch=468.0, valid_loss=1.880]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=186.0, train_loss_epoch=186.0, valid_loss=1.880]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=506.0, train_loss_epoch=506.0, valid_loss=1.880]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=854.0, train_loss_epoch=854.0, valid_loss=1.880]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=658.0, train_loss_epoch=658.0, valid_loss=1.880]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=233.0, train_loss_epoch=233.0, valid_loss=1.880]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=546.0, train_loss_epoch=233.0, valid_loss=1.880]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.39it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=546.0, train_loss_epoch=546.0, valid_loss=0.347]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=831.0, train_loss_epoch=831.0, valid_loss=0.347]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=806.0, train_loss_epoch=806.0, valid_loss=0.347]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=260.0, train_loss_epoch=260.0, valid_loss=0.347]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=596.0, train_loss_epoch=596.0, valid_loss=0.347]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=971.0, train_loss_epoch=971.0, valid_loss=0.347]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=680.0, train_loss_epoch=680.0, valid_loss=0.347]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=237.0, train_loss_epoch=237.0, valid_loss=0.347]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=602.0, train_loss_epoch=602.0, valid_loss=0.347]\n",
            "Epoch 208: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=897.0, train_loss_epoch=897.0, valid_loss=0.347]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=897.0, train_loss_epoch=897.0, valid_loss=0.347]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=793.0, train_loss_epoch=793.0, valid_loss=0.347]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=355.0, train_loss_epoch=355.0, valid_loss=0.347]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=400.0, train_loss_epoch=400.0, valid_loss=0.347]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=626.0, train_loss_epoch=626.0, valid_loss=0.347]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=534.0, train_loss_epoch=534.0, valid_loss=0.347]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=113.0, train_loss_epoch=113.0, valid_loss=0.347]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=681.0, train_loss_epoch=681.0, valid_loss=0.347]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=977.0, train_loss_epoch=977.0, valid_loss=0.347]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=736.0, train_loss_epoch=736.0, valid_loss=0.347]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=296.0, train_loss_epoch=296.0, valid_loss=0.347]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=482.0, train_loss_epoch=482.0, valid_loss=0.347]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=887.0, train_loss_epoch=887.0, valid_loss=0.347]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=862.0, train_loss_epoch=862.0, valid_loss=0.347]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=531.0, train_loss_epoch=531.0, valid_loss=0.347]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.347]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=380.0, train_loss_epoch=380.0, valid_loss=0.347]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=295.0, train_loss_epoch=295.0, valid_loss=0.347]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=101.0, train_loss_epoch=101.0, valid_loss=0.347]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=154.0, train_loss_epoch=154.0, valid_loss=0.347]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=169.0, train_loss_epoch=169.0, valid_loss=0.347]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=140.0, train_loss_epoch=140.0, valid_loss=0.347]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=188.0, train_loss_epoch=188.0, valid_loss=0.347]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.80, train_loss_epoch=88.80, valid_loss=0.347]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=231.0, train_loss_epoch=231.0, valid_loss=0.347]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=143.0, train_loss_epoch=143.0, valid_loss=0.347]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=79.40, train_loss_epoch=79.40, valid_loss=0.347]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=120.0, train_loss_epoch=120.0, valid_loss=0.347]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.30, train_loss_epoch=35.30, valid_loss=0.347]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=193.0, train_loss_epoch=193.0, valid_loss=0.347]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=192.0, train_loss_epoch=192.0, valid_loss=0.347]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=65.50, train_loss_epoch=65.50, valid_loss=0.347]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=238.0, train_loss_epoch=238.0, valid_loss=0.347]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=309.0, train_loss_epoch=309.0, valid_loss=0.347]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=227.0, train_loss_epoch=227.0, valid_loss=0.347]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.70, train_loss_epoch=43.70, valid_loss=0.347]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=295.0, train_loss_epoch=295.0, valid_loss=0.347]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=432.0, train_loss_epoch=432.0, valid_loss=0.347]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=335.0, train_loss_epoch=335.0, valid_loss=0.347]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0, valid_loss=0.347]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=258.0, train_loss_epoch=258.0, valid_loss=0.347]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=376.0, train_loss_epoch=376.0, valid_loss=0.347]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=408.0, train_loss_epoch=408.0, valid_loss=0.347]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=267.0, train_loss_epoch=267.0, valid_loss=0.347]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=59.60, train_loss_epoch=59.60, valid_loss=0.347]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=167.0, train_loss_epoch=167.0, valid_loss=0.347]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=116.0, train_loss_epoch=116.0, valid_loss=0.347]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.90, train_loss_epoch=95.90, valid_loss=0.347]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=127.0, train_loss_epoch=127.0, valid_loss=0.347]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.90, train_loss_epoch=41.90, valid_loss=0.347]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=183.0, train_loss_epoch=183.0, valid_loss=0.347]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=223.0, train_loss_epoch=223.0, valid_loss=0.347]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=64.40, train_loss_epoch=64.40, valid_loss=0.347]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=227.0, train_loss_epoch=227.0, valid_loss=0.347]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=284.0, train_loss_epoch=284.0, valid_loss=0.347]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=230.0, train_loss_epoch=230.0, valid_loss=0.347]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=54.30, train_loss_epoch=54.30, valid_loss=0.347]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=265.0, train_loss_epoch=265.0, valid_loss=0.347]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=365.0, train_loss_epoch=365.0, valid_loss=0.347]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=319.0, train_loss_epoch=319.0, valid_loss=0.347]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=127.0, train_loss_epoch=127.0, valid_loss=0.347]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=195.0, train_loss_epoch=195.0, valid_loss=0.347]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=324.0, train_loss_epoch=324.0, valid_loss=0.347]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=310.0, train_loss_epoch=310.0, valid_loss=0.347]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:01<00:00,  0.57it/s, v_num=0, train_loss_step=171.0, train_loss_epoch=310.0, valid_loss=0.347]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=171.0, train_loss_epoch=171.0, valid_loss=0.347]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=135.0, train_loss_epoch=135.0, valid_loss=0.347]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=250.0, train_loss_epoch=250.0, valid_loss=0.347]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=161.0, train_loss_epoch=161.0, valid_loss=0.347]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.10, train_loss_epoch=68.10, valid_loss=0.347]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=149.0, train_loss_epoch=149.0, valid_loss=0.347]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.70, train_loss_epoch=78.70, valid_loss=0.347]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=128.0, train_loss_epoch=128.0, valid_loss=0.347]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=174.0, train_loss_epoch=174.0, valid_loss=0.347]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=66.70, train_loss_epoch=66.70, valid_loss=0.347]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=66.70, train_loss_epoch=66.70, valid_loss=0.347]\n",
            "Epoch 282: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=169.0, train_loss_epoch=66.70, valid_loss=0.347]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=169.0, train_loss_epoch=169.0, valid_loss=0.347]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=209.0, train_loss_epoch=209.0, valid_loss=0.347]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=121.0, train_loss_epoch=121.0, valid_loss=0.347]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=138.0, train_loss_epoch=138.0, valid_loss=0.347]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=212.0, train_loss_epoch=212.0, valid_loss=0.347]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.347]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.347]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=219.0, train_loss_epoch=219.0, valid_loss=0.347]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=192.0, train_loss_epoch=192.0, valid_loss=0.347]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90, valid_loss=0.347]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=215.0, train_loss_epoch=215.0, valid_loss=0.347]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=261.0, train_loss_epoch=261.0, valid_loss=0.347]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=168.0, train_loss_epoch=168.0, valid_loss=0.347]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=85.00, train_loss_epoch=85.00, valid_loss=0.347]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=141.0, train_loss_epoch=141.0, valid_loss=0.347]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=85.10, train_loss_epoch=85.10, valid_loss=0.347]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=142.0, train_loss_epoch=142.0, valid_loss=0.347]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=171.0, train_loss_epoch=142.0, valid_loss=0.347]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.19it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=171.0, train_loss_epoch=171.0, valid_loss=0.014]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=94.50, train_loss_epoch=94.50, valid_loss=0.014]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.014]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=158.0, train_loss_epoch=158.0, valid_loss=0.014]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=71.40, train_loss_epoch=71.40, valid_loss=0.014]\n",
            "Epoch 304: 100%|██████████| 1/1 [00:02<00:00,  0.35it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=71.40, valid_loss=0.014]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=147.0, train_loss_epoch=147.0, valid_loss=0.014]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=174.0, train_loss_epoch=174.0, valid_loss=0.014]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.10, train_loss_epoch=40.10, valid_loss=0.014]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=225.0, train_loss_epoch=225.0, valid_loss=0.014]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=310.0, train_loss_epoch=310.0, valid_loss=0.014]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=215.0, train_loss_epoch=215.0, valid_loss=0.014]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.00, train_loss_epoch=38.00, valid_loss=0.014]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=288.0, train_loss_epoch=288.0, valid_loss=0.014]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=358.0, train_loss_epoch=358.0, valid_loss=0.014]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=309.0, train_loss_epoch=309.0, valid_loss=0.014]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=128.0, train_loss_epoch=128.0, valid_loss=0.014]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=183.0, train_loss_epoch=183.0, valid_loss=0.014]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=339.0, train_loss_epoch=339.0, valid_loss=0.014]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=317.0, train_loss_epoch=317.0, valid_loss=0.014]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=173.0, train_loss_epoch=173.0, valid_loss=0.014]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=132.0, train_loss_epoch=132.0, valid_loss=0.014]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=266.0, train_loss_epoch=266.0, valid_loss=0.014]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=241.0, train_loss_epoch=241.0, valid_loss=0.014]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.90, train_loss_epoch=88.90, valid_loss=0.014]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=207.0, train_loss_epoch=207.0, valid_loss=0.014]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=295.0, train_loss_epoch=295.0, valid_loss=0.014]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=237.0, train_loss_epoch=237.0, valid_loss=0.014]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.40, train_loss_epoch=56.40, valid_loss=0.014]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=264.0, train_loss_epoch=264.0, valid_loss=0.014]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=406.0, train_loss_epoch=406.0, valid_loss=0.014]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=345.0, train_loss_epoch=345.0, valid_loss=0.014]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=167.0, train_loss_epoch=167.0, valid_loss=0.014]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=173.0, train_loss_epoch=173.0, valid_loss=0.014]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=283.0, train_loss_epoch=283.0, valid_loss=0.014]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=262.0, train_loss_epoch=262.0, valid_loss=0.014]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=123.0, train_loss_epoch=123.0, valid_loss=0.014]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=156.0, train_loss_epoch=156.0, valid_loss=0.014]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=271.0, train_loss_epoch=271.0, valid_loss=0.014]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=193.0, train_loss_epoch=193.0, valid_loss=0.014]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=35.60, train_loss_epoch=193.0, valid_loss=0.014]\n",
            "Epoch 338: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=35.60, train_loss_epoch=35.60, valid_loss=0.014]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.60, train_loss_epoch=35.60, valid_loss=0.014]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0, valid_loss=0.014]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.60, train_loss_epoch=76.60, valid_loss=0.014]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=89.30, train_loss_epoch=89.30, valid_loss=0.014]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.90, train_loss_epoch=98.90, valid_loss=0.014]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=80.80, train_loss_epoch=80.80, valid_loss=0.014]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=84.80, train_loss_epoch=84.80, valid_loss=0.014]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=84.80, train_loss_epoch=84.80, valid_loss=0.014]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.80, train_loss_epoch=40.80, valid_loss=0.014]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.90, train_loss_epoch=39.90, valid_loss=0.014]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=50.50, train_loss_epoch=50.50, valid_loss=0.014]\n",
            "Epoch 348: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=71.20, train_loss_epoch=71.20, valid_loss=0.014]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=71.20, train_loss_epoch=71.20, valid_loss=0.014]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.60, train_loss_epoch=42.60, valid_loss=0.014]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.50, train_loss_epoch=88.50, valid_loss=0.014]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.60, train_loss_epoch=41.60, valid_loss=0.014]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=130.0, train_loss_epoch=130.0, valid_loss=0.014]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=119.0, train_loss_epoch=119.0, valid_loss=0.014]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.50, train_loss_epoch=41.50, valid_loss=0.014]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.014]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=110.0, train_loss_epoch=110.0, valid_loss=0.014]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=85.60, train_loss_epoch=85.60, valid_loss=0.014]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=91.50, train_loss_epoch=91.50, valid_loss=0.014]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.30, train_loss_epoch=78.30, valid_loss=0.014]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.20, train_loss_epoch=78.20, valid_loss=0.014]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0, valid_loss=0.014]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.70, train_loss_epoch=38.70, valid_loss=0.014]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:02<00:00,  0.34it/s, v_num=0, train_loss_step=38.70, train_loss_epoch=38.70, valid_loss=0.014]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=160.0, train_loss_epoch=160.0, valid_loss=0.014]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=144.0, train_loss_epoch=144.0, valid_loss=0.014]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.10, train_loss_epoch=53.10, valid_loss=0.014]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=91.10, train_loss_epoch=91.10, valid_loss=0.014]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.80, train_loss_epoch=41.80, valid_loss=0.014]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=45.10, train_loss_epoch=45.10, valid_loss=0.014]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=65.70, train_loss_epoch=65.70, valid_loss=0.014]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:02<00:00,  0.35it/s, v_num=0, train_loss_step=50.30, train_loss_epoch=65.70, valid_loss=0.014]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=50.30, train_loss_epoch=50.30, valid_loss=0.014]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.90, train_loss_epoch=41.90, valid_loss=0.014]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=72.70, train_loss_epoch=72.70, valid_loss=0.014]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.50, train_loss_epoch=42.50, valid_loss=0.014]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=50.70, train_loss_epoch=50.70, valid_loss=0.014]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=82.50, train_loss_epoch=82.50, valid_loss=0.014]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.90, train_loss_epoch=60.90, valid_loss=0.014]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=81.20, train_loss_epoch=81.20, valid_loss=0.014]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=67.90, train_loss_epoch=67.90, valid_loss=0.014]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=87.70, train_loss_epoch=87.70, valid_loss=0.014]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.80, train_loss_epoch=76.80, valid_loss=0.014]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=112.0, train_loss_epoch=112.0, valid_loss=0.014]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.014]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.80, train_loss_epoch=78.80, valid_loss=0.014]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=115.0, train_loss_epoch=115.0, valid_loss=0.014]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=122.0, train_loss_epoch=122.0, valid_loss=0.014]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.40, train_loss_epoch=49.40, valid_loss=0.014]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=216.0, train_loss_epoch=216.0, valid_loss=0.014]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=255.0, train_loss_epoch=255.0, valid_loss=0.014]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=160.0, train_loss_epoch=160.0, valid_loss=0.014]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=97.90, train_loss_epoch=97.90, valid_loss=0.014]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=183.0, train_loss_epoch=183.0, valid_loss=0.014]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=137.0, train_loss_epoch=137.0, valid_loss=0.014]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=66.80, train_loss_epoch=66.80, valid_loss=0.014]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0, valid_loss=0.014]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.30, train_loss_epoch=39.30, valid_loss=0.014]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.014]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=103.0, train_loss_epoch=103.0, valid_loss=0.014]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=80.70, train_loss_epoch=80.70, valid_loss=0.014]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:02<00:00,  0.49it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=80.70, valid_loss=0.014]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.79it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0, valid_loss=0.0265]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00, valid_loss=0.0265]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0265]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=91.70, train_loss_epoch=91.70, valid_loss=0.0265]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=71.00, train_loss_epoch=71.00, valid_loss=0.0265]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=77.80, train_loss_epoch=77.80, valid_loss=0.0265]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.50, train_loss_epoch=53.50, valid_loss=0.0265]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=135.0, train_loss_epoch=135.0, valid_loss=0.0265]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=166.0, train_loss_epoch=166.0, valid_loss=0.0265]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=75.90, train_loss_epoch=75.90, valid_loss=0.0265]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=155.0, train_loss_epoch=155.0, valid_loss=0.0265]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=202.0, train_loss_epoch=202.0, valid_loss=0.0265]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=115.0, train_loss_epoch=115.0, valid_loss=0.0265]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=100.0, train_loss_epoch=100.0, valid_loss=0.0265]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=150.0, train_loss_epoch=150.0, valid_loss=0.0265]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=93.80, train_loss_epoch=93.80, valid_loss=0.0265]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=105.0, train_loss_epoch=105.0, valid_loss=0.0265]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=165.0, train_loss_epoch=165.0, valid_loss=0.0265]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.10, train_loss_epoch=76.10, valid_loss=0.0265]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=158.0, train_loss_epoch=158.0, valid_loss=0.0265]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=198.0, train_loss_epoch=198.0, valid_loss=0.0265]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=153.0, train_loss_epoch=153.0, valid_loss=0.0265]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=70.40, train_loss_epoch=70.40, valid_loss=0.0265]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.0265]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=60.00, valid_loss=0.0265]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=141.0, train_loss_epoch=141.0, valid_loss=0.0265]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=167.0, train_loss_epoch=167.0, valid_loss=0.0265]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.40, train_loss_epoch=88.40, valid_loss=0.0265]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=127.0, train_loss_epoch=127.0, valid_loss=0.0265]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=165.0, train_loss_epoch=165.0, valid_loss=0.0265]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=52.10, train_loss_epoch=52.10, valid_loss=0.0265]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=183.0, train_loss_epoch=183.0, valid_loss=0.0265]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=254.0, train_loss_epoch=254.0, valid_loss=0.0265]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=175.0, train_loss_epoch=175.0, valid_loss=0.0265]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=47.50, train_loss_epoch=47.50, valid_loss=0.0265]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=126.0, train_loss_epoch=126.0, valid_loss=0.0265]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=57.80, train_loss_epoch=57.80, valid_loss=0.0265]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=142.0, train_loss_epoch=142.0, valid_loss=0.0265]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=180.0, train_loss_epoch=180.0, valid_loss=0.0265]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=90.70, train_loss_epoch=90.70, valid_loss=0.0265]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=139.0, train_loss_epoch=139.0, valid_loss=0.0265]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=211.0, train_loss_epoch=211.0, valid_loss=0.0265]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=111.0, train_loss_epoch=111.0, valid_loss=0.0265]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=122.0, train_loss_epoch=122.0, valid_loss=0.0265]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=205.0, train_loss_epoch=205.0, valid_loss=0.0265]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=143.0, train_loss_epoch=143.0, valid_loss=0.0265]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.50, train_loss_epoch=49.50, valid_loss=0.0265]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=91.20, train_loss_epoch=91.20, valid_loss=0.0265]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.10, train_loss_epoch=48.10, valid_loss=0.0265]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.40, train_loss_epoch=42.40, valid_loss=0.0265]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=91.00, train_loss_epoch=91.00, valid_loss=0.0265]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=32.70, valid_loss=0.0265]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=140.0, train_loss_epoch=140.0, valid_loss=0.0265]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=154.0, train_loss_epoch=154.0, valid_loss=0.0265]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.40, train_loss_epoch=56.40, valid_loss=0.0265]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=168.0, train_loss_epoch=168.0, valid_loss=0.0265]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=259.0, train_loss_epoch=259.0, valid_loss=0.0265]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=171.0, train_loss_epoch=171.0, valid_loss=0.0265]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=87.80, train_loss_epoch=87.80, valid_loss=0.0265]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=164.0, train_loss_epoch=164.0, valid_loss=0.0265]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=119.0, train_loss_epoch=119.0, valid_loss=0.0265]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=70.10, train_loss_epoch=70.10, valid_loss=0.0265]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=115.0, train_loss_epoch=115.0, valid_loss=0.0265]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.90, train_loss_epoch=36.90, valid_loss=0.0265]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=145.0, train_loss_epoch=145.0, valid_loss=0.0265]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=146.0, train_loss_epoch=146.0, valid_loss=0.0265]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.20, train_loss_epoch=68.20, valid_loss=0.0265]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=140.0, train_loss_epoch=140.0, valid_loss=0.0265]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=149.0, train_loss_epoch=149.0, valid_loss=0.0265]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=90.10, train_loss_epoch=90.10, valid_loss=0.0265]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=51.10, train_loss_epoch=51.10, valid_loss=0.0265]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0, valid_loss=0.0265]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0, valid_loss=0.0265]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.80, train_loss_epoch=68.80, valid_loss=0.0265]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=66.90, train_loss_epoch=66.90, valid_loss=0.0265]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=89.40, train_loss_epoch=89.40, valid_loss=0.0265]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=64.40, train_loss_epoch=64.40, valid_loss=0.0265]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=55.00, train_loss_epoch=55.00, valid_loss=0.0265]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=79.40, train_loss_epoch=79.40, valid_loss=0.0265]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=58.20, train_loss_epoch=58.20, valid_loss=0.0265]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.90, train_loss_epoch=49.90, valid_loss=0.0265]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=58.40, train_loss_epoch=58.40, valid_loss=0.0265]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.40, train_loss_epoch=37.40, valid_loss=0.0265]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.90, train_loss_epoch=53.90, valid_loss=0.0265]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.10, train_loss_epoch=36.10, valid_loss=0.0265]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=66.70, train_loss_epoch=66.70, valid_loss=0.0265]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=59.80, train_loss_epoch=59.80, valid_loss=0.0265]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=44.10, train_loss_epoch=44.10, valid_loss=0.0265]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.20, train_loss_epoch=56.20, valid_loss=0.0265]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.60, train_loss_epoch=34.60, valid_loss=0.0265]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.20, train_loss_epoch=76.20, valid_loss=0.0265]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=67.20, train_loss_epoch=67.20, valid_loss=0.0265]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.60, train_loss_epoch=41.60, valid_loss=0.0265]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.50, train_loss_epoch=60.50, valid_loss=0.0265]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.70, train_loss_epoch=41.70, valid_loss=0.0265]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=64.90, train_loss_epoch=64.90, valid_loss=0.0265]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=58.00, train_loss_epoch=58.00, valid_loss=0.0265]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.40, train_loss_epoch=42.40, valid_loss=0.0265]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=61.20, train_loss_epoch=61.20, valid_loss=0.0265]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=46.00, train_loss_epoch=46.00, valid_loss=0.0265]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=59.00, train_loss_epoch=46.00, valid_loss=0.0265]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.15it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=59.00, train_loss_epoch=59.00, valid_loss=0.0198]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=64.90, train_loss_epoch=64.90, valid_loss=0.0198]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.00, train_loss_epoch=42.00, valid_loss=0.0198]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.60, train_loss_epoch=53.60, valid_loss=0.0198]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.50, train_loss_epoch=34.50, valid_loss=0.0198]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.60, train_loss_epoch=60.60, valid_loss=0.0198]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.80, train_loss_epoch=49.80, valid_loss=0.0198]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:01<00:00,  0.57it/s, v_num=0, train_loss_step=49.50, train_loss_epoch=49.80, valid_loss=0.0198]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:01<00:00,  0.57it/s, v_num=0, train_loss_step=49.50, train_loss_epoch=49.50, valid_loss=0.0198]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.50, train_loss_epoch=49.50, valid_loss=0.0198]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=65.60, train_loss_epoch=65.60, valid_loss=0.0198]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.70, train_loss_epoch=37.70, valid_loss=0.0198]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=73.60, train_loss_epoch=73.60, valid_loss=0.0198]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=62.30, train_loss_epoch=62.30, valid_loss=0.0198]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.70, train_loss_epoch=42.70, valid_loss=0.0198]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=54.60, train_loss_epoch=54.60, valid_loss=0.0198]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.50, train_loss_epoch=36.50, valid_loss=0.0198]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=74.10, train_loss_epoch=74.10, valid_loss=0.0198]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.80, train_loss_epoch=68.80, valid_loss=0.0198]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=47.10, train_loss_epoch=47.10, valid_loss=0.0198]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=61.70, train_loss_epoch=61.70, valid_loss=0.0198]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.80, train_loss_epoch=36.80, valid_loss=0.0198]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=74.30, train_loss_epoch=74.30, valid_loss=0.0198]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.80, train_loss_epoch=76.80, valid_loss=0.0198]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.10, train_loss_epoch=34.10, valid_loss=0.0198]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.90, train_loss_epoch=43.90, valid_loss=0.0198]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0198]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.70, train_loss_epoch=63.70, valid_loss=0.0198]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.10, train_loss_epoch=34.10, valid_loss=0.0198]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=71.20, train_loss_epoch=71.20, valid_loss=0.0198]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.20, train_loss_epoch=76.20, valid_loss=0.0198]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.60, train_loss_epoch=42.60, valid_loss=0.0198]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=76.00, train_loss_epoch=76.00, valid_loss=0.0198]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=87.60, train_loss_epoch=87.60, valid_loss=0.0198]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.30, train_loss_epoch=41.30, valid_loss=0.0198]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=92.20, train_loss_epoch=92.20, valid_loss=0.0198]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=114.0, train_loss_epoch=114.0, valid_loss=0.0198]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=100.0, train_loss_epoch=100.0, valid_loss=0.0198]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.80, train_loss_epoch=41.80, valid_loss=0.0198]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=96.60, train_loss_epoch=96.60, valid_loss=0.0198]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=117.0, train_loss_epoch=117.0, valid_loss=0.0198]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.00, train_loss_epoch=56.00, valid_loss=0.0198]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.30, train_loss_epoch=78.30, valid_loss=0.0198]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=108.0, train_loss_epoch=108.0, valid_loss=0.0198]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=94.00, train_loss_epoch=94.00, valid_loss=0.0198]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.80, train_loss_epoch=37.80, valid_loss=0.0198]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=77.70, train_loss_epoch=77.70, valid_loss=0.0198]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=87.10, train_loss_epoch=87.10, valid_loss=0.0198]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.20, train_loss_epoch=32.20, valid_loss=0.0198]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=91.80, train_loss_epoch=91.80, valid_loss=0.0198]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=114.0, train_loss_epoch=114.0, valid_loss=0.0198]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0, valid_loss=0.0198]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.30, train_loss_epoch=60.30, valid_loss=0.0198]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=92.60, train_loss_epoch=92.60, valid_loss=0.0198]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=108.0, train_loss_epoch=108.0, valid_loss=0.0198]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=74.20, train_loss_epoch=74.20, valid_loss=0.0198]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=62.30, train_loss_epoch=62.30, valid_loss=0.0198]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=93.80, train_loss_epoch=93.80, valid_loss=0.0198]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=81.30, train_loss_epoch=81.30, valid_loss=0.0198]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0198]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=99.00, train_loss_epoch=99.00, valid_loss=0.0198]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=102.0, train_loss_epoch=102.0, valid_loss=0.0198]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.10, train_loss_epoch=49.10, valid_loss=0.0198]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.60, train_loss_epoch=88.60, valid_loss=0.0198]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=118.0, train_loss_epoch=118.0, valid_loss=0.0198]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=94.40, train_loss_epoch=94.40, valid_loss=0.0198]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.70, train_loss_epoch=33.70, valid_loss=0.0198]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=120.0, train_loss_epoch=120.0, valid_loss=0.0198]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=149.0, train_loss_epoch=149.0, valid_loss=0.0198]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=115.0, train_loss_epoch=115.0, valid_loss=0.0198]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.80, train_loss_epoch=36.80, valid_loss=0.0198]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=82.70, train_loss_epoch=82.70, valid_loss=0.0198]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=85.80, train_loss_epoch=85.80, valid_loss=0.0198]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.50, train_loss_epoch=48.50, valid_loss=0.0198]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=74.10, train_loss_epoch=74.10, valid_loss=0.0198]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=97.10, train_loss_epoch=97.10, valid_loss=0.0198]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=44.90, train_loss_epoch=44.90, valid_loss=0.0198]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=85.30, train_loss_epoch=85.30, valid_loss=0.0198]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=115.0, train_loss_epoch=115.0, valid_loss=0.0198]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.00, train_loss_epoch=95.00, valid_loss=0.0198]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.10, train_loss_epoch=36.10, valid_loss=0.0198]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0, valid_loss=0.0198]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=132.0, train_loss_epoch=132.0, valid_loss=0.0198]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=79.80, train_loss_epoch=79.80, valid_loss=0.0198]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.00, train_loss_epoch=63.00, valid_loss=0.0198]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.90, train_loss_epoch=95.90, valid_loss=0.0198]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=79.70, train_loss_epoch=79.70, valid_loss=0.0198]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.30, train_loss_epoch=33.30, valid_loss=0.0198]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=106.0, train_loss_epoch=106.0, valid_loss=0.0198]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=127.0, train_loss_epoch=127.0, valid_loss=0.0198]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.90, train_loss_epoch=78.90, valid_loss=0.0198]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.50, train_loss_epoch=63.50, valid_loss=0.0198]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=99.30, train_loss_epoch=99.30, valid_loss=0.0198]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=82.70, train_loss_epoch=82.70, valid_loss=0.0198]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.10, train_loss_epoch=36.10, valid_loss=0.0198]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=104.0, train_loss_epoch=104.0, valid_loss=0.0198]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=133.0, train_loss_epoch=133.0, valid_loss=0.0198]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.50, train_loss_epoch=88.50, valid_loss=0.0198]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=51.40, train_loss_epoch=51.40, valid_loss=0.0198]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=83.10, train_loss_epoch=83.10, valid_loss=0.0198]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=79.30, train_loss_epoch=79.30, valid_loss=0.0198]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.10, train_loss_epoch=36.10, valid_loss=0.0198]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:02<00:00,  0.39it/s, v_num=0, train_loss_step=87.60, train_loss_epoch=36.10, valid_loss=0.0198]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.49it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=87.60, train_loss_epoch=87.60, valid_loss=0.046]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.90, train_loss_epoch=98.90, valid_loss=0.046]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.60, train_loss_epoch=40.60, valid_loss=0.046]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=94.10, train_loss_epoch=94.10, valid_loss=0.046]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=125.0, train_loss_epoch=125.0, valid_loss=0.046]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=112.0, train_loss_epoch=112.0, valid_loss=0.046]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.90, train_loss_epoch=43.90, valid_loss=0.046]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=111.0, train_loss_epoch=111.0, valid_loss=0.046]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=128.0, train_loss_epoch=128.0, valid_loss=0.046]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0, valid_loss=0.046]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.00, train_loss_epoch=35.00, valid_loss=0.046]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=117.0, train_loss_epoch=117.0, valid_loss=0.046]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=159.0, train_loss_epoch=159.0, valid_loss=0.046]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=138.0, train_loss_epoch=138.0, valid_loss=0.046]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=73.10, train_loss_epoch=73.10, valid_loss=0.046]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=88.60, train_loss_epoch=88.60, valid_loss=0.046]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=128.0, train_loss_epoch=128.0, valid_loss=0.046]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=112.0, train_loss_epoch=112.0, valid_loss=0.046]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.20, train_loss_epoch=39.20, valid_loss=0.046]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=114.0, train_loss_epoch=114.0, valid_loss=0.046]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=172.0, train_loss_epoch=172.0, valid_loss=0.046]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=157.0, train_loss_epoch=157.0, valid_loss=0.046]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=78.40, train_loss_epoch=78.40, valid_loss=0.046]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=74.80, train_loss_epoch=74.80, valid_loss=0.046]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=122.0, train_loss_epoch=122.0, valid_loss=0.046]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=127.0, train_loss_epoch=127.0, valid_loss=0.046]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=55.50, train_loss_epoch=55.50, valid_loss=0.046]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95.60, train_loss_epoch=95.60, valid_loss=0.046]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=156.0, train_loss_epoch=156.0, valid_loss=0.046]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=142.0, train_loss_epoch=142.0, valid_loss=0.046]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=75.60, train_loss_epoch=75.60, valid_loss=0.046]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=73.50, train_loss_epoch=73.50, valid_loss=0.046]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=114.0, train_loss_epoch=114.0, valid_loss=0.046]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=84.70, train_loss_epoch=84.70, valid_loss=0.046]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.50, train_loss_epoch=35.50, valid_loss=0.046]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.90, train_loss_epoch=63.90, valid_loss=0.046]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=52.40, train_loss_epoch=52.40, valid_loss=0.046]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.30, train_loss_epoch=53.30, valid_loss=0.046]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=52.30, train_loss_epoch=52.30, valid_loss=0.046]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=45.50, train_loss_epoch=45.50, valid_loss=0.046]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.20, train_loss_epoch=49.20, valid_loss=0.046]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.70, train_loss_epoch=38.70, valid_loss=0.046]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=73.30, train_loss_epoch=73.30, valid_loss=0.046]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=61.00, train_loss_epoch=61.00, valid_loss=0.046]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.10, train_loss_epoch=53.10, valid_loss=0.046]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=77.90, train_loss_epoch=77.90, valid_loss=0.046]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.60, train_loss_epoch=56.60, valid_loss=0.046]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.40, train_loss_epoch=48.40, valid_loss=0.046]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.40, train_loss_epoch=53.40, valid_loss=0.046]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.50, train_loss_epoch=43.50, valid_loss=0.046]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=52.00, train_loss_epoch=52.00, valid_loss=0.046]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.10, train_loss_epoch=33.10, valid_loss=0.046]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=75.60, train_loss_epoch=75.60, valid_loss=0.046]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=70.30, train_loss_epoch=70.30, valid_loss=0.046]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=42.60, train_loss_epoch=42.60, valid_loss=0.046]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=55.60, train_loss_epoch=55.60, valid_loss=0.046]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.80, train_loss_epoch=37.80, valid_loss=0.046]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=69.60, train_loss_epoch=69.60, valid_loss=0.046]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=64.60, train_loss_epoch=64.60, valid_loss=0.046]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.70, train_loss_epoch=38.70, valid_loss=0.046]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=59.80, train_loss_epoch=59.80, valid_loss=0.046]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.30, train_loss_epoch=49.30, valid_loss=0.046]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.20, train_loss_epoch=56.20, valid_loss=0.046]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=47.40, train_loss_epoch=47.40, valid_loss=0.046]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=50.80, train_loss_epoch=50.80, valid_loss=0.046]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=66.40, train_loss_epoch=66.40, valid_loss=0.046]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.50, train_loss_epoch=36.50, valid_loss=0.046]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=82.20, train_loss_epoch=82.20, valid_loss=0.046]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=80.70, train_loss_epoch=80.70, valid_loss=0.046]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60, valid_loss=0.046]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=50.00, train_loss_epoch=50.00, valid_loss=0.046]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.90, train_loss_epoch=38.90, valid_loss=0.046]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.50, train_loss_epoch=60.50, valid_loss=0.046]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.30, train_loss_epoch=41.30, valid_loss=0.046]\n",
            "Epoch 673: 100%|██████████| 1/1 [00:01<00:00,  0.57it/s, v_num=0, train_loss_step=66.90, train_loss_epoch=41.30, valid_loss=0.046]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=66.90, train_loss_epoch=66.90, valid_loss=0.046]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=77.00, train_loss_epoch=77.00, valid_loss=0.046]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=47.70, train_loss_epoch=47.70, valid_loss=0.046]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=63.40, train_loss_epoch=63.40, valid_loss=0.046]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=61.40, train_loss_epoch=61.40, valid_loss=0.046]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.60, train_loss_epoch=37.60, valid_loss=0.046]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=53.30, train_loss_epoch=53.30, valid_loss=0.046]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60, valid_loss=0.046]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=74.20, train_loss_epoch=74.20, valid_loss=0.046]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.10, train_loss_epoch=68.10, valid_loss=0.046]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.70, train_loss_epoch=41.70, valid_loss=0.046]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=56.10, train_loss_epoch=56.10, valid_loss=0.046]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.20, train_loss_epoch=36.20, valid_loss=0.046]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=69.90, train_loss_epoch=69.90, valid_loss=0.046]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=66.60, train_loss_epoch=66.60, valid_loss=0.046]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.00, train_loss_epoch=37.00, valid_loss=0.046]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=52.60, train_loss_epoch=52.60, valid_loss=0.046]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.30, train_loss_epoch=33.30, valid_loss=0.046]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=60.00, train_loss_epoch=60.00, valid_loss=0.046]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=43.40, train_loss_epoch=43.40, valid_loss=0.046]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.60, train_loss_epoch=68.60, valid_loss=0.046]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=82.40, train_loss_epoch=82.40, valid_loss=0.046]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=49.10, train_loss_epoch=49.10, valid_loss=0.046]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=68.80, train_loss_epoch=68.80, valid_loss=0.046]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=75.40, train_loss_epoch=75.40, valid_loss=0.046]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.00, train_loss_epoch=33.00, valid_loss=0.046]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 19:06:14,858\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m `Trainer.fit` stopped: `max_steps=700.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \rEpoch 699: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=0, train_loss_step=33.00, train_loss_epoch=33.00, valid_loss=0.046]\rEpoch 699: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=0, train_loss_step=50.00, train_loss_epoch=33.00, valid_loss=0.046]\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 79.96it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=20119)\u001b[0m \r                                                                      \u001b[A\rEpoch 699: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=0, train_loss_step=50.00, train_loss_epoch=33.00, valid_loss=0.0303]\rEpoch 699: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=0, train_loss_step=50.00, train_loss_epoch=50.00, valid_loss=0.0303]\rEpoch 699: 100%|██████████| 1/1 [00:02<00:00,  0.36it/s, v_num=0, train_loss_step=50.00, train_loss_epoch=50.00, valid_loss=0.0303]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=26253)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 2025-06-15 19:06:28.598526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m E0000 00:00:1750014388.655903   26341 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m E0000 00:00:1750014388.673701   26341 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 2025-06-15 19:06:28.718333: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 3 | blocks       | ModuleList    | 10.2 M | train\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 10.2 M    Trainable params\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 10.2 M    Total params\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 40.927    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.576, train_loss_epoch=0.576]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.584, train_loss_epoch=0.584]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.431, train_loss_epoch=0.431]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.327, train_loss_epoch=0.327]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.317, train_loss_epoch=0.317]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.291, train_loss_epoch=0.291]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187]\n",
            "Epoch 13: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.187]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.162, train_loss_epoch=0.162]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.159, train_loss_epoch=0.159]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.150, train_loss_epoch=0.150]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.121, train_loss_epoch=0.121]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.112, train_loss_epoch=0.112]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.107, train_loss_epoch=0.107]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0972, train_loss_epoch=0.0972]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103]\n",
            "Epoch 23: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=0.103, train_loss_epoch=0.103]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0951, train_loss_epoch=0.0951]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.095, train_loss_epoch=0.095]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0942, train_loss_epoch=0.0942]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0763, train_loss_epoch=0.0763]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0748, train_loss_epoch=0.0748]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0764, train_loss_epoch=0.0764]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0662, train_loss_epoch=0.0662]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0774, train_loss_epoch=0.0774]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0625, train_loss_epoch=0.0625]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0672, train_loss_epoch=0.0672]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0582, train_loss_epoch=0.0582]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0621, train_loss_epoch=0.0621]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0561, train_loss_epoch=0.0561]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.056, train_loss_epoch=0.056]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0577]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0547, train_loss_epoch=0.0547]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0491, train_loss_epoch=0.0491]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0465, train_loss_epoch=0.0465]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0416, train_loss_epoch=0.0416]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0496, train_loss_epoch=0.0496]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0533, train_loss_epoch=0.0533]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0537, train_loss_epoch=0.0537]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0498, train_loss_epoch=0.0498]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0472, train_loss_epoch=0.0472]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.051, train_loss_epoch=0.051]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0474, train_loss_epoch=0.0474]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0424, train_loss_epoch=0.0424]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.050, train_loss_epoch=0.050]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0427, train_loss_epoch=0.0427]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.047, train_loss_epoch=0.047]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0429, train_loss_epoch=0.0429]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0453, train_loss_epoch=0.0453]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384]\n",
            "Epoch 93: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0384]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366]\n",
            "Epoch 94: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0367, train_loss_epoch=0.0367]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:01<00:00,  0.69it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0347]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.91it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0332]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.0332]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=0.0332]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0318, train_loss_epoch=0.0318, valid_loss=0.0332]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=0.0332]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0332]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0332]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=0.0332]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.0332]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=0.0332]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.0332]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.0332]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0389, train_loss_epoch=0.0389, valid_loss=0.0332]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0332]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.0332]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=0.0332]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=0.0332]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.0332]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.0332]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.0332]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=0.0332]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0374, train_loss_epoch=0.0374, valid_loss=0.0332]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.0332]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0402, train_loss_epoch=0.0402, valid_loss=0.0332]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=0.0332]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=0.0332]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.0332]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.0332]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.0332]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=0.0332]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.0332]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.0332]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.0332]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=0.0332]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.0332]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0332]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.0332]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.0332]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.0332]\n",
            "Epoch 138: 100%|██████████| 1/1 [00:02<00:00,  0.47it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.0332]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.0332]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.0332]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=0.0332]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.0332]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=0.0332]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256, valid_loss=0.0332]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=0.0332]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274, valid_loss=0.0332]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.0332]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.0332]\n",
            "Epoch 148: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0332]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0332]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.0332]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0332]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.0332]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0332]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.0332]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.0332]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.0332]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.0332]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.0332]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0332]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=0.0332]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419, valid_loss=0.0332]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0407, train_loss_epoch=0.0407, valid_loss=0.0332]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.0332]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=0.0332]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0379, train_loss_epoch=0.0379, valid_loss=0.0332]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.0332]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0386, train_loss_epoch=0.0386, valid_loss=0.0332]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.0332]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=0.0332]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.0332]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=0.0332]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0436, train_loss_epoch=0.0436, valid_loss=0.0332]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.0332]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=0.0332]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=0.0332]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.0332]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.0332]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=0.0332]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.0332]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.0332]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.0332]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.0332]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.0332]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.0332]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0332]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0332]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.0332]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.0332]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=0.0332]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.0332]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:01<00:00,  0.68it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=0.0332]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=0.0332]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.0332]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.0332]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.0332]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0332]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.0332]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.0332]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.0332]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.0332]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.0332]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.040, valid_loss=0.0332]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.08it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=0.0308]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0308]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0418, train_loss_epoch=0.0418, valid_loss=0.0308]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.0308]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=0.0308]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=0.0308]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0308]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.0308]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391, valid_loss=0.0308]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.0308]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0329, train_loss_epoch=0.0329, valid_loss=0.0308]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=0.0308]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0251, train_loss_epoch=0.0251, valid_loss=0.0308]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.0308]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.0308]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0344, train_loss_epoch=0.0344, valid_loss=0.0308]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.0308]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.0308]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.0308]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=0.0308]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0308]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.0308]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.0308]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.0308]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=0.0308]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0308]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.0308]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.0308]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=0.0308]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=0.0308]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.0308]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0417, train_loss_epoch=0.0417, valid_loss=0.0308]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0308]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=0.0308]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.0308]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=0.0308]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.0308]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=0.0308]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393, valid_loss=0.0308]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=0.0308]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.0308]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.0308]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.0308]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0254, train_loss_epoch=0.0254, valid_loss=0.0308]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0384, train_loss_epoch=0.0384, valid_loss=0.0308]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.0308]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0308]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.0308]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.0308]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357, valid_loss=0.0308]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0319, train_loss_epoch=0.0319, valid_loss=0.0308]\n",
            "Epoch 250: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0308]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0308]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.0308]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0308]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.0308]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0244, valid_loss=0.0308]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.0308]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0311, train_loss_epoch=0.0311, valid_loss=0.0308]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.0308]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385, valid_loss=0.0308]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0308]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.0308]\n",
            "Epoch 260: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.0308]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.0308]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.0308]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0308]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0308]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.0308]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=0.0308]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.0308]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0406, train_loss_epoch=0.0406, valid_loss=0.0308]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:01<00:00,  0.69it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0406, valid_loss=0.0308]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.0308]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0354, train_loss_epoch=0.0354, valid_loss=0.0308]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=0.0308]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=0.0308]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.0308]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0297, train_loss_epoch=0.0297, valid_loss=0.0308]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.0308]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=0.0308]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=0.0308]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=0.0308]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.0308]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.0308]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=0.0308]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.0308]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=0.0308]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0369, train_loss_epoch=0.0369, valid_loss=0.0308]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=0.0308]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.0308]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.0308]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.0308]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.0308]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.0308]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=0.0308]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.0308]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0362, train_loss_epoch=0.0362, valid_loss=0.0308]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.0308]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.0308]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0428, train_loss_epoch=0.0428, valid_loss=0.0308]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=0.0308]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0398, train_loss_epoch=0.0398, valid_loss=0.0308]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0373, train_loss_epoch=0.0373, valid_loss=0.0308]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0373, valid_loss=0.0308]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.93it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.0306]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.0306]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=0.0306]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0306]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=0.0306]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.0306]\n",
            "Epoch 305: 100%|██████████| 1/1 [00:01<00:00,  0.69it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0298, valid_loss=0.0306]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.0306]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.0306]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.0306]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.0306]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:01<00:00,  0.68it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=0.0306] \n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=0.0306]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.0306]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.0306]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.0306]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0306]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.0306]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.0306]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.0306]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=0.0306]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=0.0306]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=0.0306]\n",
            "Epoch 320: 100%|██████████| 1/1 [00:01<00:00,  0.68it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0231, valid_loss=0.0306]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0262, train_loss_epoch=0.0262, valid_loss=0.0306]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0223, train_loss_epoch=0.0223, valid_loss=0.0306]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.0306]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0205, train_loss_epoch=0.0205, valid_loss=0.0306]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0239, train_loss_epoch=0.0239, valid_loss=0.0306]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=0.0306]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.0306]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0234, train_loss_epoch=0.0234, valid_loss=0.0306]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0252, train_loss_epoch=0.0252, valid_loss=0.0306]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0205, train_loss_epoch=0.0205, valid_loss=0.0306]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.0306]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.0306]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.0306]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=0.0306]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0228, train_loss_epoch=0.0228, valid_loss=0.0306]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.0306]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020, valid_loss=0.0306]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.0306]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.0306]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.0306]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.0306]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0306]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0306]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0315, train_loss_epoch=0.0315, valid_loss=0.0306]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=0.0306]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=0.0306]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0306]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=0.0306]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0306]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.032, valid_loss=0.0306]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.0306]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.0306]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.0306]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0308, train_loss_epoch=0.0308, valid_loss=0.0306]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.0306]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.0306]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.0306]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0306]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.0306]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=0.0306]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.0306]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.0306]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.0306]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.0306]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038, valid_loss=0.0306]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.0306]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=0.0306]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.0306]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.0306]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.0306]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0306]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.0306]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.0306]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0271, train_loss_epoch=0.0271, valid_loss=0.0306]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.0306]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.0306]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=0.0306]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307, valid_loss=0.0306]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0217, train_loss_epoch=0.0217, valid_loss=0.0306]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296, valid_loss=0.0306]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.0306]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0306]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=0.0306]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0306]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0255, train_loss_epoch=0.0255, valid_loss=0.0306]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0298, train_loss_epoch=0.0298, valid_loss=0.0306]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194, valid_loss=0.0306]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.0306]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0253, train_loss_epoch=0.0253, valid_loss=0.0306]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.0306]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248, valid_loss=0.0306]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0235, train_loss_epoch=0.0235, valid_loss=0.0306]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0306]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0224, train_loss_epoch=0.0224, valid_loss=0.0306]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0221, train_loss_epoch=0.0221, valid_loss=0.0306]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.0306]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.0306]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.0306]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.0306]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022, valid_loss=0.0306]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:01<00:00,  0.69it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.022, valid_loss=0.0306]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.05it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.029]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.029]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.023, train_loss_epoch=0.023, valid_loss=0.029]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.029]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.029]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.029]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.029]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179, valid_loss=0.029]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.029]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.029]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.029]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.029]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.029]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.029]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.029]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163, valid_loss=0.029]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.029]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.029]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.029]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.029]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.029]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.029]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.029]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.029]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.029]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.029]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.029]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.029]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.029]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00869, train_loss_epoch=0.00869, valid_loss=0.029]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.029]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00876, train_loss_epoch=0.00876, valid_loss=0.029]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.029]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00746, train_loss_epoch=0.00746, valid_loss=0.029]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.029]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.029]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.029]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00945, train_loss_epoch=0.00945, valid_loss=0.029]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.029]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.029]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.029]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.029]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.029]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.029]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.029]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.029]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.029]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00995, train_loss_epoch=0.00995, valid_loss=0.029]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.029]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.029]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.029]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.029]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.029]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.029]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.029]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.029]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.029]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.029]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.029]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.029]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.029]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.029]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.029]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.029]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.029]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.029]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.029]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.029]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.029]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.029]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.029]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.029]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.029]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.029]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.029]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.029]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.029]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.029]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0125, valid_loss=0.029]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.029]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.029]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.029]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.029]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.029]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.029]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.029]\n",
            "Epoch 484: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.029]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.029]        \n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.029]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.029]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.029]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0098, train_loss_epoch=0.0098, valid_loss=0.029]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00859, train_loss_epoch=0.00859, valid_loss=0.029]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.029]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00876, train_loss_epoch=0.00876, valid_loss=0.029]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.029]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.029]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.029]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.029]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.029]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.029]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.029]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.029]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:01<00:00,  0.69it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0138, valid_loss=0.029]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 77.17it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0293]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0293]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00951, train_loss_epoch=0.00951, valid_loss=0.0293]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0293]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00952, train_loss_epoch=0.00952, valid_loss=0.0293]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00885, train_loss_epoch=0.00885, valid_loss=0.0293]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00983, train_loss_epoch=0.00983, valid_loss=0.0293]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00893, train_loss_epoch=0.00893, valid_loss=0.0293]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0293]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0293]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0293]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0293]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0293]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00929, train_loss_epoch=0.00929, valid_loss=0.0293]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0293]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0293]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0293]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0293]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.0293]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.0293]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0293]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0293]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0293]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0293]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0293]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0293]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.0293]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0293]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0293]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0293]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0293]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00864, train_loss_epoch=0.00864, valid_loss=0.0293]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00987, train_loss_epoch=0.00987, valid_loss=0.0293]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00945, train_loss_epoch=0.00945, valid_loss=0.0293]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0293]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0293]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0293]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0293]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0293]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.0293]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0293]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0293]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0293]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00957, train_loss_epoch=0.00957, valid_loss=0.0293]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0293]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0293]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.0293]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.0293]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.0293]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.0293]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0293]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0293]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.0293]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0293]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.0293]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0293]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0293]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0293]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0293]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0293]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0293]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.0293]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00951, train_loss_epoch=0.00951, valid_loss=0.0293]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:01<00:00,  0.71it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.00951, valid_loss=0.0293] \n",
            "Epoch 562: 100%|██████████| 1/1 [00:01<00:00,  0.70it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0293] \n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0293]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0293]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.0293]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0293]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0293]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0293]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0293]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0293]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0293]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00944, train_loss_epoch=0.00944, valid_loss=0.0293]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:01<00:00,  0.58it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00944, valid_loss=0.0293]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00912, valid_loss=0.0293]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00826, train_loss_epoch=0.00826, valid_loss=0.0293]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0293]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00924, train_loss_epoch=0.00924, valid_loss=0.0293]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00954, train_loss_epoch=0.00954, valid_loss=0.0293]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00781, train_loss_epoch=0.00781, valid_loss=0.0293]\n",
            "Epoch 578: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s, v_num=0, train_loss_step=0.00841, train_loss_epoch=0.00781, valid_loss=0.0293]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00841, train_loss_epoch=0.00841, valid_loss=0.0293]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00859, train_loss_epoch=0.00859, valid_loss=0.0293]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00845, train_loss_epoch=0.00845, valid_loss=0.0293]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00755, train_loss_epoch=0.00755, valid_loss=0.0293]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00904, train_loss_epoch=0.00904, valid_loss=0.0293]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00892, train_loss_epoch=0.00892, valid_loss=0.0293]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0293]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0293]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00983, train_loss_epoch=0.00983, valid_loss=0.0293]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00957, train_loss_epoch=0.00957, valid_loss=0.0293]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00874, train_loss_epoch=0.00874, valid_loss=0.0293]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00941, train_loss_epoch=0.00941, valid_loss=0.0293]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0293]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00998, train_loss_epoch=0.00998, valid_loss=0.0293]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0293]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0293]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00814, train_loss_epoch=0.00814, valid_loss=0.0293]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00909, train_loss_epoch=0.00909, valid_loss=0.0293]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00916, train_loss_epoch=0.00916, valid_loss=0.0293]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00815, train_loss_epoch=0.00815, valid_loss=0.0293]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0293]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.50it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.0104, valid_loss=0.0293]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.44it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.0305]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0071, train_loss_epoch=0.0071, valid_loss=0.0305]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00913, train_loss_epoch=0.00913, valid_loss=0.0305]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0305]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0305]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0305]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00994, train_loss_epoch=0.00994, valid_loss=0.0305]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0305]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0305]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00976, train_loss_epoch=0.00976, valid_loss=0.0305]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0305]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0305]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00917, train_loss_epoch=0.00917, valid_loss=0.0305]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0305]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0305]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0305]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.0305]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00857, train_loss_epoch=0.00857, valid_loss=0.0305]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.0305]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0305]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.0305]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0305]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.0305]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0305]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0305]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0305]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0305]\n",
            "Epoch 634: 100%|██████████| 1/1 [00:01<00:00,  0.70it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0126, valid_loss=0.0305]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0305]        \n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0305]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0305]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.0305]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.0305]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0305]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0305]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00977, train_loss_epoch=0.00977, valid_loss=0.0305]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846, valid_loss=0.0305]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00986, train_loss_epoch=0.00986, valid_loss=0.0305]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00917, train_loss_epoch=0.00917, valid_loss=0.0305]\n",
            "Epoch 647: 100%|██████████| 1/1 [00:01<00:00,  0.68it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.00917, valid_loss=0.0305] \n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00912, valid_loss=0.0305]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00899, train_loss_epoch=0.00899, valid_loss=0.0305]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00862, train_loss_epoch=0.00862, valid_loss=0.0305]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00828, train_loss_epoch=0.00828, valid_loss=0.0305]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0305]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00741, train_loss_epoch=0.00741, valid_loss=0.0305]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0305]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00906, train_loss_epoch=0.00906, valid_loss=0.0305]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0305]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00977, train_loss_epoch=0.00977, valid_loss=0.0305]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0305]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0305]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00904, train_loss_epoch=0.00904, valid_loss=0.0305]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0305]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0305]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.0305]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0305]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0305]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.0305]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0305]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988, valid_loss=0.0305]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0305]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0305]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0305]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0305]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0305]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.0305]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0305]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0305]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.0305]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0305]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.0305]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0305]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0305]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0305]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00992, train_loss_epoch=0.00992, valid_loss=0.0305]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0305]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00935, train_loss_epoch=0.00935, valid_loss=0.0305]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00997, train_loss_epoch=0.00997, valid_loss=0.0305]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00912, valid_loss=0.0305]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00886, train_loss_epoch=0.00886, valid_loss=0.0305]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00928, train_loss_epoch=0.00928, valid_loss=0.0305]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756, valid_loss=0.0305]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:01<00:00,  0.56it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.00756, valid_loss=0.0305] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.93it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0305]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00893, train_loss_epoch=0.00893, valid_loss=0.0305]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00914, train_loss_epoch=0.00914, valid_loss=0.0305]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00808, train_loss_epoch=0.00808, valid_loss=0.0305]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0305]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0305]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0305]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00983, train_loss_epoch=0.00983, valid_loss=0.0305]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0305]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00839, train_loss_epoch=0.00839, valid_loss=0.0305]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0305]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.0305]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00951, train_loss_epoch=0.00951, valid_loss=0.0305]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.0305]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00942, train_loss_epoch=0.00942, valid_loss=0.0305]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.0305]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.0305]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0305]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.0305]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00864, train_loss_epoch=0.00864, valid_loss=0.0305]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.0305]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00978, train_loss_epoch=0.00978, valid_loss=0.0305]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0305]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00925, train_loss_epoch=0.00925, valid_loss=0.0305]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0305]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00904, train_loss_epoch=0.00904, valid_loss=0.0305]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 733: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0305]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.0305]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0305]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0305]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=0.0305]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0305]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0305]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0305]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0305]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.0305]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0305]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0305]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0305]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00972, train_loss_epoch=0.00972, valid_loss=0.0305]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0305]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0305]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0305]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00903, train_loss_epoch=0.00903, valid_loss=0.0305]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00963, train_loss_epoch=0.00963, valid_loss=0.0305]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00824, train_loss_epoch=0.00824, valid_loss=0.0305]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0305]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00834, train_loss_epoch=0.00834, valid_loss=0.0305]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.0305]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0305]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00978, train_loss_epoch=0.00978, valid_loss=0.0305]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0305]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0305]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00964, train_loss_epoch=0.00964, valid_loss=0.0305]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0305]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00893, train_loss_epoch=0.00893, valid_loss=0.0305]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0305]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00947, train_loss_epoch=0.00947, valid_loss=0.0305]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.0305]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0305]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0094, train_loss_epoch=0.0094, valid_loss=0.0305]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0305]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0305]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0305]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.0305]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00996, train_loss_epoch=0.00996, valid_loss=0.0305]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.0305]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0305]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00979, train_loss_epoch=0.00979, valid_loss=0.0305]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0305]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00864, train_loss_epoch=0.00864, valid_loss=0.0305]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0305]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0305]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0305]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.0305]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0305]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0305]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0305]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.0305]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0305]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.0305]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0305]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0305]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0305]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0305]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00981, train_loss_epoch=0.00981, valid_loss=0.0305]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0305]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0305]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0305]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00968, train_loss_epoch=0.00968, valid_loss=0.0305]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:01<00:00,  0.65it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.00968, valid_loss=0.0305] \n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.20it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0304]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.0304]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0075, train_loss_epoch=0.0075, valid_loss=0.0304]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00809, train_loss_epoch=0.00809, valid_loss=0.0304]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.00871, valid_loss=0.0304]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00694, train_loss_epoch=0.00694, valid_loss=0.0304]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00605, train_loss_epoch=0.00605, valid_loss=0.0304]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0068, train_loss_epoch=0.0068, valid_loss=0.0304]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.0304]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00661, train_loss_epoch=0.00661, valid_loss=0.0304]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0048, train_loss_epoch=0.0048, valid_loss=0.0304]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00514, train_loss_epoch=0.00514, valid_loss=0.0304]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=0.0304]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00496, train_loss_epoch=0.00496, valid_loss=0.0304]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00574, train_loss_epoch=0.00574, valid_loss=0.0304]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=0.0304]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00488, train_loss_epoch=0.00488, valid_loss=0.0304]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00491, train_loss_epoch=0.00491, valid_loss=0.0304]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00495, train_loss_epoch=0.00495, valid_loss=0.0304]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00478, train_loss_epoch=0.00478, valid_loss=0.0304]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.0304]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00455, train_loss_epoch=0.00455, valid_loss=0.0304]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00506, train_loss_epoch=0.00506, valid_loss=0.0304]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00478, train_loss_epoch=0.00478, valid_loss=0.0304]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.0304]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00565, train_loss_epoch=0.00565, valid_loss=0.0304]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.0304]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0044, train_loss_epoch=0.0044, valid_loss=0.0304]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00576, train_loss_epoch=0.00576, valid_loss=0.0304]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.0304]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.0304]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00582, train_loss_epoch=0.00582, valid_loss=0.0304]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00632, train_loss_epoch=0.00632, valid_loss=0.0304]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=0.0304]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00564, train_loss_epoch=0.00564, valid_loss=0.0304]\n",
            "Epoch 834: 100%|██████████| 1/1 [00:01<00:00,  0.67it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=0.0304]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00386, train_loss_epoch=0.00386, valid_loss=0.0304]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00569, train_loss_epoch=0.00569, valid_loss=0.0304]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00531, train_loss_epoch=0.00531, valid_loss=0.0304]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0304]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00531, train_loss_epoch=0.00531, valid_loss=0.0304]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.0304]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0304]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=0.0304]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00493, train_loss_epoch=0.00493, valid_loss=0.0304]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00525, train_loss_epoch=0.00525, valid_loss=0.0304]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=0.0304]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00437, train_loss_epoch=0.00437, valid_loss=0.0304]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00454, train_loss_epoch=0.00454, valid_loss=0.0304]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00331, train_loss_epoch=0.00331, valid_loss=0.0304]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=0.0304]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00451, train_loss_epoch=0.00451, valid_loss=0.0304]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0053, train_loss_epoch=0.0053, valid_loss=0.0304]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00429, train_loss_epoch=0.00429, valid_loss=0.0304]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00525, train_loss_epoch=0.00525, valid_loss=0.0304]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00452, train_loss_epoch=0.00452, valid_loss=0.0304]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00553, train_loss_epoch=0.00553, valid_loss=0.0304]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00596, train_loss_epoch=0.00596, valid_loss=0.0304]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00418, train_loss_epoch=0.00418, valid_loss=0.0304]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00507, train_loss_epoch=0.00507, valid_loss=0.0304]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00458, train_loss_epoch=0.00458, valid_loss=0.0304]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00405, train_loss_epoch=0.00405, valid_loss=0.0304]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00584, train_loss_epoch=0.00584, valid_loss=0.0304]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00429, train_loss_epoch=0.00429, valid_loss=0.0304]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0063, train_loss_epoch=0.0063, valid_loss=0.0304]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00503, train_loss_epoch=0.00503, valid_loss=0.0304]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=0.0304]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.0304]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00555, train_loss_epoch=0.00555, valid_loss=0.0304]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00592, train_loss_epoch=0.00592, valid_loss=0.0304]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00524, train_loss_epoch=0.00524, valid_loss=0.0304]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00588, train_loss_epoch=0.00588, valid_loss=0.0304]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.0304]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00425, train_loss_epoch=0.00425, valid_loss=0.0304]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00634, train_loss_epoch=0.00634, valid_loss=0.0304]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=0.0304]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00495, train_loss_epoch=0.00495, valid_loss=0.0304]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00668, train_loss_epoch=0.00668, valid_loss=0.0304]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00588, train_loss_epoch=0.00588, valid_loss=0.0304]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0304]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0304]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00611, train_loss_epoch=0.00611, valid_loss=0.0304]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0069, train_loss_epoch=0.0069, valid_loss=0.0304]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00703, train_loss_epoch=0.00703, valid_loss=0.0304]\n",
            "Epoch 882: 100%|██████████| 1/1 [00:02<00:00,  0.40it/s, v_num=0, train_loss_step=0.00526, train_loss_epoch=0.00703, valid_loss=0.0304]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00526, train_loss_epoch=0.00526, valid_loss=0.0304]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00616, train_loss_epoch=0.00616, valid_loss=0.0304]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00507, train_loss_epoch=0.00507, valid_loss=0.0304]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=0.0304]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00622, valid_loss=0.0304]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00506, train_loss_epoch=0.00506, valid_loss=0.0304]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00691, train_loss_epoch=0.00691, valid_loss=0.0304]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00593, train_loss_epoch=0.00593, valid_loss=0.0304]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0304]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00611, train_loss_epoch=0.00611, valid_loss=0.0304]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.0304]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00572, train_loss_epoch=0.00572, valid_loss=0.0304]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00607, train_loss_epoch=0.00607, valid_loss=0.0304]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=0.0304]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00665, train_loss_epoch=0.00665, valid_loss=0.0304]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00687, train_loss_epoch=0.00687, valid_loss=0.0304]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00651, train_loss_epoch=0.00651, valid_loss=0.0304]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00651, valid_loss=0.0304]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.29it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.0305]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0305]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00578, train_loss_epoch=0.00578, valid_loss=0.0305]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00519, valid_loss=0.0305]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00571, train_loss_epoch=0.00571, valid_loss=0.0305]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0305]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0052, train_loss_epoch=0.0052, valid_loss=0.0305]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00441, train_loss_epoch=0.00441, valid_loss=0.0305]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.0305]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00504, train_loss_epoch=0.00504, valid_loss=0.0305]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0058, train_loss_epoch=0.0058, valid_loss=0.0305]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=0.0305]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=0.0305]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.0305]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00606, train_loss_epoch=0.00606, valid_loss=0.0305]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00507, train_loss_epoch=0.00507, valid_loss=0.0305]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=0.0305]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00605, train_loss_epoch=0.00605, valid_loss=0.0305]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00516, train_loss_epoch=0.00516, valid_loss=0.0305]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00484, train_loss_epoch=0.00484, valid_loss=0.0305]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00628, train_loss_epoch=0.00628, valid_loss=0.0305]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0305]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00466, train_loss_epoch=0.00466, valid_loss=0.0305]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=0.0305]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0305]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00414, train_loss_epoch=0.00414, valid_loss=0.0305]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00606, train_loss_epoch=0.00606, valid_loss=0.0305]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00486, train_loss_epoch=0.00486, valid_loss=0.0305]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00699, train_loss_epoch=0.00699, valid_loss=0.0305]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00565, train_loss_epoch=0.00565, valid_loss=0.0305]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00583, train_loss_epoch=0.00583, valid_loss=0.0305]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00714, train_loss_epoch=0.00714, valid_loss=0.0305]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00634, train_loss_epoch=0.00634, valid_loss=0.0305]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00566, train_loss_epoch=0.00566, valid_loss=0.0305]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0305]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=0.0305]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00642, train_loss_epoch=0.00642, valid_loss=0.0305]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00652, train_loss_epoch=0.00652, valid_loss=0.0305]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.0305]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.0305]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=0.0305]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00527, train_loss_epoch=0.00527, valid_loss=0.0305]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00477, train_loss_epoch=0.00477, valid_loss=0.0305]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00664, train_loss_epoch=0.00664, valid_loss=0.0305]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.0305]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00625, train_loss_epoch=0.00625, valid_loss=0.0305]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00568, train_loss_epoch=0.00568, valid_loss=0.0305]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.0305]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00527, train_loss_epoch=0.00527, valid_loss=0.0305]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00668, train_loss_epoch=0.00668, valid_loss=0.0305]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=0.0305]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00618, train_loss_epoch=0.00618, valid_loss=0.0305]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00531, train_loss_epoch=0.00531, valid_loss=0.0305]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00578, train_loss_epoch=0.00578, valid_loss=0.0305]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00507, train_loss_epoch=0.00507, valid_loss=0.0305]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00574, train_loss_epoch=0.00574, valid_loss=0.0305]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00503, train_loss_epoch=0.00503, valid_loss=0.0305]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00647, train_loss_epoch=0.00647, valid_loss=0.0305]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00578, train_loss_epoch=0.00578, valid_loss=0.0305]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00723, train_loss_epoch=0.00723, valid_loss=0.0305]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.0305]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00598, train_loss_epoch=0.00598, valid_loss=0.0305]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=0.0305]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00546, train_loss_epoch=0.00546, valid_loss=0.0305]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=0.0305]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00501, valid_loss=0.0305]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00471, valid_loss=0.0305]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00552, train_loss_epoch=0.00552, valid_loss=0.0305]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00394, train_loss_epoch=0.00394, valid_loss=0.0305]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00591, train_loss_epoch=0.00591, valid_loss=0.0305]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00448, train_loss_epoch=0.00448, valid_loss=0.0305]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0064, train_loss_epoch=0.0064, valid_loss=0.0305]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00541, train_loss_epoch=0.00541, valid_loss=0.0305]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00582, train_loss_epoch=0.00582, valid_loss=0.0305]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00525, train_loss_epoch=0.00525, valid_loss=0.0305]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00497, train_loss_epoch=0.00497, valid_loss=0.0305]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0045, train_loss_epoch=0.0045, valid_loss=0.0305]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0305]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00418, train_loss_epoch=0.00418, valid_loss=0.0305]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=0.0305]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=0.0305]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00586, train_loss_epoch=0.00586, valid_loss=0.0305]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=0.0305]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00576, train_loss_epoch=0.00576, valid_loss=0.0305]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00538, train_loss_epoch=0.00538, valid_loss=0.0305]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=0.0305]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00433, train_loss_epoch=0.00433, valid_loss=0.0305]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00674, train_loss_epoch=0.00674, valid_loss=0.0305]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.0305]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00677, train_loss_epoch=0.00677, valid_loss=0.0305]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=0.0305]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00581, train_loss_epoch=0.00581, valid_loss=0.0305]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00497, train_loss_epoch=0.00497, valid_loss=0.0305]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00618, train_loss_epoch=0.00618, valid_loss=0.0305]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00541, train_loss_epoch=0.00541, valid_loss=0.0305]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00512, train_loss_epoch=0.00512, valid_loss=0.0305]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=0.0305]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00591, train_loss_epoch=0.00591, valid_loss=0.0305]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00586, train_loss_epoch=0.00586, valid_loss=0.0305]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00511, train_loss_epoch=0.00511, valid_loss=0.0305]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:01<00:00,  0.65it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00511, valid_loss=0.0305]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.42it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00471, valid_loss=0.0304]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00522, train_loss_epoch=0.00522, valid_loss=0.0304]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00478, train_loss_epoch=0.00478, valid_loss=0.0304]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00599, train_loss_epoch=0.00599, valid_loss=0.0304]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00578, train_loss_epoch=0.00578, valid_loss=0.0304]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.0304]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00549, train_loss_epoch=0.00549, valid_loss=0.0304]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00583, train_loss_epoch=0.00583, valid_loss=0.0304]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00533, train_loss_epoch=0.00533, valid_loss=0.0304]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00388, train_loss_epoch=0.00388, valid_loss=0.0304]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=0.0304]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0047, train_loss_epoch=0.0047, valid_loss=0.0304]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=0.0304]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00483, train_loss_epoch=0.00483, valid_loss=0.0304]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0304]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0047, train_loss_epoch=0.0047, valid_loss=0.0304]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0304]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00448, train_loss_epoch=0.00448, valid_loss=0.0304]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00464, train_loss_epoch=0.00464, valid_loss=0.0304]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00496, train_loss_epoch=0.00496, valid_loss=0.0304]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00416, train_loss_epoch=0.00416, valid_loss=0.0304]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00395, train_loss_epoch=0.00395, valid_loss=0.0304]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0051, train_loss_epoch=0.0051, valid_loss=0.0304]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0046, train_loss_epoch=0.0046, valid_loss=0.0304]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00437, train_loss_epoch=0.00437, valid_loss=0.0304]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=0.0304]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00482, train_loss_epoch=0.00482, valid_loss=0.0304]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00377, train_loss_epoch=0.00377, valid_loss=0.0304]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0304]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00462, train_loss_epoch=0.00462, valid_loss=0.0304]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00465, train_loss_epoch=0.00465, valid_loss=0.0304]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0045, train_loss_epoch=0.0045, valid_loss=0.0304]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=0.0304]\n",
            "Epoch 1032: 100%|██████████| 1/1 [00:01<00:00,  0.64it/s, v_num=0, train_loss_step=0.00424, train_loss_epoch=0.00499, valid_loss=0.0304]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00424, train_loss_epoch=0.00424, valid_loss=0.0304]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00493, train_loss_epoch=0.00493, valid_loss=0.0304]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00473, train_loss_epoch=0.00473, valid_loss=0.0304]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0043, train_loss_epoch=0.0043, valid_loss=0.0304]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00448, train_loss_epoch=0.00448, valid_loss=0.0304]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00553, train_loss_epoch=0.00553, valid_loss=0.0304]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.0304]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.0304]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0304]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00594, train_loss_epoch=0.00594, valid_loss=0.0304]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.0304]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=0.0304]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0069, train_loss_epoch=0.0069, valid_loss=0.0304]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0304]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00502, train_loss_epoch=0.00502, valid_loss=0.0304]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00535, train_loss_epoch=0.00535, valid_loss=0.0304]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00504, train_loss_epoch=0.00504, valid_loss=0.0304]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00515, train_loss_epoch=0.00515, valid_loss=0.0304]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00438, valid_loss=0.0304]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00576, train_loss_epoch=0.00576, valid_loss=0.0304]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=0.0304]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00734, train_loss_epoch=0.00734, valid_loss=0.0304]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00624, train_loss_epoch=0.00624, valid_loss=0.0304]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.005, train_loss_epoch=0.005, valid_loss=0.0304]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00587, train_loss_epoch=0.00587, valid_loss=0.0304]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0304]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.0304]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00571, train_loss_epoch=0.00571, valid_loss=0.0304]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00661, train_loss_epoch=0.00661, valid_loss=0.0304]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00482, train_loss_epoch=0.00482, valid_loss=0.0304]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00687, train_loss_epoch=0.00687, valid_loss=0.0304]\n",
            "Epoch 1063: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00687, valid_loss=0.0304]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00716, valid_loss=0.0304]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00509, train_loss_epoch=0.00509, valid_loss=0.0304]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00667, train_loss_epoch=0.00667, valid_loss=0.0304]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00605, train_loss_epoch=0.00605, valid_loss=0.0304]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=0.0304]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=0.0304]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00691, train_loss_epoch=0.00691, valid_loss=0.0304]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0304]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0304]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00701, train_loss_epoch=0.00701, valid_loss=0.0304]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0052, train_loss_epoch=0.0052, valid_loss=0.0304]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.0304]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00632, train_loss_epoch=0.00632, valid_loss=0.0304]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00655, train_loss_epoch=0.00655, valid_loss=0.0304]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00561, train_loss_epoch=0.00561, valid_loss=0.0304]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=0.0304]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0066, train_loss_epoch=0.0066, valid_loss=0.0304]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00494, train_loss_epoch=0.00494, valid_loss=0.0304]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00453, train_loss_epoch=0.00453, valid_loss=0.0304]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00523, train_loss_epoch=0.00523, valid_loss=0.0304]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00404, train_loss_epoch=0.00404, valid_loss=0.0304]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00501, valid_loss=0.0304]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00483, train_loss_epoch=0.00483, valid_loss=0.0304]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0304]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00551, train_loss_epoch=0.00551, valid_loss=0.0304]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0304]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0047, train_loss_epoch=0.0047, valid_loss=0.0304]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00603, train_loss_epoch=0.00603, valid_loss=0.0304]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00647, train_loss_epoch=0.00647, valid_loss=0.0304]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00591, train_loss_epoch=0.00591, valid_loss=0.0304]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00421, train_loss_epoch=0.00421, valid_loss=0.0304]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00676, train_loss_epoch=0.00676, valid_loss=0.0304]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=0.0304]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00564, train_loss_epoch=0.00564, valid_loss=0.0304]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00551, train_loss_epoch=0.00551, valid_loss=0.0304]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00531, train_loss_epoch=0.00531, valid_loss=0.0304]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=0, train_loss_step=0.00572, train_loss_epoch=0.00531, valid_loss=0.0304]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.71it/s]\u001b[A\n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00572, train_loss_epoch=0.00572, valid_loss=0.0304]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00589, train_loss_epoch=0.00589, valid_loss=0.0304]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0304]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00596, train_loss_epoch=0.00596, valid_loss=0.0304]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0304]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00685, train_loss_epoch=0.00685, valid_loss=0.0304]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00607, train_loss_epoch=0.00607, valid_loss=0.0304]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.0304]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00593, train_loss_epoch=0.00593, valid_loss=0.0304]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00762, train_loss_epoch=0.00762, valid_loss=0.0304]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00667, train_loss_epoch=0.00667, valid_loss=0.0304]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00572, train_loss_epoch=0.00572, valid_loss=0.0304]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=0.0304]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00744, train_loss_epoch=0.00744, valid_loss=0.0304]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00561, train_loss_epoch=0.00561, valid_loss=0.0304]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00736, train_loss_epoch=0.00736, valid_loss=0.0304]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0051, train_loss_epoch=0.0051, valid_loss=0.0304]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00724, valid_loss=0.0304]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00652, train_loss_epoch=0.00652, valid_loss=0.0304]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.0304]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00565, train_loss_epoch=0.00565, valid_loss=0.0304]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00679, train_loss_epoch=0.00679, valid_loss=0.0304]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00543, train_loss_epoch=0.00543, valid_loss=0.0304]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00584, train_loss_epoch=0.00584, valid_loss=0.0304]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00461, train_loss_epoch=0.00461, valid_loss=0.0304]\n",
            "Epoch 1124: 100%|██████████| 1/1 [00:02<00:00,  0.41it/s, v_num=0, train_loss_step=0.00598, train_loss_epoch=0.00461, valid_loss=0.0304]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00598, train_loss_epoch=0.00598, valid_loss=0.0304]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00545, valid_loss=0.0304]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00604, train_loss_epoch=0.00604, valid_loss=0.0304]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00676, train_loss_epoch=0.00676, valid_loss=0.0304]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.0304]\n",
            "Epoch 1129: 100%|██████████| 1/1 [00:01<00:00,  0.68it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.0304]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00739, train_loss_epoch=0.00739, valid_loss=0.0304]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00652, train_loss_epoch=0.00652, valid_loss=0.0304]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0304]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00751, train_loss_epoch=0.00751, valid_loss=0.0304]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00496, train_loss_epoch=0.00496, valid_loss=0.0304]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0081, train_loss_epoch=0.0081, valid_loss=0.0304]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0304]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00611, train_loss_epoch=0.00611, valid_loss=0.0304]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00684, train_loss_epoch=0.00684, valid_loss=0.0304]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00527, train_loss_epoch=0.00527, valid_loss=0.0304]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.0304]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00439, train_loss_epoch=0.00439, valid_loss=0.0304]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00506, train_loss_epoch=0.00506, valid_loss=0.0304]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00526, train_loss_epoch=0.00526, valid_loss=0.0304]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00496, train_loss_epoch=0.00496, valid_loss=0.0304]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00571, train_loss_epoch=0.00571, valid_loss=0.0304]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00506, train_loss_epoch=0.00506, valid_loss=0.0304]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0304]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0304]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=0.0304]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=0.0304]\n",
            "Epoch 1150: 100%|██████████| 1/1 [00:02<00:00,  0.42it/s, v_num=0, train_loss_step=0.00457, train_loss_epoch=0.00529, valid_loss=0.0304]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00457, train_loss_epoch=0.00457, valid_loss=0.0304]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00741, train_loss_epoch=0.00741, valid_loss=0.0304]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.0304]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00759, train_loss_epoch=0.00759, valid_loss=0.0304]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.0304]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00684, train_loss_epoch=0.00684, valid_loss=0.0304]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.0304]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0068, train_loss_epoch=0.0068, valid_loss=0.0304]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00686, train_loss_epoch=0.00686, valid_loss=0.0304]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=0.0304]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00747, train_loss_epoch=0.00747, valid_loss=0.0304]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=0.0304]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00615, train_loss_epoch=0.00615, valid_loss=0.0304]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00742, train_loss_epoch=0.00742, valid_loss=0.0304]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00667, train_loss_epoch=0.00667, valid_loss=0.0304]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0304]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0064, train_loss_epoch=0.0064, valid_loss=0.0304]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00502, train_loss_epoch=0.00502, valid_loss=0.0304]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00591, train_loss_epoch=0.00591, valid_loss=0.0304]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00547, train_loss_epoch=0.00547, valid_loss=0.0304]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.0304]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00599, train_loss_epoch=0.00599, valid_loss=0.0304]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.0304]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00472, train_loss_epoch=0.00472, valid_loss=0.0304]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00559, train_loss_epoch=0.00559, valid_loss=0.0304]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00476, train_loss_epoch=0.00476, valid_loss=0.0304]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0061, train_loss_epoch=0.0061, valid_loss=0.0304]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=0.0304]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0304]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00657, train_loss_epoch=0.00657, valid_loss=0.0304]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00695, train_loss_epoch=0.00695, valid_loss=0.0304]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.006, train_loss_epoch=0.006, valid_loss=0.0304]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0055, train_loss_epoch=0.0055, valid_loss=0.0304]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00545, valid_loss=0.0304]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00565, train_loss_epoch=0.00565, valid_loss=0.0304]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00486, train_loss_epoch=0.00486, valid_loss=0.0304]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0063, train_loss_epoch=0.0063, valid_loss=0.0304]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00607, train_loss_epoch=0.00607, valid_loss=0.0304]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00649, train_loss_epoch=0.00649, valid_loss=0.0304]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00623, train_loss_epoch=0.00623, valid_loss=0.0304]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.0304]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=0.0304]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=0.0304]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0304]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0054, train_loss_epoch=0.0054, valid_loss=0.0304]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00498, train_loss_epoch=0.00498, valid_loss=0.0304]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00631, train_loss_epoch=0.00631, valid_loss=0.0304]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0052, train_loss_epoch=0.0052, valid_loss=0.0304]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00679, train_loss_epoch=0.00679, valid_loss=0.0304]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 19:41:01,289\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (60, 8, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m `Trainer.fit` stopped: `max_steps=1200.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s, v_num=0, train_loss_step=0.00679, train_loss_epoch=0.00679, valid_loss=0.0304]\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.66it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00679, valid_loss=0.0304]\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.92it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=26253)\u001b[0m \r                                                                       \u001b[A\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.65it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00679, valid_loss=0.0308]\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.65it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=0.0308]\rEpoch 1199: 100%|██████████| 1/1 [00:01<00:00,  0.65it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=0.0308]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=34928)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 2025-06-15 19:41:16.025247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m E0000 00:00:1750016476.062736   35022 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m E0000 00:00:1750016476.072130   35022 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 2025-06-15 19:41:16.105817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 3 | blocks       | ModuleList    | 8.2 M  | train\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 8.2 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 8.2 M     Total params\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 32.860    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.80, train_loss_epoch=33.80]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.40, train_loss_epoch=34.40]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.80, train_loss_epoch=31.80]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.70, train_loss_epoch=27.70]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.30, train_loss_epoch=26.30]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.50, train_loss_epoch=25.50]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.20, train_loss_epoch=25.20]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.20, train_loss_epoch=24.20]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.10, train_loss_epoch=23.10]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.20, train_loss_epoch=22.20]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.00, train_loss_epoch=20.00]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:01<00:00,  0.58it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.960, train_loss_epoch=9.960]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.840, train_loss_epoch=9.840]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.980, train_loss_epoch=9.980]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.670, train_loss_epoch=9.670]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.700, train_loss_epoch=9.700]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.590, train_loss_epoch=9.590]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.590, train_loss_epoch=9.590]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.500, train_loss_epoch=9.500]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=9.150]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.890, train_loss_epoch=8.890]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.190, train_loss_epoch=9.190]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.960, train_loss_epoch=8.960]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.480, train_loss_epoch=8.480]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.570, train_loss_epoch=8.570]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.340, train_loss_epoch=8.340]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.260, train_loss_epoch=8.260]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=8.910]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.560, train_loss_epoch=8.560]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.860, train_loss_epoch=7.860]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:01<00:00,  0.59it/s, v_num=0, train_loss_step=8.250, train_loss_epoch=7.860]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.28it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.250, train_loss_epoch=8.250, valid_loss=0.00409]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:02<00:00,  0.39it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00409]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00409]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.00409]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.260, train_loss_epoch=8.260, valid_loss=0.00409]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.00409]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930, valid_loss=0.00409]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.360, train_loss_epoch=8.360, valid_loss=0.00409]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.00409]\n",
            "Epoch 107: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=8.310, train_loss_epoch=7.600, valid_loss=0.00409]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.310, train_loss_epoch=8.310, valid_loss=0.00409]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.960, train_loss_epoch=7.960, valid_loss=0.00409]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.00409]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.00409]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.00409]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.00409]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.00409]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=0.00409]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.280, train_loss_epoch=7.280, valid_loss=0.00409]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930, valid_loss=0.00409]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=7.310, valid_loss=0.00409]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.00409]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.280, train_loss_epoch=7.280, valid_loss=0.00409]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.250, train_loss_epoch=7.250, valid_loss=0.00409]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.530, train_loss_epoch=7.530, valid_loss=0.00409]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.530, train_loss_epoch=7.530, valid_loss=0.00409]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.290, train_loss_epoch=7.290, valid_loss=0.00409]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.840, train_loss_epoch=6.840, valid_loss=0.00409]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.250, train_loss_epoch=7.250, valid_loss=0.00409]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.280, train_loss_epoch=7.280, valid_loss=0.00409]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.020, train_loss_epoch=7.020, valid_loss=0.00409]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.330, train_loss_epoch=7.330, valid_loss=0.00409]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.880, train_loss_epoch=6.880, valid_loss=0.00409]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.650, train_loss_epoch=6.650, valid_loss=0.00409]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.950, train_loss_epoch=6.950, valid_loss=0.00409]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.00409]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.940, train_loss_epoch=6.940, valid_loss=0.00409]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.670, train_loss_epoch=6.670, valid_loss=0.00409]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.560, train_loss_epoch=6.560, valid_loss=0.00409]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.600, train_loss_epoch=6.600, valid_loss=0.00409]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=0.00409]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460, valid_loss=0.00409]\n",
            "Epoch 139: 100%|██████████| 1/1 [00:02<00:00,  0.37it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.460, valid_loss=0.00409]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.690, valid_loss=0.00409]\n",
            "Epoch 140: 100%|██████████| 1/1 [00:01<00:00,  0.52it/s, v_num=0, train_loss_step=6.800, train_loss_epoch=6.690, valid_loss=0.00409]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.800, train_loss_epoch=6.800, valid_loss=0.00409]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.660, train_loss_epoch=6.660, valid_loss=0.00409]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=0.00409]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590, valid_loss=0.00409]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.320, train_loss_epoch=6.320, valid_loss=0.00409]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=0.00409]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.760, train_loss_epoch=6.760, valid_loss=0.00409]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.050, train_loss_epoch=6.050, valid_loss=0.00409]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.180, train_loss_epoch=6.180, valid_loss=0.00409]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.120, valid_loss=0.00409]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.00409]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.290, train_loss_epoch=6.290, valid_loss=0.00409]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.350, train_loss_epoch=6.350, valid_loss=0.00409]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.160, valid_loss=0.00409]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.310, train_loss_epoch=6.310, valid_loss=0.00409]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.390, train_loss_epoch=6.390, valid_loss=0.00409]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.010, train_loss_epoch=6.010, valid_loss=0.00409]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.480, train_loss_epoch=6.480, valid_loss=0.00409]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.320, train_loss_epoch=6.320, valid_loss=0.00409]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.830, train_loss_epoch=6.830, valid_loss=0.00409]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.130, train_loss_epoch=6.130, valid_loss=0.00409]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.450, train_loss_epoch=6.450, valid_loss=0.00409]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.380, train_loss_epoch=6.380, valid_loss=0.00409]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.990, train_loss_epoch=5.990, valid_loss=0.00409]\n",
            "Epoch 164: 100%|██████████| 1/1 [00:02<00:00,  0.44it/s, v_num=0, train_loss_step=6.340, train_loss_epoch=6.340, valid_loss=0.00409]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.340, train_loss_epoch=6.340, valid_loss=0.00409]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.220, train_loss_epoch=6.220, valid_loss=0.00409]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.160, valid_loss=0.00409]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.940, train_loss_epoch=5.940, valid_loss=0.00409]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.370, train_loss_epoch=6.370, valid_loss=0.00409]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.940, train_loss_epoch=5.940, valid_loss=0.00409]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960, valid_loss=0.00409]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.070, train_loss_epoch=6.070, valid_loss=0.00409]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.790, train_loss_epoch=5.790, valid_loss=0.00409]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.980, train_loss_epoch=5.980, valid_loss=0.00409]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.920, valid_loss=0.00409]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.740, train_loss_epoch=5.740, valid_loss=0.00409]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.460, valid_loss=0.00409]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.00409]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.900, train_loss_epoch=5.900, valid_loss=0.00409]\n",
            "Epoch 179: 100%|██████████| 1/1 [00:02<00:00,  0.37it/s, v_num=0, train_loss_step=6.230, train_loss_epoch=5.900, valid_loss=0.00409]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.230, train_loss_epoch=6.230, valid_loss=0.00409]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.630, train_loss_epoch=5.630, valid_loss=0.00409]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.120, valid_loss=0.00409]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.940, train_loss_epoch=5.940, valid_loss=0.00409]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.940, train_loss_epoch=5.940, valid_loss=0.00409]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.940, train_loss_epoch=5.940, valid_loss=0.00409]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.980, train_loss_epoch=5.980, valid_loss=0.00409]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.860, train_loss_epoch=5.860, valid_loss=0.00409]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.770, train_loss_epoch=5.770, valid_loss=0.00409]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.00409]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620, valid_loss=0.00409]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=0.00409]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.010, train_loss_epoch=5.010, valid_loss=0.00409]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.550, train_loss_epoch=5.550, valid_loss=0.00409]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370, valid_loss=0.00409]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.430, train_loss_epoch=5.430, valid_loss=0.00409]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.120, train_loss_epoch=5.120, valid_loss=0.00409]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.190, valid_loss=0.00409]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00409]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.110, train_loss_epoch=5.110, valid_loss=0.00409]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=5.640, train_loss_epoch=5.110, valid_loss=0.00409]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.51it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.640, train_loss_epoch=5.640, valid_loss=0.00372]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.180, train_loss_epoch=5.180, valid_loss=0.00372]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.870, train_loss_epoch=4.870, valid_loss=0.00372]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.810, train_loss_epoch=4.810, valid_loss=0.00372]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.710, train_loss_epoch=4.710, valid_loss=0.00372]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.680, train_loss_epoch=4.680, valid_loss=0.00372]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.650, train_loss_epoch=4.650, valid_loss=0.00372]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.450, train_loss_epoch=4.450, valid_loss=0.00372]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.650, train_loss_epoch=4.650, valid_loss=0.00372]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.400, train_loss_epoch=4.400, valid_loss=0.00372]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.480, train_loss_epoch=4.480, valid_loss=0.00372]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.370, train_loss_epoch=4.370, valid_loss=0.00372]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.270, train_loss_epoch=4.270, valid_loss=0.00372]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=4.350, valid_loss=0.00372]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=4.350, valid_loss=0.00372]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.390, train_loss_epoch=4.390, valid_loss=0.00372]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220, valid_loss=0.00372]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.140, train_loss_epoch=4.140, valid_loss=0.00372]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=0.00372]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.240, train_loss_epoch=4.240, valid_loss=0.00372]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=0.00372]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=0.00372]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.280, train_loss_epoch=4.280, valid_loss=0.00372]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.240, train_loss_epoch=4.240, valid_loss=0.00372]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220, valid_loss=0.00372]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=0.00372]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.080, train_loss_epoch=4.080, valid_loss=0.00372]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:02<00:00,  0.37it/s, v_num=0, train_loss_step=4.080, train_loss_epoch=4.080, valid_loss=0.00372]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.080, train_loss_epoch=4.080, valid_loss=0.00372]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=0.00372]\n",
            "Epoch 228: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=4.090, valid_loss=0.00372]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=0.00372]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.100, train_loss_epoch=4.100, valid_loss=0.00372]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.930, train_loss_epoch=3.930, valid_loss=0.00372]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=0.00372]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.060, train_loss_epoch=4.060, valid_loss=0.00372]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00372]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00372]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00372]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.940, train_loss_epoch=3.940, valid_loss=0.00372]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.930, train_loss_epoch=3.930, valid_loss=0.00372]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=3.900, valid_loss=0.00372]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00372]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00372]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880, valid_loss=0.00372]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780, valid_loss=0.00372]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=0.00372]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00372]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00372]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880, valid_loss=0.00372]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=3.900, valid_loss=0.00372]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.900, valid_loss=0.00372]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=0.00372]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00372]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.770, train_loss_epoch=3.770, valid_loss=0.00372]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=0.00372]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=0.00372]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.060, train_loss_epoch=4.060, valid_loss=0.00372]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00372]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00372]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780, valid_loss=0.00372]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=0.00372]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00372]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=0.00372]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00372]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00372]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00372]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=0.00372]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.500, valid_loss=0.00372]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=0.00372]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.640, train_loss_epoch=3.640, valid_loss=0.00372]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.00372]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780, valid_loss=0.00372]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=0.00372]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.600, train_loss_epoch=3.600, valid_loss=0.00372]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00372]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=0.00372]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.590, train_loss_epoch=3.590, valid_loss=0.00372]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00372]\n",
            "Epoch 274: 100%|██████████| 1/1 [00:02<00:00,  0.37it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.790, valid_loss=0.00372]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560, valid_loss=0.00372]\n",
            "Epoch 275: 100%|██████████| 1/1 [00:01<00:00,  0.51it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00372]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00372]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=0.00372]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.640, train_loss_epoch=3.640, valid_loss=0.00372]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.710, train_loss_epoch=3.710, valid_loss=0.00372]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00372]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00372]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00372]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00372]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00372]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=3.430, valid_loss=0.00372]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00372]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00372]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00372]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=0.00372]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00372]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00372]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.490, train_loss_epoch=3.490, valid_loss=0.00372]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=0.00372]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00372]        \n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00372]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00372]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410, valid_loss=0.00372]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.500, valid_loss=0.00372]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=0.00372]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00372]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:01<00:00,  0.60it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.350, valid_loss=0.00372]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.12it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00378]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00378]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=3.430, valid_loss=0.00378]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=0.00378]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00378]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00378]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=0.00378]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00378]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400, valid_loss=0.00378]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=0.00378]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00378]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00378]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270, valid_loss=0.00378]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00378]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00378]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00378]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270, valid_loss=0.00378]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00378]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00378]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00378]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00378]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00378]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00378]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00378]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00378]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00378]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00378]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00378]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00378]\n",
            "Epoch 327: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00378]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00378]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00378]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00378]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00378]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00378]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00378]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00378]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00378]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00378]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00378]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00378]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00378]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00378]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00378]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00378]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00378]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00378]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00378]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00378]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00378]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00378]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00378]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00378]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00378]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00378]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00378]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00378]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00378]\n",
            "Epoch 355: 100%|██████████| 1/1 [00:01<00:00,  0.50it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00378]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00378]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00378]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00378]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00378]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00378]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00378]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00378]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.00378]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00378]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00378]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00378]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.00378]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00378]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00378]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00378]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00378]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00378]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00378]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00378]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.00378]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00378]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00378]\n",
            "Epoch 377: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00378]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00378]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00378]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00378]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00378]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00378]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00378]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00378]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00378]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00378]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00378]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.00378]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00378]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00378]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00378]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.00378]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00378]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00378]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00378]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00378]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00378]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00378]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00378]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.750, valid_loss=0.00378]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.22it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00363]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00363]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00363]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00363]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00363]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00363]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00363]\n",
            "Epoch 406: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.590, valid_loss=0.00363]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00363]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00363]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00363]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00363]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00363]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00363]\n",
            "Epoch 412: 100%|██████████| 1/1 [00:01<00:00,  0.64it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.450, valid_loss=0.00363]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00363]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00363]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00363]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00363]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00363]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00363]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00363]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00363]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00363]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.00363]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00363]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00363]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00363]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00363]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00363]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00363]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00363]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00363]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00363]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00363]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00363]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00363]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00363]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00363]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00363]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00363]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00363]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00363]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00363]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00363]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00363]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00363]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00363]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00363]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00363]\n",
            "Epoch 450: 100%|██████████| 1/1 [00:02<00:00,  0.38it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.300, valid_loss=0.00363]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00363]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00363]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00363]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00363]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00363]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00363]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00363]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00363]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00363]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00363]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00363]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.00363]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00363]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00363]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00363]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00363]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00363]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00363]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00363]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00363]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.00363]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00363]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00363]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00363]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00363]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00363]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00363]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00363]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00363]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00363]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00363]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00363]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00363]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00363]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00363]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00363]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00363]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00363]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00363]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00363]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00363]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00363]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00363]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00363]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00363]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.190, valid_loss=0.00363]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.47it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00331]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00331]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00331]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00331]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00331]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00331]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00331]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00331]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00331]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00331]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00331]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00331]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00331]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00331]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00331]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00331]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00331]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00331]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00331]\n",
            "Epoch 527: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.090, valid_loss=0.00331]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00331]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.00331]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00331]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:01<00:00,  0.50it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.140, valid_loss=0.00331]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00331]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00331]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00331]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00331]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00331]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00331]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00331]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00331]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 547: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00331]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00331]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00331]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00331]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00331]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00331]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00331]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00331]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00331]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00331]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00331]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00331]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00331]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00331]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.00331]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00331]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00331]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00331]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00331]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00331]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00331]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00331]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00331]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00331]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00331]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.00331]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:01<00:00,  0.60it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.170, valid_loss=0.00331]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00331]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00331]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00331]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00331]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00331]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00331]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00331]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00331]\n",
            "Epoch 596: 100%|██████████| 1/1 [00:01<00:00,  0.63it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.230, valid_loss=0.00331]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00331]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.00331]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 20:00:12,623\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m `Trainer.fit` stopped: `max_steps=600.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \rEpoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00331]\rEpoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.55it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.120, valid_loss=0.00331]\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.68it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=34928)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.120, valid_loss=0.00321]\rEpoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00321]\rEpoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00321]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=39735)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 2025-06-15 20:00:25.664735: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m E0000 00:00:1750017625.700306   39820 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m E0000 00:00:1750017625.709293   39820 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 2025-06-15 20:00:25.739390: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 3 | blocks       | ModuleList    | 10.2 M | train\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 10.2 M    Trainable params\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 10.2 M    Total params\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 40.881    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.50, train_loss_epoch=48.50]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=58.20, train_loss_epoch=58.20]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.00, train_loss_epoch=34.00]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.10, train_loss_epoch=33.10]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.30, train_loss_epoch=32.30]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.30, train_loss_epoch=32.30]\n",
            "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=32.30]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.20, train_loss_epoch=27.20]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.20, train_loss_epoch=26.20]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.60, train_loss_epoch=25.60]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.60, train_loss_epoch=25.60]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.10, train_loss_epoch=25.10]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.40, train_loss_epoch=24.40]\n",
            "Epoch 21: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=24.40, train_loss_epoch=24.40]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.40, train_loss_epoch=23.40]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.40, train_loss_epoch=22.40]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.30, train_loss_epoch=23.30]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.30, train_loss_epoch=22.30]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=21.50]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.70, train_loss_epoch=20.70]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.40, train_loss_epoch=20.40]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.00, train_loss_epoch=20.00]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30]\n",
            "Epoch 43: 100%|██████████| 1/1 [00:01<00:00,  0.71it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.30]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.20]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 68: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.60]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.650, train_loss_epoch=9.650]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.580, train_loss_epoch=9.580]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.550, train_loss_epoch=9.550]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.520, train_loss_epoch=9.520]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.430, train_loss_epoch=9.430]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=9.150]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.650, train_loss_epoch=9.650]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.280, train_loss_epoch=9.280]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.370, train_loss_epoch=9.370]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.380, train_loss_epoch=9.380]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.340, train_loss_epoch=9.340]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.700, train_loss_epoch=8.700]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.400, train_loss_epoch=9.400]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.750, train_loss_epoch=8.750]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.590, train_loss_epoch=8.590]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.470, train_loss_epoch=9.470]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.850, train_loss_epoch=8.850]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.650, train_loss_epoch=9.650]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.650]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.10it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.270, valid_loss=0.0045]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.420, train_loss_epoch=9.420, valid_loss=0.0045]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.180, train_loss_epoch=9.180, valid_loss=0.0045]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.880, train_loss_epoch=8.880, valid_loss=0.0045]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.550, train_loss_epoch=8.550, valid_loss=0.0045]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.110, train_loss_epoch=8.110, valid_loss=0.0045]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.810, train_loss_epoch=8.810, valid_loss=0.0045]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.0045]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.460, train_loss_epoch=8.460, valid_loss=0.0045]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.0045]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.420, train_loss_epoch=8.420, valid_loss=0.0045]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.0045]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.530, train_loss_epoch=8.530, valid_loss=0.0045]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930, valid_loss=0.0045]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.470, train_loss_epoch=8.470, valid_loss=0.0045]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.770, train_loss_epoch=7.770, valid_loss=0.0045]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.0045]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.680, train_loss_epoch=7.680, valid_loss=0.0045]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.380, train_loss_epoch=7.380, valid_loss=0.0045]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.350, train_loss_epoch=7.350, valid_loss=0.0045]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.0045]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.0045]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.090, train_loss_epoch=7.090, valid_loss=0.0045]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.330, train_loss_epoch=7.330, valid_loss=0.0045]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=7.380, train_loss_epoch=7.330, valid_loss=0.0045]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.380, train_loss_epoch=7.380, valid_loss=0.0045]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.840, train_loss_epoch=6.840, valid_loss=0.0045]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180, valid_loss=0.0045]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.960, train_loss_epoch=6.960, valid_loss=0.0045]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.510, train_loss_epoch=7.510, valid_loss=0.0045]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.980, train_loss_epoch=6.980, valid_loss=0.0045]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.070, train_loss_epoch=7.070, valid_loss=0.0045]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.020, train_loss_epoch=7.020, valid_loss=0.0045]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.570, train_loss_epoch=6.570, valid_loss=0.0045]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.220, train_loss_epoch=7.220, valid_loss=0.0045]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.120, train_loss_epoch=7.120, valid_loss=0.0045]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.220, train_loss_epoch=7.220, valid_loss=0.0045]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.170, train_loss_epoch=7.170, valid_loss=0.0045]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.0045]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.910, train_loss_epoch=6.910, valid_loss=0.0045]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.040, train_loss_epoch=7.040, valid_loss=0.0045]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.650, train_loss_epoch=6.650, valid_loss=0.0045]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.430, train_loss_epoch=6.430, valid_loss=0.0045]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.040, train_loss_epoch=7.040, valid_loss=0.0045]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.070, train_loss_epoch=6.070, valid_loss=0.0045]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.640, train_loss_epoch=6.640, valid_loss=0.0045]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.730, train_loss_epoch=6.730, valid_loss=0.0045]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.500, train_loss_epoch=6.500, valid_loss=0.0045]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.820, train_loss_epoch=6.820, valid_loss=0.0045]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.250, train_loss_epoch=6.250, valid_loss=0.0045]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.450, train_loss_epoch=6.450, valid_loss=0.0045]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.560, train_loss_epoch=6.560, valid_loss=0.0045]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.510, train_loss_epoch=6.510, valid_loss=0.0045]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.540, train_loss_epoch=6.540, valid_loss=0.0045]\n",
            "Epoch 152: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, v_num=0, train_loss_step=6.430, train_loss_epoch=6.540, valid_loss=0.0045]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.430, train_loss_epoch=6.430, valid_loss=0.0045]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.680, train_loss_epoch=6.680, valid_loss=0.0045]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.340, train_loss_epoch=6.340, valid_loss=0.0045]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.720, train_loss_epoch=6.720, valid_loss=0.0045]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590, valid_loss=0.0045]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=0.0045]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.100, train_loss_epoch=6.100, valid_loss=0.0045]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.710, train_loss_epoch=6.710, valid_loss=0.0045]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.600, train_loss_epoch=6.600, valid_loss=0.0045]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.900, train_loss_epoch=6.900, valid_loss=0.0045]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.630, train_loss_epoch=6.630, valid_loss=0.0045]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.710, train_loss_epoch=6.710, valid_loss=0.0045]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.520, train_loss_epoch=6.520, valid_loss=0.0045]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.830, train_loss_epoch=6.830, valid_loss=0.0045]\n",
            "Epoch 166: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=6.530, train_loss_epoch=6.530, valid_loss=0.0045]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.530, train_loss_epoch=6.530, valid_loss=0.0045]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.0045]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.000, train_loss_epoch=7.000, valid_loss=0.0045]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=6.550, valid_loss=0.0045]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.0045]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.730, train_loss_epoch=6.730, valid_loss=0.0045]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.360, train_loss_epoch=7.360, valid_loss=0.0045]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.0045]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.420, train_loss_epoch=6.420, valid_loss=0.0045]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.950, train_loss_epoch=6.950, valid_loss=0.0045]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.390, train_loss_epoch=6.390, valid_loss=0.0045]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.580, train_loss_epoch=6.580, valid_loss=0.0045]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.300, train_loss_epoch=7.300, valid_loss=0.0045]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.610, train_loss_epoch=6.610, valid_loss=0.0045]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.070, train_loss_epoch=7.070, valid_loss=0.0045]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.430, train_loss_epoch=6.430, valid_loss=0.0045]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.890, train_loss_epoch=6.890, valid_loss=0.0045]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.490, train_loss_epoch=6.490, valid_loss=0.0045]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.530, train_loss_epoch=6.530, valid_loss=0.0045]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.180, train_loss_epoch=6.180, valid_loss=0.0045]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.120, train_loss_epoch=7.120, valid_loss=0.0045]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.140, train_loss_epoch=6.140, valid_loss=0.0045]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.370, train_loss_epoch=6.370, valid_loss=0.0045]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.490, train_loss_epoch=6.490, valid_loss=0.0045]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000, valid_loss=0.0045]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.430, train_loss_epoch=6.430, valid_loss=0.0045]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.920, valid_loss=0.0045]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.0045]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.0045]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.0045]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350, valid_loss=0.0045]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.050, train_loss_epoch=6.050, valid_loss=0.0045]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.0045]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.580, valid_loss=0.0045]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.72it/s]\u001b[A\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00229]\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00229]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.560, train_loss_epoch=5.560, valid_loss=0.00229]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.950, train_loss_epoch=4.950, valid_loss=0.00229]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.080, train_loss_epoch=5.080, valid_loss=0.00229]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.130, train_loss_epoch=5.130, valid_loss=0.00229]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.530, train_loss_epoch=4.530, valid_loss=0.00229]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.930, train_loss_epoch=4.930, valid_loss=0.00229]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.640, train_loss_epoch=4.640, valid_loss=0.00229]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.890, train_loss_epoch=4.890, valid_loss=0.00229]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.730, train_loss_epoch=4.730, valid_loss=0.00229]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.560, train_loss_epoch=4.560, valid_loss=0.00229]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=4.640, train_loss_epoch=4.640, valid_loss=0.00229]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.640, train_loss_epoch=4.640, valid_loss=0.00229]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.540, train_loss_epoch=4.540, valid_loss=0.00229]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.580, train_loss_epoch=4.580, valid_loss=0.00229]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.460, train_loss_epoch=4.460, valid_loss=0.00229]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320, valid_loss=0.00229]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.410, train_loss_epoch=4.410, valid_loss=0.00229]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.410, train_loss_epoch=4.410, valid_loss=0.00229]\n",
            "Epoch 217: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, v_num=0, train_loss_step=4.300, train_loss_epoch=4.410, valid_loss=0.00229]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.300, train_loss_epoch=4.300, valid_loss=0.00229]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.280, train_loss_epoch=4.280, valid_loss=0.00229]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.230, train_loss_epoch=4.230, valid_loss=0.00229]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320, valid_loss=0.00229]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220, valid_loss=0.00229]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=0.00229]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.180, train_loss_epoch=4.180, valid_loss=0.00229]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.010, train_loss_epoch=4.010, valid_loss=0.00229]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.170, train_loss_epoch=4.170, valid_loss=0.00229]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=0.00229]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.110, train_loss_epoch=4.110, valid_loss=0.00229]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220, valid_loss=0.00229]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=0.00229]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.050, train_loss_epoch=4.050, valid_loss=0.00229]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=0.00229]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=0.00229]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.080, train_loss_epoch=4.080, valid_loss=0.00229]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.080, train_loss_epoch=4.080, valid_loss=0.00229]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00229]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=3.950, valid_loss=0.00229]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=0.00229]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=0.00229]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00229]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=0.00229]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=0.00229]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00229]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.290, train_loss_epoch=4.290, valid_loss=0.00229]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=3.950, valid_loss=0.00229]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=0.00229]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=3.970, valid_loss=0.00229]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=3.950, valid_loss=0.00229]\n",
            "Epoch 248: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00229]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00229]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=3.950, valid_loss=0.00229]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00229]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=0.00229]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.110, train_loss_epoch=4.110, valid_loss=0.00229]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.940, train_loss_epoch=3.940, valid_loss=0.00229]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.990, train_loss_epoch=3.990, valid_loss=0.00229]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=3.970, valid_loss=0.00229]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880, valid_loss=0.00229]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070, valid_loss=0.00229]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=0.00229]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=3.970, valid_loss=0.00229]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00229]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=0.00229]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880, valid_loss=0.00229]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00229]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.890, train_loss_epoch=3.890, valid_loss=0.00229]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.940, train_loss_epoch=3.940, valid_loss=0.00229]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.930, train_loss_epoch=3.930, valid_loss=0.00229]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00229]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00229]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00229]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=3.900, valid_loss=0.00229]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00229]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.060, train_loss_epoch=4.060, valid_loss=0.00229]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.710, train_loss_epoch=3.710, valid_loss=0.00229]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=0.00229]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=0.00229]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00229]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00229]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=0.00229]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=0.00229]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00229]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.710, train_loss_epoch=3.710, valid_loss=0.00229]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00229]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00229]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=0.00229]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=0.00229]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=0.00229]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=0.00229]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00229]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.770, train_loss_epoch=3.770, valid_loss=0.00229]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=0.00229]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.110, train_loss_epoch=4.110, valid_loss=0.00229]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.810, train_loss_epoch=3.810, valid_loss=0.00229]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=0.00229]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=0.00229]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00229]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00229]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:01<00:00,  0.72it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00229]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:01<00:00,  0.71it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=3.980, valid_loss=0.00229]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00229]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00229]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00229]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.75it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00224]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.850, valid_loss=0.00224]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=0.00224]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00224]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=0.00224]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00224]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00224]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00224]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=0.00224]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=0.00224]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00224]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=0.00224]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00224]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00224]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=0.00224]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.600, train_loss_epoch=3.600, valid_loss=0.00224]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00224]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00224]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00224]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00224]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00224]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=0.00224]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540, valid_loss=0.00224]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00224]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00224]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00224]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00224]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410, valid_loss=0.00224]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00224]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00224]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00224]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00224]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00224]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470, valid_loss=0.00224]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00224]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00224]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00224]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00224]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00224]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00224]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00224]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00224]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00224]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00224]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00224]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00224]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00224]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=0.00224]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00224]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00224]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00224]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00224]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00224]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00224]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00224]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00224]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00224]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00224]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00224]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00224]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00224]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00224]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00224]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00224]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00224]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00224]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00224]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00224]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00224]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00224]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00224]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00224]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:01<00:00,  0.71it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=3.190, valid_loss=0.00224]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00224]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00224]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00224]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00224]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00224]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00224]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00224]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00224]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00224]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00224]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00224]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00224]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00224]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00224]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00224]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00224]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00224]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00224]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00224]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00224]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00224]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00224]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00224]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00224]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00224]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00224]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00224]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00224]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00224]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:01<00:00,  0.86it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.670, valid_loss=0.00224]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.17it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0021]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0021]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0021]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0021]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0021]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0021]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0021]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0021]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0021]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0021]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0021]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0021]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0021]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0021]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0021]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0021]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0021]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0021]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0021]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0021]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0021]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0021]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0021]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0021]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0021]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.380, valid_loss=0.0021]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0021]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0021]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0021]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.0021]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0021]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0021]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0021]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.0021]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0021]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.0021]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0021]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0021]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0021]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0021]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0021]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0021]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0021]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0021]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0021]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0021]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0021]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.0021]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0021]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0021]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0021]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0021]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0021]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0021]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0021]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0021]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0021]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0021]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0021]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0021]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0021]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:01<00:00,  0.72it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0021]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0021]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0021]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0021]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0021]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0021]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0021]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0021]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0021]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0021]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0021]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.0021]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0021]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0021]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0021]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.0021]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0021]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.0021]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.0021]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0021]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.0021]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0021]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0021]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0021]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0021]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.0021]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0021]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.0021]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.0021]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:01<00:00,  0.69it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.0021]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.0021]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0021]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.0021]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0021]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.110, valid_loss=0.0021]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.65it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00172]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00172]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00172]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00172]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:01<00:00,  0.71it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00172]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00172]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00172]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00172]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00172]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00172]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00172]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00172]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00172]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00172]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00172]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00172]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00172]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00172]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00172]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00172]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00172]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 532: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00172]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00172]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00172]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00172]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00172]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00172]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00172]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00172]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00172]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00172]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00172]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00172]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00172]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00172]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00172]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00172]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00172]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00172]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00172]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00172]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00172]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00172]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00172]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00172]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00172]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00172]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00172]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00172]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00172]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00172]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00172]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00172]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00172]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00172]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00172]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00172]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00172]\n",
            "Epoch 573: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00172]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00172]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00172]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00172]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00172]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00172]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00172]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00172]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00172]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00172]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00172]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00172]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00172]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00172]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00172]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00172]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00172]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00172]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00172]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00172]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00172]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00172]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00172]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00172]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 20:10:36,688\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00172]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.900, valid_loss=0.00172]\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.16it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=39735)\u001b[0m \r                                                                      \u001b[A\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.900, valid_loss=0.00171]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00171]\rEpoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00171]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=39735)\u001b[0m `Trainer.fit` stopped: `max_steps=600.0` reached.\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 2025-06-15 20:10:50.556299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m E0000 00:00:1750018250.585852   42463 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m E0000 00:00:1750018250.595012   42463 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 2025-06-15 20:10:50.625101: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 3 | blocks       | ModuleList    | 9.7 M  | train\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 9.7 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 9.7 M     Total params\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 38.969    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.90, train_loss_epoch=37.90]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=62.00, train_loss_epoch=62.00]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=64.30, train_loss_epoch=64.30]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.80, train_loss_epoch=40.80]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.60, train_loss_epoch=32.60]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=31.50]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.40, train_loss_epoch=27.40]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.60, train_loss_epoch=27.60]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.40, train_loss_epoch=32.40]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s, v_num=0, train_loss_step=26.40, train_loss_epoch=32.40]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.40, train_loss_epoch=26.40]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.80, train_loss_epoch=27.80]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.10, train_loss_epoch=27.10]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.30, train_loss_epoch=26.30]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.60, train_loss_epoch=25.60]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.00, train_loss_epoch=24.00]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.30, train_loss_epoch=23.30]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.60, train_loss_epoch=22.60]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.10, train_loss_epoch=23.10]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.00, train_loss_epoch=22.00]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.00, train_loss_epoch=21.00]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=21.70]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=21.70]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.10, train_loss_epoch=21.10]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.300, train_loss_epoch=9.300]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.580, train_loss_epoch=9.580]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.890, train_loss_epoch=9.890]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.720, train_loss_epoch=9.720]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.560, train_loss_epoch=9.560]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.820, train_loss_epoch=9.820]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=9.260, train_loss_epoch=9.820]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 87.36it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.260, train_loss_epoch=9.260, valid_loss=0.00509]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.420, train_loss_epoch=9.420, valid_loss=0.00509]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.710, train_loss_epoch=9.710, valid_loss=0.00509]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.900, train_loss_epoch=9.900, valid_loss=0.00509]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.050, train_loss_epoch=9.050, valid_loss=0.00509]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.260, train_loss_epoch=9.260, valid_loss=0.00509]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.660, train_loss_epoch=9.660, valid_loss=0.00509]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.770, valid_loss=0.00509]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.000, train_loss_epoch=9.000, valid_loss=0.00509]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.850, train_loss_epoch=9.850, valid_loss=0.00509]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.390, train_loss_epoch=9.390, valid_loss=0.00509]\n",
            "Epoch 110: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=0, train_loss_step=9.760, train_loss_epoch=9.760, valid_loss=0.00509]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.760, train_loss_epoch=9.760, valid_loss=0.00509]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.760, train_loss_epoch=8.760, valid_loss=0.00509]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.00509]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.570, train_loss_epoch=9.570, valid_loss=0.00509]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.970, train_loss_epoch=9.970, valid_loss=0.00509]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00509]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.950, train_loss_epoch=9.950, valid_loss=0.00509]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00509]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.180, train_loss_epoch=9.180, valid_loss=0.00509]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.760, train_loss_epoch=8.760, valid_loss=0.00509]\n",
            "Epoch 120: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.760, valid_loss=0.00509]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.770, valid_loss=0.00509]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.390, train_loss_epoch=8.390, valid_loss=0.00509]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.120, train_loss_epoch=9.120, valid_loss=0.00509]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00509]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.250, train_loss_epoch=9.250, valid_loss=0.00509]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.860, train_loss_epoch=8.860, valid_loss=0.00509]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.00509]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950, valid_loss=0.00509]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.210, train_loss_epoch=9.210, valid_loss=0.00509]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.730, train_loss_epoch=8.730, valid_loss=0.00509]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540, valid_loss=0.00509]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950, valid_loss=0.00509]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.200, train_loss_epoch=8.200, valid_loss=0.00509]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.650, train_loss_epoch=8.650, valid_loss=0.00509]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.050, train_loss_epoch=9.050, valid_loss=0.00509]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.020, train_loss_epoch=8.020, valid_loss=0.00509]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00509]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.450, train_loss_epoch=8.450, valid_loss=0.00509]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.670, train_loss_epoch=8.670, valid_loss=0.00509]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.290, train_loss_epoch=8.290, valid_loss=0.00509]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.110, train_loss_epoch=8.110, valid_loss=0.00509]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00509]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.190, train_loss_epoch=9.190, valid_loss=0.00509]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.480, train_loss_epoch=7.480, valid_loss=0.00509]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950, valid_loss=0.00509]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.430, train_loss_epoch=8.430, valid_loss=0.00509]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=8.790, valid_loss=0.00509]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.00509]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.610, train_loss_epoch=8.610, valid_loss=0.00509]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.580, train_loss_epoch=8.580, valid_loss=0.00509]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.260, train_loss_epoch=9.260, valid_loss=0.00509]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00509]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540, valid_loss=0.00509]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00509]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.330, train_loss_epoch=8.330, valid_loss=0.00509]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.00509]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.130, train_loss_epoch=8.130, valid_loss=0.00509]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00509]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.020, train_loss_epoch=8.020, valid_loss=0.00509]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00509]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00509]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.00509]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.500, train_loss_epoch=7.500, valid_loss=0.00509]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00509]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=0.00509]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.240, train_loss_epoch=8.240, valid_loss=0.00509]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.00509]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.00509]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.480, train_loss_epoch=7.480, valid_loss=0.00509]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.960, train_loss_epoch=7.960, valid_loss=0.00509]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00509]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.680, train_loss_epoch=7.680, valid_loss=0.00509]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.290, train_loss_epoch=7.290, valid_loss=0.00509]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=0.00509]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.00509]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.750, train_loss_epoch=7.750, valid_loss=0.00509]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.00509]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.670, train_loss_epoch=6.670, valid_loss=0.00509]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.890, train_loss_epoch=7.890, valid_loss=0.00509]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.940, train_loss_epoch=6.940, valid_loss=0.00509]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.00509]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.00509]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.350, train_loss_epoch=6.350, valid_loss=0.00509]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.00509]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.420, train_loss_epoch=6.420, valid_loss=0.00509]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.00509]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.840, train_loss_epoch=6.840, valid_loss=0.00509]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=6.780, valid_loss=0.00509]\n",
            "Epoch 188: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.780, valid_loss=0.00509]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=0.00509]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=0.00509]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.580, train_loss_epoch=6.580, valid_loss=0.00509]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.230, train_loss_epoch=7.230, valid_loss=0.00509]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.730, train_loss_epoch=6.730, valid_loss=0.00509]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.300, train_loss_epoch=7.300, valid_loss=0.00509]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.840, train_loss_epoch=6.840, valid_loss=0.00509]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.290, train_loss_epoch=7.290, valid_loss=0.00509]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.010, train_loss_epoch=7.010, valid_loss=0.00509]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.910, train_loss_epoch=6.910, valid_loss=0.00509]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.370, train_loss_epoch=7.370, valid_loss=0.00509]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.720, train_loss_epoch=6.720, valid_loss=0.00509]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.93it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=6.720, valid_loss=0.00509]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.59it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.00294]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.810, train_loss_epoch=6.810, valid_loss=0.00294]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=8.790, valid_loss=0.00294]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.00294]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.00294]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.500, train_loss_epoch=7.500, valid_loss=0.00294]        \n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.500, train_loss_epoch=7.500, valid_loss=0.00294]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.800, train_loss_epoch=6.800, valid_loss=0.00294]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.150, train_loss_epoch=7.150, valid_loss=0.00294]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00294]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.520, train_loss_epoch=6.520, valid_loss=0.00294]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.940, train_loss_epoch=6.940, valid_loss=0.00294]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.070, train_loss_epoch=7.070, valid_loss=0.00294]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00294]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.130, train_loss_epoch=6.130, valid_loss=0.00294]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=6.550, valid_loss=0.00294]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.300, train_loss_epoch=6.300, valid_loss=0.00294]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.990, train_loss_epoch=5.990, valid_loss=0.00294]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.420, train_loss_epoch=6.420, valid_loss=0.00294]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=5.760, valid_loss=0.00294]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.260, train_loss_epoch=6.260, valid_loss=0.00294]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.240, train_loss_epoch=6.240, valid_loss=0.00294]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=0.00294]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.00294]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960, valid_loss=0.00294]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.860, train_loss_epoch=5.860, valid_loss=0.00294]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.080, train_loss_epoch=6.080, valid_loss=0.00294]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.690, valid_loss=0.00294]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.870, train_loss_epoch=5.870, valid_loss=0.00294]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.110, train_loss_epoch=6.110, valid_loss=0.00294]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=6.440, valid_loss=0.00294]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.970, train_loss_epoch=5.970, valid_loss=0.00294]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.530, train_loss_epoch=5.530, valid_loss=0.00294]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.640, train_loss_epoch=5.640, valid_loss=0.00294]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.770, train_loss_epoch=5.770, valid_loss=0.00294]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.680, train_loss_epoch=5.680, valid_loss=0.00294]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.160, valid_loss=0.00294]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.880, train_loss_epoch=5.880, valid_loss=0.00294]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.360, train_loss_epoch=6.360, valid_loss=0.00294]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.430, train_loss_epoch=6.430, valid_loss=0.00294]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.370, train_loss_epoch=6.370, valid_loss=0.00294]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.00294]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.890, train_loss_epoch=5.890, valid_loss=0.00294]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.870, train_loss_epoch=6.870, valid_loss=0.00294]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.00294]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.370, train_loss_epoch=6.370, valid_loss=0.00294]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.050, train_loss_epoch=6.050, valid_loss=0.00294]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.450, train_loss_epoch=6.450, valid_loss=0.00294]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930, valid_loss=0.00294]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.420, train_loss_epoch=6.420, valid_loss=0.00294]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.050, train_loss_epoch=6.050, valid_loss=0.00294]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=6.780, valid_loss=0.00294]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.660, train_loss_epoch=6.660, valid_loss=0.00294]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.040, train_loss_epoch=6.040, valid_loss=0.00294]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=0.00294]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.140, train_loss_epoch=6.140, valid_loss=0.00294]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.250, train_loss_epoch=6.250, valid_loss=0.00294]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.360, train_loss_epoch=6.360, valid_loss=0.00294]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.160, valid_loss=0.00294]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.350, train_loss_epoch=6.350, valid_loss=0.00294]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.980, train_loss_epoch=5.980, valid_loss=0.00294]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.00294]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.010, train_loss_epoch=6.010, valid_loss=0.00294]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.790, train_loss_epoch=5.790, valid_loss=0.00294]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=6.060, valid_loss=0.00294]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.00294]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.340, train_loss_epoch=6.340, valid_loss=0.00294]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.920, valid_loss=0.00294]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780, valid_loss=0.00294]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.080, train_loss_epoch=6.080, valid_loss=0.00294]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650, valid_loss=0.00294]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.00294]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00294]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.440, train_loss_epoch=5.440, valid_loss=0.00294]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=0.00294]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.820, train_loss_epoch=5.820, valid_loss=0.00294]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.100, train_loss_epoch=5.100, valid_loss=0.00294]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.500, train_loss_epoch=5.500, valid_loss=0.00294]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.100, train_loss_epoch=5.100, valid_loss=0.00294]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.340, train_loss_epoch=5.340, valid_loss=0.00294]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.380, train_loss_epoch=5.380, valid_loss=0.00294]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=0, train_loss_step=5.250, train_loss_epoch=5.380, valid_loss=0.00294]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.250, train_loss_epoch=5.250, valid_loss=0.00294]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.920, train_loss_epoch=4.920, valid_loss=0.00294]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.180, train_loss_epoch=6.180, valid_loss=0.00294]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00294]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.870, train_loss_epoch=5.870, valid_loss=0.00294]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.590, train_loss_epoch=5.590, valid_loss=0.00294]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.980, train_loss_epoch=5.980, valid_loss=0.00294]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.520, train_loss_epoch=5.520, valid_loss=0.00294]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.360, train_loss_epoch=5.360, valid_loss=0.00294]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.530, train_loss_epoch=5.530, valid_loss=0.00294]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=0.00294]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930, valid_loss=0.00294]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.590, train_loss_epoch=5.590, valid_loss=0.00294]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.110, train_loss_epoch=6.110, valid_loss=0.00294]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.040, train_loss_epoch=6.040, valid_loss=0.00294]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.790, train_loss_epoch=5.790, valid_loss=0.00294]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.450, train_loss_epoch=5.450, valid_loss=0.00294]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930, valid_loss=0.00294]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00294]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.460, valid_loss=0.00294]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s, v_num=0, train_loss_step=5.850, train_loss_epoch=5.460, valid_loss=0.00294]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.58it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.850, train_loss_epoch=5.850, valid_loss=0.00298]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.700, train_loss_epoch=5.700, valid_loss=0.00298]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.860, train_loss_epoch=5.860, valid_loss=0.00298]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.840, train_loss_epoch=5.840, valid_loss=0.00298]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.740, train_loss_epoch=5.740, valid_loss=0.00298]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.880, train_loss_epoch=5.880, valid_loss=0.00298]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=0.00298]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.290, train_loss_epoch=6.290, valid_loss=0.00298]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.200, train_loss_epoch=6.200, valid_loss=0.00298]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.590, train_loss_epoch=5.590, valid_loss=0.00298]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780, valid_loss=0.00298]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.640, train_loss_epoch=5.640, valid_loss=0.00298]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.00298]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.720, train_loss_epoch=5.720, valid_loss=0.00298]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00298]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.030, train_loss_epoch=6.030, valid_loss=0.00298]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.470, train_loss_epoch=5.470, valid_loss=0.00298]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.900, train_loss_epoch=5.900, valid_loss=0.00298]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.840, train_loss_epoch=5.840, valid_loss=0.00298]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=5.760, valid_loss=0.00298]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.240, train_loss_epoch=6.240, valid_loss=0.00298]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.390, train_loss_epoch=5.390, valid_loss=0.00298]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.510, train_loss_epoch=6.510, valid_loss=0.00298]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350, valid_loss=0.00298]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.920, valid_loss=0.00298]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.360, train_loss_epoch=5.360, valid_loss=0.00298]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.100, train_loss_epoch=6.100, valid_loss=0.00298]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.320, train_loss_epoch=5.320, valid_loss=0.00298]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.400, train_loss_epoch=5.400, valid_loss=0.00298]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.860, train_loss_epoch=5.860, valid_loss=0.00298]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.00298]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=5.570, valid_loss=0.00298]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.040, train_loss_epoch=5.040, valid_loss=0.00298]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.500, train_loss_epoch=5.500, valid_loss=0.00298]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.080, train_loss_epoch=5.080, valid_loss=0.00298]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00298]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.870, train_loss_epoch=4.870, valid_loss=0.00298]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.010, train_loss_epoch=5.010, valid_loss=0.00298]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.580, train_loss_epoch=4.580, valid_loss=0.00298]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090, valid_loss=0.00298]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.580, train_loss_epoch=4.580, valid_loss=0.00298]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.860, train_loss_epoch=4.860, valid_loss=0.00298]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.850, train_loss_epoch=4.850, valid_loss=0.00298]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.400, train_loss_epoch=4.400, valid_loss=0.00298]\n",
            "Epoch 343: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=4.310, train_loss_epoch=4.310, valid_loss=0.00298]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.310, train_loss_epoch=4.310, valid_loss=0.00298]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.630, train_loss_epoch=4.630, valid_loss=0.00298]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=4.800, valid_loss=0.00298]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.610, train_loss_epoch=4.610, valid_loss=0.00298]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.850, train_loss_epoch=4.850, valid_loss=0.00298]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.070, train_loss_epoch=5.070, valid_loss=0.00298]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=4.800, valid_loss=0.00298]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=0.00298]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.560, train_loss_epoch=4.560, valid_loss=0.00298]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.760, train_loss_epoch=4.760, valid_loss=0.00298]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.010, train_loss_epoch=5.010, valid_loss=0.00298]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.300, train_loss_epoch=5.300, valid_loss=0.00298]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.050, train_loss_epoch=5.050, valid_loss=0.00298]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, v_num=0, train_loss_step=5.320, train_loss_epoch=5.050, valid_loss=0.00298]\n",
            "Epoch 356: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, v_num=0, train_loss_step=5.320, train_loss_epoch=5.320, valid_loss=0.00298]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.320, train_loss_epoch=5.320, valid_loss=0.00298]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.470, train_loss_epoch=5.470, valid_loss=0.00298]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=4.840, valid_loss=0.00298]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.220, train_loss_epoch=5.220, valid_loss=0.00298]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.680, train_loss_epoch=4.680, valid_loss=0.00298]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.740, train_loss_epoch=4.740, valid_loss=0.00298]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.480, train_loss_epoch=4.480, valid_loss=0.00298]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.390, train_loss_epoch=4.390, valid_loss=0.00298]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.250, train_loss_epoch=4.250, valid_loss=0.00298]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.480, train_loss_epoch=4.480, valid_loss=0.00298]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.400, train_loss_epoch=4.400, valid_loss=0.00298]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.270, train_loss_epoch=4.270, valid_loss=0.00298]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.300, train_loss_epoch=4.300, valid_loss=0.00298]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.270, train_loss_epoch=4.270, valid_loss=0.00298]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.000, train_loss_epoch=4.000, valid_loss=0.00298]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00298]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.540, train_loss_epoch=4.540, valid_loss=0.00298]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.250, train_loss_epoch=4.250, valid_loss=0.00298]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.290, train_loss_epoch=4.290, valid_loss=0.00298]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.420, train_loss_epoch=4.420, valid_loss=0.00298]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.230, train_loss_epoch=4.230, valid_loss=0.00298]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.340, train_loss_epoch=4.340, valid_loss=0.00298]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.300, train_loss_epoch=4.300, valid_loss=0.00298]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.110, train_loss_epoch=4.110, valid_loss=0.00298]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320, valid_loss=0.00298]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=0.00298]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=4.350, valid_loss=0.00298]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=0.00298]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.230, train_loss_epoch=4.230, valid_loss=0.00298]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.400, train_loss_epoch=4.400, valid_loss=0.00298]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320, valid_loss=0.00298]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.230, train_loss_epoch=4.230, valid_loss=0.00298]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.740, train_loss_epoch=4.740, valid_loss=0.00298]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.390, train_loss_epoch=4.390, valid_loss=0.00298]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.390, train_loss_epoch=4.390, valid_loss=0.00298]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.570, train_loss_epoch=4.570, valid_loss=0.00298]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.720, train_loss_epoch=4.720, valid_loss=0.00298]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320, valid_loss=0.00298]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.560, train_loss_epoch=4.560, valid_loss=0.00298]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.310, train_loss_epoch=4.310, valid_loss=0.00298]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.460, train_loss_epoch=4.460, valid_loss=0.00298]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.630, train_loss_epoch=4.630, valid_loss=0.00298]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.040, train_loss_epoch=4.040, valid_loss=0.00298]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, v_num=0, train_loss_step=4.250, train_loss_epoch=4.040, valid_loss=0.00298]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.08it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.250, train_loss_epoch=4.250, valid_loss=0.00152]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.440, train_loss_epoch=4.440, valid_loss=0.00152]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.000, train_loss_epoch=4.000, valid_loss=0.00152]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.810, train_loss_epoch=3.810, valid_loss=0.00152]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.770, train_loss_epoch=3.770, valid_loss=0.00152]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00152]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=0.00152]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00152]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=0.00152]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00152]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.490, train_loss_epoch=3.490, valid_loss=0.00152]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00152]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00152]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00152]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00152]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00152]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00152]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00152]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00152]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00152]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00152]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00152]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00152]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00152]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00152]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00152]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00152]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.00152]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00152]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00152]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00152]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00152]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00152]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00152]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00152]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00152]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00152]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00152]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00152]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00152]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00152]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00152]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00152]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00152]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00152]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00152]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00152]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00152]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00152]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.840, valid_loss=0.00152]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00152]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00152]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00152]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00152]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00152]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00152]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00152]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00152]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00152]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00152]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00152]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00152]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.680, valid_loss=0.00152]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00152]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00152]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00152]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00152]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00152]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00152]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00152]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00152]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00152]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00152]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00152]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00152]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00152]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00152]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00152]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00152]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00152]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00152]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00152]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00152]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00152]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00152]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00152]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00152]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00152]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00152]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00152]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00152]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00152]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00152]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00152]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00152]\n",
            "Epoch 491: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00152]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00152]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00152]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00152]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00152]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00152]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00152]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00152]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00152]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.430, valid_loss=0.00152]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.40it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00153]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00153]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00153]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00153]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00153]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00153]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00153]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00153]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00153]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00153]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00153]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00153]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00153]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.00153]\n",
            "Epoch 513: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.00153]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00153]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00153]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00153]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00153]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00153]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00153]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00153]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00153]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00153]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00153]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00153]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00153]\n",
            "Epoch 525: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00153]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00153]        \n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00153]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00153]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00153]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00153]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00153]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00153]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00153]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00153]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00153]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00153]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00153]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00153]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00153]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00153]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00153]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00153]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00153]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00153]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00153]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00153]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00153]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00153]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00153]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00153]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.00153]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00153]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00153]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00153]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00153]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00153]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00153]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00153]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00153]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00153]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00153]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00153]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00153]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00153]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00153]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00153]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00153]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00153]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00153]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00153]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00153]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00153]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00153]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00153]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00153]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00153]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00153]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00153]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00153]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00153]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00153]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00153]\n",
            "Epoch 579: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00153]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00153]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00153]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00153]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00153]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00153]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00153]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00153]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00153]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=0.00153]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00153]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=0.00153]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00153]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00153]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00153]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00153]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00153]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00153]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00153]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00153]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00153]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.920, valid_loss=0.00153]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.79it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00174]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00174]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00174]\n",
            "Epoch 602: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00174]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00174]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00174]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00174]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00174]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00174]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00174]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00174]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00174]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00174]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00174]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00174]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00174]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00174]\n",
            "Epoch 615: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=3.260, valid_loss=0.00174]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00174]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00174]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00174]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00174]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00174]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00174]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00174]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00174]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00174]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00174]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00174]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00174]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00174]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00174]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00174]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00174]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00174]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00174]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00174]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00174]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00174]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00174]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00174]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00174]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00174]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00174]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00174]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00174]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00174]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00174]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00174]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00174]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00174]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00174]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00174]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00174]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00174]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00174]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00174]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00174]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00174]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00174]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00174]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00174]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00174]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00174]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00174]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00174]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00174]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00174]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00174]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00174]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00174]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00174]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00174]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00174]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00174]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00174]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00174]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00174]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00174]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00174]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00174]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00174]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00174]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00174]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00174]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00174]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00174]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00174]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00174]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00174]\n",
            "Epoch 685: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00174]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00174]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00174]\n",
            "Epoch 687: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00174]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00174]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00174]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00174]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00174]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00174]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00174]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00174]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00174]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00174]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00174]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00174]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00174]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.550, valid_loss=0.00174]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.84it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00167]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00167]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00167]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00167]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00167]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.00167]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00167]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00167]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00167]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00167]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00167]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00167]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00167]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00167]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00167]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00167]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00167]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00167]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00167]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00167]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00167]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00167]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00167]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00167]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00167]\n",
            "Epoch 724: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00167]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00167]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00167]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00167]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00167]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00167]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00167]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00167]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00167]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00167]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00167]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00167]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00167]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00167]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00167]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00167]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00167]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00167]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00167]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00167]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00167]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00167]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00167]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00167]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00167]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.00167]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00167]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00167]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00167]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00167]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00167]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00167]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00167]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00167]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00167]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00167]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00167]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00167]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00167]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00167]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00167]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00167]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00167]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00167]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00167]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00167]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00167]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00167]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00167]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00167]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00167]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00167]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00167]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00167]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00167]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00167]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00167]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00167]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00167]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00167]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00167]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00167]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00167]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00167]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00167]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00167]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00167]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00167]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00167]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00167]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00167]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00167]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00167]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00167]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00167]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00167]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.470, valid_loss=0.00167]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 101.83it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00144]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00144]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00144]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00144]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00144]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00144]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00144]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00144]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00144]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00144]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00144]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00144]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00144]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00144]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00144]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00144]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00144]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00144]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00144]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00144]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00144]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00144]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00144]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00144]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00144]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00144]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00144]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00144]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00144]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00144]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00144]\n",
            "Epoch 830: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00144]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00144]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00144]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00144]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00144]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00144]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00144]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00144]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00144]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00144]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00144]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00144]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00144]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00144]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00144]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00144]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00144]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00144]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00144]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00144]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00144]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00144]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00144]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00144]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00144]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00144]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00144]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00144]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00144]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00144]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00144]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00144]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00144]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00144]\n",
            "Epoch 865: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00144]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00144]\n",
            "Epoch 868: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.700, valid_loss=0.00144]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00144]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00144]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00144]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00144]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00144]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00144]\n",
            "Epoch 875: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.750, valid_loss=0.00144]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00144]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00144]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00144]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00144]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00144]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00144]\n",
            "Epoch 881: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.770, valid_loss=0.00144]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00144]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00144]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00144]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00144]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00144]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00144]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00144]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00144]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00144]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00144]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00144]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00144]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00144]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00144]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00144]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00144]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00144]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00144]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00144]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.93it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0014]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.0014]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0014]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.0014]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0014]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0014]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0014]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0014]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.0014]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0014]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0014]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.0014]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.0014]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.0014]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0014]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.0014]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.0014]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.0014]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.0014]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.0014]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.0014]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0014]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0014]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.0014]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.0014]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0014]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.0014]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0014]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0014]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0014]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.0014]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0014]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0014]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0014]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 953: 100%|██████████| 1/1 [00:00<00:00,  1.69it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0014]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.0014]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.0014]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.0014]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.0014]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.0014]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0014]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0014]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.0014]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.0014]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0014]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0014]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0014]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0014]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0014]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0014]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.0014]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0014]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.0014]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0014]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0014]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0014]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.0014]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0014]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.0014]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.0014]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.0014]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0014]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.0014]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.0014]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0014]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0014]\n",
            "Epoch 995: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.810, valid_loss=0.0014]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.0014]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0014]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0014]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0014]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.710, valid_loss=0.0014]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.16it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00133]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00133]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00133]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00133]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00133]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00133]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00133]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00133]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00133]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00133]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00133]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00133]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00133]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00133]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1015: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1015: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00133]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00133]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1018: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00133]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00133]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00133]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00133]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00133]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00133]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00133]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00133]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00133]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00133]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00133]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00133]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00133]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00133]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00133]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00133]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00133]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00133]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00133]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00133]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00133]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00133]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00133]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00133]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00133]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00133]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00133]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00133]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00133]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00133]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00133]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00133]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00133]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00133]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00133]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00133]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00133]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00133]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00133]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00133]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00133]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00133]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00133]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00133]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00133]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00133]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00133]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00133]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00133]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00133]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00133]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00133]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00133]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00133]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00133]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00133]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00133]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00133]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00133]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00133]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00133]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00133]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00133]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00133]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00133]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00133]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00133]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00133]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00133]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.530, valid_loss=0.00133]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.24it/s]\u001b[A\n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00135]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00135]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00135]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00135]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00135]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00135]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00135]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00135]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00135]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00135]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00135]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00135]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00135]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00135]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00135]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00135]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00135]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00135]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00135]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00135]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00135]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00135]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00135]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00135]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00135]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00135]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00135]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00135]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00135]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00135]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00135]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00135]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00135]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00135]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00135]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00135]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00135]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00135]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00135]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00135]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00135]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00135]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00135]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00135]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00135]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00135]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00135]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00135]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00135]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00135]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00135]\n",
            "Epoch 1150: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.890, valid_loss=0.00135]\n",
            "Epoch 1150: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00135]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00135]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00135]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00135]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00135]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00135]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00135]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00135]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00135]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00135]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00135]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00135]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00135]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00135]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00135]\n",
            "Epoch 1164: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.750, valid_loss=0.00135]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00135]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00135]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00135]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00135]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00135]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00135]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00135]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00135]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00135]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00135]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00135]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00135]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00135]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00135]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00135]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00135]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00135]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00135]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00135]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00135]\n",
            "Epoch 1184: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00135]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00135]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00135]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00135]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00135]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00135]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00135]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00135]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00135]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00135]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00135]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00135]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00135]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00135]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00135]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00135]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 20:23:35,149\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m `Trainer.fit` stopped: `max_steps=1200.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00135]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.810, valid_loss=0.00135]\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.62it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=42365)\u001b[0m \r                                                                      \u001b[A\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.810, valid_loss=0.00131]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00131]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=45643)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 2025-06-15 20:23:49.529884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m E0000 00:00:1750019029.576607   45735 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m E0000 00:00:1750019029.590808   45735 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 2025-06-15 20:23:49.637778: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 3 | blocks       | ModuleList    | 4.9 M  | train\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 4.9 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 4.9 M     Total params\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 19.447    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=41.80, train_loss_epoch=41.80]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=44.20, train_loss_epoch=44.20]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=38.10]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=31.50]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.90, train_loss_epoch=34.90]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.10, train_loss_epoch=34.10]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.00, train_loss_epoch=37.00]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.00, train_loss_epoch=27.00]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.70, train_loss_epoch=27.70]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.20, train_loss_epoch=26.20]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.00, train_loss_epoch=24.00]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.60, train_loss_epoch=24.60]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.30, train_loss_epoch=22.30]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=21.70]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.40, train_loss_epoch=22.40]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.00, train_loss_epoch=24.00]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.20, train_loss_epoch=22.20]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.40, train_loss_epoch=20.40]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.00, train_loss_epoch=21.00]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=21.50]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=12.10]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.57it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.00561]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.00561]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00561]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.00561]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.00561]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.00561]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=0.00561]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00561]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00561]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00561]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00561]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00561]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00561]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00561]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00561]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.710, train_loss_epoch=9.710, valid_loss=0.00561]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.550, train_loss_epoch=9.550, valid_loss=0.00561]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00561]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.320, train_loss_epoch=9.320, valid_loss=0.00561]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.880, train_loss_epoch=9.880, valid_loss=0.00561]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00561]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00561]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.770, valid_loss=0.00561]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.600, train_loss_epoch=8.600, valid_loss=0.00561]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.280, train_loss_epoch=9.280, valid_loss=0.00561]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.550, train_loss_epoch=9.550, valid_loss=0.00561]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.800, train_loss_epoch=8.800, valid_loss=0.00561]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.370, train_loss_epoch=8.370, valid_loss=0.00561]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.750, train_loss_epoch=8.750, valid_loss=0.00561]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.630, train_loss_epoch=8.630, valid_loss=0.00561]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.470, train_loss_epoch=8.470, valid_loss=0.00561]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.140, train_loss_epoch=9.140, valid_loss=0.00561]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.620, train_loss_epoch=8.620, valid_loss=0.00561]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.490, train_loss_epoch=8.490, valid_loss=0.00561]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=0.00561]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950, valid_loss=0.00561]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.050, train_loss_epoch=8.050, valid_loss=0.00561]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.00561]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=0.00561]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.00561]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.360, train_loss_epoch=8.360, valid_loss=0.00561]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.060, train_loss_epoch=8.060, valid_loss=0.00561]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.160, train_loss_epoch=8.160, valid_loss=0.00561]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.160, train_loss_epoch=8.160, valid_loss=0.00561]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.860, train_loss_epoch=8.860, valid_loss=0.00561]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.620, train_loss_epoch=8.620, valid_loss=0.00561]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.00561]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00561]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.120, train_loss_epoch=8.120, valid_loss=0.00561]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.800, train_loss_epoch=8.800, valid_loss=0.00561]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00561]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.00561]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.250, train_loss_epoch=8.250, valid_loss=0.00561]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.280, train_loss_epoch=8.280, valid_loss=0.00561]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.490, train_loss_epoch=8.490, valid_loss=0.00561]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460, valid_loss=0.00561]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.370, train_loss_epoch=8.370, valid_loss=0.00561]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00561]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.270, valid_loss=0.00561]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.560, train_loss_epoch=8.560, valid_loss=0.00561]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.00561]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350, valid_loss=0.00561]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.370, train_loss_epoch=8.370, valid_loss=0.00561]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.940, train_loss_epoch=8.940, valid_loss=0.00561]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.00561]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=0.00561]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.00561]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540, valid_loss=0.00561]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.170, train_loss_epoch=8.170, valid_loss=0.00561]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.00561]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.610, train_loss_epoch=8.610, valid_loss=0.00561]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.00561]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.130, train_loss_epoch=8.130, valid_loss=0.00561]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00561]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.560, train_loss_epoch=8.560, valid_loss=0.00561]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.260, train_loss_epoch=8.260, valid_loss=0.00561]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.000, train_loss_epoch=9.000, valid_loss=0.00561]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.690, train_loss_epoch=8.690, valid_loss=0.00561]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.540, train_loss_epoch=9.540, valid_loss=0.00561]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.280, train_loss_epoch=8.280, valid_loss=0.00561]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.990, train_loss_epoch=8.990, valid_loss=0.00561]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.390, train_loss_epoch=9.390, valid_loss=0.00561]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.410, train_loss_epoch=8.410, valid_loss=0.00561]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.500, train_loss_epoch=8.500, valid_loss=0.00561]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.340, train_loss_epoch=7.340, valid_loss=0.00561]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.010, train_loss_epoch=8.010, valid_loss=0.00561]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=7.880, valid_loss=0.00561]\n",
            "Epoch 186: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00561]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00561]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.00561]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.00561]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=0.00561]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.00561]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.120, train_loss_epoch=8.120, valid_loss=0.00561]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.040, train_loss_epoch=7.040, valid_loss=0.00561]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.510, train_loss_epoch=7.510, valid_loss=0.00561]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=0.00561]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.340, train_loss_epoch=7.340, valid_loss=0.00561]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.00561]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.00561]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.00561]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s, v_num=0, train_loss_step=6.800, train_loss_epoch=7.670, valid_loss=0.00561]\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 57.58it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.800, train_loss_epoch=6.800, valid_loss=0.003]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.070, train_loss_epoch=7.070, valid_loss=0.003]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.140, train_loss_epoch=7.140, valid_loss=0.003]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.940, train_loss_epoch=6.940, valid_loss=0.003]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=6.780, valid_loss=0.003]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.260, train_loss_epoch=7.260, valid_loss=0.003]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.200, train_loss_epoch=6.200, valid_loss=0.003]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.940, train_loss_epoch=6.940, valid_loss=0.003]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=6.440, valid_loss=0.003]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.290, train_loss_epoch=7.290, valid_loss=0.003]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.040, train_loss_epoch=7.040, valid_loss=0.003]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.140, train_loss_epoch=7.140, valid_loss=0.003]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.003]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.003]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.003]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.003]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.050, train_loss_epoch=7.050, valid_loss=0.003]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.910, train_loss_epoch=7.910, valid_loss=0.003]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.003]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.990, train_loss_epoch=7.990, valid_loss=0.003]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=0.003]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.200, train_loss_epoch=7.200, valid_loss=0.003]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.003]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.003]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.100, train_loss_epoch=7.100, valid_loss=0.003]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=6.440, valid_loss=0.003]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.010, train_loss_epoch=7.010, valid_loss=0.003]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=0.003]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180, valid_loss=0.003]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.690, valid_loss=0.003]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.240, train_loss_epoch=7.240, valid_loss=0.003]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.090, train_loss_epoch=7.090, valid_loss=0.003]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.003]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.003]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.010, train_loss_epoch=7.010, valid_loss=0.003]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.930, train_loss_epoch=6.930, valid_loss=0.003]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.210, train_loss_epoch=7.210, valid_loss=0.003]\n",
            "Epoch 236: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, v_num=0, train_loss_step=7.210, train_loss_epoch=7.210, valid_loss=0.003]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.580, train_loss_epoch=6.580, valid_loss=0.003]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.130, train_loss_epoch=7.130, valid_loss=0.003]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.620, train_loss_epoch=6.620, valid_loss=0.003]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.120, train_loss_epoch=7.120, valid_loss=0.003]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.003]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.690, valid_loss=0.003]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  3.61it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.690, valid_loss=0.003]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.003]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.580, train_loss_epoch=6.580, valid_loss=0.003]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.270, train_loss_epoch=7.270, valid_loss=0.003]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.260, train_loss_epoch=7.260, valid_loss=0.003]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.170, train_loss_epoch=7.170, valid_loss=0.003]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.580, train_loss_epoch=6.580, valid_loss=0.003]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.020, train_loss_epoch=7.020, valid_loss=0.003]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.230, train_loss_epoch=7.230, valid_loss=0.003]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.810, train_loss_epoch=6.810, valid_loss=0.003]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180, valid_loss=0.003]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=0.003]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.650, train_loss_epoch=7.650, valid_loss=0.003]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.840, train_loss_epoch=6.840, valid_loss=0.003]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=0.003]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.620, train_loss_epoch=6.620, valid_loss=0.003]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.070, train_loss_epoch=7.070, valid_loss=0.003]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.003]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=0.003]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.390, train_loss_epoch=6.390, valid_loss=0.003]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.390, train_loss_epoch=7.390, valid_loss=0.003]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.003]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.050, train_loss_epoch=7.050, valid_loss=0.003]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=0.003]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.003]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.003]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=6.440, valid_loss=0.003]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.003]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.650, train_loss_epoch=6.650, valid_loss=0.003]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.110, train_loss_epoch=7.110, valid_loss=0.003]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.380, train_loss_epoch=6.380, valid_loss=0.003]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.003]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.370, train_loss_epoch=6.370, valid_loss=0.003]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.110, train_loss_epoch=7.110, valid_loss=0.003]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.120, train_loss_epoch=7.120, valid_loss=0.003]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.170, train_loss_epoch=7.170, valid_loss=0.003]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.370, train_loss_epoch=6.370, valid_loss=0.003]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.690, train_loss_epoch=6.690, valid_loss=0.003]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.003]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590, valid_loss=0.003]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.540, train_loss_epoch=6.540, valid_loss=0.003]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.180, train_loss_epoch=6.180, valid_loss=0.003]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.660, train_loss_epoch=6.660, valid_loss=0.003]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.760, train_loss_epoch=6.760, valid_loss=0.003]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.003]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.250, train_loss_epoch=6.250, valid_loss=0.003]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.880, train_loss_epoch=5.880, valid_loss=0.003]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.950, train_loss_epoch=5.950, valid_loss=0.003]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.003]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=6.060, valid_loss=0.003]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370, valid_loss=0.003]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.230, train_loss_epoch=6.230, valid_loss=0.003]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.940, train_loss_epoch=5.940, valid_loss=0.003]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.120, valid_loss=0.003]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.530, train_loss_epoch=5.530, valid_loss=0.003]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=0.003]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.890, train_loss_epoch=5.890, valid_loss=0.003]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.630, train_loss_epoch=5.630, valid_loss=0.003]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=5.630, valid_loss=0.003]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 56.58it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.120, valid_loss=0.00263]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=0.00263]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.870, train_loss_epoch=5.870, valid_loss=0.00263]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.890, train_loss_epoch=5.890, valid_loss=0.00263]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.900, train_loss_epoch=5.900, valid_loss=0.00263]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650, valid_loss=0.00263]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.00263]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.100, train_loss_epoch=6.100, valid_loss=0.00263]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.460, valid_loss=0.00263]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.470, train_loss_epoch=5.470, valid_loss=0.00263]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=0.00263]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.630, train_loss_epoch=5.630, valid_loss=0.00263]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.490, valid_loss=0.00263]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.220, train_loss_epoch=6.220, valid_loss=0.00263]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00263]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.530, train_loss_epoch=5.530, valid_loss=0.00263]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.330, train_loss_epoch=5.330, valid_loss=0.00263]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.430, train_loss_epoch=5.430, valid_loss=0.00263]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.230, train_loss_epoch=5.230, valid_loss=0.00263]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.050, train_loss_epoch=5.050, valid_loss=0.00263]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.240, train_loss_epoch=5.240, valid_loss=0.00263]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=0.00263]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900, valid_loss=0.00263]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.180, train_loss_epoch=5.180, valid_loss=0.00263]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.300, train_loss_epoch=5.300, valid_loss=0.00263]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.680, train_loss_epoch=5.680, valid_loss=0.00263]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.430, train_loss_epoch=5.430, valid_loss=0.00263]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.860, train_loss_epoch=4.860, valid_loss=0.00263]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.320, train_loss_epoch=5.320, valid_loss=0.00263]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.770, train_loss_epoch=4.770, valid_loss=0.00263]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.000, train_loss_epoch=5.000, valid_loss=0.00263]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.240, train_loss_epoch=5.240, valid_loss=0.00263]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090, valid_loss=0.00263]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.220, train_loss_epoch=5.220, valid_loss=0.00263]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.110, train_loss_epoch=5.110, valid_loss=0.00263]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.110, train_loss_epoch=5.110, valid_loss=0.00263]\n",
            "Epoch 335: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00263]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00263]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00263]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00263]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620, valid_loss=0.00263]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.550, train_loss_epoch=5.550, valid_loss=0.00263]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.880, train_loss_epoch=5.880, valid_loss=0.00263]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=0, train_loss_step=5.740, train_loss_epoch=5.740, valid_loss=0.00263]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.740, train_loss_epoch=5.740, valid_loss=0.00263]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00263]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.500, train_loss_epoch=5.500, valid_loss=0.00263]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.00263]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.100, train_loss_epoch=5.100, valid_loss=0.00263]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.600, train_loss_epoch=5.600, valid_loss=0.00263]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.110, train_loss_epoch=5.110, valid_loss=0.00263]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.050, train_loss_epoch=5.050, valid_loss=0.00263]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.960, train_loss_epoch=4.960, valid_loss=0.00263]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.910, train_loss_epoch=5.910, valid_loss=0.00263]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=0.00263]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00263]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780, valid_loss=0.00263]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.820, train_loss_epoch=5.820, valid_loss=0.00263]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.00263]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000, valid_loss=0.00263]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.020, train_loss_epoch=6.020, valid_loss=0.00263]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.040, train_loss_epoch=6.040, valid_loss=0.00263]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.00263]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.600, train_loss_epoch=5.600, valid_loss=0.00263]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.990, train_loss_epoch=5.990, valid_loss=0.00263]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.320, train_loss_epoch=5.320, valid_loss=0.00263]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=5.570, valid_loss=0.00263]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.080, train_loss_epoch=6.080, valid_loss=0.00263]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00263]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.010, train_loss_epoch=6.010, valid_loss=0.00263]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.110, train_loss_epoch=5.110, valid_loss=0.00263]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=5.110, valid_loss=0.00263]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.00263]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.770, train_loss_epoch=5.770, valid_loss=0.00263]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.290, train_loss_epoch=5.290, valid_loss=0.00263]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970, valid_loss=0.00263]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.630, train_loss_epoch=5.630, valid_loss=0.00263]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=0.00263]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.630, train_loss_epoch=5.630, valid_loss=0.00263]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.00263]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.440, train_loss_epoch=5.440, valid_loss=0.00263]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.950, train_loss_epoch=4.950, valid_loss=0.00263]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620, valid_loss=0.00263]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350, valid_loss=0.00263]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.240, train_loss_epoch=5.240, valid_loss=0.00263]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=0.00263]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00263]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210, valid_loss=0.00263]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.100, train_loss_epoch=5.100, valid_loss=0.00263]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.070, train_loss_epoch=5.070, valid_loss=0.00263]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00263]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.080, train_loss_epoch=5.080, valid_loss=0.00263]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.780, train_loss_epoch=4.780, valid_loss=0.00263]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00263]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.530, train_loss_epoch=5.530, valid_loss=0.00263]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00263]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.820, train_loss_epoch=4.820, valid_loss=0.00263]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650, valid_loss=0.00263]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=0.00263]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00263]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370, valid_loss=0.00263]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.040, train_loss_epoch=6.040, valid_loss=0.00263]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.600, train_loss_epoch=5.600, valid_loss=0.00263]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.600, valid_loss=0.00263]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.53it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.00291]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=0.00291]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.240, train_loss_epoch=5.240, valid_loss=0.00291]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.820, train_loss_epoch=4.820, valid_loss=0.00291]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.000, train_loss_epoch=5.000, valid_loss=0.00291]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=0.00291]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.180, train_loss_epoch=5.180, valid_loss=0.00291]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.360, train_loss_epoch=5.360, valid_loss=0.00291]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.030, train_loss_epoch=5.030, valid_loss=0.00291]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=0.00291]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.070, train_loss_epoch=5.070, valid_loss=0.00291]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.600, train_loss_epoch=4.600, valid_loss=0.00291]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.570, train_loss_epoch=4.570, valid_loss=0.00291]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.640, train_loss_epoch=4.640, valid_loss=0.00291]\n",
            "Epoch 413: 100%|██████████| 1/1 [00:00<00:00,  3.35it/s, v_num=0, train_loss_step=4.610, train_loss_epoch=4.610, valid_loss=0.00291]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.610, train_loss_epoch=4.610, valid_loss=0.00291]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.650, train_loss_epoch=4.650, valid_loss=0.00291]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.980, train_loss_epoch=4.980, valid_loss=0.00291]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=0.00291]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370, valid_loss=0.00291]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=4.690, valid_loss=0.00291]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00291]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.130, train_loss_epoch=5.130, valid_loss=0.00291]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.360, train_loss_epoch=5.360, valid_loss=0.00291]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900, valid_loss=0.00291]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.130, train_loss_epoch=5.130, valid_loss=0.00291]\n",
            "Epoch 424: 100%|██████████| 1/1 [00:00<00:00,  2.33it/s, v_num=0, train_loss_step=4.950, train_loss_epoch=4.950, valid_loss=0.00291]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.950, train_loss_epoch=4.950, valid_loss=0.00291]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.600, train_loss_epoch=5.600, valid_loss=0.00291]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.820, train_loss_epoch=4.820, valid_loss=0.00291]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.230, train_loss_epoch=5.230, valid_loss=0.00291]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.120, train_loss_epoch=5.120, valid_loss=0.00291]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.760, train_loss_epoch=4.760, valid_loss=0.00291]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.800, train_loss_epoch=4.800, valid_loss=0.00291]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210, valid_loss=0.00291]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.810, train_loss_epoch=4.810, valid_loss=0.00291]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=0.00291]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.930, train_loss_epoch=4.930, valid_loss=0.00291]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.560, train_loss_epoch=5.560, valid_loss=0.00291]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.740, train_loss_epoch=5.740, valid_loss=0.00291]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00291]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.00291]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970, valid_loss=0.00291]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.260, train_loss_epoch=6.260, valid_loss=0.00291]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900, valid_loss=0.00291]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=0.00291]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.470, train_loss_epoch=5.470, valid_loss=0.00291]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.950, train_loss_epoch=4.950, valid_loss=0.00291]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.570, train_loss_epoch=5.570, valid_loss=0.00291]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.610, train_loss_epoch=4.610, valid_loss=0.00291]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.230, train_loss_epoch=5.230, valid_loss=0.00291]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880, valid_loss=0.00291]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.590, train_loss_epoch=5.590, valid_loss=0.00291]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.230, train_loss_epoch=5.230, valid_loss=0.00291]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.260, train_loss_epoch=5.260, valid_loss=0.00291]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.110, train_loss_epoch=5.110, valid_loss=0.00291]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.580, train_loss_epoch=4.580, valid_loss=0.00291]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.750, train_loss_epoch=4.750, valid_loss=0.00291]\n",
            "Epoch 455: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=0, train_loss_step=4.890, train_loss_epoch=4.890, valid_loss=0.00291]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.890, train_loss_epoch=4.890, valid_loss=0.00291]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.010, train_loss_epoch=5.010, valid_loss=0.00291]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.850, train_loss_epoch=4.850, valid_loss=0.00291]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.370, train_loss_epoch=4.370, valid_loss=0.00291]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.510, train_loss_epoch=4.510, valid_loss=0.00291]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.530, train_loss_epoch=4.530, valid_loss=0.00291]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.810, train_loss_epoch=4.810, valid_loss=0.00291]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.010, train_loss_epoch=5.010, valid_loss=0.00291]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00291]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.610, train_loss_epoch=4.610, valid_loss=0.00291]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.900, train_loss_epoch=4.900, valid_loss=0.00291]\n",
            "Epoch 466: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s, v_num=0, train_loss_step=4.680, train_loss_epoch=4.680, valid_loss=0.00291]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.680, train_loss_epoch=4.680, valid_loss=0.00291]\n",
            "Epoch 467: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00291]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00291]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.020, train_loss_epoch=4.020, valid_loss=0.00291]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.850, valid_loss=0.00291]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=3.900, valid_loss=0.00291]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.770, train_loss_epoch=3.770, valid_loss=0.00291]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00291]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=0.00291]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.000, train_loss_epoch=4.000, valid_loss=0.00291]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.500, valid_loss=0.00291]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.890, train_loss_epoch=3.890, valid_loss=0.00291]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00291]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=0.00291]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=0.00291]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.710, train_loss_epoch=3.710, valid_loss=0.00291]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470, valid_loss=0.00291]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00291]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00291]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=3.900, valid_loss=0.00291]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00291]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=0.00291]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410, valid_loss=0.00291]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=0.00291]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.00291]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00291]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00291]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00291]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00291]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00291]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00291]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400, valid_loss=0.00291]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00291]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00291]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  3.48it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.170, valid_loss=0.00291]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.70it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00237]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00237]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00237]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00237]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00237]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00237]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.290, train_loss_epoch=3.290, valid_loss=0.00237]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00237]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00237]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00237]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00237]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=0.00237]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470, valid_loss=0.00237]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00237]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=0.00237]\n",
            "Epoch 514: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00237]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00237]        \n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00237]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00237]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=0.00237]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00237]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.840, train_loss_epoch=3.840, valid_loss=0.00237]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00237]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=0.00237]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00237]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.290, train_loss_epoch=3.290, valid_loss=0.00237]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00237]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00237]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.530, train_loss_epoch=3.530, valid_loss=0.00237]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00237]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00237]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00237]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00237]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.320, train_loss_epoch=3.320, valid_loss=0.00237]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=0.00237]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00237]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00237]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00237]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540, valid_loss=0.00237]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=0.00237]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00237]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.410, train_loss_epoch=3.410, valid_loss=0.00237]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00237]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00237]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00237]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00237]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00237]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.290, train_loss_epoch=3.290, valid_loss=0.00237]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=0.00237]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00237]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00237]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.290, train_loss_epoch=3.290, valid_loss=0.00237]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00237]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00,  3.29it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00237]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00237]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00237]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00237]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00237]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00237]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00237]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540, valid_loss=0.00237]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00237]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00237]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00237]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00237]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00237]\n",
            "Epoch 562: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=2.830, valid_loss=0.00237]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=0.00237]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00237]\n",
            "Epoch 564: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00237]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00237]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00237]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00237]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00237]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00237]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00237]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.00237]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00237]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00237]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00237]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00237]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00237]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00237]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00237]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00237]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00237]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00237]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00237]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00237]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00237]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00237]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00237]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00237]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00237]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00237]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00237]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00237]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00237]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00237]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00237]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00237]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00237]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00237]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00237]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00237]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.45it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.010, valid_loss=0.00237]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.46it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00188]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00188]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00188]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00188]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00188]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00188]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.00188]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00188]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00188]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00188]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00188]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00188]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00188]\n",
            "Epoch 612: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00188]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00188]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00188]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00188]\n",
            "Epoch 615: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.730, valid_loss=0.00188]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00188]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00188]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00188]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00188]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00188]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00188]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00188]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00188]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00188]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00188]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00188]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00188]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00188]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00188]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00188]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00188]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00188]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00188]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00188]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00188]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00188]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00188]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00188]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00188]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00188]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00188]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00188]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00188]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00188]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00188]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00188]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00188]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00188]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00188]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00188]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00188]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00188]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00188]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00188]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00188]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00188]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00188]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00188]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00188]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00188]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00188]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00188]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00188]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00188]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00188]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00188]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00188]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00188]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00188]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00188]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00188]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00188]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00188]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00188]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00188]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00188]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00188]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00188]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00188]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00188]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00188]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00188]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00188]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00188]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00188]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00188]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00188]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00188]\n",
            "Epoch 688: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00188]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00188]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00188]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00188]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00188]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00188]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00188]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00188]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00188]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00188]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00188]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00188]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.790, valid_loss=0.00188]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.84it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00299]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00299]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00299]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00299]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00299]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00299]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00299]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00299]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00299]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00299]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00299]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00299]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00299]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00299]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00299]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00299]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00299]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00299]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00299]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00299]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00299]\n",
            "Epoch 720: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.410, valid_loss=0.00299]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00299]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00299]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00299]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00299]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00299]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00299]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00299]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00299]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00299]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00299]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00299]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00299]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00299]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00299]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00299]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00299]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00299]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00299]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00299]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00299]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00299]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00299]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00299]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00299]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00299]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00299]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00299]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00299]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00299]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00299]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00299]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00299]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00299]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00299]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00299]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00299]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00299]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.00299]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00299]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00299]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00299]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00299]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00299]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00299]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00299]\n",
            "Epoch 765: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.750, valid_loss=0.00299]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00299]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00299]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00299]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00299]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00299]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00299]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00299]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00299]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00299]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00299]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00299]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00299]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00299]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00299]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00299]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00299]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00299]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00299]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00299]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00299]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00299]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00299]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00299]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00299]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00299]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00299]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00299]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00299]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00299]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00299]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00299]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00299]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00299]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00299]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.760, valid_loss=0.00299]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 133.53it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0022]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0022]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0022]\n",
            "Epoch 802: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.0022]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.0022]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0022]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0022]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0022]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0022]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0022]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0022]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0022]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0022]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0022]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0022]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0022]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0022]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0022]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0022]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0022]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0022]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0022]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0022]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0022]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0022]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0022]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0022]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0022]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0022]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0022]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0022]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0022]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0022]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0022]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0022]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0022]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0022]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0022]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0022]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0022]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0022]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0022]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0022]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0022]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0022]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.0022]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0022]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.0022]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.0022]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.0022]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0022]\n",
            "Epoch 849: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0022]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.0022]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.0022]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0022]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.0022]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.0022]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.0022]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0022]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0022]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0022]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0022]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.0022]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.0022]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0022]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0022]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0022]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.0022]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0022]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.0022]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0022]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0022]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0022]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0022]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0022]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0022]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0022]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0022]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0022]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0022]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0022]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0022]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0022]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0022]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0022]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0022]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.0022]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0022]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.0022]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.0022]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.0022]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0022]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0022]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.0022]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.0022]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0022]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.0022]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0022]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0022]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0022]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0022]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0022]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.570, valid_loss=0.0022]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 120.76it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00245]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00245]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00245]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00245]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00245]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00245]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00245]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00245]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00245]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00245]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00245]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.00245]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00245]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00245]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00245]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00245]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00245]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00245]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00245]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00245]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00245]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00245]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00245]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00245]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00245]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00245]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00245]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00245]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00245]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00245]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00245]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00245]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00245]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00245]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00245]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00245]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00245]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00245]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00245]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00245]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00245]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00245]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00245]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00245]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00245]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00245]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00245]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00245]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00245]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00245]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00245]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00245]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00245]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00245]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00245]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00245]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00245]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00245]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00245]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00245]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00245]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00245]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00245]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00245]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00245]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00245]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00245]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00245]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00245]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00245]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00245]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00245]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00245]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00245]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00245]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00245]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00245]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00245]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00245]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00245]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00245]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00245]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00245]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00245]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00245]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00245]\n",
            "Epoch 985: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00245]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00245]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00245]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00245]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00245]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00245]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00245]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00245]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00245]\n",
            "Epoch 993: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00245]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00245]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00245]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00245]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00245]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00245]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00245]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.880, valid_loss=0.00245]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.37it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0021]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.0021]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.0021]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.0021]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.0021]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.0021]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0021]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.0021]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0021]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.0021]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.0021]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.0021]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.0021]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.0021]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0021]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.0021]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.0021]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.0021]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.0021]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.0021]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0021]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.0021]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.0021]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.0021]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0021]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.0021]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.0021]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.0021]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.0021]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.0021]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.0021]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.0021]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.0021]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.0021]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.0021]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.0021]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0021]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0021]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.0021]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.0021]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0021]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.0021]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0021]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.0021]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0021]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.0021]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0021]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0021]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.0021]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.0021]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0021]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.0021]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0021]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0021]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.0021]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0021]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0021]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0021]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.0021]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0021]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0021]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.0021]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.0021]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.0021]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0021]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0021]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0021]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.0021]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0021]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0021]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.0021]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0021]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0021]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0021]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.0021]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0021]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0021]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.0021]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0021]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.0021]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.0021]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.0021]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0021]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0021]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0021]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0021]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.0021]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0021]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.0021]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.0021]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0021]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.0021]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0021]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.0021]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0021]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.0021]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.0021]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.0021]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0021]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.0021]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.970, valid_loss=0.0021]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 127.67it/s]\u001b[A\n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00214]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00214]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00214]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00214]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00214]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00214]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00214]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00214]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00214]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00214]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00214]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00214]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00214]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00214]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00214]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00214]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00214]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00214]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00214]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00214]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00214]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00214]\n",
            "Epoch 1121: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00214]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00214]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00214]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00214]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00214]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00214]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00214]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00214]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00214]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00214]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00214]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00214]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00214]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00214]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00214]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00214]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00214]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00214]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00214]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00214]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00214]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00214]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00214]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00214]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00214]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00214]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00214]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00214]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00214]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00214]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00214]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00214]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00214]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00214]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00214]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00214]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00214]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00214]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00214]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00214]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00214]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00214]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00214]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00214]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00214]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00214]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00214]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00214]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00214]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00214]\n",
            "Epoch 1170: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.910, valid_loss=0.00214]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00214]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00214]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00214]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00214]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00214]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00214]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00214]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00214]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00214]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00214]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00214]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00214]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00214]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00214]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00214]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00214]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00214]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00214]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00214]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00214]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00214]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00214]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00214]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00214]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00214]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00214]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00214]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00214]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00214]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.780, valid_loss=0.00214]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 72.76it/s]\u001b[A\n",
            "Epoch 1200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00188]\n",
            "Epoch 1201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00188]\n",
            "Epoch 1202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00188]\n",
            "Epoch 1203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00188]\n",
            "Epoch 1205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00188]\n",
            "Epoch 1207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00188]\n",
            "Epoch 1208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00188]\n",
            "Epoch 1210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00188]\n",
            "Epoch 1212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00188]\n",
            "Epoch 1213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00188]\n",
            "Epoch 1214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00188]\n",
            "Epoch 1215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00188]\n",
            "Epoch 1216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00188]\n",
            "Epoch 1217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00188]\n",
            "Epoch 1218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00188]\n",
            "Epoch 1219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00188]\n",
            "Epoch 1220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00188]\n",
            "Epoch 1222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00188]\n",
            "Epoch 1223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00188]\n",
            "Epoch 1224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00188]\n",
            "Epoch 1225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00188]\n",
            "Epoch 1229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00188]\n",
            "Epoch 1229: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.850, valid_loss=0.00188]\n",
            "Epoch 1230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00188]\n",
            "Epoch 1231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00188]\n",
            "Epoch 1232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00188]\n",
            "Epoch 1234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00188]\n",
            "Epoch 1235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00188]\n",
            "Epoch 1237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00188]\n",
            "Epoch 1241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00188]\n",
            "Epoch 1242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00188]\n",
            "Epoch 1243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00188]\n",
            "Epoch 1244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00188]\n",
            "Epoch 1246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00188]\n",
            "Epoch 1248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00188]\n",
            "Epoch 1249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1253: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.770, valid_loss=0.00188]\n",
            "Epoch 1253: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00188]\n",
            "Epoch 1254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00188]\n",
            "Epoch 1255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00188]\n",
            "Epoch 1256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00188]\n",
            "Epoch 1258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00188]\n",
            "Epoch 1260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00188]\n",
            "Epoch 1261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00188]\n",
            "Epoch 1262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00188]\n",
            "Epoch 1263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00188]\n",
            "Epoch 1264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00188]\n",
            "Epoch 1266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00188]\n",
            "Epoch 1268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00188]\n",
            "Epoch 1269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00188]\n",
            "Epoch 1270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00188]\n",
            "Epoch 1271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00188]\n",
            "Epoch 1272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00188]\n",
            "Epoch 1273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00188]\n",
            "Epoch 1274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00188]\n",
            "Epoch 1275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00188]\n",
            "Epoch 1276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00188]\n",
            "Epoch 1277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00188]\n",
            "Epoch 1278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00188]\n",
            "Epoch 1281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00188]\n",
            "Epoch 1282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00188]\n",
            "Epoch 1284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00188]\n",
            "Epoch 1286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00188]\n",
            "Epoch 1287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00188]\n",
            "Epoch 1289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00188]\n",
            "Epoch 1290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00188]\n",
            "Epoch 1291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00188]\n",
            "Epoch 1292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00188]\n",
            "Epoch 1293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00188]\n",
            "Epoch 1294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00188]\n",
            "Epoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00188]\n",
            "Epoch 1296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00188]\n",
            "Epoch 1297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00188]\n",
            "Epoch 1298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00188]\n",
            "Epoch 1299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00188]\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.830, valid_loss=0.00188]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.62it/s]\u001b[A\n",
            "Epoch 1300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00212]\n",
            "Epoch 1301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00212]\n",
            "Epoch 1301: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.820, valid_loss=0.00212]\n",
            "Epoch 1302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00212]\n",
            "Epoch 1303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00212]\n",
            "Epoch 1304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00212]\n",
            "Epoch 1305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00212]\n",
            "Epoch 1306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00212]\n",
            "Epoch 1308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00212]\n",
            "Epoch 1309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00212]\n",
            "Epoch 1311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00212]\n",
            "Epoch 1312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00212]\n",
            "Epoch 1313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00212]\n",
            "Epoch 1314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00212]\n",
            "Epoch 1315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00212]\n",
            "Epoch 1316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00212]\n",
            "Epoch 1317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00212]\n",
            "Epoch 1318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00212]\n",
            "Epoch 1320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00212]\n",
            "Epoch 1321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00212]\n",
            "Epoch 1322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00212]\n",
            "Epoch 1323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00212]\n",
            "Epoch 1324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00212]\n",
            "Epoch 1325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00212]\n",
            "Epoch 1326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00212]\n",
            "Epoch 1327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00212]\n",
            "Epoch 1328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00212]\n",
            "Epoch 1329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00212]\n",
            "Epoch 1330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00212]\n",
            "Epoch 1331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00212]\n",
            "Epoch 1332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00212]\n",
            "Epoch 1333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00212]\n",
            "Epoch 1334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00212]\n",
            "Epoch 1335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00212]\n",
            "Epoch 1336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00212]\n",
            "Epoch 1337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00212]\n",
            "Epoch 1339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00212]\n",
            "Epoch 1340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00212]\n",
            "Epoch 1341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00212]\n",
            "Epoch 1342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00212]\n",
            "Epoch 1343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00212]\n",
            "Epoch 1344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00212]\n",
            "Epoch 1345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820, valid_loss=0.00212]\n",
            "Epoch 1346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00212]\n",
            "Epoch 1347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00212]\n",
            "Epoch 1348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00212]\n",
            "Epoch 1349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00212]\n",
            "Epoch 1351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00212]\n",
            "Epoch 1351: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.940, valid_loss=0.00212]\n",
            "Epoch 1352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00212]\n",
            "Epoch 1352: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=1.830, valid_loss=0.00212]\n",
            "Epoch 1353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00212]\n",
            "Epoch 1354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00212]\n",
            "Epoch 1355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00212]\n",
            "Epoch 1356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00212]\n",
            "Epoch 1357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00212]\n",
            "Epoch 1358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00212]\n",
            "Epoch 1359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00212]\n",
            "Epoch 1360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00212]\n",
            "Epoch 1361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00212]\n",
            "Epoch 1362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00212]\n",
            "Epoch 1363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00212]\n",
            "Epoch 1365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00212]\n",
            "Epoch 1366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00212]\n",
            "Epoch 1367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00212]\n",
            "Epoch 1368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00212]\n",
            "Epoch 1369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00212]\n",
            "Epoch 1370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00212]\n",
            "Epoch 1371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00212]\n",
            "Epoch 1372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00212]\n",
            "Epoch 1373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00212]\n",
            "Epoch 1374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00212]\n",
            "Epoch 1375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00212]\n",
            "Epoch 1376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00212]\n",
            "Epoch 1377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00212]\n",
            "Epoch 1378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00212]\n",
            "Epoch 1378: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00212]\n",
            "Epoch 1379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00212]\n",
            "Epoch 1380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00212]\n",
            "Epoch 1381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00212]\n",
            "Epoch 1382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1382: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00212]\n",
            "Epoch 1383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.830, train_loss_epoch=1.830, valid_loss=0.00212]\n",
            "Epoch 1384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00212]\n",
            "Epoch 1385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00212]\n",
            "Epoch 1386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00212]\n",
            "Epoch 1387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00212]\n",
            "Epoch 1388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00212]\n",
            "Epoch 1389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00212]\n",
            "Epoch 1390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00212]\n",
            "Epoch 1391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00212]\n",
            "Epoch 1392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00212]\n",
            "Epoch 1393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00212]\n",
            "Epoch 1394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00212]\n",
            "Epoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00212]\n",
            "Epoch 1396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00212]\n",
            "Epoch 1397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00212]\n",
            "Epoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00212]\n",
            "Epoch 1399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 20:32:27,430\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (16, 8, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m `Trainer.fit` stopped: `max_steps=1400.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00212]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=1.970, valid_loss=0.00212]\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 134.95it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=45643)\u001b[0m \r                                                                       \u001b[A\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=1.970, valid_loss=0.00193]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00193]\rEpoch 1399: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00193]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=47907)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 2025-06-15 20:32:42.200828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m E0000 00:00:1750019562.232099   48003 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m E0000 00:00:1750019562.241410   48003 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 2025-06-15 20:32:42.278502: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 3 | blocks       | ModuleList    | 5.1 M  | train\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 5.1 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 5.1 M     Total params\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 20.238    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 38.17it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.319, train_loss_epoch=0.319]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.574, train_loss_epoch=0.574]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  6.54it/s, v_num=0, train_loss_step=0.171, train_loss_epoch=0.171]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  6.47it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.114, train_loss_epoch=0.114]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.105, train_loss_epoch=0.105]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0896, train_loss_epoch=0.0896]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0791, train_loss_epoch=0.0791]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0709, train_loss_epoch=0.0709]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0813, train_loss_epoch=0.0813]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0911, train_loss_epoch=0.0911]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.065, train_loss_epoch=0.065]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0717, train_loss_epoch=0.0717]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0719, train_loss_epoch=0.0719]\n",
            "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  6.63it/s, v_num=0, train_loss_step=0.0571, train_loss_epoch=0.0571]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0571, train_loss_epoch=0.0571]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0522, train_loss_epoch=0.0522]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0673, train_loss_epoch=0.0673]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0639, train_loss_epoch=0.0639]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0511, train_loss_epoch=0.0511]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.054, train_loss_epoch=0.054]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0433, train_loss_epoch=0.0433]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0521, train_loss_epoch=0.0521]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0467, train_loss_epoch=0.0467]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0427, train_loss_epoch=0.0427]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0579, train_loss_epoch=0.0579]\n",
            "Epoch 28: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.0579] \n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.053, train_loss_epoch=0.053]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452]\n",
            "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0452]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0529, train_loss_epoch=0.0529]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0403, train_loss_epoch=0.0403]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0391, train_loss_epoch=0.0391]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0307, train_loss_epoch=0.0307]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.038, train_loss_epoch=0.038]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0245, train_loss_epoch=0.0245]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0274, train_loss_epoch=0.0274]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.021, train_loss_epoch=0.021]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206]\n",
            "Epoch 52: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0206]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.019, train_loss_epoch=0.019]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148]\n",
            "Epoch 57: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=0, train_loss_step=0.0193, train_loss_epoch=0.0193]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0193, train_loss_epoch=0.0193]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0237, train_loss_epoch=0.0237]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0214, train_loss_epoch=0.0214]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.53it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0214]\n",
            "Epoch 63: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0247, train_loss_epoch=0.0247]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.020, train_loss_epoch=0.020]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0171, train_loss_epoch=0.0171]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0194, train_loss_epoch=0.0194]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0248, train_loss_epoch=0.0248]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0208, train_loss_epoch=0.0208]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0179, train_loss_epoch=0.0179]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0242, train_loss_epoch=0.0242]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0203, train_loss_epoch=0.0203]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0192, train_loss_epoch=0.0192]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0264, train_loss_epoch=0.0264]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0236, train_loss_epoch=0.0236]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.33it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0188]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.04it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0216, train_loss_epoch=0.0216, valid_loss=0.0414]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0414]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0414]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0414]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.0414]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.0414]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0414]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0414]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.0414]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0414]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0414]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0414]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0414]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00784, train_loss_epoch=0.00784, valid_loss=0.0414]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00675, train_loss_epoch=0.00675, valid_loss=0.0414]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.0414]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0202, train_loss_epoch=0.0202, valid_loss=0.0414]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0414]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0414]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.0414]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0414]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0414]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0092, train_loss_epoch=0.0092, valid_loss=0.0414]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00754, train_loss_epoch=0.00754, valid_loss=0.0414]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0414]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00608, train_loss_epoch=0.00608, valid_loss=0.0414]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00632, train_loss_epoch=0.00632, valid_loss=0.0414]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0414]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0414]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00726, train_loss_epoch=0.00726, valid_loss=0.0414]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00954, train_loss_epoch=0.00954, valid_loss=0.0414]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.0414]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0414]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.0414]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00883, train_loss_epoch=0.00883, valid_loss=0.0414]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0171, train_loss_epoch=0.0171, valid_loss=0.0414]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.0414]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0137, valid_loss=0.0414]\n",
            "Epoch 136: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.0414]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.0414]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.0414]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00797, train_loss_epoch=0.00797, valid_loss=0.0414]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0414]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0414]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00799, train_loss_epoch=0.00799, valid_loss=0.0414]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0414]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0092, train_loss_epoch=0.0092, valid_loss=0.0414]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00619, train_loss_epoch=0.00619, valid_loss=0.0414]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00712, train_loss_epoch=0.00712, valid_loss=0.0414]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00928, train_loss_epoch=0.00928, valid_loss=0.0414]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0414]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00673, train_loss_epoch=0.00673, valid_loss=0.0414]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00662, train_loss_epoch=0.00662, valid_loss=0.0414]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00709, train_loss_epoch=0.00709, valid_loss=0.0414]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.0414]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00934, train_loss_epoch=0.00934, valid_loss=0.0414]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0151, train_loss_epoch=0.0151, valid_loss=0.0414]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00922, train_loss_epoch=0.00922, valid_loss=0.0414]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00869, train_loss_epoch=0.00869, valid_loss=0.0414]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0414]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0414]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00886, train_loss_epoch=0.00886, valid_loss=0.0414]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.0414]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00993, train_loss_epoch=0.00993, valid_loss=0.0414]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00708, train_loss_epoch=0.00708, valid_loss=0.0414]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00812, train_loss_epoch=0.00812, valid_loss=0.0414]\n",
            "Epoch 163: 100%|██████████| 1/1 [00:00<00:00,  6.62it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.0414] \n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.0414]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0094, train_loss_epoch=0.0094, valid_loss=0.0414]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.0414]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00747, train_loss_epoch=0.00747, valid_loss=0.0414]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.0414]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0414]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.0414]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.0414]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0185, train_loss_epoch=0.0185, valid_loss=0.0414]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.0414]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.0414]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.0414]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0414]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0414]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00952, train_loss_epoch=0.00952, valid_loss=0.0414]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0414]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0414]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00998, train_loss_epoch=0.00998, valid_loss=0.0414]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.0414]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00833, train_loss_epoch=0.00833, valid_loss=0.0414]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0414]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00868, train_loss_epoch=0.00868, valid_loss=0.0414]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00632, train_loss_epoch=0.00632, valid_loss=0.0414]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0067, train_loss_epoch=0.0067, valid_loss=0.0414]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0414]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.0414]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  6.70it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.0414]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00808, train_loss_epoch=0.00808, valid_loss=0.0414]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0414]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00684, train_loss_epoch=0.00684, valid_loss=0.0414]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0414]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0414]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=0.0414]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0414]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0102, train_loss_epoch=0.0102, valid_loss=0.0414]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00991, train_loss_epoch=0.00991, valid_loss=0.0414]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00854, train_loss_epoch=0.00854, valid_loss=0.0414]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  6.23it/s, v_num=0, train_loss_step=0.00674, train_loss_epoch=0.00854, valid_loss=0.0414]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.51it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00674, train_loss_epoch=0.00674, valid_loss=0.0454]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0073, train_loss_epoch=0.0073, valid_loss=0.0454]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988, valid_loss=0.0454]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00854, train_loss_epoch=0.00854, valid_loss=0.0454]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00715, train_loss_epoch=0.00715, valid_loss=0.0454]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.0454]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0099, train_loss_epoch=0.0099, valid_loss=0.0454]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.0454]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00711, train_loss_epoch=0.00711, valid_loss=0.0454]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=0.0454]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.0454]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00892, train_loss_epoch=0.00892, valid_loss=0.0454]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00687, train_loss_epoch=0.00687, valid_loss=0.0454]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00592, train_loss_epoch=0.00592, valid_loss=0.0454]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010, valid_loss=0.0454]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00551, train_loss_epoch=0.00551, valid_loss=0.0454]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00859, train_loss_epoch=0.00859, valid_loss=0.0454]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00856, train_loss_epoch=0.00856, valid_loss=0.0454]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00453, train_loss_epoch=0.00453, valid_loss=0.0454]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00749, train_loss_epoch=0.00749, valid_loss=0.0454]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00918, train_loss_epoch=0.00918, valid_loss=0.0454]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00525, train_loss_epoch=0.00525, valid_loss=0.0454]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0106, train_loss_epoch=0.0106, valid_loss=0.0454]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00799, train_loss_epoch=0.00799, valid_loss=0.0454]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0076, train_loss_epoch=0.0076, valid_loss=0.0454]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00911, train_loss_epoch=0.00911, valid_loss=0.0454]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.0454]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00739, train_loss_epoch=0.00739, valid_loss=0.0454]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0077, train_loss_epoch=0.0077, valid_loss=0.0454]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.0454]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00428, train_loss_epoch=0.00428, valid_loss=0.0454]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00389, train_loss_epoch=0.00389, valid_loss=0.0454]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00467, train_loss_epoch=0.00467, valid_loss=0.0454]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00816, train_loss_epoch=0.00816, valid_loss=0.0454]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00661, train_loss_epoch=0.00661, valid_loss=0.0454]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00582, train_loss_epoch=0.00582, valid_loss=0.0454]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00863, train_loss_epoch=0.00863, valid_loss=0.0454]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00653, train_loss_epoch=0.00653, valid_loss=0.0454]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00642, train_loss_epoch=0.00642, valid_loss=0.0454]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00912, valid_loss=0.0454]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00593, train_loss_epoch=0.00593, valid_loss=0.0454]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00445, train_loss_epoch=0.00445, valid_loss=0.0454]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00828, train_loss_epoch=0.00828, valid_loss=0.0454]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.0454]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00446, train_loss_epoch=0.00446, valid_loss=0.0454]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00481, train_loss_epoch=0.00481, valid_loss=0.0454]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00628, train_loss_epoch=0.00628, valid_loss=0.0454]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.0454]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0046, train_loss_epoch=0.0046, valid_loss=0.0454]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00772, train_loss_epoch=0.00772, valid_loss=0.0454]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0083, train_loss_epoch=0.0083, valid_loss=0.0454]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00524, train_loss_epoch=0.00524, valid_loss=0.0454]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00668, train_loss_epoch=0.00668, valid_loss=0.0454]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00731, train_loss_epoch=0.00731, valid_loss=0.0454]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00535, train_loss_epoch=0.00535, valid_loss=0.0454]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00583, train_loss_epoch=0.00583, valid_loss=0.0454]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00694, train_loss_epoch=0.00694, valid_loss=0.0454]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00685, train_loss_epoch=0.00685, valid_loss=0.0454]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0454]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00853, train_loss_epoch=0.00853, valid_loss=0.0454]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00854, train_loss_epoch=0.00854, valid_loss=0.0454]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00791, train_loss_epoch=0.00791, valid_loss=0.0454]\n",
            "Epoch 261: 100%|██████████| 1/1 [00:00<00:00,  6.77it/s, v_num=0, train_loss_step=0.00767, train_loss_epoch=0.00767, valid_loss=0.0454]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00767, train_loss_epoch=0.00767, valid_loss=0.0454]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00686, train_loss_epoch=0.00686, valid_loss=0.0454]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=0.0454]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0454]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0454]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00582, train_loss_epoch=0.00582, valid_loss=0.0454]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00545, valid_loss=0.0454]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00575, train_loss_epoch=0.00575, valid_loss=0.0454]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00664, train_loss_epoch=0.00664, valid_loss=0.0454]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0454]\n",
            "Epoch 271: 100%|██████████| 1/1 [00:00<00:00,  6.72it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0454]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00588, train_loss_epoch=0.00588, valid_loss=0.0454]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00544, train_loss_epoch=0.00544, valid_loss=0.0454]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00726, train_loss_epoch=0.00726, valid_loss=0.0454]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=0.0454]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00503, train_loss_epoch=0.00503, valid_loss=0.0454]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.0454]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0066, train_loss_epoch=0.0066, valid_loss=0.0454]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.0454]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.0454]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00656, train_loss_epoch=0.00656, valid_loss=0.0454]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00666, train_loss_epoch=0.00666, valid_loss=0.0454]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00501, valid_loss=0.0454]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00478, train_loss_epoch=0.00478, valid_loss=0.0454]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00596, train_loss_epoch=0.00596, valid_loss=0.0454]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00568, train_loss_epoch=0.00568, valid_loss=0.0454]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00619, train_loss_epoch=0.00619, valid_loss=0.0454]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00581, train_loss_epoch=0.00581, valid_loss=0.0454]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0454]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00469, train_loss_epoch=0.00469, valid_loss=0.0454]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00509, train_loss_epoch=0.00509, valid_loss=0.0454]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00671, train_loss_epoch=0.00671, valid_loss=0.0454]\n",
            "Epoch 292: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.0454]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.0454]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00546, train_loss_epoch=0.00546, valid_loss=0.0454]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0454]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00604, train_loss_epoch=0.00604, valid_loss=0.0454]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00841, train_loss_epoch=0.00841, valid_loss=0.0454]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00476, train_loss_epoch=0.00476, valid_loss=0.0454]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=0.0454]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=0, train_loss_step=0.00644, train_loss_epoch=0.00646, valid_loss=0.0454]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 81.14it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00644, train_loss_epoch=0.00644, valid_loss=0.040]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00518, train_loss_epoch=0.00518, valid_loss=0.040]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.040]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00622, valid_loss=0.040]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00619, train_loss_epoch=0.00619, valid_loss=0.040]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.040]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00498, train_loss_epoch=0.00498, valid_loss=0.040]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00516, train_loss_epoch=0.00516, valid_loss=0.040]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00545, valid_loss=0.040]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00447, train_loss_epoch=0.00447, valid_loss=0.040]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0045, train_loss_epoch=0.0045, valid_loss=0.040]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00748, train_loss_epoch=0.00748, valid_loss=0.040]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.040]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00488, train_loss_epoch=0.00488, valid_loss=0.040]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00535, train_loss_epoch=0.00535, valid_loss=0.040]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00468, train_loss_epoch=0.00468, valid_loss=0.040]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00787, train_loss_epoch=0.00787, valid_loss=0.040]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00497, train_loss_epoch=0.00497, valid_loss=0.040]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00452, train_loss_epoch=0.00452, valid_loss=0.040]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.040]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00744, train_loss_epoch=0.00744, valid_loss=0.040]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00724, valid_loss=0.040]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00695, train_loss_epoch=0.00695, valid_loss=0.040]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00608, train_loss_epoch=0.00608, valid_loss=0.040]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0043, train_loss_epoch=0.0043, valid_loss=0.040]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00406, train_loss_epoch=0.00406, valid_loss=0.040]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00478, train_loss_epoch=0.00478, valid_loss=0.040]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.040]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00575, train_loss_epoch=0.00575, valid_loss=0.040]\n",
            "Epoch 328: 100%|██████████| 1/1 [00:00<00:00,  6.56it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.040]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.040]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00474, train_loss_epoch=0.00474, valid_loss=0.040]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00703, train_loss_epoch=0.00703, valid_loss=0.040]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00494, train_loss_epoch=0.00494, valid_loss=0.040]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00511, train_loss_epoch=0.00511, valid_loss=0.040]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.040]\n",
            "Epoch 334: 100%|██████████| 1/1 [00:00<00:00,  6.64it/s, v_num=0, train_loss_step=0.00727, train_loss_epoch=0.00727, valid_loss=0.040]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00727, train_loss_epoch=0.00727, valid_loss=0.040]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00689, train_loss_epoch=0.00689, valid_loss=0.040]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00707, train_loss_epoch=0.00707, valid_loss=0.040]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00946, train_loss_epoch=0.00946, valid_loss=0.040]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00384, train_loss_epoch=0.00384, valid_loss=0.040]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0068, train_loss_epoch=0.0068, valid_loss=0.040]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.040]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=0.040]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=0.040]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00373, train_loss_epoch=0.00373, valid_loss=0.040]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00622, valid_loss=0.040]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0068, train_loss_epoch=0.0068, valid_loss=0.040]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00623, train_loss_epoch=0.00623, valid_loss=0.040]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.040]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00533, train_loss_epoch=0.00533, valid_loss=0.040]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00668, train_loss_epoch=0.00668, valid_loss=0.040]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00563, train_loss_epoch=0.00563, valid_loss=0.040]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.040]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00469, train_loss_epoch=0.00469, valid_loss=0.040]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00609, train_loss_epoch=0.00609, valid_loss=0.040]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00806, train_loss_epoch=0.00806, valid_loss=0.040]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00656, train_loss_epoch=0.00656, valid_loss=0.040]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.040]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00752, train_loss_epoch=0.00752, valid_loss=0.040]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.040]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00464, train_loss_epoch=0.00464, valid_loss=0.040]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00669, train_loss_epoch=0.00669, valid_loss=0.040]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=0.040]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00421, train_loss_epoch=0.00421, valid_loss=0.040]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0071, train_loss_epoch=0.0071, valid_loss=0.040]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00733, train_loss_epoch=0.00733, valid_loss=0.040]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00467, train_loss_epoch=0.00467, valid_loss=0.040]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00694, train_loss_epoch=0.00694, valid_loss=0.040]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00498, train_loss_epoch=0.00498, valid_loss=0.040]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.040]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0043, train_loss_epoch=0.0043, valid_loss=0.040]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=0.040]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00511, train_loss_epoch=0.00511, valid_loss=0.040]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.040]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=0.040]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00608, train_loss_epoch=0.00608, valid_loss=0.040]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00433, train_loss_epoch=0.00433, valid_loss=0.040]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00526, train_loss_epoch=0.00526, valid_loss=0.040]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00428, train_loss_epoch=0.00428, valid_loss=0.040]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00564, train_loss_epoch=0.00564, valid_loss=0.040]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00305, train_loss_epoch=0.00305, valid_loss=0.040]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00554, train_loss_epoch=0.00554, valid_loss=0.040]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00351, train_loss_epoch=0.00351, valid_loss=0.040]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00603, train_loss_epoch=0.00603, valid_loss=0.040]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00374, train_loss_epoch=0.00374, valid_loss=0.040]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.040]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0057, train_loss_epoch=0.0057, valid_loss=0.040]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00462, train_loss_epoch=0.00462, valid_loss=0.040]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00572, train_loss_epoch=0.00572, valid_loss=0.040]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00336, train_loss_epoch=0.00336, valid_loss=0.040]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=0.040]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.040]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00451, train_loss_epoch=0.00451, valid_loss=0.040]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=0.040]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.004, train_loss_epoch=0.004, valid_loss=0.040]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=0.040]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.040]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00391, train_loss_epoch=0.00391, valid_loss=0.040]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00268, train_loss_epoch=0.00268, valid_loss=0.040]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.040]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.99it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00248, valid_loss=0.040]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 144.01it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=0.0417]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00294, train_loss_epoch=0.00294, valid_loss=0.0417]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0417]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00183, train_loss_epoch=0.00183, valid_loss=0.0417]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=0.0417]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0417]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0029, train_loss_epoch=0.0029, valid_loss=0.0417]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=0.0417]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0417]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00313, train_loss_epoch=0.00313, valid_loss=0.0417]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00227, valid_loss=0.0417]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00213, train_loss_epoch=0.00213, valid_loss=0.0417]\n",
            "Epoch 411: 100%|██████████| 1/1 [00:00<00:00,  6.66it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=0.0417] \n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=0.0417]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=0.0417]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0417]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0043, train_loss_epoch=0.0043, valid_loss=0.0417]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0417]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00443, train_loss_epoch=0.00443, valid_loss=0.0417]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00309, train_loss_epoch=0.00309, valid_loss=0.0417]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00411, train_loss_epoch=0.00411, valid_loss=0.0417]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00336, train_loss_epoch=0.00336, valid_loss=0.0417]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=0.0417]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.0417]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00394, train_loss_epoch=0.00394, valid_loss=0.0417]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00483, train_loss_epoch=0.00483, valid_loss=0.0417]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00449, train_loss_epoch=0.00449, valid_loss=0.0417]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00424, train_loss_epoch=0.00424, valid_loss=0.0417]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00372, train_loss_epoch=0.00372, valid_loss=0.0417]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00498, train_loss_epoch=0.00498, valid_loss=0.0417]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0417]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=0.0417]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00328, train_loss_epoch=0.00328, valid_loss=0.0417]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00438, valid_loss=0.0417]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00349, train_loss_epoch=0.00349, valid_loss=0.0417]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00562, train_loss_epoch=0.00562, valid_loss=0.0417]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00296, train_loss_epoch=0.00296, valid_loss=0.0417]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00622, valid_loss=0.0417]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00583, train_loss_epoch=0.00583, valid_loss=0.0417]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00541, train_loss_epoch=0.00541, valid_loss=0.0417]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00426, train_loss_epoch=0.00426, valid_loss=0.0417]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00543, train_loss_epoch=0.00543, valid_loss=0.0417]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.0417]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00305, train_loss_epoch=0.00305, valid_loss=0.0417]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00471, valid_loss=0.0417]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=0.0417]\n",
            "Epoch 444: 100%|██████████| 1/1 [00:00<00:00,  6.71it/s, v_num=0, train_loss_step=0.00367, train_loss_epoch=0.00345, valid_loss=0.0417]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00367, train_loss_epoch=0.00367, valid_loss=0.0417]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00346, train_loss_epoch=0.00346, valid_loss=0.0417]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00303, train_loss_epoch=0.00303, valid_loss=0.0417]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00354, train_loss_epoch=0.00354, valid_loss=0.0417]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00281, train_loss_epoch=0.00281, valid_loss=0.0417]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00331, train_loss_epoch=0.00331, valid_loss=0.0417]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00252, train_loss_epoch=0.00252, valid_loss=0.0417]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00262, train_loss_epoch=0.00262, valid_loss=0.0417]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=0.0417]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0417]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=0.0417]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00259, train_loss_epoch=0.00259, valid_loss=0.0417]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=0.0417]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=0.0417]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0417]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=0.0417]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0022, train_loss_epoch=0.0022, valid_loss=0.0417]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0417]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0417]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0417]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=0.0417]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0417]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=0.0417]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00246, train_loss_epoch=0.00246, valid_loss=0.0417]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00194, train_loss_epoch=0.00194, valid_loss=0.0417]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0417]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0417]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00186, train_loss_epoch=0.00186, valid_loss=0.0417]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00171, train_loss_epoch=0.00171, valid_loss=0.0417]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00217, train_loss_epoch=0.00217, valid_loss=0.0417]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00316, train_loss_epoch=0.00316, valid_loss=0.0417]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00299, train_loss_epoch=0.00299, valid_loss=0.0417]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=0.0417]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00256, valid_loss=0.0417]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00256, valid_loss=0.0417]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0417]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0417]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00252, train_loss_epoch=0.00252, valid_loss=0.0417]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0417]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0417]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0417]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0417]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0417]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00297, train_loss_epoch=0.00297, valid_loss=0.0417]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0417]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=0.0417]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00259, train_loss_epoch=0.00259, valid_loss=0.0417]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=0.0417]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0417]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=0.0417]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=0.0417]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00219, train_loss_epoch=0.00219, valid_loss=0.0417]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=0.0417]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00261, train_loss_epoch=0.00261, valid_loss=0.0417]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=0.0417]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=0.0417]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  6.06it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00237, valid_loss=0.0417]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 143.28it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0391]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00315, train_loss_epoch=0.00315, valid_loss=0.0391]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0391]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=0.0391]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0391]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00371, train_loss_epoch=0.00371, valid_loss=0.0391]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=0.0391]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00329, train_loss_epoch=0.00329, valid_loss=0.0391]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00332, train_loss_epoch=0.00332, valid_loss=0.0391]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00186, train_loss_epoch=0.00186, valid_loss=0.0391]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00246, train_loss_epoch=0.00246, valid_loss=0.0391]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00377, train_loss_epoch=0.00377, valid_loss=0.0391]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0391]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:00<00:00,  6.49it/s, v_num=0, train_loss_step=0.00268, train_loss_epoch=0.00268, valid_loss=0.0391]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00268, train_loss_epoch=0.00268, valid_loss=0.0391]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00391, train_loss_epoch=0.00391, valid_loss=0.0391]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00245, train_loss_epoch=0.00245, valid_loss=0.0391]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00326, train_loss_epoch=0.00326, valid_loss=0.0391]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=0.0391]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0391]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00427, train_loss_epoch=0.00427, valid_loss=0.0391]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00307, train_loss_epoch=0.00307, valid_loss=0.0391]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00426, train_loss_epoch=0.00426, valid_loss=0.0391]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=0.0391]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00276, train_loss_epoch=0.00276, valid_loss=0.0391]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00457, train_loss_epoch=0.00457, valid_loss=0.0391]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00349, train_loss_epoch=0.00349, valid_loss=0.0391]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00388, train_loss_epoch=0.00388, valid_loss=0.0391]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00264, train_loss_epoch=0.00264, valid_loss=0.0391]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00381, train_loss_epoch=0.00381, valid_loss=0.0391]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0391]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00452, train_loss_epoch=0.00452, valid_loss=0.0391]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0391]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0037, train_loss_epoch=0.0037, valid_loss=0.0391]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00336, train_loss_epoch=0.00336, valid_loss=0.0391]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00291, train_loss_epoch=0.00291, valid_loss=0.0391]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00347, train_loss_epoch=0.00347, valid_loss=0.0391]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00183, train_loss_epoch=0.00183, valid_loss=0.0391]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0391]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=0.0391]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=0.0391]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00411, train_loss_epoch=0.00411, valid_loss=0.0391]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00257, train_loss_epoch=0.00257, valid_loss=0.0391]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=0.0391]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00335, train_loss_epoch=0.00335, valid_loss=0.0391]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00225, train_loss_epoch=0.00225, valid_loss=0.0391]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00196, train_loss_epoch=0.00196, valid_loss=0.0391]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00388, train_loss_epoch=0.00388, valid_loss=0.0391]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0019, train_loss_epoch=0.0019, valid_loss=0.0391]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=0.0391]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=0.0391]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0391]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00346, train_loss_epoch=0.00346, valid_loss=0.0391]\n",
            "Epoch 551: 100%|██████████| 1/1 [00:00<00:00,  3.93it/s, v_num=0, train_loss_step=0.00346, train_loss_epoch=0.00346, valid_loss=0.0391]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00361, train_loss_epoch=0.00361, valid_loss=0.0391]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.003, train_loss_epoch=0.003, valid_loss=0.0391]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=0.0391]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00283, train_loss_epoch=0.00283, valid_loss=0.0391]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=0.0391]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00365, train_loss_epoch=0.00365, valid_loss=0.0391]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=0.0391]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00351, train_loss_epoch=0.00351, valid_loss=0.0391]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0391]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=0.0391]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00383, train_loss_epoch=0.00383, valid_loss=0.0391]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00208, train_loss_epoch=0.00208, valid_loss=0.0391]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00283, train_loss_epoch=0.00283, valid_loss=0.0391]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00319, train_loss_epoch=0.00319, valid_loss=0.0391]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00192, train_loss_epoch=0.00192, valid_loss=0.0391]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00337, train_loss_epoch=0.00337, valid_loss=0.0391]\n",
            "Epoch 567: 100%|██████████| 1/1 [00:00<00:00,  6.65it/s, v_num=0, train_loss_step=0.00337, train_loss_epoch=0.00337, valid_loss=0.0391]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=0.0391]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00303, train_loss_epoch=0.00303, valid_loss=0.0391]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0391]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=0.0391]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00255, train_loss_epoch=0.00255, valid_loss=0.0391]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00335, train_loss_epoch=0.00335, valid_loss=0.0391]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00171, train_loss_epoch=0.00171, valid_loss=0.0391]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00245, train_loss_epoch=0.00245, valid_loss=0.0391]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=0.0391]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0022, train_loss_epoch=0.0022, valid_loss=0.0391]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00361, train_loss_epoch=0.00361, valid_loss=0.0391]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0391]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00184, train_loss_epoch=0.00184, valid_loss=0.0391]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00426, train_loss_epoch=0.00426, valid_loss=0.0391]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00246, train_loss_epoch=0.00246, valid_loss=0.0391]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0391]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00378, train_loss_epoch=0.00378, valid_loss=0.0391]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0391]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00438, valid_loss=0.0391]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00261, train_loss_epoch=0.00261, valid_loss=0.0391]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0046, train_loss_epoch=0.0046, valid_loss=0.0391]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=0.0391]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00357, train_loss_epoch=0.00357, valid_loss=0.0391]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00329, train_loss_epoch=0.00329, valid_loss=0.0391]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00272, train_loss_epoch=0.00272, valid_loss=0.0391]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00445, train_loss_epoch=0.00445, valid_loss=0.0391]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0391]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00402, train_loss_epoch=0.00402, valid_loss=0.0391]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00211, train_loss_epoch=0.00211, valid_loss=0.0391]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00336, train_loss_epoch=0.00336, valid_loss=0.0391]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00299, train_loss_epoch=0.00299, valid_loss=0.0391]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0022, train_loss_epoch=0.0022, valid_loss=0.0391]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  6.12it/s, v_num=0, train_loss_step=0.00392, train_loss_epoch=0.0022, valid_loss=0.0391]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 119.30it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00392, train_loss_epoch=0.00392, valid_loss=0.0411]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=0.0411]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00391, train_loss_epoch=0.00391, valid_loss=0.0411]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0411]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=0.0411]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00456, train_loss_epoch=0.00456, valid_loss=0.0411]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00263, train_loss_epoch=0.00263, valid_loss=0.0411]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0053, train_loss_epoch=0.0053, valid_loss=0.0411]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00391, train_loss_epoch=0.00391, valid_loss=0.0411]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00569, train_loss_epoch=0.00569, valid_loss=0.0411]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00378, train_loss_epoch=0.00378, valid_loss=0.0411]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=0.0411]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00518, train_loss_epoch=0.00518, valid_loss=0.0411]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0411]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0041, train_loss_epoch=0.0041, valid_loss=0.0411]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00412, train_loss_epoch=0.00412, valid_loss=0.0411]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00349, train_loss_epoch=0.00349, valid_loss=0.0411]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00402, train_loss_epoch=0.00402, valid_loss=0.0411]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0411]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00504, train_loss_epoch=0.00504, valid_loss=0.0411]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0037, train_loss_epoch=0.0037, valid_loss=0.0411]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00437, train_loss_epoch=0.00437, valid_loss=0.0411]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00349, train_loss_epoch=0.00349, valid_loss=0.0411]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00492, train_loss_epoch=0.00492, valid_loss=0.0411]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.004, train_loss_epoch=0.004, valid_loss=0.0411]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00482, train_loss_epoch=0.00482, valid_loss=0.0411]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=0.0411]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00545, train_loss_epoch=0.00545, valid_loss=0.0411]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00469, train_loss_epoch=0.00469, valid_loss=0.0411]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00358, train_loss_epoch=0.00358, valid_loss=0.0411]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00442, train_loss_epoch=0.00442, valid_loss=0.0411]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00425, train_loss_epoch=0.00425, valid_loss=0.0411]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00428, train_loss_epoch=0.00428, valid_loss=0.0411]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00389, train_loss_epoch=0.00389, valid_loss=0.0411]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00429, train_loss_epoch=0.00429, valid_loss=0.0411]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0411]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00366, train_loss_epoch=0.00366, valid_loss=0.0411]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0038, train_loss_epoch=0.0038, valid_loss=0.0411]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00255, train_loss_epoch=0.00255, valid_loss=0.0411]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00387, train_loss_epoch=0.00387, valid_loss=0.0411]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0411]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00314, train_loss_epoch=0.00314, valid_loss=0.0411]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00318, train_loss_epoch=0.00318, valid_loss=0.0411]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00227, valid_loss=0.0411]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=0.0411]\n",
            "Epoch 644: 100%|██████████| 1/1 [00:00<00:00,  4.87it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00324, valid_loss=0.0411]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0411]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0411]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=0.0411]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.003, train_loss_epoch=0.003, valid_loss=0.0411]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00251, train_loss_epoch=0.00251, valid_loss=0.0411]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=0.0411]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0411]\n",
            "Epoch 651: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=0.0411]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=0.0411]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0411]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0411]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=0.0411]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0022, train_loss_epoch=0.0022, valid_loss=0.0411]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00252, train_loss_epoch=0.00252, valid_loss=0.0411]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00225, train_loss_epoch=0.00225, valid_loss=0.0411]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00211, train_loss_epoch=0.00211, valid_loss=0.0411]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0411]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.003, train_loss_epoch=0.003, valid_loss=0.0411]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00209, train_loss_epoch=0.00209, valid_loss=0.0411]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00188, train_loss_epoch=0.00188, valid_loss=0.0411]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0411]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0411]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00321, train_loss_epoch=0.00321, valid_loss=0.0411]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0411]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0411]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0022, train_loss_epoch=0.0022, valid_loss=0.0411]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00202, train_loss_epoch=0.00202, valid_loss=0.0411]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0411]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0411]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0411]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00211, train_loss_epoch=0.00211, valid_loss=0.0411]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=0.0411]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=0.0411]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00177, train_loss_epoch=0.00177, valid_loss=0.0411]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0411]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=0.0411]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=0.0411]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0411]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=0.0411]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00201, train_loss_epoch=0.00201, valid_loss=0.0411]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00359, train_loss_epoch=0.00359, valid_loss=0.0411]\n",
            "Epoch 684: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=0, train_loss_step=0.00359, train_loss_epoch=0.00359, valid_loss=0.0411]\n",
            "Epoch 684: 100%|██████████| 1/1 [00:00<00:00,  4.03it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=0.0411]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=0.0411]\n",
            "Epoch 685: 100%|██████████| 1/1 [00:00<00:00,  4.64it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0411]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0411]\n",
            "Epoch 686: 100%|██████████| 1/1 [00:00<00:00,  4.68it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0411]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00312, train_loss_epoch=0.00312, valid_loss=0.0411]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0411]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0034, train_loss_epoch=0.0034, valid_loss=0.0411]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=0.0411]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=0.0411]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0411]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00293, train_loss_epoch=0.00293, valid_loss=0.0411]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0025, train_loss_epoch=0.0025, valid_loss=0.0411]\n",
            "Epoch 694: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0411]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0411]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00296, train_loss_epoch=0.00296, valid_loss=0.0411]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0411]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=0.0411]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0411]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s, v_num=0, train_loss_step=0.00322, train_loss_epoch=0.00254, valid_loss=0.0411]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.59it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00322, train_loss_epoch=0.00322, valid_loss=0.0402]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00327, train_loss_epoch=0.00327, valid_loss=0.0402]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=0.0402]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0402]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0402]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0402]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00257, train_loss_epoch=0.00257, valid_loss=0.0402]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0402]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0402]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00192, train_loss_epoch=0.00192, valid_loss=0.0402]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0029, train_loss_epoch=0.0029, valid_loss=0.0402]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0402]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00196, train_loss_epoch=0.00196, valid_loss=0.0402]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=0.0402]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00245, train_loss_epoch=0.00245, valid_loss=0.0402]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0402]\n",
            "Epoch 715: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=0.0402]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=0.0402]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00178, train_loss_epoch=0.00178, valid_loss=0.0402]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0402]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=0.0402]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00219, train_loss_epoch=0.00219, valid_loss=0.0402]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0402]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00213, train_loss_epoch=0.00213, valid_loss=0.0402]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0402]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0402]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0402]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00303, train_loss_epoch=0.00303, valid_loss=0.0402]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0034, train_loss_epoch=0.0034, valid_loss=0.0402]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00207, train_loss_epoch=0.00207, valid_loss=0.0402]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=0.0402]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0402]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00293, train_loss_epoch=0.00293, valid_loss=0.0402]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0402]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0402]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00189, train_loss_epoch=0.00189, valid_loss=0.0402]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00194, train_loss_epoch=0.00194, valid_loss=0.0402]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0402]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=0.0402]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=0.0402]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0402]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0402]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=0.0402]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0402]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0402]\n",
            "Epoch 743: 100%|██████████| 1/1 [00:00<00:00,  4.25it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00125, valid_loss=0.0402]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0402]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000966, train_loss_epoch=0.000966, valid_loss=0.0402]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0402]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0402]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000929, train_loss_epoch=0.000929, valid_loss=0.0402]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00099, train_loss_epoch=0.00099, valid_loss=0.0402]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=0.0402]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000925, train_loss_epoch=0.000925, valid_loss=0.0402]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00098, train_loss_epoch=0.00098, valid_loss=0.0402]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0402]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.001, train_loss_epoch=0.001, valid_loss=0.0402]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000971, train_loss_epoch=0.000971, valid_loss=0.0402]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=0.0402]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000981, train_loss_epoch=0.000981, valid_loss=0.0402]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000866, train_loss_epoch=0.000866, valid_loss=0.0402]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000833, train_loss_epoch=0.000833, valid_loss=0.0402]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000972, train_loss_epoch=0.000972, valid_loss=0.0402]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000918, train_loss_epoch=0.000918, valid_loss=0.0402]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000981, train_loss_epoch=0.000981, valid_loss=0.0402]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=0.0402]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0402]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000918, train_loss_epoch=0.000918, valid_loss=0.0402]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=0.0402]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=0.0402]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00104, train_loss_epoch=0.00104, valid_loss=0.0402]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000852, train_loss_epoch=0.000852, valid_loss=0.0402]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0402]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0402]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000961, train_loss_epoch=0.000961, valid_loss=0.0402]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000712, train_loss_epoch=0.000712, valid_loss=0.0402]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000896, train_loss_epoch=0.000896, valid_loss=0.0402]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0402]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=0.0402]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0402]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0402]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0402]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0402]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0402]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0402]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0402]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=0.0402]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0402]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0402]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0402]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0402]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0402]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0402]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0402]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=0.0402]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0402]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000939, train_loss_epoch=0.000939, valid_loss=0.0402]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=0.0402]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000976, train_loss_epoch=0.000976, valid_loss=0.0402]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000857, train_loss_epoch=0.000857, valid_loss=0.0402]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0402]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=0.0402]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.0016, valid_loss=0.0402]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.21it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0389]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0389]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0389]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0389]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0389]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0389]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0389]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0389]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0389]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0389]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0389]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0389]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000962, train_loss_epoch=0.000962, valid_loss=0.0389]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000875, train_loss_epoch=0.000875, valid_loss=0.0389]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00082, train_loss_epoch=0.00082, valid_loss=0.0389]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000919, train_loss_epoch=0.000919, valid_loss=0.0389]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000924, train_loss_epoch=0.000924, valid_loss=0.0389]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000995, train_loss_epoch=0.000995, valid_loss=0.0389]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000872, train_loss_epoch=0.000872, valid_loss=0.0389]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000896, train_loss_epoch=0.000896, valid_loss=0.0389]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000791, train_loss_epoch=0.000791, valid_loss=0.0389]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000828, train_loss_epoch=0.000828, valid_loss=0.0389]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000729, train_loss_epoch=0.000729, valid_loss=0.0389]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000894, train_loss_epoch=0.000894, valid_loss=0.0389]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000988, train_loss_epoch=0.000988, valid_loss=0.0389]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=0.0389]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000877, train_loss_epoch=0.000877, valid_loss=0.0389]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000969, train_loss_epoch=0.000969, valid_loss=0.0389]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00157, train_loss_epoch=0.00157, valid_loss=0.0389]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=0.0389]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000911, train_loss_epoch=0.000911, valid_loss=0.0389]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0389]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00099, train_loss_epoch=0.00099, valid_loss=0.0389]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000979, train_loss_epoch=0.000979, valid_loss=0.0389]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00074, train_loss_epoch=0.00074, valid_loss=0.0389]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000911, train_loss_epoch=0.000911, valid_loss=0.0389]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0389]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0389]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0389]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000933, train_loss_epoch=0.000933, valid_loss=0.0389]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000768, train_loss_epoch=0.000768, valid_loss=0.0389]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=0.0389]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=0.0389]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0389]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0389]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0389]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0389]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=0.0389]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00184, train_loss_epoch=0.00184, valid_loss=0.0389]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00165, train_loss_epoch=0.00165, valid_loss=0.0389]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=0.0389]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=0.0389]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=0.0389]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0389]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0389]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0389]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0389]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0389]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=0.0389]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0389]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0389]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00157, train_loss_epoch=0.00157, valid_loss=0.0389]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000965, train_loss_epoch=0.000965, valid_loss=0.0389]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0389]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0389]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0389]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=0.0389]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0389]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=0.0389]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0389]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000951, train_loss_epoch=0.000951, valid_loss=0.0389]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=0.0389]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0389]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000948, train_loss_epoch=0.000948, valid_loss=0.0389]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0389]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0389]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0389]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0389]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0389]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00104, train_loss_epoch=0.00104, valid_loss=0.0389]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0389]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000993, train_loss_epoch=0.000993, valid_loss=0.0389]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=0.0389]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0389]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0389]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0389]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0389]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0389]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0389]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000849, train_loss_epoch=0.000849, valid_loss=0.0389]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0389]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000918, train_loss_epoch=0.000918, valid_loss=0.0389]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0389]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0389]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0389]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00088, train_loss_epoch=0.00088, valid_loss=0.0389]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000916, train_loss_epoch=0.000916, valid_loss=0.0389]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000875, train_loss_epoch=0.000875, valid_loss=0.0389]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000656, train_loss_epoch=0.000656, valid_loss=0.0389]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000976, train_loss_epoch=0.000976, valid_loss=0.0389]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  4.60it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.000976, valid_loss=0.0389] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 149.35it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0405]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000949, train_loss_epoch=0.000949, valid_loss=0.0405]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000775, train_loss_epoch=0.000775, valid_loss=0.0405]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00085, train_loss_epoch=0.00085, valid_loss=0.0405]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0405]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=0.0405]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=0.0405]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=0.0405]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0405]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0405]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0405]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=0.0405]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=0.0405]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000789, train_loss_epoch=0.000789, valid_loss=0.0405]\n",
            "Epoch 913: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s, v_num=0, train_loss_step=0.000789, train_loss_epoch=0.000789, valid_loss=0.0405]\n",
            "Epoch 913: 100%|██████████| 1/1 [00:00<00:00,  4.51it/s, v_num=0, train_loss_step=0.000843, train_loss_epoch=0.000843, valid_loss=0.0405]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000843, train_loss_epoch=0.000843, valid_loss=0.0405]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=0.0405]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000942, train_loss_epoch=0.000942, valid_loss=0.0405]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=0.0405]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00178, train_loss_epoch=0.00178, valid_loss=0.0405]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0405]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00202, train_loss_epoch=0.00202, valid_loss=0.0405]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=0.0405]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0405]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00189, train_loss_epoch=0.00189, valid_loss=0.0405]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=0.0405]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=0.0405]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=0.0405]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=0.0405]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0405]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0405]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=0.0405]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00173, train_loss_epoch=0.00173, valid_loss=0.0405]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0405]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0405]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0405]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0405]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0405]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0405]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0405]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=0.0405]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0405]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0405]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0405]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=0.0405]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00167, train_loss_epoch=0.00167, valid_loss=0.0405]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0405]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.0017, valid_loss=0.0405]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00178, train_loss_epoch=0.00178, valid_loss=0.0405]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0405]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=0.0405]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00157, train_loss_epoch=0.00157, valid_loss=0.0405]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0405]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=0.0405]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=0.0405]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0405]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=0.0405]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0405]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0405]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0405]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=0.0405]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.001, train_loss_epoch=0.001, valid_loss=0.0405]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0405]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0405]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000812, train_loss_epoch=0.000812, valid_loss=0.0405]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000982, train_loss_epoch=0.000982, valid_loss=0.0405]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=0.0405]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000847, train_loss_epoch=0.000847, valid_loss=0.0405]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=0.0405]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0405]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000951, train_loss_epoch=0.000951, valid_loss=0.0405]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0405]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0405]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=0.0405]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0405]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0405]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000988, train_loss_epoch=0.000988, valid_loss=0.0405]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00189, train_loss_epoch=0.00189, valid_loss=0.0405]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0405]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0405]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00182, train_loss_epoch=0.00182, valid_loss=0.0405]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0405]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00202, train_loss_epoch=0.00202, valid_loss=0.0405]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=0.0405]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=0.0405]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=0.0405]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000977, train_loss_epoch=0.000977, valid_loss=0.0405]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0018, train_loss_epoch=0.0018, valid_loss=0.0405]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000982, train_loss_epoch=0.000982, valid_loss=0.0405]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=0.0405]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00177, train_loss_epoch=0.00177, valid_loss=0.0405]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0405]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00209, train_loss_epoch=0.00209, valid_loss=0.0405]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00157, train_loss_epoch=0.00157, valid_loss=0.0405]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=0.0405]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=0.0405]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0405]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0405]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0405]\n",
            "Epoch 997: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00135, valid_loss=0.0405]\n",
            "Epoch 997: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0405]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0405]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0405]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  3.14it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00162, valid_loss=0.0405]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.36it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0394]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0394]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00256, valid_loss=0.0394]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0394]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0394]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=0.0394]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00307, train_loss_epoch=0.00307, valid_loss=0.0394]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0394]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00295, train_loss_epoch=0.00295, valid_loss=0.0394]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=0.0394]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0394]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=0.0394]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00175, train_loss_epoch=0.00175, valid_loss=0.0394]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00288, train_loss_epoch=0.00288, valid_loss=0.0394]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00188, train_loss_epoch=0.00188, valid_loss=0.0394]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0394]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0394]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0394]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00272, train_loss_epoch=0.00272, valid_loss=0.0394]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00168, train_loss_epoch=0.00168, valid_loss=0.0394]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0394]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0394]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00154, train_loss_epoch=0.00154, valid_loss=0.0394]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=0.0394]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00167, train_loss_epoch=0.00167, valid_loss=0.0394]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00182, train_loss_epoch=0.00182, valid_loss=0.0394]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=0.0394]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=0.0394]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=0.0394]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00219, train_loss_epoch=0.00219, valid_loss=0.0394]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0394]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0394]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=0.0394]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=0.0394]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00167, train_loss_epoch=0.00167, valid_loss=0.0394]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0394]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00207, train_loss_epoch=0.00207, valid_loss=0.0394]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0394]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00181, train_loss_epoch=0.00181, valid_loss=0.0394]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=0.0394]\n",
            "Epoch 1039: 100%|██████████| 1/1 [00:00<00:00,  4.58it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0394]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0394]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0394]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0394]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0394]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0394]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=0.0394]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00201, train_loss_epoch=0.00201, valid_loss=0.0394]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0394]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=0.0394]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0394]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0394]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0394]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00151, train_loss_epoch=0.00151, valid_loss=0.0394]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0394]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0394]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0394]\n",
            "Epoch 1055: 100%|██████████| 1/1 [00:00<00:00,  3.28it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0394]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0394]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0394]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0394]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0394]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0394]\n",
            "Epoch 1060: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00125, valid_loss=0.0394]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0394]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0394]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=0.0394]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0394]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0394]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0394]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0394]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000938, train_loss_epoch=0.000938, valid_loss=0.0394]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00083, train_loss_epoch=0.00083, valid_loss=0.0394]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0394]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000912, train_loss_epoch=0.000912, valid_loss=0.0394]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0394]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000989, train_loss_epoch=0.000989, valid_loss=0.0394]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000865, train_loss_epoch=0.000865, valid_loss=0.0394]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0394]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0394]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000905, train_loss_epoch=0.000905, valid_loss=0.0394]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000929, train_loss_epoch=0.000929, valid_loss=0.0394]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000766, train_loss_epoch=0.000766, valid_loss=0.0394]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0394]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0394]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0394]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000792, train_loss_epoch=0.000792, valid_loss=0.0394]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0394]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00099, train_loss_epoch=0.00099, valid_loss=0.0394]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=0.0394]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=0.0394]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0394]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0394]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000999, train_loss_epoch=0.000999, valid_loss=0.0394]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=0.0394]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0394]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000874, train_loss_epoch=0.000874, valid_loss=0.0394]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=0.0394]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0394]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0394]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00201, train_loss_epoch=0.00201, valid_loss=0.0394]\n",
            "Epoch 1097: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0394]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0394]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 20:36:41,034\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (4, 4, 4), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rEpoch 1098: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0394]\rEpoch 1098: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00145, valid_loss=0.0394]\rEpoch 1098: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0394]\rEpoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0394]        \rEpoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0394]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=47907)\u001b[0m `Trainer.fit` stopped: `max_steps=1100.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0394]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00233, valid_loss=0.0394]\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.46it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=47907)\u001b[0m \r                                                                       \u001b[A\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  4.48it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00233, valid_loss=0.0416]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0416]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0416]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=49023)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 2025-06-15 20:36:55.336130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m E0000 00:00:1750019815.366098   49115 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m E0000 00:00:1750019815.374602   49115 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 2025-06-15 20:36:55.405820: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 3 | blocks       | ModuleList    | 12.8 M | train\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 12.8 M    Trainable params\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 12.8 M    Total params\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 51.269    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.20, train_loss_epoch=26.20]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.34e+5, train_loss_epoch=9.34e+5]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.32e+9, train_loss_epoch=5.32e+9]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+8, train_loss_epoch=1.41e+8]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+9, train_loss_epoch=2.19e+9]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.5e+10, train_loss_epoch=1.5e+10]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+9, train_loss_epoch=1.54e+9]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.31e+8, train_loss_epoch=3.31e+8]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.78e+8, train_loss_epoch=3.78e+8]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.55e+8, train_loss_epoch=6.55e+8]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.72e+9, train_loss_epoch=1.72e+9]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.67e+10, train_loss_epoch=3.67e+10]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.24e+9, train_loss_epoch=2.24e+9]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.88e+9, train_loss_epoch=4.88e+9]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.68e+9, train_loss_epoch=8.68e+9]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.94e+8, train_loss_epoch=4.94e+8]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.66e+8, train_loss_epoch=9.66e+8]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+10, train_loss_epoch=2.28e+10]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.48e+8, train_loss_epoch=7.48e+8]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+8, train_loss_epoch=7.95e+8]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.61e+8, train_loss_epoch=4.61e+8]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+8, train_loss_epoch=2.54e+8]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+8, train_loss_epoch=1.16e+8]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.51e+7, train_loss_epoch=7.51e+7]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+8, train_loss_epoch=1.33e+8]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.24e+8, train_loss_epoch=2.24e+8]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+8, train_loss_epoch=2.45e+8]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.54e+8, train_loss_epoch=3.54e+8]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.81e+7, train_loss_epoch=9.81e+7]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.96e+7, train_loss_epoch=5.96e+7]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+7, train_loss_epoch=1.41e+7]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.75e+5, train_loss_epoch=3.75e+5]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.32e+5, train_loss_epoch=3.32e+5]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.11e+5, train_loss_epoch=6.11e+5]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+5, train_loss_epoch=2.1e+5]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.94e+7, train_loss_epoch=4.94e+7]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.61e+5, train_loss_epoch=4.61e+5]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.61e+5, train_loss_epoch=3.61e+5]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+6, train_loss_epoch=1.01e+6]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.03e+8, train_loss_epoch=7.03e+8]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+8, train_loss_epoch=2.26e+8]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+6, train_loss_epoch=2.31e+6]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.35e+6, train_loss_epoch=4.35e+6]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+7, train_loss_epoch=1.2e+7]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.43e+9, train_loss_epoch=7.43e+9]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.45e+9, train_loss_epoch=1.45e+9]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+8, train_loss_epoch=1.26e+8]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.2e+6, train_loss_epoch=3.2e+6]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.14e+6, train_loss_epoch=2.14e+6]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+6, train_loss_epoch=1.06e+6]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+7, train_loss_epoch=3.11e+7]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+6, train_loss_epoch=1.03e+6]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+6, train_loss_epoch=3.24e+6]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.1e+6, train_loss_epoch=5.1e+6]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.6e+6, train_loss_epoch=4.6e+6]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.31e+6, train_loss_epoch=4.31e+6]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+6, train_loss_epoch=2.7e+6]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e+6, train_loss_epoch=1.83e+6]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+6, train_loss_epoch=1.51e+6]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+6, train_loss_epoch=1.34e+6]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+6, train_loss_epoch=1.01e+6]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.38e+5, train_loss_epoch=3.38e+5]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+5, train_loss_epoch=2.93e+5]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+5, train_loss_epoch=2.34e+5]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+5, train_loss_epoch=2.1e+5]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.92e+5, train_loss_epoch=1.92e+5]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.45e+5, train_loss_epoch=1.45e+5]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+5, train_loss_epoch=1.19e+5]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+5, train_loss_epoch=1.1e+5]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+5, train_loss_epoch=1.13e+5]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+5, train_loss_epoch=1.26e+5]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+5, train_loss_epoch=1.22e+5]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+5, train_loss_epoch=1.11e+5]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.39e+4, train_loss_epoch=9.39e+4]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.35e+4, train_loss_epoch=9.35e+4]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.57e+4, train_loss_epoch=9.57e+4]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.02e+5]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.02e+5]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+5, train_loss_epoch=1.06e+5]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.02e+5]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.42e+4, train_loss_epoch=9.42e+4]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.29e+4, train_loss_epoch=9.29e+4]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.31e+4, train_loss_epoch=9.31e+4]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.47e+4, train_loss_epoch=9.47e+4]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.74e+4, train_loss_epoch=8.74e+4]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.62e+4, train_loss_epoch=8.62e+4]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.23e+4, train_loss_epoch=8.23e+4]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.07e+4, train_loss_epoch=8.07e+4]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.71e+4, train_loss_epoch=7.71e+4]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.11e+4, train_loss_epoch=7.11e+4]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.45e+4, train_loss_epoch=6.45e+4]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.89e+4, train_loss_epoch=6.89e+4]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.89e+4, train_loss_epoch=6.89e+4]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.72e+4, train_loss_epoch=6.72e+4]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.04e+4, train_loss_epoch=6.04e+4]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.94e+4, train_loss_epoch=5.94e+4]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.93e+4, train_loss_epoch=5.93e+4]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.34e+4, train_loss_epoch=5.34e+4]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48248.0, train_loss_epoch=48248.0]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s, v_num=0, train_loss_step=5.12e+4, train_loss_epoch=48248.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.45it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.12e+4, train_loss_epoch=5.12e+4, valid_loss=323.0]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.23e+4, train_loss_epoch=4.23e+4, valid_loss=323.0]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.32e+4, train_loss_epoch=4.32e+4, valid_loss=323.0]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+4, train_loss_epoch=4.15e+4, valid_loss=323.0]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.27e+4, train_loss_epoch=4.27e+4, valid_loss=323.0]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.53e+4, train_loss_epoch=3.53e+4, valid_loss=323.0]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.43e+4, train_loss_epoch=4.43e+4, valid_loss=323.0]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.99e+4, train_loss_epoch=3.99e+4, valid_loss=323.0]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.27e+4, train_loss_epoch=3.27e+4, valid_loss=323.0]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.57e+4, train_loss_epoch=3.57e+4, valid_loss=323.0]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.68e+4, train_loss_epoch=3.68e+4, valid_loss=323.0]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+4, train_loss_epoch=3.76e+4, valid_loss=323.0]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+4, train_loss_epoch=3.85e+4, valid_loss=323.0]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.59e+4, train_loss_epoch=3.59e+4, valid_loss=323.0]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+4, train_loss_epoch=3.39e+4, valid_loss=323.0]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.75e+4, train_loss_epoch=3.75e+4, valid_loss=323.0]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+4, train_loss_epoch=3.17e+4, valid_loss=323.0]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.21e+4, train_loss_epoch=3.21e+4, valid_loss=323.0]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.46e+4, train_loss_epoch=3.46e+4, valid_loss=323.0]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+4, train_loss_epoch=3.25e+4, valid_loss=323.0]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+4, train_loss_epoch=3.45e+4, valid_loss=323.0]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+4, train_loss_epoch=3.05e+4, valid_loss=323.0]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+4, train_loss_epoch=3.08e+4, valid_loss=323.0]        \n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+4, train_loss_epoch=3.08e+4, valid_loss=323.0]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.7e+4, train_loss_epoch=3.7e+4, valid_loss=323.0]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+4, train_loss_epoch=2.9e+4, valid_loss=323.0]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+4, train_loss_epoch=3.07e+4, valid_loss=323.0]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+4, train_loss_epoch=3.16e+4, valid_loss=323.0]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+4, train_loss_epoch=3.17e+4, valid_loss=323.0]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+4, train_loss_epoch=2.89e+4, valid_loss=323.0]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+4, train_loss_epoch=2.31e+4, valid_loss=323.0]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+4, train_loss_epoch=2.69e+4, valid_loss=323.0]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+4, train_loss_epoch=2.74e+4, valid_loss=323.0]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+4, train_loss_epoch=2.58e+4, valid_loss=323.0]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+4, train_loss_epoch=3.01e+4, valid_loss=323.0]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+4, train_loss_epoch=2.35e+4, valid_loss=323.0]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.12e+4, train_loss_epoch=2.12e+4, valid_loss=323.0]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+4, train_loss_epoch=2.6e+4, valid_loss=323.0]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+4, train_loss_epoch=2.72e+4, valid_loss=323.0]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.06e+4, train_loss_epoch=3.06e+4, valid_loss=323.0]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.24e+4, train_loss_epoch=2.24e+4, valid_loss=323.0]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+4, train_loss_epoch=2.34e+4, valid_loss=323.0]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+4, train_loss_epoch=2.53e+4, valid_loss=323.0]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.23e+4, train_loss_epoch=2.23e+4, valid_loss=323.0]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.24e+4, train_loss_epoch=2.24e+4, valid_loss=323.0]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+4, train_loss_epoch=3.08e+4, valid_loss=323.0]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+4, train_loss_epoch=2.69e+4, valid_loss=323.0]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+4, train_loss_epoch=2.81e+4, valid_loss=323.0]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+4, train_loss_epoch=2.35e+4, valid_loss=323.0]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+4, train_loss_epoch=2.5e+4, valid_loss=323.0]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+4, train_loss_epoch=2.45e+4, valid_loss=323.0]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.03e+4, train_loss_epoch=2.03e+4, valid_loss=323.0]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+4, train_loss_epoch=2.77e+4, valid_loss=323.0]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.91e+4, train_loss_epoch=1.91e+4, valid_loss=323.0]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+4, train_loss_epoch=2.35e+4, valid_loss=323.0]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.18e+4, train_loss_epoch=2.18e+4, valid_loss=323.0]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+4, train_loss_epoch=2.66e+4, valid_loss=323.0]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+4, train_loss_epoch=2.7e+4, valid_loss=323.0]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.79e+4, train_loss_epoch=1.79e+4, valid_loss=323.0]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+4, train_loss_epoch=2.36e+4, valid_loss=323.0]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+4, train_loss_epoch=2.29e+4, valid_loss=323.0]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+4, train_loss_epoch=2.44e+4, valid_loss=323.0]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+4, train_loss_epoch=2.49e+4, valid_loss=323.0]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.84e+4, train_loss_epoch=1.84e+4, valid_loss=323.0]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+4, train_loss_epoch=2.33e+4, valid_loss=323.0]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.17e+4, train_loss_epoch=2.17e+4, valid_loss=323.0]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+4, train_loss_epoch=1.96e+4, valid_loss=323.0]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+4, train_loss_epoch=2.27e+4, valid_loss=323.0]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+4, train_loss_epoch=1.86e+4, valid_loss=323.0]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+4, train_loss_epoch=2.41e+4, valid_loss=323.0]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.17e+4, train_loss_epoch=2.17e+4, valid_loss=323.0]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+4, train_loss_epoch=2.19e+4, valid_loss=323.0]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+4, train_loss_epoch=2.25e+4, valid_loss=323.0]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+4, train_loss_epoch=2.6e+4, valid_loss=323.0]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.82e+4, train_loss_epoch=1.82e+4, valid_loss=323.0]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+4, train_loss_epoch=1.61e+4, valid_loss=323.0]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.13e+4, train_loss_epoch=2.13e+4, valid_loss=323.0]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.87e+4, train_loss_epoch=1.87e+4, valid_loss=323.0]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+4, train_loss_epoch=2.28e+4, valid_loss=323.0]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+4, train_loss_epoch=2.26e+4, valid_loss=323.0]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+4, train_loss_epoch=2.32e+4, valid_loss=323.0]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.22e+4, train_loss_epoch=2.22e+4, valid_loss=323.0]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+4, train_loss_epoch=2.1e+4, valid_loss=323.0]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2e+4, train_loss_epoch=2e+4, valid_loss=323.0]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+4, train_loss_epoch=1.59e+4, valid_loss=323.0]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.02e+4, train_loss_epoch=2.02e+4, valid_loss=323.0]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.76e+4, train_loss_epoch=1.76e+4, valid_loss=323.0]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.9e+4, train_loss_epoch=1.9e+4, valid_loss=323.0]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+4, train_loss_epoch=1.51e+4, valid_loss=323.0]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.99e+4, train_loss_epoch=1.99e+4, valid_loss=323.0]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e+4, train_loss_epoch=1.62e+4, valid_loss=323.0]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+4, train_loss_epoch=1.42e+4, valid_loss=323.0]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.63e+4, train_loss_epoch=1.63e+4, valid_loss=323.0]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+4, train_loss_epoch=1.68e+4, valid_loss=323.0]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.75e+4, train_loss_epoch=1.75e+4, valid_loss=323.0]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.52e+4, train_loss_epoch=1.52e+4, valid_loss=323.0]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+4, train_loss_epoch=1.59e+4, valid_loss=323.0]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.67e+4, train_loss_epoch=1.67e+4, valid_loss=323.0]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.72e+4, train_loss_epoch=1.72e+4, valid_loss=323.0]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+4, train_loss_epoch=1.65e+4, valid_loss=323.0]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.46e+4, train_loss_epoch=1.46e+4, valid_loss=323.0]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s, v_num=0, train_loss_step=1.62e+4, train_loss_epoch=1.46e+4, valid_loss=323.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.36it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e+4, train_loss_epoch=1.62e+4, valid_loss=149.0]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.5e+4, train_loss_epoch=1.5e+4, valid_loss=149.0]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+4, train_loss_epoch=1.68e+4, valid_loss=149.0]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+4, train_loss_epoch=1.28e+4, valid_loss=149.0]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+4, train_loss_epoch=1.48e+4, valid_loss=149.0]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+4, train_loss_epoch=1.26e+4, valid_loss=149.0]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.23e+4, train_loss_epoch=1.23e+4, valid_loss=149.0]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+4, train_loss_epoch=1.33e+4, valid_loss=149.0]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+4, train_loss_epoch=1.28e+4, valid_loss=149.0]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.74e+4, train_loss_epoch=1.74e+4, valid_loss=149.0]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.46e+4, train_loss_epoch=1.46e+4, valid_loss=149.0]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+4, train_loss_epoch=1.32e+4, valid_loss=149.0]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+4, train_loss_epoch=1.65e+4, valid_loss=149.0]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.58e+4, train_loss_epoch=1.58e+4, valid_loss=149.0]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+4, train_loss_epoch=1.14e+4, valid_loss=149.0]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+4, train_loss_epoch=1.68e+4, valid_loss=149.0]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+4, train_loss_epoch=1.64e+4, valid_loss=149.0]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.25e+4, train_loss_epoch=1.25e+4, valid_loss=149.0]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+4, train_loss_epoch=1.39e+4, valid_loss=149.0]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+4, train_loss_epoch=1.38e+4, valid_loss=149.0]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+4, train_loss_epoch=1.21e+4, valid_loss=149.0]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+4, train_loss_epoch=1.31e+4, valid_loss=149.0]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+4, train_loss_epoch=1.1e+4, valid_loss=149.0]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+4, train_loss_epoch=1.49e+4, valid_loss=149.0]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+4, train_loss_epoch=1.47e+4, valid_loss=149.0]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+4, train_loss_epoch=1.3e+4, valid_loss=149.0]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+4, train_loss_epoch=1.34e+4, valid_loss=149.0]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+4, train_loss_epoch=1.27e+4, valid_loss=149.0]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+4, train_loss_epoch=1.01e+4, valid_loss=149.0]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+4, train_loss_epoch=1.29e+4, valid_loss=149.0]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.63e+3, train_loss_epoch=9.63e+3, valid_loss=149.0]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.96e+3, train_loss_epoch=9.96e+3, valid_loss=149.0]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.41e+3, train_loss_epoch=8.41e+3, valid_loss=149.0]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+4, train_loss_epoch=1.09e+4, valid_loss=149.0]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+4, train_loss_epoch=1.19e+4, valid_loss=149.0]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.23e+3, train_loss_epoch=9.23e+3, valid_loss=149.0]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+4, train_loss_epoch=1.08e+4, valid_loss=149.0]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+4, train_loss_epoch=1e+4, valid_loss=149.0]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.64e+3, train_loss_epoch=9.64e+3, valid_loss=149.0]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.59e+3, train_loss_epoch=9.59e+3, valid_loss=149.0]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+4, train_loss_epoch=1.02e+4, valid_loss=149.0]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.37e+3, train_loss_epoch=8.37e+3, valid_loss=149.0]\n",
            "Epoch 241: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, v_num=0, train_loss_step=8.08e+3, train_loss_epoch=8.08e+3, valid_loss=149.0]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.08e+3, train_loss_epoch=8.08e+3, valid_loss=149.0]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.89e+3, train_loss_epoch=8.89e+3, valid_loss=149.0]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.02e+3, train_loss_epoch=9.02e+3, valid_loss=149.0]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.6e+3, train_loss_epoch=8.6e+3, valid_loss=149.0]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.19e+3, train_loss_epoch=7.19e+3, valid_loss=149.0]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.22e+3, train_loss_epoch=8.22e+3, valid_loss=149.0]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.98e+3, train_loss_epoch=8.98e+3, valid_loss=149.0]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.51e+3, train_loss_epoch=6.51e+3, valid_loss=149.0]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.22e+3, train_loss_epoch=7.22e+3, valid_loss=149.0]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.61e+3, train_loss_epoch=7.61e+3, valid_loss=149.0]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.5e+3, train_loss_epoch=6.5e+3, valid_loss=149.0]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.4e+3, train_loss_epoch=7.4e+3, valid_loss=149.0]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.48e+3, train_loss_epoch=6.48e+3, valid_loss=149.0]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.58e+3, train_loss_epoch=6.58e+3, valid_loss=149.0]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.1e+3, train_loss_epoch=5.1e+3, valid_loss=149.0]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.18e+3, train_loss_epoch=7.18e+3, valid_loss=149.0]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.53e+3, train_loss_epoch=6.53e+3, valid_loss=149.0]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.18e+3, train_loss_epoch=6.18e+3, valid_loss=149.0]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.91e+3, train_loss_epoch=6.91e+3, valid_loss=149.0]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.87e+3, train_loss_epoch=6.87e+3, valid_loss=149.0]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.67e+3, train_loss_epoch=5.67e+3, valid_loss=149.0]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.43e+3, train_loss_epoch=8.43e+3, valid_loss=149.0]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.98e+3, train_loss_epoch=7.98e+3, valid_loss=149.0]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.94e+3, train_loss_epoch=6.94e+3, valid_loss=149.0]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.11e+3, train_loss_epoch=8.11e+3, valid_loss=149.0]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.91e+3, train_loss_epoch=7.91e+3, valid_loss=149.0]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.14e+3, train_loss_epoch=7.14e+3, valid_loss=149.0]\n",
            "Epoch 268: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s, v_num=0, train_loss_step=7.97e+3, train_loss_epoch=7.97e+3, valid_loss=149.0]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.97e+3, train_loss_epoch=7.97e+3, valid_loss=149.0]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.71e+3, train_loss_epoch=7.71e+3, valid_loss=149.0]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.15e+3, train_loss_epoch=5.15e+3, valid_loss=149.0]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.39e+3, train_loss_epoch=7.39e+3, valid_loss=149.0]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.28e+3, train_loss_epoch=6.28e+3, valid_loss=149.0]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.77e+3, train_loss_epoch=6.77e+3, valid_loss=149.0]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+3, train_loss_epoch=7.95e+3, valid_loss=149.0]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.7e+3, train_loss_epoch=5.7e+3, valid_loss=149.0]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.39e+3, train_loss_epoch=6.39e+3, valid_loss=149.0]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.3e+3, train_loss_epoch=6.3e+3, valid_loss=149.0]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.28e+3, train_loss_epoch=4.28e+3, valid_loss=149.0]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.76e+3, train_loss_epoch=5.76e+3, valid_loss=149.0]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.79e+3, train_loss_epoch=4.79e+3, valid_loss=149.0]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.23e+3, train_loss_epoch=5.23e+3, valid_loss=149.0]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.95e+3, train_loss_epoch=4.95e+3, valid_loss=149.0]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.16e+3, train_loss_epoch=4.16e+3, valid_loss=149.0]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.73e+3, train_loss_epoch=4.73e+3, valid_loss=149.0]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+3, train_loss_epoch=3.62e+3, valid_loss=149.0]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+3, train_loss_epoch=3.85e+3, valid_loss=149.0]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.11e+3, train_loss_epoch=4.11e+3, valid_loss=149.0]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.97e+3, train_loss_epoch=3.97e+3, valid_loss=149.0]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.73e+3, train_loss_epoch=3.73e+3, valid_loss=149.0]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.49e+3, train_loss_epoch=3.49e+3, valid_loss=149.0]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+3, train_loss_epoch=3.16e+3, valid_loss=149.0]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+3, train_loss_epoch=3.07e+3, valid_loss=149.0]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.66e+3, train_loss_epoch=3.66e+3, valid_loss=149.0]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.2e+3, train_loss_epoch=3.2e+3, valid_loss=149.0]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+3, train_loss_epoch=2.3e+3, valid_loss=149.0]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=149.0]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=149.0]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=149.0]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s, v_num=0, train_loss_step=2.31e+3, train_loss_epoch=2.56e+3, valid_loss=149.0]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.15it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+3, train_loss_epoch=2.31e+3, valid_loss=74.50]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=74.50]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=74.50]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+3, train_loss_epoch=2.21e+3, valid_loss=74.50]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+3, train_loss_epoch=2.1e+3, valid_loss=74.50]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.67e+3, train_loss_epoch=1.67e+3, valid_loss=74.50]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+3, train_loss_epoch=1.86e+3, valid_loss=74.50]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+3, train_loss_epoch=1.59e+3, valid_loss=74.50]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.77e+3, train_loss_epoch=1.77e+3, valid_loss=74.50]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.66e+3, train_loss_epoch=1.66e+3, valid_loss=74.50]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.5e+3, train_loss_epoch=1.5e+3, valid_loss=74.50]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+3, train_loss_epoch=1.56e+3, valid_loss=74.50]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.67e+3, train_loss_epoch=1.67e+3, valid_loss=74.50]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+3, train_loss_epoch=1.31e+3, valid_loss=74.50]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+3, train_loss_epoch=1.33e+3, valid_loss=74.50]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+3, train_loss_epoch=1.14e+3, valid_loss=74.50]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+3, train_loss_epoch=1.24e+3, valid_loss=74.50]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+3, train_loss_epoch=1.21e+3, valid_loss=74.50]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+3, train_loss_epoch=1.14e+3, valid_loss=74.50]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+3, train_loss_epoch=1.13e+3, valid_loss=74.50]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=949.0, train_loss_epoch=949.0, valid_loss=74.50]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=913.0, train_loss_epoch=913.0, valid_loss=74.50]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=860.0, train_loss_epoch=860.0, valid_loss=74.50]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=990.0, train_loss_epoch=990.0, valid_loss=74.50]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=960.0, train_loss_epoch=960.0, valid_loss=74.50]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=975.0, train_loss_epoch=975.0, valid_loss=74.50]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=931.0, train_loss_epoch=931.0, valid_loss=74.50]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.18e+3, train_loss_epoch=1.18e+3, valid_loss=74.50]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=765.0, train_loss_epoch=765.0, valid_loss=74.50]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+3, train_loss_epoch=1.05e+3, valid_loss=74.50]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=969.0, train_loss_epoch=969.0, valid_loss=74.50]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=74.50]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+3, train_loss_epoch=1.2e+3, valid_loss=74.50]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=862.0, train_loss_epoch=862.0, valid_loss=74.50]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3, valid_loss=74.50]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+3, train_loss_epoch=1.16e+3, valid_loss=74.50]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=824.0, train_loss_epoch=824.0, valid_loss=74.50]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+3, train_loss_epoch=1.38e+3, valid_loss=74.50]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+3, train_loss_epoch=1.24e+3, valid_loss=74.50]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+3, train_loss_epoch=1.44e+3, valid_loss=74.50]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=950.0, train_loss_epoch=950.0, valid_loss=74.50]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+3, train_loss_epoch=1.32e+3, valid_loss=74.50]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+3, train_loss_epoch=1.33e+3, valid_loss=74.50]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=976.0, train_loss_epoch=976.0, valid_loss=74.50]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+3, train_loss_epoch=1.17e+3, valid_loss=74.50]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+3, train_loss_epoch=1.26e+3, valid_loss=74.50]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=676.0, train_loss_epoch=676.0, valid_loss=74.50]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3, valid_loss=74.50]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=797.0, train_loss_epoch=797.0, valid_loss=74.50]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3, valid_loss=74.50]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=960.0, train_loss_epoch=960.0, valid_loss=74.50]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=755.0, train_loss_epoch=755.0, valid_loss=74.50]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=890.0, train_loss_epoch=890.0, valid_loss=74.50]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=74.50]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=688.0, train_loss_epoch=688.0, valid_loss=74.50]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+3, train_loss_epoch=1.32e+3, valid_loss=74.50]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=895.0, train_loss_epoch=895.0, valid_loss=74.50]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=852.0, train_loss_epoch=852.0, valid_loss=74.50]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=873.0, train_loss_epoch=873.0, valid_loss=74.50]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=874.0, train_loss_epoch=874.0, valid_loss=74.50]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=795.0, train_loss_epoch=795.0, valid_loss=74.50]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=780.0, train_loss_epoch=780.0, valid_loss=74.50]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=900.0, train_loss_epoch=900.0, valid_loss=74.50]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3, valid_loss=74.50]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=966.0, train_loss_epoch=966.0, valid_loss=74.50]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+3, train_loss_epoch=1.24e+3, valid_loss=74.50]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=926.0, train_loss_epoch=926.0, valid_loss=74.50]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+3, train_loss_epoch=1.03e+3, valid_loss=74.50]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+3, train_loss_epoch=1.22e+3, valid_loss=74.50]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=74.50]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+3, train_loss_epoch=1.03e+3, valid_loss=74.50]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+3, train_loss_epoch=1.31e+3, valid_loss=74.50]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+3, train_loss_epoch=1.34e+3, valid_loss=74.50]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=74.50]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=935.0, train_loss_epoch=935.0, valid_loss=74.50]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=805.0, train_loss_epoch=805.0, valid_loss=74.50]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=896.0, train_loss_epoch=896.0, valid_loss=74.50]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=714.0, train_loss_epoch=714.0, valid_loss=74.50]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=753.0, train_loss_epoch=753.0, valid_loss=74.50]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=854.0, train_loss_epoch=854.0, valid_loss=74.50]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=846.0, train_loss_epoch=846.0, valid_loss=74.50]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=718.0, train_loss_epoch=718.0, valid_loss=74.50]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=905.0, train_loss_epoch=905.0, valid_loss=74.50]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=74.50]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=795.0, train_loss_epoch=795.0, valid_loss=74.50]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=829.0, train_loss_epoch=829.0, valid_loss=74.50]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=729.0, train_loss_epoch=729.0, valid_loss=74.50]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=935.0, train_loss_epoch=935.0, valid_loss=74.50]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=730.0, train_loss_epoch=730.0, valid_loss=74.50]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+3, train_loss_epoch=1.13e+3, valid_loss=74.50]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=955.0, train_loss_epoch=955.0, valid_loss=74.50]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+3, train_loss_epoch=1.01e+3, valid_loss=74.50]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=882.0, train_loss_epoch=882.0, valid_loss=74.50]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=723.0, train_loss_epoch=723.0, valid_loss=74.50]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+3, train_loss_epoch=1.09e+3, valid_loss=74.50]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=774.0, train_loss_epoch=774.0, valid_loss=74.50]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+3, train_loss_epoch=1.26e+3, valid_loss=74.50]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=819.0, train_loss_epoch=819.0, valid_loss=74.50]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=669.0, train_loss_epoch=669.0, valid_loss=74.50]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=672.0, train_loss_epoch=672.0, valid_loss=74.50]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s, v_num=0, train_loss_step=743.0, train_loss_epoch=672.0, valid_loss=74.50]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.01it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=743.0, train_loss_epoch=743.0, valid_loss=7.990]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=703.0, train_loss_epoch=703.0, valid_loss=7.990]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=744.0, train_loss_epoch=744.0, valid_loss=7.990]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=744.0, train_loss_epoch=744.0, valid_loss=7.990]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=765.0, train_loss_epoch=765.0, valid_loss=7.990]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=773.0, train_loss_epoch=773.0, valid_loss=7.990]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=879.0, train_loss_epoch=879.0, valid_loss=7.990]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.06e+3, valid_loss=7.990]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=823.0, train_loss_epoch=823.0, valid_loss=7.990]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+3, train_loss_epoch=1.65e+3, valid_loss=7.990]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.5e+3, train_loss_epoch=1.5e+3, valid_loss=7.990]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=992.0, train_loss_epoch=992.0, valid_loss=7.990]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+3, train_loss_epoch=1.29e+3, valid_loss=7.990]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.6e+3, train_loss_epoch=1.6e+3, valid_loss=7.990]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+3, train_loss_epoch=1.29e+3, valid_loss=7.990]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=970.0, train_loss_epoch=970.0, valid_loss=7.990]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+3, train_loss_epoch=1.31e+3, valid_loss=7.990]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+3, train_loss_epoch=1.13e+3, valid_loss=7.990]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=734.0, train_loss_epoch=734.0, valid_loss=7.990]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=7.990]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=941.0, train_loss_epoch=941.0, valid_loss=7.990]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=682.0, train_loss_epoch=682.0, valid_loss=7.990]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3, valid_loss=7.990]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=703.0, train_loss_epoch=703.0, valid_loss=7.990]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=580.0, train_loss_epoch=580.0, valid_loss=7.990]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=707.0, train_loss_epoch=707.0, valid_loss=7.990]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=700.0, train_loss_epoch=700.0, valid_loss=7.990]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=740.0, train_loss_epoch=740.0, valid_loss=7.990]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=822.0, train_loss_epoch=822.0, valid_loss=7.990]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=702.0, train_loss_epoch=702.0, valid_loss=7.990]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+3, train_loss_epoch=1.05e+3, valid_loss=7.990]        \n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+3, train_loss_epoch=1.05e+3, valid_loss=7.990]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=572.0, train_loss_epoch=572.0, valid_loss=7.990]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+3, train_loss_epoch=1.37e+3, valid_loss=7.990]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+3, train_loss_epoch=1.13e+3, valid_loss=7.990]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=989.0, train_loss_epoch=989.0, valid_loss=7.990]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+3, train_loss_epoch=1.08e+3, valid_loss=7.990]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+3, train_loss_epoch=1.35e+3, valid_loss=7.990]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+3, train_loss_epoch=1.05e+3, valid_loss=7.990]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=905.0, train_loss_epoch=905.0, valid_loss=7.990]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=979.0, train_loss_epoch=979.0, valid_loss=7.990]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+3, train_loss_epoch=1.14e+3, valid_loss=7.990]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+3, train_loss_epoch=1.27e+3, valid_loss=7.990]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=819.0, train_loss_epoch=819.0, valid_loss=7.990]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+3, train_loss_epoch=1.51e+3, valid_loss=7.990]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.67e+3, train_loss_epoch=1.67e+3, valid_loss=7.990]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+3, train_loss_epoch=1.09e+3, valid_loss=7.990]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+3, train_loss_epoch=1.42e+3, valid_loss=7.990]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+3, train_loss_epoch=1.01e+3, valid_loss=7.990]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=7.990]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+3, train_loss_epoch=1.56e+3, valid_loss=7.990]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=809.0, train_loss_epoch=809.0, valid_loss=7.990]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+3, train_loss_epoch=1.16e+3, valid_loss=7.990]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=7.990]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=721.0, train_loss_epoch=721.0, valid_loss=7.990]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=7.990]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=938.0, train_loss_epoch=938.0, valid_loss=7.990]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=588.0, train_loss_epoch=588.0, valid_loss=7.990]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=970.0, train_loss_epoch=970.0, valid_loss=7.990]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=691.0, train_loss_epoch=691.0, valid_loss=7.990]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=863.0, train_loss_epoch=863.0, valid_loss=7.990]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=694.0, train_loss_epoch=694.0, valid_loss=7.990]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=813.0, train_loss_epoch=813.0, valid_loss=7.990]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=571.0, train_loss_epoch=571.0, valid_loss=7.990]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=723.0, train_loss_epoch=723.0, valid_loss=7.990]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=493.0, train_loss_epoch=493.0, valid_loss=7.990]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=937.0, train_loss_epoch=937.0, valid_loss=7.990]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=892.0, train_loss_epoch=892.0, valid_loss=7.990]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=604.0, train_loss_epoch=604.0, valid_loss=7.990]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=908.0, train_loss_epoch=908.0, valid_loss=7.990]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=657.0, train_loss_epoch=657.0, valid_loss=7.990]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=872.0, train_loss_epoch=872.0, valid_loss=7.990]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=996.0, train_loss_epoch=996.0, valid_loss=7.990]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+3, train_loss_epoch=1.36e+3, valid_loss=7.990]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=871.0, train_loss_epoch=871.0, valid_loss=7.990]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+3, train_loss_epoch=1.1e+3, valid_loss=7.990]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=915.0, train_loss_epoch=915.0, valid_loss=7.990]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=981.0, train_loss_epoch=981.0, valid_loss=7.990]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+3, train_loss_epoch=1.05e+3, valid_loss=7.990]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=912.0, train_loss_epoch=912.0, valid_loss=7.990]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=753.0, train_loss_epoch=753.0, valid_loss=7.990]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+3, train_loss_epoch=1.03e+3, valid_loss=7.990]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=7.990]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=944.0, train_loss_epoch=944.0, valid_loss=7.990]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=836.0, train_loss_epoch=836.0, valid_loss=7.990]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=722.0, train_loss_epoch=722.0, valid_loss=7.990]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=980.0, train_loss_epoch=980.0, valid_loss=7.990]        \n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=980.0, train_loss_epoch=980.0, valid_loss=7.990]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+3, train_loss_epoch=1.07e+3, valid_loss=7.990]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=944.0, train_loss_epoch=944.0, valid_loss=7.990]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3, valid_loss=7.990]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=7.990]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+3, train_loss_epoch=1e+3, valid_loss=7.990]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+3, train_loss_epoch=1.16e+3, valid_loss=7.990]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=840.0, train_loss_epoch=840.0, valid_loss=7.990]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=7.990]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=788.0, train_loss_epoch=788.0, valid_loss=7.990]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=891.0, train_loss_epoch=891.0, valid_loss=7.990]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=896.0, train_loss_epoch=896.0, valid_loss=7.990]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=837.0, train_loss_epoch=837.0, valid_loss=7.990]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=879.0, train_loss_epoch=879.0, valid_loss=7.990]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=999.0, train_loss_epoch=999.0, valid_loss=7.990]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s, v_num=0, train_loss_step=742.0, train_loss_epoch=999.0, valid_loss=7.990]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.52it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=742.0, train_loss_epoch=742.0, valid_loss=5.730]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=754.0, train_loss_epoch=754.0, valid_loss=5.730]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=804.0, train_loss_epoch=804.0, valid_loss=5.730]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=5.730]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=843.0, train_loss_epoch=843.0, valid_loss=5.730]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+3, train_loss_epoch=1.14e+3, valid_loss=5.730]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=730.0, train_loss_epoch=730.0, valid_loss=5.730]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=838.0, train_loss_epoch=838.0, valid_loss=5.730]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=656.0, train_loss_epoch=656.0, valid_loss=5.730]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=841.0, train_loss_epoch=841.0, valid_loss=5.730]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=578.0, train_loss_epoch=578.0, valid_loss=5.730]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+3, train_loss_epoch=1.04e+3, valid_loss=5.730]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=638.0, train_loss_epoch=638.0, valid_loss=5.730]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=786.0, train_loss_epoch=786.0, valid_loss=5.730]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=638.0, train_loss_epoch=638.0, valid_loss=5.730]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=729.0, train_loss_epoch=729.0, valid_loss=5.730]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=785.0, train_loss_epoch=785.0, valid_loss=5.730]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=770.0, train_loss_epoch=770.0, valid_loss=5.730]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=589.0, train_loss_epoch=589.0, valid_loss=5.730]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=474.0, train_loss_epoch=474.0, valid_loss=5.730]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=470.0, train_loss_epoch=470.0, valid_loss=5.730]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=542.0, train_loss_epoch=542.0, valid_loss=5.730]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=684.0, train_loss_epoch=684.0, valid_loss=5.730]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=705.0, train_loss_epoch=705.0, valid_loss=5.730]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=717.0, train_loss_epoch=717.0, valid_loss=5.730]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=518.0, train_loss_epoch=518.0, valid_loss=5.730]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=619.0, train_loss_epoch=619.0, valid_loss=5.730]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=689.0, train_loss_epoch=689.0, valid_loss=5.730]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=664.0, train_loss_epoch=664.0, valid_loss=5.730]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=785.0, train_loss_epoch=785.0, valid_loss=5.730]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=896.0, train_loss_epoch=896.0, valid_loss=5.730]\n",
            "Epoch 530: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s, v_num=0, train_loss_step=816.0, train_loss_epoch=896.0, valid_loss=5.730]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=816.0, train_loss_epoch=816.0, valid_loss=5.730]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=965.0, train_loss_epoch=965.0, valid_loss=5.730]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=858.0, train_loss_epoch=858.0, valid_loss=5.730]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=865.0, train_loss_epoch=865.0, valid_loss=5.730]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.46e+3, train_loss_epoch=1.46e+3, valid_loss=5.730]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=998.0, train_loss_epoch=998.0, valid_loss=5.730]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=5.730]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=5.730]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=761.0, train_loss_epoch=761.0, valid_loss=5.730]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+3, train_loss_epoch=1.01e+3, valid_loss=5.730]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=784.0, train_loss_epoch=784.0, valid_loss=5.730]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+3, train_loss_epoch=1.34e+3, valid_loss=5.730]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+3, train_loss_epoch=1.54e+3, valid_loss=5.730]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=914.0, train_loss_epoch=914.0, valid_loss=5.730]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.57e+3, train_loss_epoch=1.57e+3, valid_loss=5.730]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+3, train_loss_epoch=1.31e+3, valid_loss=5.730]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=967.0, train_loss_epoch=967.0, valid_loss=5.730]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+3, train_loss_epoch=1.3e+3, valid_loss=5.730]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+3, train_loss_epoch=1e+3, valid_loss=5.730]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+3, train_loss_epoch=1.34e+3, valid_loss=5.730]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=5.730]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.68e+3, valid_loss=5.730]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.53e+3, train_loss_epoch=1.53e+3, valid_loss=5.730]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.6e+3, train_loss_epoch=1.6e+3, valid_loss=5.730]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+3, train_loss_epoch=1.2e+3, valid_loss=5.730]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.08e+3, train_loss_epoch=2.08e+3, valid_loss=5.730]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.78e+3, train_loss_epoch=1.78e+3, valid_loss=5.730]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+3, train_loss_epoch=1.36e+3, valid_loss=5.730]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+3, train_loss_epoch=2.19e+3, valid_loss=5.730]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+3, train_loss_epoch=1.38e+3, valid_loss=5.730]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=5.730]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=5.730]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=964.0, train_loss_epoch=964.0, valid_loss=5.730]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+3, train_loss_epoch=2.21e+3, valid_loss=5.730]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.14e+3, train_loss_epoch=2.14e+3, valid_loss=5.730]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.5e+3, train_loss_epoch=1.5e+3, valid_loss=5.730]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e+3, train_loss_epoch=1.83e+3, valid_loss=5.730]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+3, train_loss_epoch=1.1e+3, valid_loss=5.730]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=5.730]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=5.730]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.02e+3, train_loss_epoch=2.02e+3, valid_loss=5.730]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=5.730]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.25e+3, train_loss_epoch=1.25e+3, valid_loss=5.730]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.94e+3, train_loss_epoch=1.94e+3, valid_loss=5.730]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.43e+3, train_loss_epoch=1.43e+3, valid_loss=5.730]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+3, train_loss_epoch=1.38e+3, valid_loss=5.730]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+3, train_loss_epoch=1.47e+3, valid_loss=5.730]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+3, train_loss_epoch=1.37e+3, valid_loss=5.730]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+3, train_loss_epoch=1.35e+3, valid_loss=5.730]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=5.730]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+3, train_loss_epoch=1.48e+3, valid_loss=5.730]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+3, train_loss_epoch=1.81e+3, valid_loss=5.730]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+3, train_loss_epoch=1.41e+3, valid_loss=5.730]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+3, train_loss_epoch=1.14e+3, valid_loss=5.730]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.38e+3, train_loss_epoch=1.38e+3, valid_loss=5.730]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+3, train_loss_epoch=1.11e+3, valid_loss=5.730]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+3, train_loss_epoch=1.65e+3, valid_loss=5.730]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.55e+3, train_loss_epoch=1.55e+3, valid_loss=5.730]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+3, train_loss_epoch=1.29e+3, valid_loss=5.730]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=5.730]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+3, train_loss_epoch=1.26e+3, valid_loss=5.730]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+3, train_loss_epoch=1.28e+3, valid_loss=5.730]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+3, train_loss_epoch=1.29e+3, valid_loss=5.730]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.55e+3, train_loss_epoch=1.55e+3, valid_loss=5.730]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=5.730]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+3, train_loss_epoch=1.29e+3, valid_loss=5.730]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+3, train_loss_epoch=1.68e+3, valid_loss=5.730]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=864.0, train_loss_epoch=864.0, valid_loss=5.730]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+3, train_loss_epoch=1.12e+3, valid_loss=5.730]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.12e+3, valid_loss=5.730]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.93it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=5.730]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=650.0, train_loss_epoch=650.0, valid_loss=5.730]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=761.0, train_loss_epoch=761.0, valid_loss=5.730]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=772.0, train_loss_epoch=772.0, valid_loss=5.730]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=574.0, train_loss_epoch=574.0, valid_loss=5.730]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=601.0, train_loss_epoch=601.0, valid_loss=5.730]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=720.0, train_loss_epoch=720.0, valid_loss=5.730]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=528.0, train_loss_epoch=528.0, valid_loss=5.730]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=540.0, train_loss_epoch=540.0, valid_loss=5.730]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=617.0, train_loss_epoch=617.0, valid_loss=5.730]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=345.0, train_loss_epoch=345.0, valid_loss=5.730]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=457.0, train_loss_epoch=457.0, valid_loss=5.730]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=627.0, train_loss_epoch=627.0, valid_loss=5.730]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=444.0, train_loss_epoch=444.0, valid_loss=5.730]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=595.0, train_loss_epoch=595.0, valid_loss=5.730]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=676.0, train_loss_epoch=676.0, valid_loss=5.730]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=555.0, train_loss_epoch=555.0, valid_loss=5.730]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=600.0, train_loss_epoch=600.0, valid_loss=5.730]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=559.0, train_loss_epoch=559.0, valid_loss=5.730]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=490.0, train_loss_epoch=490.0, valid_loss=5.730]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=500.0, train_loss_epoch=500.0, valid_loss=5.730]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=431.0, train_loss_epoch=431.0, valid_loss=5.730]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=409.0, train_loss_epoch=409.0, valid_loss=5.730]\n",
            "Epoch 622: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s, v_num=0, train_loss_step=346.0, train_loss_epoch=409.0, valid_loss=5.730]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=346.0, train_loss_epoch=346.0, valid_loss=5.730]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=329.0, train_loss_epoch=329.0, valid_loss=5.730]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=249.0, train_loss_epoch=249.0, valid_loss=5.730]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=486.0, train_loss_epoch=486.0, valid_loss=5.730]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=345.0, train_loss_epoch=345.0, valid_loss=5.730]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=391.0, train_loss_epoch=391.0, valid_loss=5.730]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=596.0, train_loss_epoch=596.0, valid_loss=5.730]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=441.0, train_loss_epoch=441.0, valid_loss=5.730]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=588.0, train_loss_epoch=588.0, valid_loss=5.730]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=392.0, train_loss_epoch=392.0, valid_loss=5.730]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=358.0, train_loss_epoch=358.0, valid_loss=5.730]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=487.0, train_loss_epoch=487.0, valid_loss=5.730]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=354.0, train_loss_epoch=354.0, valid_loss=5.730]\n",
            "Epoch 635: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s, v_num=0, train_loss_step=402.0, train_loss_epoch=354.0, valid_loss=5.730]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=402.0, train_loss_epoch=402.0, valid_loss=5.730]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=432.0, train_loss_epoch=432.0, valid_loss=5.730]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=672.0, train_loss_epoch=672.0, valid_loss=5.730]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=508.0, train_loss_epoch=508.0, valid_loss=5.730]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=464.0, train_loss_epoch=464.0, valid_loss=5.730]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=526.0, train_loss_epoch=526.0, valid_loss=5.730]\n",
            "Epoch 641: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, v_num=0, train_loss_step=452.0, train_loss_epoch=526.0, valid_loss=5.730]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=452.0, train_loss_epoch=452.0, valid_loss=5.730]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=582.0, train_loss_epoch=582.0, valid_loss=5.730]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=410.0, train_loss_epoch=410.0, valid_loss=5.730]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=601.0, train_loss_epoch=601.0, valid_loss=5.730]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=507.0, train_loss_epoch=507.0, valid_loss=5.730]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=528.0, train_loss_epoch=528.0, valid_loss=5.730]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=306.0, train_loss_epoch=306.0, valid_loss=5.730]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=530.0, train_loss_epoch=530.0, valid_loss=5.730]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=523.0, train_loss_epoch=523.0, valid_loss=5.730]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=527.0, train_loss_epoch=527.0, valid_loss=5.730]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=669.0, train_loss_epoch=669.0, valid_loss=5.730]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=854.0, train_loss_epoch=854.0, valid_loss=5.730]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=988.0, train_loss_epoch=988.0, valid_loss=5.730]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=593.0, train_loss_epoch=593.0, valid_loss=5.730]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=995.0, train_loss_epoch=995.0, valid_loss=5.730]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=5.730]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=944.0, train_loss_epoch=944.0, valid_loss=5.730]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=853.0, train_loss_epoch=853.0, valid_loss=5.730]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=817.0, train_loss_epoch=817.0, valid_loss=5.730]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=852.0, train_loss_epoch=852.0, valid_loss=5.730]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=672.0, train_loss_epoch=672.0, valid_loss=5.730]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=765.0, train_loss_epoch=765.0, valid_loss=5.730]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=538.0, train_loss_epoch=538.0, valid_loss=5.730]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=683.0, train_loss_epoch=683.0, valid_loss=5.730]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=428.0, train_loss_epoch=428.0, valid_loss=5.730]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=681.0, train_loss_epoch=681.0, valid_loss=5.730]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=668.0, train_loss_epoch=668.0, valid_loss=5.730]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=372.0, train_loss_epoch=372.0, valid_loss=5.730]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=595.0, train_loss_epoch=595.0, valid_loss=5.730]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=538.0, train_loss_epoch=538.0, valid_loss=5.730]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=480.0, train_loss_epoch=480.0, valid_loss=5.730]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=432.0, train_loss_epoch=432.0, valid_loss=5.730]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=434.0, train_loss_epoch=434.0, valid_loss=5.730]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=398.0, train_loss_epoch=398.0, valid_loss=5.730]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=371.0, train_loss_epoch=371.0, valid_loss=5.730]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=407.0, train_loss_epoch=407.0, valid_loss=5.730]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=397.0, train_loss_epoch=397.0, valid_loss=5.730]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=456.0, train_loss_epoch=456.0, valid_loss=5.730]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=317.0, train_loss_epoch=317.0, valid_loss=5.730]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=334.0, train_loss_epoch=334.0, valid_loss=5.730]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=364.0, train_loss_epoch=364.0, valid_loss=5.730]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=394.0, train_loss_epoch=394.0, valid_loss=5.730]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=300.0, train_loss_epoch=300.0, valid_loss=5.730]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=357.0, train_loss_epoch=357.0, valid_loss=5.730]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=337.0, train_loss_epoch=337.0, valid_loss=5.730]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=395.0, train_loss_epoch=395.0, valid_loss=5.730]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=430.0, train_loss_epoch=430.0, valid_loss=5.730]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=375.0, train_loss_epoch=375.0, valid_loss=5.730]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=470.0, train_loss_epoch=470.0, valid_loss=5.730]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=348.0, train_loss_epoch=348.0, valid_loss=5.730]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=349.0, train_loss_epoch=349.0, valid_loss=5.730]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=296.0, train_loss_epoch=296.0, valid_loss=5.730]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=477.0, train_loss_epoch=477.0, valid_loss=5.730]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=472.0, train_loss_epoch=472.0, valid_loss=5.730]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=480.0, train_loss_epoch=480.0, valid_loss=5.730]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=371.0, train_loss_epoch=371.0, valid_loss=5.730]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=374.0, train_loss_epoch=374.0, valid_loss=5.730]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=419.0, train_loss_epoch=419.0, valid_loss=5.730]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=424.0, train_loss_epoch=419.0, valid_loss=5.730]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.63it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=424.0, train_loss_epoch=424.0, valid_loss=5.660]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=569.0, train_loss_epoch=569.0, valid_loss=5.660]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=385.0, train_loss_epoch=385.0, valid_loss=5.660]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=342.0, train_loss_epoch=342.0, valid_loss=5.660]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=742.0, train_loss_epoch=742.0, valid_loss=5.660]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=366.0, train_loss_epoch=366.0, valid_loss=5.660]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=669.0, train_loss_epoch=669.0, valid_loss=5.660]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=649.0, train_loss_epoch=649.0, valid_loss=5.660]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=393.0, train_loss_epoch=393.0, valid_loss=5.660]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=852.0, train_loss_epoch=852.0, valid_loss=5.660]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=592.0, train_loss_epoch=592.0, valid_loss=5.660]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=885.0, train_loss_epoch=885.0, valid_loss=5.660]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=871.0, train_loss_epoch=871.0, valid_loss=5.660]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=682.0, train_loss_epoch=682.0, valid_loss=5.660]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+3, train_loss_epoch=1.06e+3, valid_loss=5.660]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=627.0, train_loss_epoch=627.0, valid_loss=5.660]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=775.0, train_loss_epoch=775.0, valid_loss=5.660]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=406.0, train_loss_epoch=406.0, valid_loss=5.660]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=834.0, train_loss_epoch=834.0, valid_loss=5.660]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=779.0, train_loss_epoch=779.0, valid_loss=5.660]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=742.0, train_loss_epoch=742.0, valid_loss=5.660]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=656.0, train_loss_epoch=656.0, valid_loss=5.660]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=562.0, train_loss_epoch=562.0, valid_loss=5.660]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=546.0, train_loss_epoch=546.0, valid_loss=5.660]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=523.0, train_loss_epoch=523.0, valid_loss=5.660]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=569.0, train_loss_epoch=569.0, valid_loss=5.660]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=677.0, train_loss_epoch=677.0, valid_loss=5.660]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=652.0, train_loss_epoch=652.0, valid_loss=5.660]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=502.0, train_loss_epoch=502.0, valid_loss=5.660]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=422.0, train_loss_epoch=422.0, valid_loss=5.660]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=641.0, train_loss_epoch=641.0, valid_loss=5.660]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=516.0, train_loss_epoch=516.0, valid_loss=5.660]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=425.0, train_loss_epoch=425.0, valid_loss=5.660]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=425.0, train_loss_epoch=425.0, valid_loss=5.660]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=330.0, train_loss_epoch=330.0, valid_loss=5.660]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=393.0, train_loss_epoch=393.0, valid_loss=5.660]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=343.0, train_loss_epoch=343.0, valid_loss=5.660]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=384.0, train_loss_epoch=384.0, valid_loss=5.660]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=536.0, train_loss_epoch=536.0, valid_loss=5.660]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=787.0, train_loss_epoch=787.0, valid_loss=5.660]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=589.0, train_loss_epoch=589.0, valid_loss=5.660]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=597.0, train_loss_epoch=597.0, valid_loss=5.660]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=483.0, train_loss_epoch=483.0, valid_loss=5.660]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=452.0, train_loss_epoch=452.0, valid_loss=5.660]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=555.0, train_loss_epoch=555.0, valid_loss=5.660]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=391.0, train_loss_epoch=391.0, valid_loss=5.660]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=554.0, train_loss_epoch=554.0, valid_loss=5.660]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=382.0, train_loss_epoch=382.0, valid_loss=5.660]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=487.0, train_loss_epoch=487.0, valid_loss=5.660]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=392.0, train_loss_epoch=392.0, valid_loss=5.660]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=537.0, train_loss_epoch=537.0, valid_loss=5.660]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=333.0, train_loss_epoch=333.0, valid_loss=5.660]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=659.0, train_loss_epoch=659.0, valid_loss=5.660]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=674.0, train_loss_epoch=674.0, valid_loss=5.660]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=324.0, train_loss_epoch=324.0, valid_loss=5.660]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=618.0, train_loss_epoch=618.0, valid_loss=5.660]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=526.0, train_loss_epoch=526.0, valid_loss=5.660]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=464.0, train_loss_epoch=464.0, valid_loss=5.660]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=481.0, train_loss_epoch=481.0, valid_loss=5.660]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=554.0, train_loss_epoch=554.0, valid_loss=5.660]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=363.0, train_loss_epoch=363.0, valid_loss=5.660]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=492.0, train_loss_epoch=492.0, valid_loss=5.660]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=423.0, train_loss_epoch=423.0, valid_loss=5.660]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=644.0, train_loss_epoch=644.0, valid_loss=5.660]\n",
            "Epoch 763: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=423.0, train_loss_epoch=423.0, valid_loss=5.660]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=423.0, train_loss_epoch=423.0, valid_loss=5.660]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=760.0, train_loss_epoch=760.0, valid_loss=5.660]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=475.0, train_loss_epoch=475.0, valid_loss=5.660]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=628.0, train_loss_epoch=628.0, valid_loss=5.660]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=405.0, train_loss_epoch=405.0, valid_loss=5.660]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=569.0, train_loss_epoch=569.0, valid_loss=5.660]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=351.0, train_loss_epoch=351.0, valid_loss=5.660]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=371.0, train_loss_epoch=371.0, valid_loss=5.660]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=705.0, train_loss_epoch=705.0, valid_loss=5.660]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=516.0, train_loss_epoch=516.0, valid_loss=5.660]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=780.0, train_loss_epoch=780.0, valid_loss=5.660]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=531.0, train_loss_epoch=531.0, valid_loss=5.660]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=5.660]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+3, train_loss_epoch=1.13e+3, valid_loss=5.660]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=717.0, train_loss_epoch=717.0, valid_loss=5.660]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+3, train_loss_epoch=1.21e+3, valid_loss=5.660]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+3, train_loss_epoch=1.15e+3, valid_loss=5.660]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=721.0, train_loss_epoch=721.0, valid_loss=5.660]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=923.0, train_loss_epoch=923.0, valid_loss=5.660]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=642.0, train_loss_epoch=642.0, valid_loss=5.660]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=968.0, train_loss_epoch=968.0, valid_loss=5.660]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=619.0, train_loss_epoch=619.0, valid_loss=5.660]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+3, train_loss_epoch=1.01e+3, valid_loss=5.660]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=977.0, train_loss_epoch=977.0, valid_loss=5.660]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=510.0, train_loss_epoch=510.0, valid_loss=5.660]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=859.0, train_loss_epoch=859.0, valid_loss=5.660]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+3, train_loss_epoch=1.02e+3, valid_loss=5.660]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+3, train_loss_epoch=1.08e+3, valid_loss=5.660]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=864.0, train_loss_epoch=864.0, valid_loss=5.660]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=881.0, train_loss_epoch=881.0, valid_loss=5.660]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=938.0, train_loss_epoch=938.0, valid_loss=5.660]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=967.0, train_loss_epoch=967.0, valid_loss=5.660]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=662.0, train_loss_epoch=662.0, valid_loss=5.660]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=775.0, train_loss_epoch=775.0, valid_loss=5.660]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=473.0, train_loss_epoch=473.0, valid_loss=5.660]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=653.0, train_loss_epoch=653.0, valid_loss=5.660]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, v_num=0, train_loss_step=535.0, train_loss_epoch=653.0, valid_loss=5.660]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.45it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=535.0, train_loss_epoch=535.0, valid_loss=5.740]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=564.0, train_loss_epoch=564.0, valid_loss=5.740]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=322.0, train_loss_epoch=322.0, valid_loss=5.740]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=574.0, train_loss_epoch=574.0, valid_loss=5.740]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=350.0, train_loss_epoch=350.0, valid_loss=5.740]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=603.0, train_loss_epoch=603.0, valid_loss=5.740]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=545.0, train_loss_epoch=545.0, valid_loss=5.740]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=619.0, train_loss_epoch=619.0, valid_loss=5.740]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=464.0, train_loss_epoch=464.0, valid_loss=5.740]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=542.0, train_loss_epoch=542.0, valid_loss=5.740]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=659.0, train_loss_epoch=659.0, valid_loss=5.740]\n",
            "Epoch 810: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s, v_num=0, train_loss_step=502.0, train_loss_epoch=502.0, valid_loss=5.740]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=502.0, train_loss_epoch=502.0, valid_loss=5.740]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=773.0, train_loss_epoch=773.0, valid_loss=5.740]\n",
            "Epoch 812: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s, v_num=0, train_loss_step=426.0, train_loss_epoch=426.0, valid_loss=5.740]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=426.0, train_loss_epoch=426.0, valid_loss=5.740]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=795.0, train_loss_epoch=795.0, valid_loss=5.740]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=581.0, train_loss_epoch=581.0, valid_loss=5.740]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=647.0, train_loss_epoch=647.0, valid_loss=5.740]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=546.0, train_loss_epoch=546.0, valid_loss=5.740]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=644.0, train_loss_epoch=644.0, valid_loss=5.740]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=334.0, train_loss_epoch=334.0, valid_loss=5.740]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=848.0, train_loss_epoch=848.0, valid_loss=5.740]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=460.0, train_loss_epoch=460.0, valid_loss=5.740]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=562.0, train_loss_epoch=562.0, valid_loss=5.740]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=712.0, train_loss_epoch=712.0, valid_loss=5.740]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=445.0, train_loss_epoch=445.0, valid_loss=5.740]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=754.0, train_loss_epoch=754.0, valid_loss=5.740]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=623.0, train_loss_epoch=623.0, valid_loss=5.740]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=465.0, train_loss_epoch=465.0, valid_loss=5.740]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=693.0, train_loss_epoch=693.0, valid_loss=5.740]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=464.0, train_loss_epoch=464.0, valid_loss=5.740]\n",
            "Epoch 829: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s, v_num=0, train_loss_step=508.0, train_loss_epoch=508.0, valid_loss=5.740]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=508.0, train_loss_epoch=508.0, valid_loss=5.740]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=568.0, train_loss_epoch=568.0, valid_loss=5.740]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=582.0, train_loss_epoch=582.0, valid_loss=5.740]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=394.0, train_loss_epoch=394.0, valid_loss=5.740]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=629.0, train_loss_epoch=629.0, valid_loss=5.740]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=325.0, train_loss_epoch=325.0, valid_loss=5.740]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=633.0, train_loss_epoch=633.0, valid_loss=5.740]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=508.0, train_loss_epoch=508.0, valid_loss=5.740]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=569.0, train_loss_epoch=569.0, valid_loss=5.740]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=500.0, train_loss_epoch=500.0, valid_loss=5.740]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=435.0, train_loss_epoch=435.0, valid_loss=5.740]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=560.0, train_loss_epoch=560.0, valid_loss=5.740]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=470.0, train_loss_epoch=470.0, valid_loss=5.740]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=579.0, train_loss_epoch=579.0, valid_loss=5.740]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=619.0, train_loss_epoch=619.0, valid_loss=5.740]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=610.0, train_loss_epoch=610.0, valid_loss=5.740]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=565.0, train_loss_epoch=565.0, valid_loss=5.740]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=772.0, train_loss_epoch=772.0, valid_loss=5.740]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=395.0, train_loss_epoch=395.0, valid_loss=5.740]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=514.0, train_loss_epoch=514.0, valid_loss=5.740]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=397.0, train_loss_epoch=397.0, valid_loss=5.740]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=535.0, train_loss_epoch=535.0, valid_loss=5.740]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=467.0, train_loss_epoch=467.0, valid_loss=5.740]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=347.0, train_loss_epoch=347.0, valid_loss=5.740]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=518.0, train_loss_epoch=518.0, valid_loss=5.740]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=299.0, train_loss_epoch=299.0, valid_loss=5.740]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=599.0, train_loss_epoch=599.0, valid_loss=5.740]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=430.0, train_loss_epoch=430.0, valid_loss=5.740]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=704.0, train_loss_epoch=704.0, valid_loss=5.740]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=575.0, train_loss_epoch=575.0, valid_loss=5.740]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=540.0, train_loss_epoch=540.0, valid_loss=5.740]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=633.0, train_loss_epoch=633.0, valid_loss=5.740]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=492.0, train_loss_epoch=492.0, valid_loss=5.740]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=560.0, train_loss_epoch=560.0, valid_loss=5.740]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=425.0, train_loss_epoch=425.0, valid_loss=5.740]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=393.0, train_loss_epoch=393.0, valid_loss=5.740]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=487.0, train_loss_epoch=487.0, valid_loss=5.740]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=517.0, train_loss_epoch=517.0, valid_loss=5.740]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=539.0, train_loss_epoch=539.0, valid_loss=5.740]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=571.0, train_loss_epoch=571.0, valid_loss=5.740]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=468.0, train_loss_epoch=468.0, valid_loss=5.740]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=494.0, train_loss_epoch=494.0, valid_loss=5.740]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=323.0, train_loss_epoch=323.0, valid_loss=5.740]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=507.0, train_loss_epoch=507.0, valid_loss=5.740]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=555.0, train_loss_epoch=555.0, valid_loss=5.740]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=356.0, train_loss_epoch=356.0, valid_loss=5.740]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=613.0, train_loss_epoch=613.0, valid_loss=5.740]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=393.0, train_loss_epoch=393.0, valid_loss=5.740]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=404.0, train_loss_epoch=404.0, valid_loss=5.740]\n",
            "Epoch 878: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s, v_num=0, train_loss_step=610.0, train_loss_epoch=404.0, valid_loss=5.740]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=610.0, train_loss_epoch=610.0, valid_loss=5.740]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=394.0, train_loss_epoch=394.0, valid_loss=5.740]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=638.0, train_loss_epoch=638.0, valid_loss=5.740]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=520.0, train_loss_epoch=520.0, valid_loss=5.740]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=516.0, train_loss_epoch=516.0, valid_loss=5.740]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=721.0, train_loss_epoch=721.0, valid_loss=5.740]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=680.0, train_loss_epoch=680.0, valid_loss=5.740]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=617.0, train_loss_epoch=617.0, valid_loss=5.740]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=894.0, train_loss_epoch=894.0, valid_loss=5.740]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=469.0, train_loss_epoch=469.0, valid_loss=5.740]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=793.0, train_loss_epoch=793.0, valid_loss=5.740]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=865.0, train_loss_epoch=865.0, valid_loss=5.740]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=809.0, train_loss_epoch=809.0, valid_loss=5.740]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.23e+3, train_loss_epoch=1.23e+3, valid_loss=5.740]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=560.0, train_loss_epoch=560.0, valid_loss=5.740]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+3, train_loss_epoch=1.01e+3, valid_loss=5.740]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=488.0, train_loss_epoch=488.0, valid_loss=5.740]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=858.0, train_loss_epoch=858.0, valid_loss=5.740]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=532.0, train_loss_epoch=532.0, valid_loss=5.740]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=908.0, train_loss_epoch=908.0, valid_loss=5.740]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=687.0, train_loss_epoch=687.0, valid_loss=5.740]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 20:44:07,961\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (60, 8, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m `Trainer.fit` stopped: `max_steps=900.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=0, train_loss_step=687.0, train_loss_epoch=687.0, valid_loss=5.740]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=0, train_loss_step=732.0, train_loss_epoch=687.0, valid_loss=5.740]\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.25it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=49023)\u001b[0m \r                                                                      \u001b[A\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=0, train_loss_step=732.0, train_loss_epoch=687.0, valid_loss=5.850]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=0, train_loss_step=732.0, train_loss_epoch=732.0, valid_loss=5.850]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=0, train_loss_step=732.0, train_loss_epoch=732.0, valid_loss=5.850]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=50932)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 2025-06-15 20:44:22.308596: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m E0000 00:00:1750020262.344457   51030 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m E0000 00:00:1750020262.355427   51030 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 2025-06-15 20:44:22.394080: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 3 | blocks       | ModuleList    | 5.2 M  | train\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 5.2 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 5.2 M     Total params\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 20.612    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.330, train_loss_epoch=0.330]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.86e+11, train_loss_epoch=9.86e+11]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.85e+14, train_loss_epoch=1.85e+14]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.19e+9, train_loss_epoch=5.19e+9]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+10, train_loss_epoch=3.6e+10]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.52e+14, train_loss_epoch=1.52e+14]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.23e+9, train_loss_epoch=4.23e+9]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.55e+11, train_loss_epoch=1.55e+11]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.09e+12, train_loss_epoch=9.09e+12]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+13, train_loss_epoch=1.06e+13]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+12, train_loss_epoch=2.51e+12]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+12, train_loss_epoch=1.01e+12]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+14, train_loss_epoch=2.19e+14]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.41e+11, train_loss_epoch=9.41e+11]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.88e+15, train_loss_epoch=1.88e+15]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+10, train_loss_epoch=2.93e+10]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.09e+12, train_loss_epoch=2.09e+12]\n",
            "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=0, train_loss_step=6.92e+11, train_loss_epoch=6.92e+11]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.92e+11, train_loss_epoch=6.92e+11]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9e+11, train_loss_epoch=9e+11]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.8e+11, train_loss_epoch=3.8e+11]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.76e+12, train_loss_epoch=5.76e+12]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+13, train_loss_epoch=2.57e+13]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.11e+15, train_loss_epoch=5.11e+15]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+14, train_loss_epoch=2.16e+14]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+14, train_loss_epoch=1.61e+14]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+13, train_loss_epoch=2.98e+13]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+13, train_loss_epoch=2.57e+13]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.36e+13, train_loss_epoch=4.36e+13]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+13, train_loss_epoch=2.95e+13]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+13, train_loss_epoch=1.03e+13]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.2e+11, train_loss_epoch=8.2e+11]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.23e+12, train_loss_epoch=5.23e+12]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+12, train_loss_epoch=2.85e+12]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.47e+11, train_loss_epoch=7.47e+11]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.84e+14, train_loss_epoch=6.84e+14]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.52e+13, train_loss_epoch=3.52e+13]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.61e+13, train_loss_epoch=1.61e+13]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+14, train_loss_epoch=1.17e+14]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.24e+12, train_loss_epoch=6.24e+12]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.18e+12, train_loss_epoch=7.18e+12]\n",
            "Epoch 40: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=0, train_loss_step=7.18e+12, train_loss_epoch=7.18e+12]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+12, train_loss_epoch=2.68e+12]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.71e+9, train_loss_epoch=8.71e+9]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.99e+10, train_loss_epoch=4.99e+10]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+11, train_loss_epoch=1.27e+11]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+11, train_loss_epoch=1.19e+11]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.75e+10, train_loss_epoch=6.75e+10]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+10, train_loss_epoch=2.91e+10]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+12, train_loss_epoch=1.08e+12]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+11, train_loss_epoch=1.29e+11]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+11, train_loss_epoch=2.53e+11]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.36e+11, train_loss_epoch=5.36e+11]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.8e+11, train_loss_epoch=3.8e+11]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.77e+13, train_loss_epoch=3.77e+13]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+12, train_loss_epoch=1.02e+12]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+11, train_loss_epoch=2.98e+11]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+10, train_loss_epoch=1.51e+10]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.88e+10, train_loss_epoch=4.88e+10]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.37e+10, train_loss_epoch=5.37e+10]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+10, train_loss_epoch=3.24e+10]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9e+10, train_loss_epoch=9e+10]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+10, train_loss_epoch=2.31e+10]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.07e+5, train_loss_epoch=8.07e+5]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+10, train_loss_epoch=1.01e+10]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+10, train_loss_epoch=1.68e+10]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.98e+10, train_loss_epoch=1.98e+10]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.09e+10, train_loss_epoch=2.09e+10]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+10, train_loss_epoch=1.86e+10]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+10, train_loss_epoch=1.05e+10]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.88e+5, train_loss_epoch=6.88e+5]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+10, train_loss_epoch=2.73e+10]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.45e+10, train_loss_epoch=4.45e+10]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+10, train_loss_epoch=2.84e+10]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+10, train_loss_epoch=2.3e+10]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s, v_num=0, train_loss_step=8.18e+8, train_loss_epoch=8.18e+8]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.18e+8, train_loss_epoch=8.18e+8]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.93e+9, train_loss_epoch=4.93e+9]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.92e+9, train_loss_epoch=6.92e+9]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+10, train_loss_epoch=1.09e+10]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.4e+9, train_loss_epoch=9.4e+9]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+10, train_loss_epoch=1.28e+10]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+10, train_loss_epoch=1.21e+10]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+10, train_loss_epoch=1.13e+10]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.18e+10, train_loss_epoch=1.18e+10]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.79e+9, train_loss_epoch=9.79e+9]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+10, train_loss_epoch=1.11e+10]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.07e+9, train_loss_epoch=9.07e+9]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.95e+9, train_loss_epoch=8.95e+9]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+10, train_loss_epoch=1.35e+10]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.68e+9, train_loss_epoch=6.68e+9]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.04e+9, train_loss_epoch=6.04e+9]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.04e+9, train_loss_epoch=5.04e+9]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.94e+9, train_loss_epoch=4.94e+9]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.71e+9, train_loss_epoch=4.71e+9]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.88e+9, train_loss_epoch=4.88e+9]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.9e+9, train_loss_epoch=4.9e+9]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.31e+9, train_loss_epoch=4.31e+9]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.24e+9, train_loss_epoch=4.24e+9]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.3e+9, train_loss_epoch=3.3e+9]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+9, train_loss_epoch=2.96e+9]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+9, train_loss_epoch=2.77e+9]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  4.17it/s, v_num=0, train_loss_step=2.54e+9, train_loss_epoch=2.77e+9]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.22it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+9, train_loss_epoch=2.54e+9, valid_loss=2.06e+9]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+9, train_loss_epoch=2.16e+9, valid_loss=2.06e+9]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+9, train_loss_epoch=2.2e+9, valid_loss=2.06e+9]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e+9, train_loss_epoch=1.83e+9, valid_loss=2.06e+9]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+9, train_loss_epoch=1.51e+9, valid_loss=2.06e+9]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+9, train_loss_epoch=1.3e+9, valid_loss=2.06e+9]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+9, train_loss_epoch=1.03e+9, valid_loss=2.06e+9]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.24e+8, train_loss_epoch=9.24e+8, valid_loss=2.06e+9]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.41e+8, train_loss_epoch=7.41e+8, valid_loss=2.06e+9]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7e+8, train_loss_epoch=7e+8, valid_loss=2.06e+9]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.69e+8, train_loss_epoch=6.69e+8, valid_loss=2.06e+9]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.41e+8, train_loss_epoch=7.41e+8, valid_loss=2.06e+9]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=0, train_loss_step=7.03e+8, train_loss_epoch=7.41e+8, valid_loss=2.06e+9]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.03e+8, train_loss_epoch=7.03e+8, valid_loss=2.06e+9]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.57e+8, train_loss_epoch=5.57e+8, valid_loss=2.06e+9]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.76e+8, train_loss_epoch=5.76e+8, valid_loss=2.06e+9]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.6e+8, train_loss_epoch=4.6e+8, valid_loss=2.06e+9]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.23e+8, train_loss_epoch=2.23e+8, valid_loss=2.06e+9]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+7, train_loss_epoch=1.05e+7, valid_loss=2.06e+9]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.37e+5, train_loss_epoch=6.37e+5, valid_loss=2.06e+9]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.44e+5, train_loss_epoch=6.44e+5, valid_loss=2.06e+9]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.56e+5, train_loss_epoch=6.56e+5, valid_loss=2.06e+9]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+8, train_loss_epoch=1.32e+8, valid_loss=2.06e+9]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.54e+7, train_loss_epoch=3.54e+7, valid_loss=2.06e+9]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+7, train_loss_epoch=3.03e+7, valid_loss=2.06e+9]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+7, train_loss_epoch=1.65e+7, valid_loss=2.06e+9]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.83e+6, train_loss_epoch=5.83e+6, valid_loss=2.06e+9]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.26e+5, train_loss_epoch=8.26e+5, valid_loss=2.06e+9]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.44e+5, train_loss_epoch=6.44e+5, valid_loss=2.06e+9]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.17e+5, train_loss_epoch=6.17e+5, valid_loss=2.06e+9]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.05e+5, train_loss_epoch=6.05e+5, valid_loss=2.06e+9]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+5, train_loss_epoch=5.85e+5, valid_loss=2.06e+9]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.69e+5, train_loss_epoch=5.69e+5, valid_loss=2.06e+9]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.24e+5, train_loss_epoch=5.24e+5, valid_loss=2.06e+9]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.23e+5, train_loss_epoch=5.23e+5, valid_loss=2.06e+9]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.91e+5, train_loss_epoch=4.91e+5, valid_loss=2.06e+9]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.74e+5, train_loss_epoch=4.74e+5, valid_loss=2.06e+9]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.51e+5, train_loss_epoch=4.51e+5, valid_loss=2.06e+9]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.08e+5, train_loss_epoch=4.08e+5, valid_loss=2.06e+9]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.9e+5, train_loss_epoch=3.9e+5, valid_loss=2.06e+9]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.71e+5, train_loss_epoch=3.71e+5, valid_loss=2.06e+9]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.29e+5, train_loss_epoch=3.29e+5, valid_loss=2.06e+9]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+5, train_loss_epoch=3.25e+5, valid_loss=2.06e+9]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+5, train_loss_epoch=2.9e+5, valid_loss=2.06e+9]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+5, train_loss_epoch=2.72e+5, valid_loss=2.06e+9]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+5, train_loss_epoch=2.6e+5, valid_loss=2.06e+9]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+5, train_loss_epoch=2.47e+5, valid_loss=2.06e+9]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+5, train_loss_epoch=2.29e+5, valid_loss=2.06e+9]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.13e+5, train_loss_epoch=2.13e+5, valid_loss=2.06e+9]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.9e+5, train_loss_epoch=1.9e+5, valid_loss=2.06e+9]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+5, train_loss_epoch=1.86e+5, valid_loss=2.06e+9]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+5, train_loss_epoch=1.68e+5, valid_loss=2.06e+9]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.66e+5, train_loss_epoch=1.66e+5, valid_loss=2.06e+9]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.68e+5, train_loss_epoch=1.68e+5, valid_loss=2.06e+9]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+5, train_loss_epoch=1.56e+5, valid_loss=2.06e+9]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+5, train_loss_epoch=1.48e+5, valid_loss=2.06e+9]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+5, train_loss_epoch=1.41e+5, valid_loss=2.06e+9]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+5, train_loss_epoch=1.49e+5, valid_loss=2.06e+9]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+5, train_loss_epoch=1.49e+5, valid_loss=2.06e+9]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+5, train_loss_epoch=1.51e+5, valid_loss=2.06e+9]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+5, train_loss_epoch=1.51e+5, valid_loss=2.06e+9]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.51e+5, train_loss_epoch=1.51e+5, valid_loss=2.06e+9]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.46e+5, train_loss_epoch=1.46e+5, valid_loss=2.06e+9]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.52e+5, train_loss_epoch=1.52e+5, valid_loss=2.06e+9]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.46e+5, train_loss_epoch=1.46e+5, valid_loss=2.06e+9]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+5, train_loss_epoch=1.56e+5, valid_loss=2.06e+9]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+5, train_loss_epoch=1.47e+5, valid_loss=2.06e+9]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+5, train_loss_epoch=1.44e+5, valid_loss=2.06e+9]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+5, train_loss_epoch=1.49e+5, valid_loss=2.06e+9]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.43e+5, train_loss_epoch=1.43e+5, valid_loss=2.06e+9]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+5, train_loss_epoch=1.34e+5, valid_loss=2.06e+9]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.4e+5, train_loss_epoch=1.4e+5, valid_loss=2.06e+9]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.41e+5, train_loss_epoch=1.41e+5, valid_loss=2.06e+9]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+5, train_loss_epoch=1.35e+5, valid_loss=2.06e+9]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.39e+5, train_loss_epoch=1.39e+5, valid_loss=2.06e+9]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+5, train_loss_epoch=1.3e+5, valid_loss=2.06e+9]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+5, train_loss_epoch=1.3e+5, valid_loss=2.06e+9]\n",
            "Epoch 175: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s, v_num=0, train_loss_step=1.28e+5, train_loss_epoch=1.28e+5, valid_loss=2.06e+9]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+5, train_loss_epoch=1.28e+5, valid_loss=2.06e+9]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.32e+5, train_loss_epoch=1.32e+5, valid_loss=2.06e+9]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+5, train_loss_epoch=1.29e+5, valid_loss=2.06e+9]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+5, train_loss_epoch=1.26e+5, valid_loss=2.06e+9]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.23e+5, train_loss_epoch=1.23e+5, valid_loss=2.06e+9]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+5, train_loss_epoch=1.2e+5, valid_loss=2.06e+9]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+5, train_loss_epoch=1.17e+5, valid_loss=2.06e+9]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+5, train_loss_epoch=1.21e+5, valid_loss=2.06e+9]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+5, train_loss_epoch=1.14e+5, valid_loss=2.06e+9]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.18e+5, train_loss_epoch=1.18e+5, valid_loss=2.06e+9]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+5, train_loss_epoch=1.22e+5, valid_loss=2.06e+9]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+5, train_loss_epoch=1.11e+5, valid_loss=2.06e+9]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+5, train_loss_epoch=1.04e+5, valid_loss=2.06e+9]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+5, train_loss_epoch=1.08e+5, valid_loss=2.06e+9]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+5, train_loss_epoch=1.27e+5, valid_loss=2.06e+9]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.81e+4, train_loss_epoch=9.81e+4, valid_loss=2.06e+9]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+5, train_loss_epoch=1.15e+5, valid_loss=2.06e+9]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+5, train_loss_epoch=1.15e+5, valid_loss=2.06e+9]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+5, train_loss_epoch=1.07e+5, valid_loss=2.06e+9]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+5, train_loss_epoch=1.13e+5, valid_loss=2.06e+9]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+5, train_loss_epoch=1.04e+5, valid_loss=2.06e+9]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+5, train_loss_epoch=1.11e+5, valid_loss=2.06e+9]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+5, train_loss_epoch=1.03e+5, valid_loss=2.06e+9]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+5, train_loss_epoch=1.05e+5, valid_loss=2.06e+9]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=0, train_loss_step=1.03e+5, train_loss_epoch=1.05e+5, valid_loss=2.06e+9]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.26it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+5, train_loss_epoch=1.03e+5, valid_loss=1.3e+5]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+5, train_loss_epoch=1.17e+5, valid_loss=1.3e+5]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+5, train_loss_epoch=1.09e+5, valid_loss=1.3e+5]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+5, train_loss_epoch=1.09e+5, valid_loss=1.3e+5]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+5, train_loss_epoch=1.01e+5, valid_loss=1.3e+5]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.02e+5, valid_loss=1.3e+5]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.02e+5, valid_loss=1.3e+5]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+5, train_loss_epoch=1.11e+5, valid_loss=1.3e+5]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.02e+5, valid_loss=1.3e+5]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+5, train_loss_epoch=1e+5, valid_loss=1.3e+5]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+5, train_loss_epoch=1.14e+5, valid_loss=1.3e+5]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.37e+4, train_loss_epoch=9.37e+4, valid_loss=1.3e+5]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+5, train_loss_epoch=1.04e+5, valid_loss=1.3e+5]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+5, train_loss_epoch=1.06e+5, valid_loss=1.3e+5]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.57e+4, train_loss_epoch=9.57e+4, valid_loss=1.3e+5]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.18e+4, train_loss_epoch=9.18e+4, valid_loss=1.3e+5]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.67e+4, train_loss_epoch=8.67e+4, valid_loss=1.3e+5]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+5, train_loss_epoch=1.06e+5, valid_loss=1.3e+5]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.72e+4, train_loss_epoch=9.72e+4, valid_loss=1.3e+5]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.77e+4, train_loss_epoch=9.77e+4, valid_loss=1.3e+5]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.7e+4, train_loss_epoch=9.7e+4, valid_loss=1.3e+5]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.86e+4, train_loss_epoch=9.86e+4, valid_loss=1.3e+5]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.51e+4, train_loss_epoch=9.51e+4, valid_loss=1.3e+5]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.96e+4, train_loss_epoch=8.96e+4, valid_loss=1.3e+5]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.54e+4, train_loss_epoch=9.54e+4, valid_loss=1.3e+5]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.88e+4, train_loss_epoch=9.88e+4, valid_loss=1.3e+5]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.66e+4, train_loss_epoch=9.66e+4, valid_loss=1.3e+5]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.93e+4, train_loss_epoch=8.93e+4, valid_loss=1.3e+5]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.63e+4, train_loss_epoch=9.63e+4, valid_loss=1.3e+5]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+5, train_loss_epoch=1.05e+5, valid_loss=1.3e+5]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.87e+4, train_loss_epoch=8.87e+4, valid_loss=1.3e+5]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.83e+4, train_loss_epoch=9.83e+4, valid_loss=1.3e+5]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.75e+4, train_loss_epoch=9.75e+4, valid_loss=1.3e+5]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+5, train_loss_epoch=1.02e+5, valid_loss=1.3e+5]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.51e+4, train_loss_epoch=9.51e+4, valid_loss=1.3e+5]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.85e+4, train_loss_epoch=8.85e+4, valid_loss=1.3e+5]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.51e+4, train_loss_epoch=8.51e+4, valid_loss=1.3e+5]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.48e+4, train_loss_epoch=7.48e+4, valid_loss=1.3e+5]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=95647.5, train_loss_epoch=95647.5, valid_loss=1.3e+5]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.69e+4, train_loss_epoch=8.69e+4, valid_loss=1.3e+5]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.38e+4, train_loss_epoch=8.38e+4, valid_loss=1.3e+5]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9e+4, train_loss_epoch=9e+4, valid_loss=1.3e+5]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.01e+4, train_loss_epoch=8.01e+4, valid_loss=1.3e+5]\n",
            "Epoch 242: 100%|██████████| 1/1 [00:00<00:00,  3.77it/s, v_num=0, train_loss_step=8.97e+4, train_loss_epoch=8.97e+4, valid_loss=1.3e+5]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.97e+4, train_loss_epoch=8.97e+4, valid_loss=1.3e+5]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.65e+4, train_loss_epoch=8.65e+4, valid_loss=1.3e+5]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.84e+4, train_loss_epoch=7.84e+4, valid_loss=1.3e+5]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.17e+4, train_loss_epoch=8.17e+4, valid_loss=1.3e+5]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.27e+4, train_loss_epoch=8.27e+4, valid_loss=1.3e+5]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.85e+4, train_loss_epoch=7.85e+4, valid_loss=1.3e+5]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.08e+4, train_loss_epoch=8.08e+4, valid_loss=1.3e+5]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.78e+4, train_loss_epoch=7.78e+4, valid_loss=1.3e+5]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.68e+4, train_loss_epoch=7.68e+4, valid_loss=1.3e+5]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.34e+4, train_loss_epoch=8.34e+4, valid_loss=1.3e+5]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.44e+4, train_loss_epoch=7.44e+4, valid_loss=1.3e+5]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.01e+4, train_loss_epoch=8.01e+4, valid_loss=1.3e+5]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.04e+4, train_loss_epoch=8.04e+4, valid_loss=1.3e+5]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.89e+4, train_loss_epoch=7.89e+4, valid_loss=1.3e+5]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.53e+4, train_loss_epoch=7.53e+4, valid_loss=1.3e+5]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.41e+4, train_loss_epoch=8.41e+4, valid_loss=1.3e+5]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.44e+4, train_loss_epoch=7.44e+4, valid_loss=1.3e+5]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.39e+4, train_loss_epoch=8.39e+4, valid_loss=1.3e+5]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.12e+4, train_loss_epoch=7.12e+4, valid_loss=1.3e+5]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.22e+4, train_loss_epoch=8.22e+4, valid_loss=1.3e+5]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.57e+4, train_loss_epoch=7.57e+4, valid_loss=1.3e+5]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.88e+4, train_loss_epoch=7.88e+4, valid_loss=1.3e+5]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.55e+4, train_loss_epoch=7.55e+4, valid_loss=1.3e+5]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.98e+4, train_loss_epoch=6.98e+4, valid_loss=1.3e+5]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.7e+4, train_loss_epoch=7.7e+4, valid_loss=1.3e+5]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.12e+4, train_loss_epoch=7.12e+4, valid_loss=1.3e+5]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.67e+4, train_loss_epoch=7.67e+4, valid_loss=1.3e+5]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.26e+4, train_loss_epoch=7.26e+4, valid_loss=1.3e+5]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.18e+4, train_loss_epoch=7.18e+4, valid_loss=1.3e+5]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.04e+4, train_loss_epoch=7.04e+4, valid_loss=1.3e+5]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.44e+4, train_loss_epoch=6.44e+4, valid_loss=1.3e+5]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.88e+4, train_loss_epoch=7.88e+4, valid_loss=1.3e+5]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.3e+4, train_loss_epoch=6.3e+4, valid_loss=1.3e+5]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.92e+4, train_loss_epoch=6.92e+4, valid_loss=1.3e+5]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.18e+4, train_loss_epoch=7.18e+4, valid_loss=1.3e+5]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.88e+4, train_loss_epoch=6.88e+4, valid_loss=1.3e+5]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.72e+4, train_loss_epoch=6.72e+4, valid_loss=1.3e+5]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.42e+4, train_loss_epoch=7.42e+4, valid_loss=1.3e+5]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.36e+4, train_loss_epoch=6.36e+4, valid_loss=1.3e+5]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.35e+4, train_loss_epoch=6.35e+4, valid_loss=1.3e+5]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7e+4, train_loss_epoch=7e+4, valid_loss=1.3e+5]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.58e+4, train_loss_epoch=7.58e+4, valid_loss=1.3e+5]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.13e+4, train_loss_epoch=7.13e+4, valid_loss=1.3e+5]\n",
            "Epoch 285: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, v_num=0, train_loss_step=6.61e+4, train_loss_epoch=7.13e+4, valid_loss=1.3e+5]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.61e+4, train_loss_epoch=6.61e+4, valid_loss=1.3e+5]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.05e+4, train_loss_epoch=6.05e+4, valid_loss=1.3e+5]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s, v_num=0, train_loss_step=6.62e+4, train_loss_epoch=6.62e+4, valid_loss=1.3e+5]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.62e+4, train_loss_epoch=6.62e+4, valid_loss=1.3e+5]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.98e+4, train_loss_epoch=5.98e+4, valid_loss=1.3e+5]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.53e+4, train_loss_epoch=6.53e+4, valid_loss=1.3e+5]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.98e+4, train_loss_epoch=6.98e+4, valid_loss=1.3e+5]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.09e+4, train_loss_epoch=6.09e+4, valid_loss=1.3e+5]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.58e+4, train_loss_epoch=6.58e+4, valid_loss=1.3e+5]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.55e+4, train_loss_epoch=6.55e+4, valid_loss=1.3e+5]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.19e+4, train_loss_epoch=6.19e+4, valid_loss=1.3e+5]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.63e+4, train_loss_epoch=5.63e+4, valid_loss=1.3e+5]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.77e+4, train_loss_epoch=5.77e+4, valid_loss=1.3e+5]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.07e+4, train_loss_epoch=6.07e+4, valid_loss=1.3e+5]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.88e+4, train_loss_epoch=5.88e+4, valid_loss=1.3e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s, v_num=0, train_loss_step=5.88e+4, train_loss_epoch=5.88e+4, valid_loss=1.3e+5]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  3.80it/s, v_num=0, train_loss_step=5.96e+4, train_loss_epoch=5.88e+4, valid_loss=1.3e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.74it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.96e+4, train_loss_epoch=5.96e+4, valid_loss=6.5e+4]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.33e+4, train_loss_epoch=5.33e+4, valid_loss=6.5e+4]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.95e+4, train_loss_epoch=5.95e+4, valid_loss=6.5e+4]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.32e+4, train_loss_epoch=5.32e+4, valid_loss=6.5e+4]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.49e+4, train_loss_epoch=6.49e+4, valid_loss=6.5e+4]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.09e+4, train_loss_epoch=5.09e+4, valid_loss=6.5e+4]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.79e+4, train_loss_epoch=5.79e+4, valid_loss=6.5e+4]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.13e+4, train_loss_epoch=6.13e+4, valid_loss=6.5e+4]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.64e+4, train_loss_epoch=5.64e+4, valid_loss=6.5e+4]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.33e+4, train_loss_epoch=5.33e+4, valid_loss=6.5e+4]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.18e+4, train_loss_epoch=5.18e+4, valid_loss=6.5e+4]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.58e+4, train_loss_epoch=5.58e+4, valid_loss=6.5e+4]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.64e+4, train_loss_epoch=5.64e+4, valid_loss=6.5e+4]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.29e+4, train_loss_epoch=5.29e+4, valid_loss=6.5e+4]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.88e+4, train_loss_epoch=4.88e+4, valid_loss=6.5e+4]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.29e+4, train_loss_epoch=5.29e+4, valid_loss=6.5e+4]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.54e+4, train_loss_epoch=5.54e+4, valid_loss=6.5e+4]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.07e+4, train_loss_epoch=5.07e+4, valid_loss=6.5e+4]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.74e+4, train_loss_epoch=4.74e+4, valid_loss=6.5e+4]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+4, train_loss_epoch=4.97e+4, valid_loss=6.5e+4]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.07e+4, train_loss_epoch=5.07e+4, valid_loss=6.5e+4]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.92e+4, train_loss_epoch=4.92e+4, valid_loss=6.5e+4]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.54e+4, train_loss_epoch=4.54e+4, valid_loss=6.5e+4]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+4, train_loss_epoch=4.97e+4, valid_loss=6.5e+4]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.8e+4, train_loss_epoch=4.8e+4, valid_loss=6.5e+4]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.19e+4, train_loss_epoch=5.19e+4, valid_loss=6.5e+4]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.59e+4, train_loss_epoch=4.59e+4, valid_loss=6.5e+4]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.08e+4, train_loss_epoch=5.08e+4, valid_loss=6.5e+4]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.38e+4, train_loss_epoch=4.38e+4, valid_loss=6.5e+4]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.06e+4, train_loss_epoch=4.06e+4, valid_loss=6.5e+4]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.14e+4, train_loss_epoch=4.14e+4, valid_loss=6.5e+4]\n",
            "Epoch 330: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=0, train_loss_step=4.84e+4, train_loss_epoch=4.84e+4, valid_loss=6.5e+4]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.84e+4, train_loss_epoch=4.84e+4, valid_loss=6.5e+4]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.67e+4, train_loss_epoch=4.67e+4, valid_loss=6.5e+4]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.24e+4, train_loss_epoch=4.24e+4, valid_loss=6.5e+4]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.67e+4, train_loss_epoch=4.67e+4, valid_loss=6.5e+4]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.09e+4, train_loss_epoch=4.09e+4, valid_loss=6.5e+4]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.34e+4, train_loss_epoch=4.34e+4, valid_loss=6.5e+4]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.99e+4, train_loss_epoch=3.99e+4, valid_loss=6.5e+4]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.95e+4, train_loss_epoch=3.95e+4, valid_loss=6.5e+4]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.81e+4, train_loss_epoch=3.81e+4, valid_loss=6.5e+4]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4e+4, train_loss_epoch=4e+4, valid_loss=6.5e+4]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.55e+4, train_loss_epoch=3.55e+4, valid_loss=6.5e+4]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.02e+4, train_loss_epoch=4.02e+4, valid_loss=6.5e+4]\n",
            "Epoch 342: 100%|██████████| 1/1 [00:00<00:00,  4.10it/s, v_num=0, train_loss_step=3.96e+4, train_loss_epoch=4.02e+4, valid_loss=6.5e+4]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.96e+4, train_loss_epoch=3.96e+4, valid_loss=6.5e+4]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.13e+4, train_loss_epoch=4.13e+4, valid_loss=6.5e+4]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.74e+4, train_loss_epoch=3.74e+4, valid_loss=6.5e+4]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.33e+4, train_loss_epoch=3.33e+4, valid_loss=6.5e+4]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.68e+4, train_loss_epoch=3.68e+4, valid_loss=6.5e+4]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:00<00:00,  3.90it/s, v_num=0, train_loss_step=3.9e+4, train_loss_epoch=3.9e+4, valid_loss=6.5e+4] \n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.9e+4, train_loss_epoch=3.9e+4, valid_loss=6.5e+4]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.43e+4, train_loss_epoch=3.43e+4, valid_loss=6.5e+4]\n",
            "Epoch 349: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s, v_num=0, train_loss_step=3.52e+4, train_loss_epoch=3.43e+4, valid_loss=6.5e+4]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.52e+4, train_loss_epoch=3.52e+4, valid_loss=6.5e+4]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.43e+4, train_loss_epoch=3.43e+4, valid_loss=6.5e+4]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.12e+4, train_loss_epoch=3.12e+4, valid_loss=6.5e+4]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+4, train_loss_epoch=2.96e+4, valid_loss=6.5e+4]\n",
            "Epoch 353: 100%|██████████| 1/1 [00:00<00:00,  3.84it/s, v_num=0, train_loss_step=3.7e+4, train_loss_epoch=2.96e+4, valid_loss=6.5e+4] \n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.7e+4, train_loss_epoch=3.7e+4, valid_loss=6.5e+4]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.44e+4, train_loss_epoch=3.44e+4, valid_loss=6.5e+4]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+4, train_loss_epoch=3.07e+4, valid_loss=6.5e+4]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+4, train_loss_epoch=3.4e+4, valid_loss=6.5e+4]\n",
            "Epoch 357: 100%|██████████| 1/1 [00:00<00:00,  3.85it/s, v_num=0, train_loss_step=3.12e+4, train_loss_epoch=3.12e+4, valid_loss=6.5e+4]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.12e+4, train_loss_epoch=3.12e+4, valid_loss=6.5e+4]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+4, train_loss_epoch=2.99e+4, valid_loss=6.5e+4]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+4, train_loss_epoch=2.77e+4, valid_loss=6.5e+4]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+4, train_loss_epoch=3.03e+4, valid_loss=6.5e+4]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+4, train_loss_epoch=2.94e+4, valid_loss=6.5e+4]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+4, train_loss_epoch=2.62e+4, valid_loss=6.5e+4]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+4, train_loss_epoch=2.74e+4, valid_loss=6.5e+4]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+4, train_loss_epoch=2.8e+4, valid_loss=6.5e+4]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+4, train_loss_epoch=2.29e+4, valid_loss=6.5e+4]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+4, train_loss_epoch=2.53e+4, valid_loss=6.5e+4]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+4, train_loss_epoch=2.5e+4, valid_loss=6.5e+4]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+4, train_loss_epoch=2.43e+4, valid_loss=6.5e+4]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+4, train_loss_epoch=2.64e+4, valid_loss=6.5e+4]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+4, train_loss_epoch=2.9e+4, valid_loss=6.5e+4]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+4, train_loss_epoch=2.8e+4, valid_loss=6.5e+4]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+4, train_loss_epoch=2.32e+4, valid_loss=6.5e+4]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+4, train_loss_epoch=2.25e+4, valid_loss=6.5e+4]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+4, train_loss_epoch=2.28e+4, valid_loss=6.5e+4]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+4, train_loss_epoch=2.29e+4, valid_loss=6.5e+4]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.15e+4, train_loss_epoch=2.15e+4, valid_loss=6.5e+4]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+4, train_loss_epoch=2.28e+4, valid_loss=6.5e+4]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+4, train_loss_epoch=2.1e+4, valid_loss=6.5e+4]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.15e+4, train_loss_epoch=2.15e+4, valid_loss=6.5e+4]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.05e+4, train_loss_epoch=2.05e+4, valid_loss=6.5e+4]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.99e+4, train_loss_epoch=1.99e+4, valid_loss=6.5e+4]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.06e+4, train_loss_epoch=2.06e+4, valid_loss=6.5e+4]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.02e+4, train_loss_epoch=2.02e+4, valid_loss=6.5e+4]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.18e+4, train_loss_epoch=2.18e+4, valid_loss=6.5e+4]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.88e+4, train_loss_epoch=1.88e+4, valid_loss=6.5e+4]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.81e+4, train_loss_epoch=1.81e+4, valid_loss=6.5e+4]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.89e+4, train_loss_epoch=1.89e+4, valid_loss=6.5e+4]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.86e+4, train_loss_epoch=1.86e+4, valid_loss=6.5e+4]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.85e+4, train_loss_epoch=1.85e+4, valid_loss=6.5e+4]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.71e+4, train_loss_epoch=1.71e+4, valid_loss=6.5e+4]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+4, train_loss_epoch=1.59e+4, valid_loss=6.5e+4]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.6e+4, train_loss_epoch=1.6e+4, valid_loss=6.5e+4]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.58e+4, train_loss_epoch=1.58e+4, valid_loss=6.5e+4]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+4, train_loss_epoch=1.44e+4, valid_loss=6.5e+4]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+4, train_loss_epoch=1.56e+4, valid_loss=6.5e+4]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+4, train_loss_epoch=1.35e+4, valid_loss=6.5e+4]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+4, train_loss_epoch=1.56e+4, valid_loss=6.5e+4]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+4, train_loss_epoch=1.36e+4, valid_loss=6.5e+4]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=0, train_loss_step=1.42e+4, train_loss_epoch=1.36e+4, valid_loss=6.5e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.70it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+4, train_loss_epoch=1.42e+4, valid_loss=1.06e+4]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+4, train_loss_epoch=1.28e+4, valid_loss=1.06e+4]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+4, train_loss_epoch=1.33e+4, valid_loss=1.06e+4]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+4, train_loss_epoch=1.15e+4, valid_loss=1.06e+4]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+4, train_loss_epoch=1.3e+4, valid_loss=1.06e+4]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+4, train_loss_epoch=1.36e+4, valid_loss=1.06e+4]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+4, train_loss_epoch=1.28e+4, valid_loss=1.06e+4]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.4e+4, train_loss_epoch=1.4e+4, valid_loss=1.06e+4]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+4, train_loss_epoch=1.31e+4, valid_loss=1.06e+4]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+4, train_loss_epoch=1.15e+4, valid_loss=1.06e+4]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+4, train_loss_epoch=1.2e+4, valid_loss=1.06e+4]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.62e+3, train_loss_epoch=9.62e+3, valid_loss=1.06e+4]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.09e+4, train_loss_epoch=1.09e+4, valid_loss=1.06e+4]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+4, train_loss_epoch=1.1e+4, valid_loss=1.06e+4]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.42e+3, train_loss_epoch=9.42e+3, valid_loss=1.06e+4]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+4, train_loss_epoch=1e+4, valid_loss=1.06e+4]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.6e+3, train_loss_epoch=9.6e+3, valid_loss=1.06e+4]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+4, train_loss_epoch=1.05e+4, valid_loss=1.06e+4]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+4, train_loss_epoch=1.15e+4, valid_loss=1.06e+4]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+4, train_loss_epoch=1.07e+4, valid_loss=1.06e+4]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.7e+3, train_loss_epoch=9.7e+3, valid_loss=1.06e+4]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.31e+3, train_loss_epoch=9.31e+3, valid_loss=1.06e+4]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.52e+3, train_loss_epoch=8.52e+3, valid_loss=1.06e+4]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.76e+3, train_loss_epoch=9.76e+3, valid_loss=1.06e+4]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.11e+3, train_loss_epoch=8.11e+3, valid_loss=1.06e+4]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.44e+3, train_loss_epoch=8.44e+3, valid_loss=1.06e+4]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.71e+3, train_loss_epoch=8.71e+3, valid_loss=1.06e+4]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.75e+3, train_loss_epoch=8.75e+3, valid_loss=1.06e+4]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.34e+3, train_loss_epoch=8.34e+3, valid_loss=1.06e+4]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.36e+3, train_loss_epoch=8.36e+3, valid_loss=1.06e+4]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.03e+3, train_loss_epoch=8.03e+3, valid_loss=1.06e+4]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.83e+3, train_loss_epoch=7.83e+3, valid_loss=1.06e+4]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.27e+3, train_loss_epoch=7.27e+3, valid_loss=1.06e+4]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.95e+3, train_loss_epoch=6.95e+3, valid_loss=1.06e+4]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.45e+3, train_loss_epoch=7.45e+3, valid_loss=1.06e+4]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.71e+3, train_loss_epoch=6.71e+3, valid_loss=1.06e+4]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, v_num=0, train_loss_step=6.18e+3, train_loss_epoch=6.18e+3, valid_loss=1.06e+4]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.18e+3, train_loss_epoch=6.18e+3, valid_loss=1.06e+4]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.63e+3, train_loss_epoch=6.63e+3, valid_loss=1.06e+4]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.99e+3, train_loss_epoch=7.99e+3, valid_loss=1.06e+4]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.71e+3, train_loss_epoch=5.71e+3, valid_loss=1.06e+4]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.75e+3, train_loss_epoch=6.75e+3, valid_loss=1.06e+4]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.36e+3, train_loss_epoch=6.36e+3, valid_loss=1.06e+4]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.5e+3, train_loss_epoch=6.5e+3, valid_loss=1.06e+4]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.54e+3, train_loss_epoch=6.54e+3, valid_loss=1.06e+4]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.08e+3, train_loss_epoch=5.08e+3, valid_loss=1.06e+4]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.56e+3, train_loss_epoch=5.56e+3, valid_loss=1.06e+4]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.43e+3, train_loss_epoch=5.43e+3, valid_loss=1.06e+4]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.36e+3, train_loss_epoch=5.36e+3, valid_loss=1.06e+4]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.23e+3, train_loss_epoch=5.23e+3, valid_loss=1.06e+4]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.17e+3, train_loss_epoch=5.17e+3, valid_loss=1.06e+4]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.26e+3, train_loss_epoch=5.26e+3, valid_loss=1.06e+4]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.71e+3, train_loss_epoch=4.71e+3, valid_loss=1.06e+4]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+3, train_loss_epoch=3.98e+3, valid_loss=1.06e+4]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.78e+3, train_loss_epoch=4.78e+3, valid_loss=1.06e+4]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.51e+3, train_loss_epoch=4.51e+3, valid_loss=1.06e+4]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.36e+3, train_loss_epoch=4.36e+3, valid_loss=1.06e+4]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.81e+3, train_loss_epoch=4.81e+3, valid_loss=1.06e+4]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+3, train_loss_epoch=4.15e+3, valid_loss=1.06e+4]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.14e+3, train_loss_epoch=4.14e+3, valid_loss=1.06e+4]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+3, train_loss_epoch=4.15e+3, valid_loss=1.06e+4]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.25e+3, train_loss_epoch=4.25e+3, valid_loss=1.06e+4]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.16e+3, train_loss_epoch=4.16e+3, valid_loss=1.06e+4]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.89e+3, train_loss_epoch=3.89e+3, valid_loss=1.06e+4]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.8e+3, train_loss_epoch=3.8e+3, valid_loss=1.06e+4]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.63e+3, train_loss_epoch=3.63e+3, valid_loss=1.06e+4]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.17e+3, train_loss_epoch=4.17e+3, valid_loss=1.06e+4]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.73e+3, train_loss_epoch=3.73e+3, valid_loss=1.06e+4]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.86e+3, train_loss_epoch=3.86e+3, valid_loss=1.06e+4]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.03e+3, train_loss_epoch=4.03e+3, valid_loss=1.06e+4]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.35e+3, train_loss_epoch=3.35e+3, valid_loss=1.06e+4]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.46e+3, train_loss_epoch=3.46e+3, valid_loss=1.06e+4]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3755.5, train_loss_epoch=3755.5, valid_loss=1.06e+4]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+3, train_loss_epoch=3.45e+3, valid_loss=1.06e+4]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+3, train_loss_epoch=3.45e+3, valid_loss=1.06e+4]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.5e+3, train_loss_epoch=3.5e+3, valid_loss=1.06e+4]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.83e+3, train_loss_epoch=3.83e+3, valid_loss=1.06e+4]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.47e+3, train_loss_epoch=3.47e+3, valid_loss=1.06e+4]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.41e+3, train_loss_epoch=3.41e+3, valid_loss=1.06e+4]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.31e+3, train_loss_epoch=3.31e+3, valid_loss=1.06e+4]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+3, train_loss_epoch=3.25e+3, valid_loss=1.06e+4]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.31e+3, train_loss_epoch=3.31e+3, valid_loss=1.06e+4]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.59e+3, train_loss_epoch=3.59e+3, valid_loss=1.06e+4]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+3, train_loss_epoch=3.1e+3, valid_loss=1.06e+4]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+3, train_loss_epoch=3.25e+3, valid_loss=1.06e+4]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+3, train_loss_epoch=3.45e+3, valid_loss=1.06e+4]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+3, train_loss_epoch=3.19e+3, valid_loss=1.06e+4]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+3, train_loss_epoch=3.18e+3, valid_loss=1.06e+4]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.27e+3, train_loss_epoch=3.27e+3, valid_loss=1.06e+4]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.27e+3, train_loss_epoch=3.27e+3, valid_loss=1.06e+4]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+3, train_loss_epoch=3e+3, valid_loss=1.06e+4]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+3, train_loss_epoch=3.05e+3, valid_loss=1.06e+4]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+3, train_loss_epoch=3.04e+3, valid_loss=1.06e+4]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=1.06e+4]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+3, train_loss_epoch=3.19e+3, valid_loss=1.06e+4]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=2.84e+3, valid_loss=1.06e+4]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+3, train_loss_epoch=3.17e+3, valid_loss=1.06e+4]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.43e+3, train_loss_epoch=3.43e+3, valid_loss=1.06e+4]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.12e+3, train_loss_epoch=3.12e+3, valid_loss=1.06e+4]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+3, train_loss_epoch=2.98e+3, valid_loss=1.06e+4]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=1.06e+4]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  4.06it/s, v_num=0, train_loss_step=3.08e+3, train_loss_epoch=2.94e+3, valid_loss=1.06e+4]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.08it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+3, train_loss_epoch=3.08e+3, valid_loss=3.82e+3]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.26e+3, train_loss_epoch=3.26e+3, valid_loss=3.82e+3]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+3, train_loss_epoch=2.88e+3, valid_loss=3.82e+3]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+3, train_loss_epoch=3.08e+3, valid_loss=3.82e+3]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.21e+3, train_loss_epoch=3.21e+3, valid_loss=3.82e+3]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+3, train_loss_epoch=3.01e+3, valid_loss=3.82e+3]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+3, train_loss_epoch=3.04e+3, valid_loss=3.82e+3]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+3, train_loss_epoch=3.01e+3, valid_loss=3.82e+3]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+3, train_loss_epoch=2.78e+3, valid_loss=3.82e+3]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+3, train_loss_epoch=3.09e+3, valid_loss=3.82e+3]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.06e+3, train_loss_epoch=3.06e+3, valid_loss=3.82e+3]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+3, train_loss_epoch=2.88e+3, valid_loss=3.82e+3]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+3, train_loss_epoch=2.96e+3, valid_loss=3.82e+3]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+3, train_loss_epoch=3e+3, valid_loss=3.82e+3]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+3, train_loss_epoch=2.88e+3, valid_loss=3.82e+3]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.97e+3, train_loss_epoch=2.97e+3, valid_loss=3.82e+3]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  3.70it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.97e+3, valid_loss=3.82e+3]\n",
            "Epoch 515: 100%|██████████| 1/1 [00:00<00:00,  3.58it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=3.82e+3]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=3.82e+3]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=3.82e+3]\n",
            "Epoch 517: 100%|██████████| 1/1 [00:00<00:00,  4.00it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.83e+3, valid_loss=3.82e+3]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.83e+3, valid_loss=3.82e+3]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=3.82e+3]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=3.82e+3]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=3.82e+3]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=3.82e+3]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+3, train_loss_epoch=2.9e+3, valid_loss=3.82e+3]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+3, train_loss_epoch=3.19e+3, valid_loss=3.82e+3]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=3.82e+3]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=3.82e+3]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=2.79e+3, valid_loss=3.82e+3]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+3, train_loss_epoch=3.11e+3, valid_loss=3.82e+3]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=3.82e+3]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+3, train_loss_epoch=2.78e+3, valid_loss=3.82e+3]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=3.82e+3]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=3.82e+3]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=3.82e+3]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+3, train_loss_epoch=2.98e+3, valid_loss=3.82e+3]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+3, train_loss_epoch=2.99e+3, valid_loss=3.82e+3]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.97e+3, train_loss_epoch=2.97e+3, valid_loss=3.82e+3]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=3.82e+3]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.23e+3, train_loss_epoch=3.23e+3, valid_loss=3.82e+3]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.82e+3]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=3.82e+3]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.82e+3]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+3, train_loss_epoch=3.1e+3, valid_loss=3.82e+3]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+3, train_loss_epoch=3.18e+3, valid_loss=3.82e+3]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+3, train_loss_epoch=2.87e+3, valid_loss=3.82e+3]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.14e+3, train_loss_epoch=3.14e+3, valid_loss=3.82e+3]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=2.79e+3, valid_loss=3.82e+3]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+3, train_loss_epoch=3.09e+3, valid_loss=3.82e+3]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.82e+3]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=3.82e+3]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.7e+3, valid_loss=3.82e+3]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=3.82e+3]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=3.82e+3]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+3, train_loss_epoch=2.99e+3, valid_loss=3.82e+3]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+3, train_loss_epoch=2.98e+3, valid_loss=3.82e+3]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=3.82e+3]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=3.82e+3]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=3.82e+3]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=3.82e+3]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=3.82e+3]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=3.82e+3]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+3, train_loss_epoch=2.95e+3, valid_loss=3.82e+3]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=3.82e+3]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=3.82e+3]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.82e+3]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.82e+3]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+3, train_loss_epoch=3.07e+3, valid_loss=3.82e+3]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+3, train_loss_epoch=2.9e+3, valid_loss=3.82e+3]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+3, train_loss_epoch=3.16e+3, valid_loss=3.82e+3]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=3.82e+3]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+3, train_loss_epoch=3.01e+3, valid_loss=3.82e+3]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+3, train_loss_epoch=3.05e+3, valid_loss=3.82e+3]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=3.82e+3]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=3.82e+3]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.82e+3]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+3, train_loss_epoch=3.11e+3, valid_loss=3.82e+3]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.82e+3]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+3, train_loss_epoch=3.01e+3, valid_loss=3.82e+3]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=3.82e+3]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.97e+3, train_loss_epoch=2.97e+3, valid_loss=3.82e+3]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=3.82e+3]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+3, train_loss_epoch=3.08e+3, valid_loss=3.82e+3]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.7e+3, valid_loss=3.82e+3]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+3, train_loss_epoch=2.88e+3, valid_loss=3.82e+3]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.82e+3]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.82e+3]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=3.82e+3]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=3.82e+3]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=3.82e+3]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=3.82e+3]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.92e+3, train_loss_epoch=2.92e+3, valid_loss=3.82e+3]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+3, train_loss_epoch=2.96e+3, valid_loss=3.82e+3]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=3.82e+3]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=3.82e+3]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=3.82e+3]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.82e+3]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=3.82e+3]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=3.82e+3]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+3, train_loss_epoch=3e+3, valid_loss=3.82e+3]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.82e+3]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.63it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.61e+3, valid_loss=3.82e+3] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 142.89it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.7e+3, valid_loss=5.03e+3]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+3, train_loss_epoch=3e+3, valid_loss=5.03e+3]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+3, train_loss_epoch=2.9e+3, valid_loss=5.03e+3]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=5.03e+3]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=2.84e+3, valid_loss=5.03e+3]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=5.03e+3]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+3, train_loss_epoch=3.05e+3, valid_loss=5.03e+3]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+3, train_loss_epoch=3.16e+3, valid_loss=5.03e+3]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+3, train_loss_epoch=2.95e+3, valid_loss=5.03e+3]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=5.03e+3]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+3, train_loss_epoch=2.96e+3, valid_loss=5.03e+3]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=5.03e+3]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+3, train_loss_epoch=3.05e+3, valid_loss=5.03e+3]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+3, train_loss_epoch=2.87e+3, valid_loss=5.03e+3]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+3, train_loss_epoch=2.82e+3, valid_loss=5.03e+3]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+3, train_loss_epoch=2.64e+3, valid_loss=5.03e+3]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+3, train_loss_epoch=2.95e+3, valid_loss=5.03e+3]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=5.03e+3]\n",
            "Epoch 617: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=5.03e+3]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=5.03e+3]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+3, train_loss_epoch=3e+3, valid_loss=5.03e+3]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+3, train_loss_epoch=3e+3, valid_loss=5.03e+3]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=5.03e+3]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=5.03e+3]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+3, train_loss_epoch=2.82e+3, valid_loss=5.03e+3]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+3, train_loss_epoch=2.99e+3, valid_loss=5.03e+3]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=5.03e+3]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.83e+3, valid_loss=5.03e+3]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+3, train_loss_epoch=3.04e+3, valid_loss=5.03e+3]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=5.03e+3]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=5.03e+3]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=5.03e+3]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=5.03e+3]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+3, train_loss_epoch=2.87e+3, valid_loss=5.03e+3]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=5.03e+3]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=5.03e+3]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=5.03e+3]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+3, train_loss_epoch=2.89e+3, valid_loss=5.03e+3]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=2.84e+3, valid_loss=5.03e+3]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+3, train_loss_epoch=3.09e+3, valid_loss=5.03e+3]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=5.03e+3]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=5.03e+3]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+3, train_loss_epoch=3.08e+3, valid_loss=5.03e+3]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=5.03e+3]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=5.03e+3]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=5.03e+3]\n",
            "Epoch 644: 100%|██████████| 1/1 [00:00<00:00,  3.05it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=5.03e+3]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=5.03e+3]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=5.03e+3]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+3, train_loss_epoch=2.98e+3, valid_loss=5.03e+3]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=2.79e+3, valid_loss=5.03e+3]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=5.03e+3]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=5.03e+3]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=5.03e+3]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=5.03e+3]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=5.03e+3]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=5.03e+3]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=5.03e+3]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=5.03e+3]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+3, train_loss_epoch=2.64e+3, valid_loss=5.03e+3]\n",
            "Epoch 657: 100%|██████████| 1/1 [00:00<00:00,  3.87it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.64e+3, valid_loss=5.03e+3]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+3, train_loss_epoch=2.94e+3, valid_loss=5.03e+3]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=5.03e+3]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=5.03e+3]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=5.03e+3]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=5.03e+3]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=5.03e+3]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+3, train_loss_epoch=2.86e+3, valid_loss=5.03e+3]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+3, train_loss_epoch=2.87e+3, valid_loss=5.03e+3]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+3, train_loss_epoch=2.64e+3, valid_loss=5.03e+3]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=2.79e+3, valid_loss=5.03e+3]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=5.03e+3]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=5.03e+3]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=5.03e+3]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+3, train_loss_epoch=2.85e+3, valid_loss=5.03e+3]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+3, train_loss_epoch=2.78e+3, valid_loss=5.03e+3]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=5.03e+3]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=5.03e+3]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+3, train_loss_epoch=2.78e+3, valid_loss=5.03e+3]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=5.03e+3]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=5.03e+3]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+3, train_loss_epoch=3.09e+3, valid_loss=5.03e+3]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+3, train_loss_epoch=2.64e+3, valid_loss=5.03e+3]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=5.03e+3]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.02e+3, train_loss_epoch=3.02e+3, valid_loss=5.03e+3]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.15e+3, train_loss_epoch=3.15e+3, valid_loss=5.03e+3]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=5.03e+3]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+3, train_loss_epoch=2.87e+3, valid_loss=5.03e+3]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=5.03e+3]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.83e+3, valid_loss=5.03e+3]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=5.03e+3]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=5.03e+3]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=5.03e+3]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.02e+3, train_loss_epoch=3.02e+3, valid_loss=5.03e+3]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=5.03e+3]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=5.03e+3]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=5.03e+3]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=5.03e+3]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+3, train_loss_epoch=2.78e+3, valid_loss=5.03e+3]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=5.03e+3]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=5.03e+3]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=5.03e+3]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+3, train_loss_epoch=2.99e+3, valid_loss=5.03e+3]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  3.38it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.99e+3, valid_loss=5.03e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.91it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.88e+3]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.88e+3]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.88e+3]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.88e+3]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=3.88e+3]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.88e+3]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=3.88e+3]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.88e+3]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.88e+3]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.88e+3]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.88e+3]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.92e+3, train_loss_epoch=2.92e+3, valid_loss=3.88e+3]\n",
            "Epoch 711: 100%|██████████| 1/1 [00:00<00:00,  3.75it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=3.88e+3]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=3.88e+3]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.88e+3]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+3, train_loss_epoch=2.84e+3, valid_loss=3.88e+3]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.88e+3]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.88e+3]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+3, train_loss_epoch=3.17e+3, valid_loss=3.88e+3]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=3.88e+3]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+3, train_loss_epoch=2.87e+3, valid_loss=3.88e+3]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.88e+3]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.88e+3]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.88e+3]\n",
            "Epoch 722: 100%|██████████| 1/1 [00:00<00:00,  3.68it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.88e+3]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.88e+3]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.88e+3]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.88e+3]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+3, train_loss_epoch=2.73e+3, valid_loss=3.88e+3]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=3.88e+3]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+3, train_loss_epoch=2.99e+3, valid_loss=3.88e+3]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.88e+3]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.88e+3]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+3, train_loss_epoch=2.93e+3, valid_loss=3.88e+3]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.88e+3]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.88e+3]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.88e+3]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=3.88e+3]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.88e+3]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.88e+3]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.88e+3]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.88e+3]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.88e+3]\n",
            "Epoch 740: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.88e+3]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=3.88e+3]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=2.79e+3, valid_loss=3.88e+3]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.88e+3]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=3.88e+3]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.88e+3]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.88e+3]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.88e+3]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.88e+3]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.88e+3]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+3, train_loss_epoch=2.77e+3, valid_loss=3.88e+3]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.88e+3]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=3.88e+3]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.88e+3]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.88e+3]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.88e+3]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.88e+3]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.88e+3]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.88e+3]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.88e+3]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+3, train_loss_epoch=2.82e+3, valid_loss=3.88e+3]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.88e+3]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.88e+3]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.88e+3]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=2.79e+3, valid_loss=3.88e+3]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=3.88e+3]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.88e+3]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.91e+3, train_loss_epoch=2.91e+3, valid_loss=3.88e+3]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.88e+3]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.88e+3]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.88e+3]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.88e+3]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.88e+3]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+3, train_loss_epoch=2.88e+3, valid_loss=3.88e+3]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.88e+3]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.88e+3]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.88e+3]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.7e+3, valid_loss=3.88e+3]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.88e+3]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.88e+3]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.88e+3]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.88e+3]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.88e+3]\n",
            "Epoch 782: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.88e+3]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.88e+3]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.88e+3]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=3.88e+3]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+3, train_loss_epoch=2.76e+3, valid_loss=3.88e+3]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.88e+3]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.88e+3]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+3, train_loss_epoch=2.9e+3, valid_loss=3.88e+3]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+3, train_loss_epoch=2.64e+3, valid_loss=3.88e+3]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.88e+3]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.88e+3]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.88e+3]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.88e+3]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=3.88e+3]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+3, train_loss_epoch=2.8e+3, valid_loss=3.88e+3]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+3, train_loss_epoch=2.81e+3, valid_loss=3.88e+3]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+3, train_loss_epoch=2.82e+3, valid_loss=3.88e+3]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.88e+3]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.56e+3, valid_loss=3.88e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 148.98it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.14e+3]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.14e+3]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+3, train_loss_epoch=2.79e+3, valid_loss=3.14e+3]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.14e+3]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.14e+3]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.14e+3]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.14e+3]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.14e+3]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.14e+3]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.14e+3]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.14e+3]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.14e+3]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.14e+3]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.14e+3]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.14e+3]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.14e+3]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.14e+3]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.14e+3]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.14e+3]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.14e+3]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.14e+3]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.14e+3]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.14e+3]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=3.14e+3]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.14e+3]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.14e+3]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.14e+3]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.14e+3]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+3, train_loss_epoch=2.75e+3, valid_loss=3.14e+3]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.14e+3]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.14e+3]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.14e+3]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.14e+3]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.14e+3]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.14e+3]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+3, train_loss_epoch=2.83e+3, valid_loss=3.14e+3]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.14e+3]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=3.14e+3]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.14e+3]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.14e+3]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.14e+3]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.14e+3]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.14e+3]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.14e+3]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.14e+3]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.14e+3]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.14e+3]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.14e+3]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=3.14e+3]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.14e+3]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.7e+3, valid_loss=3.14e+3]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.14e+3]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.92e+3, train_loss_epoch=2.92e+3, valid_loss=3.14e+3]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.14e+3]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.14e+3]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.14e+3]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.14e+3]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.14e+3]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.14e+3]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.14e+3]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.14e+3]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.14e+3]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.14e+3]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.14e+3]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3, valid_loss=3.14e+3]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.14e+3]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.14e+3]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.14e+3]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.14e+3]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.14e+3]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.14e+3]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+3, train_loss_epoch=2.34e+3, valid_loss=3.14e+3]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.14e+3]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.14e+3]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.14e+3]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.14e+3]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.14e+3]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.14e+3]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.14e+3]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.14e+3]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.14e+3]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.14e+3]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.14e+3]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.14e+3]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=3.14e+3]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.14e+3]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.14e+3]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.14e+3]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.14e+3]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+3, train_loss_epoch=2.71e+3, valid_loss=3.14e+3]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.14e+3]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.14e+3]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.14e+3]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.14e+3]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.14e+3]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.14e+3]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.14e+3]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.14e+3]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.14e+3]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.14e+3]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.42e+3, valid_loss=3.14e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 94.14it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.35e+3]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.35e+3]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.35e+3]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.7e+3, valid_loss=3.35e+3]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.35e+3]\n",
            "Epoch 904: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.35e+3]\n",
            "Epoch 904: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.35e+3]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+3, train_loss_epoch=2.74e+3, valid_loss=3.35e+3]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.35e+3]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.35e+3]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.35e+3]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.35e+3]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.35e+3]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.35e+3]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.35e+3]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.35e+3]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.35e+3]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.35e+3]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.35e+3]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.35e+3]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+3, train_loss_epoch=2.68e+3, valid_loss=3.35e+3]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.35e+3]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.35e+3]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.35e+3]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.35e+3]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.35e+3]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.35e+3]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.35e+3]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.35e+3]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+3, train_loss_epoch=2.69e+3, valid_loss=3.35e+3]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.35e+3]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+3, train_loss_epoch=2.7e+3, valid_loss=3.35e+3]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.35e+3]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.35e+3]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.35e+3]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.35e+3]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.35e+3]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.35e+3]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.35e+3]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+3, train_loss_epoch=2.72e+3, valid_loss=3.35e+3]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.35e+3]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.35e+3]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.35e+3]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.35e+3]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+3, train_loss_epoch=2.64e+3, valid_loss=3.35e+3]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.35e+3]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.35e+3]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.24e+3, train_loss_epoch=2.24e+3, valid_loss=3.35e+3]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.35e+3]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.35e+3]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.35e+3]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.35e+3]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.35e+3]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.35e+3]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.35e+3]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.35e+3]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.35e+3]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.35e+3]\n",
            "Epoch 955: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.35e+3]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=3.35e+3]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.35e+3]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.35e+3]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=3.35e+3]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.35e+3]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.35e+3]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.35e+3]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.35e+3]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+3, train_loss_epoch=2.55e+3, valid_loss=3.35e+3]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.35e+3]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+3, train_loss_epoch=2.21e+3, valid_loss=3.35e+3]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.35e+3]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3, valid_loss=3.35e+3]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+3, train_loss_epoch=2.27e+3, valid_loss=3.35e+3]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.35e+3]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.35e+3]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.35e+3]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.35e+3]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.35e+3]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.35e+3]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.35e+3]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.35e+3]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.35e+3]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.35e+3]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.35e+3]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.35e+3]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.35e+3]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.35e+3]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.35e+3]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.35e+3]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.35e+3]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.35e+3]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+3, train_loss_epoch=2.34e+3, valid_loss=3.35e+3]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.35e+3]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.35e+3]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+3, train_loss_epoch=2.34e+3, valid_loss=3.35e+3]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.35e+3]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.35e+3]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.35e+3]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.35e+3]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.35e+3]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.35e+3]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.35e+3]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.35e+3]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.37e+3, valid_loss=3.35e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.46it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.91e+3]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.91e+3]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.91e+3]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.91e+3]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.91e+3]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.91e+3]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.91e+3]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.91e+3]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.91e+3]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.91e+3]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.91e+3]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=2.26e+3, valid_loss=3.91e+3]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.91e+3]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.91e+3]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+3, train_loss_epoch=2.54e+3, valid_loss=3.91e+3]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.91e+3]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.91e+3]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=3.91e+3]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.91e+3]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.91e+3]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=3.91e+3]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+3, train_loss_epoch=2.57e+3, valid_loss=3.91e+3]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.91e+3]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.91e+3]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.91e+3]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.91e+3]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.23e+3, train_loss_epoch=2.23e+3, valid_loss=3.91e+3]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.91e+3]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+3, train_loss_epoch=2.1e+3, valid_loss=3.91e+3]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.91e+3]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.91e+3]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+3, train_loss_epoch=2.66e+3, valid_loss=3.91e+3]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+3, train_loss_epoch=2.56e+3, valid_loss=3.91e+3]\n",
            "Epoch 1032: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.56e+3, valid_loss=3.91e+3]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.91e+3]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.91e+3]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3, valid_loss=3.91e+3]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.91e+3]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.91e+3]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.91e+3]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.91e+3]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.91e+3]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.91e+3]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+3, train_loss_epoch=2.6e+3, valid_loss=3.91e+3]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3, valid_loss=3.91e+3]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+3, train_loss_epoch=2.5e+3, valid_loss=3.91e+3]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.91e+3]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=2.26e+3, valid_loss=3.91e+3]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=3.91e+3]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.91e+3]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.91e+3]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.91e+3]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+3, train_loss_epoch=2.63e+3, valid_loss=3.91e+3]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.91e+3]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.91e+3]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.91e+3]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.91e+3]\n",
            "Epoch 1055: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.91e+3]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.91e+3]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+3, train_loss_epoch=2.58e+3, valid_loss=3.91e+3]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+3, train_loss_epoch=2.31e+3, valid_loss=3.91e+3]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.91e+3]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.91e+3]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.91e+3]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+3, train_loss_epoch=2.67e+3, valid_loss=3.91e+3]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.91e+3]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.91e+3]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.91e+3]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.91e+3]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.22e+3, train_loss_epoch=2.22e+3, valid_loss=3.91e+3]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.91e+3]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.91e+3]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+3, train_loss_epoch=2.27e+3, valid_loss=3.91e+3]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.91e+3]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.91e+3]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.91e+3]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.91e+3]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.91e+3]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.91e+3]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+3, train_loss_epoch=2.31e+3, valid_loss=3.91e+3]\n",
            "Epoch 1077: 100%|██████████| 1/1 [00:00<00:00,  2.98it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.31e+3, valid_loss=3.91e+3]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.91e+3]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+3, train_loss_epoch=2.2e+3, valid_loss=3.91e+3]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.91e+3]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+3, train_loss_epoch=2.62e+3, valid_loss=3.91e+3]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.91e+3]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=2.26e+3, valid_loss=3.91e+3]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.91e+3]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+3, train_loss_epoch=2.34e+3, valid_loss=3.91e+3]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.91e+3]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.91e+3]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.91e+3]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.91e+3]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.91e+3]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.91e+3]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=2.26e+3, valid_loss=3.91e+3]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.91e+3]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=2.26e+3, valid_loss=3.91e+3]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+3, train_loss_epoch=2.27e+3, valid_loss=3.91e+3]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.91e+3]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.91e+3]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.91e+3]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=3.91e+3]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.28e+3, valid_loss=3.91e+3]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.45it/s]\u001b[A\n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=3.72e+3]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.72e+3]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+3, train_loss_epoch=2.35e+3, valid_loss=3.72e+3]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.72e+3]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+3, train_loss_epoch=2.52e+3, valid_loss=3.72e+3]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.72e+3]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+3, train_loss_epoch=2.61e+3, valid_loss=3.72e+3]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+3, train_loss_epoch=2.27e+3, valid_loss=3.72e+3]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.72e+3]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+3, train_loss_epoch=2.21e+3, valid_loss=3.72e+3]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.72e+3]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.72e+3]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.72e+3]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=3.72e+3]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.72e+3]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+3, train_loss_epoch=2.48e+3, valid_loss=3.72e+3]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.01e+3, train_loss_epoch=2.01e+3, valid_loss=3.72e+3]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.72e+3]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+3, train_loss_epoch=2.65e+3, valid_loss=3.72e+3]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=3.72e+3]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.72e+3]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+3, train_loss_epoch=2.45e+3, valid_loss=3.72e+3]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+3, train_loss_epoch=2.26e+3, valid_loss=3.72e+3]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.72e+3]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+3, train_loss_epoch=2.31e+3, valid_loss=3.72e+3]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.72e+3]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.72e+3]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=3.72e+3]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.72e+3]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.72e+3]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.72e+3]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.72e+3]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.72e+3]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+3, train_loss_epoch=2.2e+3, valid_loss=3.72e+3]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.72e+3]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+3, train_loss_epoch=2.49e+3, valid_loss=3.72e+3]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+3, train_loss_epoch=2.47e+3, valid_loss=3.72e+3]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3, valid_loss=3.72e+3]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.72e+3]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+3, train_loss_epoch=2.16e+3, valid_loss=3.72e+3]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.39e+3, train_loss_epoch=2.39e+3, valid_loss=3.72e+3]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.72e+3]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.72e+3]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+3, train_loss_epoch=2.53e+3, valid_loss=3.72e+3]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.72e+3]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+3, train_loss_epoch=2.34e+3, valid_loss=3.72e+3]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+3, train_loss_epoch=2.38e+3, valid_loss=3.72e+3]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.72e+3]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+3, train_loss_epoch=2.42e+3, valid_loss=3.72e+3]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+3, train_loss_epoch=2.2e+3, valid_loss=3.72e+3]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=3.72e+3]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+3, train_loss_epoch=2.21e+3, valid_loss=3.72e+3]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.72e+3]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.72e+3]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.72e+3]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.72e+3]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.72e+3]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=3.72e+3]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.72e+3]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.72e+3]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.72e+3]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.72e+3]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+3, train_loss_epoch=2.36e+3, valid_loss=3.72e+3]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+3, train_loss_epoch=2.27e+3, valid_loss=3.72e+3]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+3, train_loss_epoch=2.37e+3, valid_loss=3.72e+3]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+3, train_loss_epoch=2.19e+3, valid_loss=3.72e+3]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+3, train_loss_epoch=2.59e+3, valid_loss=3.72e+3]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.72e+3]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.29e+3, train_loss_epoch=2.29e+3, valid_loss=3.72e+3]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+3, train_loss_epoch=2.2e+3, valid_loss=3.72e+3]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.17e+3, train_loss_epoch=2.17e+3, valid_loss=3.72e+3]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+3, train_loss_epoch=2.4e+3, valid_loss=3.72e+3]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+3, train_loss_epoch=2.46e+3, valid_loss=3.72e+3]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.72e+3]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+3, train_loss_epoch=2.28e+3, valid_loss=3.72e+3]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+3, train_loss_epoch=2.41e+3, valid_loss=3.72e+3]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.14e+3, train_loss_epoch=2.14e+3, valid_loss=3.72e+3]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.72e+3]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.72e+3]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.72e+3]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.72e+3]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.14e+3, train_loss_epoch=2.14e+3, valid_loss=3.72e+3]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.24e+3, train_loss_epoch=2.24e+3, valid_loss=3.72e+3]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+3, train_loss_epoch=2.21e+3, valid_loss=3.72e+3]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+3, train_loss_epoch=2.33e+3, valid_loss=3.72e+3]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+3, train_loss_epoch=2.44e+3, valid_loss=3.72e+3]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.14e+3, train_loss_epoch=2.14e+3, valid_loss=3.72e+3]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+3, train_loss_epoch=2.43e+3, valid_loss=3.72e+3]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+3, train_loss_epoch=2.51e+3, valid_loss=3.72e+3]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.31e+3, train_loss_epoch=2.31e+3, valid_loss=3.72e+3]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=50932)\u001b[0m `Trainer.fit` stopped: `max_steps=1200.0` reached.\n",
            "2025-06-15 20:51:05,557\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=2.32e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  2.89it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.32e+3, valid_loss=3.72e+3]\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 140.38it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=50932)\u001b[0m \r                                                                       \u001b[A\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.32e+3, valid_loss=3.53e+3]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3, valid_loss=3.53e+3]\rEpoch 1199: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s, v_num=0, train_loss_step=2.25e+3, train_loss_epoch=2.25e+3, valid_loss=3.53e+3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=52718)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 2025-06-15 20:51:19.965228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m E0000 00:00:1750020679.995844   52814 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m E0000 00:00:1750020680.006188   52814 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 2025-06-15 20:51:20.038106: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 3 | blocks       | ModuleList    | 7.8 M  | train\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 7.8 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 7.8 M     Total params\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 31.336    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 39.80it/s]\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \r                                                                           \r\rTraining: |          | 0/? [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.337, train_loss_epoch=0.337]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.126, train_loss_epoch=0.126]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.132, train_loss_epoch=0.132]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0787, train_loss_epoch=0.0787]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0721, train_loss_epoch=0.0721]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0702, train_loss_epoch=0.0702]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0591, train_loss_epoch=0.0591]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0563, train_loss_epoch=0.0563]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0555, train_loss_epoch=0.0555]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0484, train_loss_epoch=0.0484]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0497, train_loss_epoch=0.0497]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0408, train_loss_epoch=0.0408]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0385, train_loss_epoch=0.0385]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0364, train_loss_epoch=0.0364]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0296, train_loss_epoch=0.0296]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0246, train_loss_epoch=0.0246]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0238, train_loss_epoch=0.0238]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.022, train_loss_epoch=0.022]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00954, train_loss_epoch=0.00954]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00996, train_loss_epoch=0.00996]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00881, train_loss_epoch=0.00881]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00853, train_loss_epoch=0.00853]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00988, train_loss_epoch=0.00988]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.010, train_loss_epoch=0.010]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00846, train_loss_epoch=0.00846]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00942, train_loss_epoch=0.00942]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00907, train_loss_epoch=0.00907]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00711, train_loss_epoch=0.00711]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00779, train_loss_epoch=0.00779]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00796, train_loss_epoch=0.00796]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00747, train_loss_epoch=0.00747]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00769, train_loss_epoch=0.00769]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00698, train_loss_epoch=0.00698]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00726, train_loss_epoch=0.00726]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00654, train_loss_epoch=0.00654]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0069, train_loss_epoch=0.0069]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00743, train_loss_epoch=0.00743]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00678, train_loss_epoch=0.00678]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00691, train_loss_epoch=0.00691]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00862, train_loss_epoch=0.00862]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00803, train_loss_epoch=0.00803]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00651, train_loss_epoch=0.00651]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00717, train_loss_epoch=0.00717]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00848, train_loss_epoch=0.00848]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00798, train_loss_epoch=0.00798]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00679, train_loss_epoch=0.00679]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00632, train_loss_epoch=0.00632]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00734, train_loss_epoch=0.00734]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00807, train_loss_epoch=0.00807]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00708, train_loss_epoch=0.00708]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00681, train_loss_epoch=0.00681]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00732, train_loss_epoch=0.00732]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00891, train_loss_epoch=0.00891]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00972, train_loss_epoch=0.00972]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss_step=0.00995, train_loss_epoch=0.00783]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.18it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00995, train_loss_epoch=0.00995, valid_loss=0.0372]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00885, train_loss_epoch=0.00885, valid_loss=0.0372]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00872, train_loss_epoch=0.00872, valid_loss=0.0372]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0372]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00932, train_loss_epoch=0.00932, valid_loss=0.0372]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.0372]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00975, train_loss_epoch=0.00975, valid_loss=0.0372]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00757, train_loss_epoch=0.00757, valid_loss=0.0372]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00975, train_loss_epoch=0.00975, valid_loss=0.0372]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00801, train_loss_epoch=0.00801, valid_loss=0.0372]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00757, train_loss_epoch=0.00757, valid_loss=0.0372]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00943, train_loss_epoch=0.00943, valid_loss=0.0372]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00827, train_loss_epoch=0.00827, valid_loss=0.0372]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00702, train_loss_epoch=0.00702, valid_loss=0.0372]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00817, train_loss_epoch=0.00817, valid_loss=0.0372]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00706, train_loss_epoch=0.00706, valid_loss=0.0372]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00669, train_loss_epoch=0.00669, valid_loss=0.0372]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00651, train_loss_epoch=0.00651, valid_loss=0.0372]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.0372]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00553, train_loss_epoch=0.00553, valid_loss=0.0372]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00561, train_loss_epoch=0.00561, valid_loss=0.0372]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00495, train_loss_epoch=0.00495, valid_loss=0.0372]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.0372]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00536, train_loss_epoch=0.00536, valid_loss=0.0372]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00482, train_loss_epoch=0.00482, valid_loss=0.0372]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.0372]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00513, train_loss_epoch=0.00513, valid_loss=0.0372]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0372]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00493, train_loss_epoch=0.00493, valid_loss=0.0372]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00483, train_loss_epoch=0.00483, valid_loss=0.0372]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00628, train_loss_epoch=0.00628, valid_loss=0.0372]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00624, train_loss_epoch=0.00624, valid_loss=0.0372]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0372]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00703, train_loss_epoch=0.00703, valid_loss=0.0372]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0072, train_loss_epoch=0.0072, valid_loss=0.0372]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00663, train_loss_epoch=0.00663, valid_loss=0.0372]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00525, train_loss_epoch=0.00525, valid_loss=0.0372]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00652, train_loss_epoch=0.00652, valid_loss=0.0372]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00694, train_loss_epoch=0.00694, valid_loss=0.0372]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=0.0372]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00527, train_loss_epoch=0.00527, valid_loss=0.0372]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00487, train_loss_epoch=0.00487, valid_loss=0.0372]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00874, train_loss_epoch=0.00874, valid_loss=0.0372]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00786, train_loss_epoch=0.00786, valid_loss=0.0372]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00492, train_loss_epoch=0.00492, valid_loss=0.0372]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00892, train_loss_epoch=0.00892, valid_loss=0.0372]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00859, train_loss_epoch=0.00859, valid_loss=0.0372]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0065, train_loss_epoch=0.0065, valid_loss=0.0372]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00918, train_loss_epoch=0.00918, valid_loss=0.0372]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00844, train_loss_epoch=0.00844, valid_loss=0.0372]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00758, train_loss_epoch=0.00758, valid_loss=0.0372]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0083, train_loss_epoch=0.0083, valid_loss=0.0372]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00785, train_loss_epoch=0.00785, valid_loss=0.0372]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=0.0372]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00781, train_loss_epoch=0.00781, valid_loss=0.0372]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00672, train_loss_epoch=0.00672, valid_loss=0.0372]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00764, train_loss_epoch=0.00764, valid_loss=0.0372]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00657, train_loss_epoch=0.00657, valid_loss=0.0372]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=0.0372]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00583, train_loss_epoch=0.00583, valid_loss=0.0372]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00743, train_loss_epoch=0.00743, valid_loss=0.0372]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00622, valid_loss=0.0372]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00836, train_loss_epoch=0.00836, valid_loss=0.0372]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00718, train_loss_epoch=0.00718, valid_loss=0.0372]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00653, train_loss_epoch=0.00653, valid_loss=0.0372]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00624, train_loss_epoch=0.00624, valid_loss=0.0372]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00569, train_loss_epoch=0.00569, valid_loss=0.0372]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00564, train_loss_epoch=0.00564, valid_loss=0.0372]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00649, train_loss_epoch=0.00649, valid_loss=0.0372]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00586, train_loss_epoch=0.00586, valid_loss=0.0372]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00606, train_loss_epoch=0.00606, valid_loss=0.0372]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00555, train_loss_epoch=0.00555, valid_loss=0.0372]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00561, train_loss_epoch=0.00561, valid_loss=0.0372]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00549, train_loss_epoch=0.00549, valid_loss=0.0372]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0048, train_loss_epoch=0.0048, valid_loss=0.0372]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0051, train_loss_epoch=0.0051, valid_loss=0.0372]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0372]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00493, train_loss_epoch=0.00493, valid_loss=0.0372]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=0.0372]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0372]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0051, train_loss_epoch=0.0051, valid_loss=0.0372]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=0.0372]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=0.0372]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00785, train_loss_epoch=0.00785, valid_loss=0.0372]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0051, train_loss_epoch=0.0051, valid_loss=0.0372]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00543, train_loss_epoch=0.00543, valid_loss=0.0372]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00605, train_loss_epoch=0.00605, valid_loss=0.0372]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=0.0372]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00487, train_loss_epoch=0.00487, valid_loss=0.0372]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00485, train_loss_epoch=0.00485, valid_loss=0.0372]\n",
            "Epoch 189: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0372] \n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0372]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=0.0372]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00613, train_loss_epoch=0.00613, valid_loss=0.0372]\n",
            "Epoch 192: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s, v_num=0, train_loss_step=0.00439, train_loss_epoch=0.00439, valid_loss=0.0372]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00439, train_loss_epoch=0.00439, valid_loss=0.0372]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00471, train_loss_epoch=0.00471, valid_loss=0.0372]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00408, train_loss_epoch=0.00408, valid_loss=0.0372]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0047, train_loss_epoch=0.0047, valid_loss=0.0372]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00677, train_loss_epoch=0.00677, valid_loss=0.0372]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00651, train_loss_epoch=0.00651, valid_loss=0.0372]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00447, train_loss_epoch=0.00447, valid_loss=0.0372]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s, v_num=0, train_loss_step=0.00498, train_loss_epoch=0.00447, valid_loss=0.0372]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 125.82it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00498, train_loss_epoch=0.00498, valid_loss=0.034]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00671, train_loss_epoch=0.00671, valid_loss=0.034]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00658, train_loss_epoch=0.00658, valid_loss=0.034]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00464, train_loss_epoch=0.00464, valid_loss=0.034]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00444, train_loss_epoch=0.00444, valid_loss=0.034]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00578, train_loss_epoch=0.00578, valid_loss=0.034]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00686, train_loss_epoch=0.00686, valid_loss=0.034]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss_step=0.00502, train_loss_epoch=0.00686, valid_loss=0.034]\n",
            "Epoch 206: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s, v_num=0, train_loss_step=0.00502, train_loss_epoch=0.00502, valid_loss=0.034]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00502, train_loss_epoch=0.00502, valid_loss=0.034]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00456, train_loss_epoch=0.00456, valid_loss=0.034]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00568, train_loss_epoch=0.00568, valid_loss=0.034]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00775, train_loss_epoch=0.00775, valid_loss=0.034]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00517, train_loss_epoch=0.00517, valid_loss=0.034]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=0.034]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=0.034]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.034]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00949, train_loss_epoch=0.00949, valid_loss=0.034]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00716, valid_loss=0.034]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00838, train_loss_epoch=0.00838, valid_loss=0.034]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00841, train_loss_epoch=0.00841, valid_loss=0.034]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=0.034]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00819, train_loss_epoch=0.00819, valid_loss=0.034]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=0.034]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.034]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00683, train_loss_epoch=0.00683, valid_loss=0.034]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00496, train_loss_epoch=0.00496, valid_loss=0.034]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00515, train_loss_epoch=0.00515, valid_loss=0.034]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00589, train_loss_epoch=0.00589, valid_loss=0.034]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=0.034]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00432, train_loss_epoch=0.00432, valid_loss=0.034]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00571, train_loss_epoch=0.00571, valid_loss=0.034]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00536, train_loss_epoch=0.00536, valid_loss=0.034]\n",
            "Epoch 230: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.034]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.034]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00501, valid_loss=0.034]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00492, train_loss_epoch=0.00492, valid_loss=0.034]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00552, train_loss_epoch=0.00552, valid_loss=0.034]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00536, train_loss_epoch=0.00536, valid_loss=0.034]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00484, train_loss_epoch=0.00484, valid_loss=0.034]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00437, train_loss_epoch=0.00437, valid_loss=0.034]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00419, train_loss_epoch=0.00419, valid_loss=0.034]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00443, train_loss_epoch=0.00443, valid_loss=0.034]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0065, train_loss_epoch=0.0065, valid_loss=0.034]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00633, train_loss_epoch=0.00633, valid_loss=0.034]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00504, train_loss_epoch=0.00504, valid_loss=0.034]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00657, train_loss_epoch=0.00657, valid_loss=0.034]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00683, train_loss_epoch=0.00683, valid_loss=0.034]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0055, train_loss_epoch=0.0055, valid_loss=0.034]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00693, train_loss_epoch=0.00693, valid_loss=0.034]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.034]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00565, train_loss_epoch=0.00565, valid_loss=0.034]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00718, train_loss_epoch=0.00718, valid_loss=0.034]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00577, train_loss_epoch=0.00577, valid_loss=0.034]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00612, train_loss_epoch=0.00612, valid_loss=0.034]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00703, train_loss_epoch=0.00703, valid_loss=0.034]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00443, train_loss_epoch=0.00443, valid_loss=0.034]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00557, train_loss_epoch=0.00557, valid_loss=0.034]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00612, train_loss_epoch=0.00612, valid_loss=0.034]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00633, train_loss_epoch=0.00633, valid_loss=0.034]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00575, train_loss_epoch=0.00575, valid_loss=0.034]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00514, train_loss_epoch=0.00514, valid_loss=0.034]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00562, train_loss_epoch=0.00562, valid_loss=0.034]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0048, train_loss_epoch=0.0048, valid_loss=0.034]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0053, train_loss_epoch=0.0053, valid_loss=0.034]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00465, train_loss_epoch=0.00465, valid_loss=0.034]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00493, train_loss_epoch=0.00493, valid_loss=0.034]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00403, train_loss_epoch=0.00403, valid_loss=0.034]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00506, train_loss_epoch=0.00506, valid_loss=0.034]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00463, train_loss_epoch=0.00463, valid_loss=0.034]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0051, train_loss_epoch=0.0051, valid_loss=0.034]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00432, train_loss_epoch=0.00432, valid_loss=0.034]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00464, train_loss_epoch=0.00464, valid_loss=0.034]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00464, valid_loss=0.034]\n",
            "Epoch 269: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00438, valid_loss=0.034]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00438, train_loss_epoch=0.00438, valid_loss=0.034]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.034]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=0.034]\n",
            "Epoch 272: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s, v_num=0, train_loss_step=0.00433, train_loss_epoch=0.00534, valid_loss=0.034]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00433, train_loss_epoch=0.00433, valid_loss=0.034]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00501, valid_loss=0.034]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00654, train_loss_epoch=0.00654, valid_loss=0.034]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.034]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00495, train_loss_epoch=0.00495, valid_loss=0.034]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00723, train_loss_epoch=0.00723, valid_loss=0.034]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00594, train_loss_epoch=0.00594, valid_loss=0.034]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00528, train_loss_epoch=0.00528, valid_loss=0.034]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00739, train_loss_epoch=0.00739, valid_loss=0.034]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00594, train_loss_epoch=0.00594, valid_loss=0.034]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=0.034]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.034]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.034]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=0.034]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.034]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0048, train_loss_epoch=0.0048, valid_loss=0.034]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00509, train_loss_epoch=0.00509, valid_loss=0.034]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=0.034]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00465, train_loss_epoch=0.00465, valid_loss=0.034]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=0.034]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00536, train_loss_epoch=0.00536, valid_loss=0.034]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00522, train_loss_epoch=0.00522, valid_loss=0.034]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00519, valid_loss=0.034]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00581, train_loss_epoch=0.00581, valid_loss=0.034]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00672, train_loss_epoch=0.00672, valid_loss=0.034]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00527, train_loss_epoch=0.00527, valid_loss=0.034]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.034]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00636, valid_loss=0.034]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 126.16it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00519, valid_loss=0.0358]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.0358]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=0.0358]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00695, train_loss_epoch=0.00695, valid_loss=0.0358]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00668, train_loss_epoch=0.00668, valid_loss=0.0358]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00623, train_loss_epoch=0.00623, valid_loss=0.0358]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.0358]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00511, train_loss_epoch=0.00511, valid_loss=0.0358]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00739, train_loss_epoch=0.00739, valid_loss=0.0358]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00535, train_loss_epoch=0.00535, valid_loss=0.0358]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00673, train_loss_epoch=0.00673, valid_loss=0.0358]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00631, train_loss_epoch=0.00631, valid_loss=0.0358]\n",
            "Epoch 311: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s, v_num=0, train_loss_step=0.00664, train_loss_epoch=0.00631, valid_loss=0.0358]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00664, train_loss_epoch=0.00664, valid_loss=0.0358]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00531, train_loss_epoch=0.00531, valid_loss=0.0358]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0073, train_loss_epoch=0.0073, valid_loss=0.0358]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=0.0358]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=0.0358]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.0358]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=0.0358]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0055, train_loss_epoch=0.0055, valid_loss=0.0358]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.0358]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00554, train_loss_epoch=0.00554, valid_loss=0.0358]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00586, train_loss_epoch=0.00586, valid_loss=0.0358]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00578, train_loss_epoch=0.00578, valid_loss=0.0358]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0358]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0048, train_loss_epoch=0.0048, valid_loss=0.0358]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00599, train_loss_epoch=0.00599, valid_loss=0.0358]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00559, train_loss_epoch=0.00559, valid_loss=0.0358]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00513, train_loss_epoch=0.00513, valid_loss=0.0358]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00496, train_loss_epoch=0.00496, valid_loss=0.0358]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00476, train_loss_epoch=0.00476, valid_loss=0.0358]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.0358]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00393, train_loss_epoch=0.00393, valid_loss=0.0358]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00491, train_loss_epoch=0.00491, valid_loss=0.0358]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00425, train_loss_epoch=0.00425, valid_loss=0.0358]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00516, train_loss_epoch=0.00516, valid_loss=0.0358]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00414, train_loss_epoch=0.00414, valid_loss=0.0358]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00399, train_loss_epoch=0.00399, valid_loss=0.0358]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00309, train_loss_epoch=0.00309, valid_loss=0.0358]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00332, train_loss_epoch=0.00332, valid_loss=0.0358]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00328, train_loss_epoch=0.00328, valid_loss=0.0358]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=0.0358]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0029, train_loss_epoch=0.0029, valid_loss=0.0358]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00258, train_loss_epoch=0.00258, valid_loss=0.0358]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0358]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00268, train_loss_epoch=0.00268, valid_loss=0.0358]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00295, train_loss_epoch=0.00295, valid_loss=0.0358]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00216, train_loss_epoch=0.00216, valid_loss=0.0358]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=0.0358]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00195, train_loss_epoch=0.00195, valid_loss=0.0358]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=0.0358]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0358]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00208, train_loss_epoch=0.00208, valid_loss=0.0358]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00194, train_loss_epoch=0.00194, valid_loss=0.0358]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0018, train_loss_epoch=0.0018, valid_loss=0.0358]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00183, train_loss_epoch=0.00183, valid_loss=0.0358]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00188, train_loss_epoch=0.00188, valid_loss=0.0358]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0358]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00232, train_loss_epoch=0.00232, valid_loss=0.0358]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00306, train_loss_epoch=0.00306, valid_loss=0.0358]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0358]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00247, train_loss_epoch=0.00247, valid_loss=0.0358]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00318, train_loss_epoch=0.00318, valid_loss=0.0358]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=0.0358]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0034, train_loss_epoch=0.0034, valid_loss=0.0358]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00323, train_loss_epoch=0.00323, valid_loss=0.0358]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00261, train_loss_epoch=0.00261, valid_loss=0.0358]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00351, train_loss_epoch=0.00351, valid_loss=0.0358]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0358]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00262, train_loss_epoch=0.00262, valid_loss=0.0358]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0034, train_loss_epoch=0.0034, valid_loss=0.0358]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00282, train_loss_epoch=0.00282, valid_loss=0.0358]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00209, train_loss_epoch=0.00209, valid_loss=0.0358]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00322, train_loss_epoch=0.00322, valid_loss=0.0358]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=0.0358]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00304, train_loss_epoch=0.00304, valid_loss=0.0358]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00431, train_loss_epoch=0.00431, valid_loss=0.0358]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0358]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0033, train_loss_epoch=0.0033, valid_loss=0.0358]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00327, train_loss_epoch=0.00327, valid_loss=0.0358]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=0.0358]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=0.0358]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00345, train_loss_epoch=0.00345, valid_loss=0.0358]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00265, train_loss_epoch=0.00265, valid_loss=0.0358]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0033, train_loss_epoch=0.0033, valid_loss=0.0358]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00333, train_loss_epoch=0.00333, valid_loss=0.0358]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=0.0358]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00339, train_loss_epoch=0.00339, valid_loss=0.0358]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00303, train_loss_epoch=0.00303, valid_loss=0.0358]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0358]        \n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0358]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00279, train_loss_epoch=0.00279, valid_loss=0.0358]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00243, train_loss_epoch=0.00243, valid_loss=0.0358]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0358]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0358]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=0.0358]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=0.0358]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=0.0358]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00227, valid_loss=0.0358]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=0.0358]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00197, train_loss_epoch=0.00197, valid_loss=0.0358]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0358]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00235, valid_loss=0.0358]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.66it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0357]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0022, train_loss_epoch=0.0022, valid_loss=0.0357]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0357]\n",
            "Epoch 402: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=0, train_loss_step=0.00201, train_loss_epoch=0.00201, valid_loss=0.0357]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00201, train_loss_epoch=0.00201, valid_loss=0.0357]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00216, train_loss_epoch=0.00216, valid_loss=0.0357]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00208, train_loss_epoch=0.00208, valid_loss=0.0357]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0357]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0357]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=0.0357]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00299, train_loss_epoch=0.00299, valid_loss=0.0357]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=0.0357]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=0.0357]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0025, train_loss_epoch=0.0025, valid_loss=0.0357]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=0.0357]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00379, train_loss_epoch=0.00379, valid_loss=0.0357]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00257, train_loss_epoch=0.00257, valid_loss=0.0357]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00423, train_loss_epoch=0.00423, valid_loss=0.0357]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00333, train_loss_epoch=0.00333, valid_loss=0.0357]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=0.0357]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00439, train_loss_epoch=0.00439, valid_loss=0.0357]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00417, train_loss_epoch=0.00417, valid_loss=0.0357]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0039, train_loss_epoch=0.0039, valid_loss=0.0357]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s, v_num=0, train_loss_step=0.0039, train_loss_epoch=0.0039, valid_loss=0.0357]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00358, train_loss_epoch=0.00358, valid_loss=0.0357]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00432, train_loss_epoch=0.00432, valid_loss=0.0357]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0357]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00351, train_loss_epoch=0.00351, valid_loss=0.0357]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00338, train_loss_epoch=0.00338, valid_loss=0.0357]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00288, train_loss_epoch=0.00288, valid_loss=0.0357]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00327, train_loss_epoch=0.00327, valid_loss=0.0357]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00375, train_loss_epoch=0.00375, valid_loss=0.0357]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s, v_num=0, train_loss_step=0.00306, train_loss_epoch=0.00306, valid_loss=0.0357]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00306, train_loss_epoch=0.00306, valid_loss=0.0357]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00298, train_loss_epoch=0.00298, valid_loss=0.0357]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00274, train_loss_epoch=0.00274, valid_loss=0.0357]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0357]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00319, train_loss_epoch=0.00319, valid_loss=0.0357]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0357]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0357]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00259, train_loss_epoch=0.00259, valid_loss=0.0357]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0357]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0029, train_loss_epoch=0.0029, valid_loss=0.0357]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00232, train_loss_epoch=0.00232, valid_loss=0.0357]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0357]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0357]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=0.0357]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0357]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0357]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=0.0357]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=0.0357]\n",
            "Epoch 447: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0357]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0357]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00363, train_loss_epoch=0.00363, valid_loss=0.0357]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00293, train_loss_epoch=0.00293, valid_loss=0.0357]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00291, train_loss_epoch=0.00291, valid_loss=0.0357]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00383, train_loss_epoch=0.00383, valid_loss=0.0357]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00274, train_loss_epoch=0.00274, valid_loss=0.0357]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00323, train_loss_epoch=0.00323, valid_loss=0.0357]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00279, train_loss_epoch=0.00279, valid_loss=0.0357]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00314, train_loss_epoch=0.00314, valid_loss=0.0357]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00324, train_loss_epoch=0.00324, valid_loss=0.0357]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.003, train_loss_epoch=0.003, valid_loss=0.0357]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00284, train_loss_epoch=0.00284, valid_loss=0.0357]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0357]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0357]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=0.0357]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=0.0357]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00214, train_loss_epoch=0.00214, valid_loss=0.0357]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0357]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0357]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0357]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0357]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0357]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=0.0357]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0357]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0357]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0357]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00211, train_loss_epoch=0.00211, valid_loss=0.0357]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0357]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0018, train_loss_epoch=0.0018, valid_loss=0.0357]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=0.0357]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00208, train_loss_epoch=0.00208, valid_loss=0.0357]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0357]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=0.0357]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0029, train_loss_epoch=0.0029, valid_loss=0.0357]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00283, train_loss_epoch=0.00283, valid_loss=0.0357]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=0.0357]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00348, train_loss_epoch=0.00348, valid_loss=0.0357]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00332, train_loss_epoch=0.00332, valid_loss=0.0357]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=0.0357]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=0.0357]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00364, train_loss_epoch=0.00364, valid_loss=0.0357]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00272, train_loss_epoch=0.00272, valid_loss=0.0357]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00412, train_loss_epoch=0.00412, valid_loss=0.0357]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00335, train_loss_epoch=0.00335, valid_loss=0.0357]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00379, train_loss_epoch=0.00379, valid_loss=0.0357]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00299, train_loss_epoch=0.00299, valid_loss=0.0357]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00357, train_loss_epoch=0.00357, valid_loss=0.0357]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=0.0357]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=0.0357]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00264, train_loss_epoch=0.00264, valid_loss=0.0357]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00307, train_loss_epoch=0.00307, valid_loss=0.0357]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0357]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0357]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00277, valid_loss=0.0357]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.84it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=0.0351]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0351]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=0.0351]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00245, train_loss_epoch=0.00245, valid_loss=0.0351]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0351]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00223, train_loss_epoch=0.00223, valid_loss=0.0351]\n",
            "Epoch 505: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0351]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0351]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00224, train_loss_epoch=0.00224, valid_loss=0.0351]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00226, train_loss_epoch=0.00226, valid_loss=0.0351]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0351]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00225, train_loss_epoch=0.00225, valid_loss=0.0351]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00188, train_loss_epoch=0.00188, valid_loss=0.0351]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00199, train_loss_epoch=0.00199, valid_loss=0.0351]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0351]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00209, train_loss_epoch=0.00209, valid_loss=0.0351]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00188, train_loss_epoch=0.00188, valid_loss=0.0351]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=0.0351]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00255, train_loss_epoch=0.00255, valid_loss=0.0351]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0351]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00202, train_loss_epoch=0.00202, valid_loss=0.0351]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00208, train_loss_epoch=0.00208, valid_loss=0.0351]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00312, train_loss_epoch=0.00312, valid_loss=0.0351]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0351]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00244, train_loss_epoch=0.00244, valid_loss=0.0351]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=0.0351]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0351]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00269, train_loss_epoch=0.00269, valid_loss=0.0351]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00215, train_loss_epoch=0.00215, valid_loss=0.0351]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00209, train_loss_epoch=0.00209, valid_loss=0.0351]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00193, train_loss_epoch=0.00193, valid_loss=0.0351]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00227, valid_loss=0.0351]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00264, train_loss_epoch=0.00264, valid_loss=0.0351]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0351]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00202, train_loss_epoch=0.00202, valid_loss=0.0351]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0351]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0351]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0351]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00259, train_loss_epoch=0.00259, valid_loss=0.0351]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0351]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00194, train_loss_epoch=0.00194, valid_loss=0.0351]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0351]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=0.0351]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00351, train_loss_epoch=0.00351, valid_loss=0.0351]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00262, train_loss_epoch=0.00262, valid_loss=0.0351]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00246, train_loss_epoch=0.00246, valid_loss=0.0351]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0037, train_loss_epoch=0.0037, valid_loss=0.0351]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=0.0351]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0036, train_loss_epoch=0.0036, valid_loss=0.0351]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00321, train_loss_epoch=0.00321, valid_loss=0.0351]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00217, train_loss_epoch=0.00217, valid_loss=0.0351]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00341, train_loss_epoch=0.00341, valid_loss=0.0351]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00342, train_loss_epoch=0.00342, valid_loss=0.0351]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0351]\n",
            "Epoch 552: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0351]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0035, train_loss_epoch=0.0035, valid_loss=0.0351]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=0.0351]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0351]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0031, train_loss_epoch=0.0031, valid_loss=0.0351]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00254, train_loss_epoch=0.00254, valid_loss=0.0351]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=0.0351]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00371, train_loss_epoch=0.00371, valid_loss=0.0351]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0351]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00275, train_loss_epoch=0.00275, valid_loss=0.0351]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00283, train_loss_epoch=0.00283, valid_loss=0.0351]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0024, train_loss_epoch=0.0024, valid_loss=0.0351]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00228, train_loss_epoch=0.00228, valid_loss=0.0351]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00271, train_loss_epoch=0.00271, valid_loss=0.0351]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00262, train_loss_epoch=0.00262, valid_loss=0.0351]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00242, train_loss_epoch=0.00242, valid_loss=0.0351]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00264, train_loss_epoch=0.00264, valid_loss=0.0351]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00317, train_loss_epoch=0.00317, valid_loss=0.0351]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00256, valid_loss=0.0351]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00212, train_loss_epoch=0.00212, valid_loss=0.0351]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s, v_num=0, train_loss_step=0.00301, train_loss_epoch=0.00212, valid_loss=0.0351]\n",
            "Epoch 571: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss_step=0.00301, train_loss_epoch=0.00301, valid_loss=0.0351]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00301, train_loss_epoch=0.00301, valid_loss=0.0351]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00213, train_loss_epoch=0.00213, valid_loss=0.0351]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00251, train_loss_epoch=0.00251, valid_loss=0.0351]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00266, train_loss_epoch=0.00266, valid_loss=0.0351]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=0.0351]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00325, train_loss_epoch=0.00325, valid_loss=0.0351]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00251, train_loss_epoch=0.00251, valid_loss=0.0351]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0351]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00309, train_loss_epoch=0.00309, valid_loss=0.0351]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00249, train_loss_epoch=0.00249, valid_loss=0.0351]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0351]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=0.0351]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00218, train_loss_epoch=0.00218, valid_loss=0.0351]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00256, train_loss_epoch=0.00256, valid_loss=0.0351]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=0.0351]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00248, train_loss_epoch=0.00248, valid_loss=0.0351]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0351]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00265, train_loss_epoch=0.00265, valid_loss=0.0351]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.0027, valid_loss=0.0351]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0018, train_loss_epoch=0.0018, valid_loss=0.0351]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=0.0351]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00225, train_loss_epoch=0.00225, valid_loss=0.0351]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00225, train_loss_epoch=0.00225, valid_loss=0.0351]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00199, train_loss_epoch=0.00199, valid_loss=0.0351]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00222, train_loss_epoch=0.00222, valid_loss=0.0351]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=0.0351]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00203, train_loss_epoch=0.00203, valid_loss=0.0351]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00217, train_loss_epoch=0.00217, valid_loss=0.0351]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00217, valid_loss=0.0351]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 118.04it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=0.0338]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0338]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00211, train_loss_epoch=0.00211, valid_loss=0.0338]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00213, train_loss_epoch=0.00213, valid_loss=0.0338]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00198, train_loss_epoch=0.00198, valid_loss=0.0338]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=0.0338]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00192, train_loss_epoch=0.00192, valid_loss=0.0338]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0338]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0033, train_loss_epoch=0.0033, valid_loss=0.0338]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00246, train_loss_epoch=0.00246, valid_loss=0.0338]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00177, train_loss_epoch=0.00177, valid_loss=0.0338]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00182, train_loss_epoch=0.00182, valid_loss=0.0338]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00241, train_loss_epoch=0.00241, valid_loss=0.0338]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00296, train_loss_epoch=0.00296, valid_loss=0.0338]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00213, train_loss_epoch=0.00213, valid_loss=0.0338]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00235, train_loss_epoch=0.00235, valid_loss=0.0338]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00354, train_loss_epoch=0.00354, valid_loss=0.0338]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00272, train_loss_epoch=0.00272, valid_loss=0.0338]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0338]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00291, train_loss_epoch=0.00291, valid_loss=0.0338]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0023, train_loss_epoch=0.0023, valid_loss=0.0338]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00273, train_loss_epoch=0.00273, valid_loss=0.0338]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00309, train_loss_epoch=0.00309, valid_loss=0.0338]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00262, train_loss_epoch=0.00262, valid_loss=0.0338]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0338]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00289, train_loss_epoch=0.00289, valid_loss=0.0338]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0338]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00264, train_loss_epoch=0.00264, valid_loss=0.0338]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00278, train_loss_epoch=0.00278, valid_loss=0.0338]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00239, train_loss_epoch=0.00239, valid_loss=0.0338]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0026, train_loss_epoch=0.0026, valid_loss=0.0338]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00274, train_loss_epoch=0.00274, valid_loss=0.0338]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0025, train_loss_epoch=0.0025, valid_loss=0.0338]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=0.0338]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0338]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00185, train_loss_epoch=0.00185, valid_loss=0.0338]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0338]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00238, train_loss_epoch=0.00238, valid_loss=0.0338]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00221, train_loss_epoch=0.00221, valid_loss=0.0338]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0028, train_loss_epoch=0.0028, valid_loss=0.0338]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00231, train_loss_epoch=0.00231, valid_loss=0.0338]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00229, train_loss_epoch=0.00229, valid_loss=0.0338]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00227, train_loss_epoch=0.00227, valid_loss=0.0338]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00214, train_loss_epoch=0.00214, valid_loss=0.0338]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0338]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00234, train_loss_epoch=0.00234, valid_loss=0.0338]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00216, train_loss_epoch=0.00216, valid_loss=0.0338]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00207, train_loss_epoch=0.00207, valid_loss=0.0338]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00204, train_loss_epoch=0.00204, valid_loss=0.0338]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00236, train_loss_epoch=0.00236, valid_loss=0.0338]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=0.0338]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0021, train_loss_epoch=0.0021, valid_loss=0.0338]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0338]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00286, train_loss_epoch=0.00286, valid_loss=0.0338]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00253, train_loss_epoch=0.00253, valid_loss=0.0338]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00283, train_loss_epoch=0.00283, valid_loss=0.0338]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=0.0338]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0027, train_loss_epoch=0.0027, valid_loss=0.0338]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00312, train_loss_epoch=0.00312, valid_loss=0.0338]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00307, train_loss_epoch=0.00307, valid_loss=0.0338]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00287, train_loss_epoch=0.00287, valid_loss=0.0338]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00277, train_loss_epoch=0.00277, valid_loss=0.0338]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0025, train_loss_epoch=0.0025, valid_loss=0.0338]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00268, train_loss_epoch=0.00268, valid_loss=0.0338]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00292, train_loss_epoch=0.00292, valid_loss=0.0338]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00237, train_loss_epoch=0.00237, valid_loss=0.0338]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00285, train_loss_epoch=0.00285, valid_loss=0.0338]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00276, train_loss_epoch=0.00276, valid_loss=0.0338]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00201, train_loss_epoch=0.00201, valid_loss=0.0338]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00199, train_loss_epoch=0.00199, valid_loss=0.0338]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00189, train_loss_epoch=0.00189, valid_loss=0.0338]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00196, train_loss_epoch=0.00196, valid_loss=0.0338]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00153, train_loss_epoch=0.00153, valid_loss=0.0338]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0018, train_loss_epoch=0.0018, valid_loss=0.0338]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=0.0338]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0338]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0338]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00153, train_loss_epoch=0.00153, valid_loss=0.0338]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0338]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=0.0338]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0338]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0338]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0338]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0338]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0338]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=0.0338]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0338]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0338]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0338]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=0.0338]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=0.0338]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0338]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0338]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0338]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0338]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0338]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0338]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000996, train_loss_epoch=0.000996, valid_loss=0.0338]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0338]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0338]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.0011, valid_loss=0.0338]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 82.30it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0344]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0344]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0344]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=0.0344]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0344]\n",
            "Epoch 704: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.00116, valid_loss=0.0344] \n",
            "Epoch 704: 100%|██████████| 1/1 [00:00<00:00,  1.68it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0344] \n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0344]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=0.0344]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0344]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0344]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0344]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0344]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=0.0344]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0344]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=0.0344]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0344]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0344]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0344]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=0.0344]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0344]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=0.0344]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=0.0344]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0344]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0344]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0344]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0344]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0344]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0344]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=0.0344]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00154, train_loss_epoch=0.00154, valid_loss=0.0344]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0344]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0344]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0344]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0344]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00109, train_loss_epoch=0.00109, valid_loss=0.0344]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0344]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=0.0344]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00159, train_loss_epoch=0.00159, valid_loss=0.0344]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0344]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=0.0344]\n",
            "Epoch 738: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00131, valid_loss=0.0344]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0344]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0344]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00169, train_loss_epoch=0.00169, valid_loss=0.0344]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0344]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00154, train_loss_epoch=0.00154, valid_loss=0.0344]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00178, train_loss_epoch=0.00178, valid_loss=0.0344]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=0.0344]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00185, train_loss_epoch=0.00185, valid_loss=0.0344]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=0.0344]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0344]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00176, train_loss_epoch=0.00176, valid_loss=0.0344]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=0.0344]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=0.0344]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00174, train_loss_epoch=0.00174, valid_loss=0.0344]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0344]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=0.0344]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00152, train_loss_epoch=0.00152, valid_loss=0.0344]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=0.0344]\n",
            "Epoch 756: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0344]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0344]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0344]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0344]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0344]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=0.0344]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0344]        \n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0344]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=0.0344]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=0.0344]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0344]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=0.0344]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=0.0344]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0344]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=0.0344]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=0.0344]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00171, train_loss_epoch=0.00171, valid_loss=0.0344]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0344]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=0.0344]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00195, train_loss_epoch=0.00195, valid_loss=0.0344]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=0.0344]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=0.0344]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0344]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0344]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00166, train_loss_epoch=0.00166, valid_loss=0.0344]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0344]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0344]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=0.0344]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=0.0344]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0344]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0344]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0344]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0344]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=0.0344]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0344]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=0.0344]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0344]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000988, train_loss_epoch=0.000988, valid_loss=0.0344]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000939, train_loss_epoch=0.000939, valid_loss=0.0344]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=0.0344]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0344]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00148, train_loss_epoch=0.00148, valid_loss=0.0344]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0344]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0344]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0344]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.00108, valid_loss=0.0344] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.39it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.0017, valid_loss=0.0345]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0345]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0345]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00163, train_loss_epoch=0.00163, valid_loss=0.0345]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0345]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00138, train_loss_epoch=0.00138, valid_loss=0.0345]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00161, train_loss_epoch=0.00161, valid_loss=0.0345]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=0.0345]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0345]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0345]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00135, train_loss_epoch=0.00135, valid_loss=0.0345]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0345]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=0.0345]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00168, train_loss_epoch=0.00168, valid_loss=0.0345]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0345]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=0.0345]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0345]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=0.0345]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0345]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0345]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0345]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=0.0345]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00089, train_loss_epoch=0.00089, valid_loss=0.0345]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0345]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00162, train_loss_epoch=0.00162, valid_loss=0.0345]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0345]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00163, train_loss_epoch=0.00163, valid_loss=0.0345]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0345]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=0.0345]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=0.0345]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0345]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0345]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0345]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=0.0345]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0345]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=0.0345]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0345]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000945, train_loss_epoch=0.000945, valid_loss=0.0345]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0345]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=0.0345]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0345]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000992, train_loss_epoch=0.000992, valid_loss=0.0345]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00104, train_loss_epoch=0.00104, valid_loss=0.0345]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00122, train_loss_epoch=0.00122, valid_loss=0.0345]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0345]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=0.0345]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00124, train_loss_epoch=0.00124, valid_loss=0.0345]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0345]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00105, train_loss_epoch=0.00105, valid_loss=0.0345]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00133, train_loss_epoch=0.00133, valid_loss=0.0345]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0345]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=0.0345]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=0.0345]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=0.0345]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000962, train_loss_epoch=0.000962, valid_loss=0.0345]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0345]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=0.0345]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00087, train_loss_epoch=0.00087, valid_loss=0.0345]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000875, train_loss_epoch=0.000875, valid_loss=0.0345]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000895, train_loss_epoch=0.000895, valid_loss=0.0345]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0009, train_loss_epoch=0.0009, valid_loss=0.0345]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0345]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00167, train_loss_epoch=0.00167, valid_loss=0.0345]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=0.0345]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0345]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0345]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=0.0345]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0345]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=0.0345]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0014, train_loss_epoch=0.0014, valid_loss=0.0345]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0345]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00206, train_loss_epoch=0.00206, valid_loss=0.0345]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=0.0345]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00188, train_loss_epoch=0.00188, valid_loss=0.0345]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=0.0345]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0345]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0345]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0345]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0345]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=0.0345]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0345]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0345]\n",
            "Epoch 881: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=0.00171, train_loss_epoch=0.00171, valid_loss=0.0345]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00171, train_loss_epoch=0.00171, valid_loss=0.0345]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0345]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=0.0345]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00185, train_loss_epoch=0.00185, valid_loss=0.0345]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00136, train_loss_epoch=0.00136, valid_loss=0.0345]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00153, train_loss_epoch=0.00153, valid_loss=0.0345]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00149, train_loss_epoch=0.00149, valid_loss=0.0345]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0345]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00142, train_loss_epoch=0.00142, valid_loss=0.0345]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0345]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00121, train_loss_epoch=0.00121, valid_loss=0.0345]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0345]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=0.0345]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00127, train_loss_epoch=0.00127, valid_loss=0.0345]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00158, train_loss_epoch=0.00158, valid_loss=0.0345]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0345]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0345]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0345]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00172, valid_loss=0.0345]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.92it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0339]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00167, train_loss_epoch=0.00167, valid_loss=0.0339]\n",
            "Epoch 901: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0339]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0339]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00117, train_loss_epoch=0.00117, valid_loss=0.0339]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=0.0339]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00156, train_loss_epoch=0.00156, valid_loss=0.0339]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0339]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00192, train_loss_epoch=0.00192, valid_loss=0.0339]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0339]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00164, train_loss_epoch=0.00164, valid_loss=0.0339]\n",
            "Epoch 909: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=0, train_loss_step=0.00181, train_loss_epoch=0.00164, valid_loss=0.0339]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00181, train_loss_epoch=0.00181, valid_loss=0.0339]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00179, train_loss_epoch=0.00179, valid_loss=0.0339]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00147, train_loss_epoch=0.00147, valid_loss=0.0339]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0015, train_loss_epoch=0.0015, valid_loss=0.0339]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00163, train_loss_epoch=0.00163, valid_loss=0.0339]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=0.0339]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=0.0339]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00131, train_loss_epoch=0.00131, valid_loss=0.0339]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=0.0339]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00143, train_loss_epoch=0.00143, valid_loss=0.0339]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0339]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0339]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0339]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=0.0339]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00137, train_loss_epoch=0.00137, valid_loss=0.0339]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0339]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0339]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00141, train_loss_epoch=0.00141, valid_loss=0.0339]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000998, train_loss_epoch=0.000998, valid_loss=0.0339]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0339]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0339]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0339]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0339]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0339]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0013, train_loss_epoch=0.0013, valid_loss=0.0339]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0339]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00129, train_loss_epoch=0.00129, valid_loss=0.0339]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00144, train_loss_epoch=0.00144, valid_loss=0.0339]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000951, train_loss_epoch=0.000951, valid_loss=0.0339]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0339]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00104, train_loss_epoch=0.00104, valid_loss=0.0339]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00103, train_loss_epoch=0.00103, valid_loss=0.0339]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000938, train_loss_epoch=0.000938, valid_loss=0.0339]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0339]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0339]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0339]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00139, train_loss_epoch=0.00139, valid_loss=0.0339]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0339]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00106, train_loss_epoch=0.00106, valid_loss=0.0339]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0339]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=0.0339]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00126, train_loss_epoch=0.00126, valid_loss=0.0339]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0339]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00116, train_loss_epoch=0.00116, valid_loss=0.0339]\n",
            "Epoch 953: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.00116, valid_loss=0.0339] \n",
            "Epoch 953: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0339] \n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0339]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0012, train_loss_epoch=0.0012, valid_loss=0.0339]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00108, train_loss_epoch=0.00108, valid_loss=0.0339]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0339]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00115, train_loss_epoch=0.00115, valid_loss=0.0339]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00118, train_loss_epoch=0.00118, valid_loss=0.0339]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00119, train_loss_epoch=0.00119, valid_loss=0.0339]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00123, train_loss_epoch=0.00123, valid_loss=0.0339]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00104, train_loss_epoch=0.00104, valid_loss=0.0339]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00128, train_loss_epoch=0.00128, valid_loss=0.0339]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00114, train_loss_epoch=0.00114, valid_loss=0.0339]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0011, train_loss_epoch=0.0011, valid_loss=0.0339]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00112, train_loss_epoch=0.00112, valid_loss=0.0339]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0339]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00101, train_loss_epoch=0.00101, valid_loss=0.0339]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00102, train_loss_epoch=0.00102, valid_loss=0.0339]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00107, train_loss_epoch=0.00107, valid_loss=0.0339]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000941, train_loss_epoch=0.000941, valid_loss=0.0339]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00096, train_loss_epoch=0.00096, valid_loss=0.0339]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000791, train_loss_epoch=0.000791, valid_loss=0.0339]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000931, train_loss_epoch=0.000931, valid_loss=0.0339]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000885, train_loss_epoch=0.000885, valid_loss=0.0339]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00113, train_loss_epoch=0.00113, valid_loss=0.0339]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00169, train_loss_epoch=0.00169, valid_loss=0.0339]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00125, train_loss_epoch=0.00125, valid_loss=0.0339]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00111, train_loss_epoch=0.00111, valid_loss=0.0339]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=0.0339]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00132, train_loss_epoch=0.00132, valid_loss=0.0339]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00187, train_loss_epoch=0.00187, valid_loss=0.0339]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=0.0339]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00134, train_loss_epoch=0.00134, valid_loss=0.0339]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00209, train_loss_epoch=0.00209, valid_loss=0.0339]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00168, train_loss_epoch=0.00168, valid_loss=0.0339]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.002, train_loss_epoch=0.002, valid_loss=0.0339]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0017, train_loss_epoch=0.0017, valid_loss=0.0339]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00233, train_loss_epoch=0.00233, valid_loss=0.0339]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00145, train_loss_epoch=0.00145, valid_loss=0.0339]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00183, train_loss_epoch=0.00183, valid_loss=0.0339]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0018, train_loss_epoch=0.0018, valid_loss=0.0339]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00146, train_loss_epoch=0.00146, valid_loss=0.0339]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00199, train_loss_epoch=0.00199, valid_loss=0.0339]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0016, train_loss_epoch=0.0016, valid_loss=0.0339]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00205, train_loss_epoch=0.00205, valid_loss=0.0339]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00155, train_loss_epoch=0.00155, valid_loss=0.0339]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00207, train_loss_epoch=0.00207, valid_loss=0.0339]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=0.0339]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 20:59:15,084\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m `Trainer.fit` stopped: `max_steps=1000.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s, v_num=0, train_loss_step=0.00191, train_loss_epoch=0.00191, valid_loss=0.0339]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00191, valid_loss=0.0339]\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.90it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=52718)\u001b[0m \r                                                                       \u001b[A\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00191, valid_loss=0.0342]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0342]\rEpoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=0.00172, train_loss_epoch=0.00172, valid_loss=0.0342]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=54810)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 2025-06-15 20:59:28.791868: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m E0000 00:00:1750021168.820915   54903 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m E0000 00:00:1750021168.834264   54903 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 2025-06-15 20:59:28.866317: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 3 | blocks       | ModuleList    | 7.6 M  | train\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 7.6 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 7.6 M     Total params\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 30.557    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=48.80, train_loss_epoch=48.80]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.70, train_loss_epoch=40.70]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.40, train_loss_epoch=37.40]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.80, train_loss_epoch=34.80]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.80, train_loss_epoch=33.80]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.90, train_loss_epoch=31.90]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.80, train_loss_epoch=25.80]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.10, train_loss_epoch=26.10]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.10, train_loss_epoch=25.10]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.30, train_loss_epoch=25.30]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.00, train_loss_epoch=25.00]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.00, train_loss_epoch=25.00]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.70, train_loss_epoch=23.70]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.20, train_loss_epoch=26.20]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.80, train_loss_epoch=24.80]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.30, train_loss_epoch=22.30]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.50, train_loss_epoch=23.50]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.00, train_loss_epoch=21.00]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.10, train_loss_epoch=21.10]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.70, train_loss_epoch=20.70]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.00, train_loss_epoch=21.00]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.00, train_loss_epoch=20.00]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.80, train_loss_epoch=20.80]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.90]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 86.87it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=0.00527]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00527]\n",
            "Epoch 101: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00527]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00527]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80, valid_loss=0.00527]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80, valid_loss=0.00527]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50, valid_loss=0.00527]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=0.00527]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80, valid_loss=0.00527]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80, valid_loss=0.00527]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=0.00527]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=0.00527]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.00527]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=0.00527]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00527]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=0.00527]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00527]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00527]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.00527]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00527]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=0.00527]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80, valid_loss=0.00527]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00527]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60, valid_loss=0.00527]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00527]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80, valid_loss=0.00527]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=0.00527]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00527]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30, valid_loss=0.00527]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00527]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.00527]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40, valid_loss=0.00527]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00527]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00527]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00527]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00, valid_loss=0.00527]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=0.00527]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=0.00527]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30, valid_loss=0.00527]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30, valid_loss=0.00527]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.20, valid_loss=0.00527]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=0.00527]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=0.00527]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00527]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00527]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=0.00527]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80, valid_loss=0.00527]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.20, valid_loss=0.00527]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=0.00527]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00527]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50, valid_loss=0.00527]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.20, valid_loss=0.00527]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00527]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=0.00527]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=0.00527]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00527]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00527]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00527]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=0.00527]\n",
            "Epoch 157: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.00527]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.00527]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40, valid_loss=0.00527]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=0.00527]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00527]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=0.00527]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40, valid_loss=0.00527]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=0.00527]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=0.00527]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40, valid_loss=0.00527]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00527]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40, valid_loss=0.00527]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=0.00527]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.00527]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=0.00527]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=0.00527]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00527]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60, valid_loss=0.00527]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60, valid_loss=0.00527]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00, valid_loss=0.00527]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60, valid_loss=0.00527]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00527]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=0.00527]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00527]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00527]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00527]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00527]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00527]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00527]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00527]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60, valid_loss=0.00527]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00527]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00527]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00527]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00527]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00527]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=0.00527]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00, valid_loss=0.00527]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00527]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00527]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00527]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00527]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00, valid_loss=0.00527]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=0.00527]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=16.70, valid_loss=0.00527]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.19it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00483]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00483]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=0.00483]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=0.00483]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00483]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00483]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00483]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00483]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00483]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00483]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00483]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=0.00483]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]        \n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00483]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00483]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00483]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00483]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00483]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00483]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00483]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00483]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00483]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00483]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00483]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00483]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00483]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00483]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=0.00483]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00483]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.20, train_loss_epoch=16.20, valid_loss=0.00483]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00483]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00483]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00483]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00483]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=0.00483]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00483]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00483]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00483]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00483]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00483]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00483]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00483]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00483]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00483]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00483]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=0.00483]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80, valid_loss=0.00483]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00483]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00483]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00483]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=0.00483]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00483]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00483]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00483]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00483]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00483]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00483]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00483]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00483]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00483]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00483]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00483]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00483]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00483]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00483]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00483]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00483]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00483]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00483]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00483]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00483]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=0.00483]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00483]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00483]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00483]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00483]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00483]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00483]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.60it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.10, valid_loss=0.00483]\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.66it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00489]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 301: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00489]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00489]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00489]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00489]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00489]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00489]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00489]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00489]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00489]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00489]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00489]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00489]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00489]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00489]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00489]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00489]\n",
            "Epoch 319: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00489]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00489]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00489]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00489]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00489]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00489]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00489]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00489]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00489]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00489]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00489]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00489]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00489]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00489]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00489]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00489]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00489]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00489]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00489]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00489]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00489]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00489]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00489]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00489]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00489]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00489]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00489]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00489]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00489]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00489]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00489]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00489]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00489]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00489]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00489]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00489]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00489]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00489]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00489]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00489]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00489]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00489]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00489]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00489]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00489]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00489]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00489]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00489]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00489]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00489]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00489]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=0.00489]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00489]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00489]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00489]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00489]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00489]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00489]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00489]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00489]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00489]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00489]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00489]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00489]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00489]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00489]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00489]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=13.70, valid_loss=0.00489]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 53.99it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00432]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00432]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00432]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00432]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00432]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00432]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00432]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00432]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00432]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00432]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00432]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00432]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00432]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00432]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00432]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00432]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00432]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00432]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00432]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00432]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00432]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00432]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00432]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00432]\n",
            "Epoch 435: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00432]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00432]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00432]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00432]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00432]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00432]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00432]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00432]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00432]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00432]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00432]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 449: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00432]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00432]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00432]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00432]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00432]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00432]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00432]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00432]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.00432]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00432]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00432]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00432]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00432]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00432]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00432]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00432]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00432]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00432]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00432]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=0.00432]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00432]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00432]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00432]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00432]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00432]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00432]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00432]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00432]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00432]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00432]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00432]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00432]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00432]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00432]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00432]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00432]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00432]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00432]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00432]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00432]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00432]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00432]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.10, valid_loss=0.00432]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.52it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00434]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.00434]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00434]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00434]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00434]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00434]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00434]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00434]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00434]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00434]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00434]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00434]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00434]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00434]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00434]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00434]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00434]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00434]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00434]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00434]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00434]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00434]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00434]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00434]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00434]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00434]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00434]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00434]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00434]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00434]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00434]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00434]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00434]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00434]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00434]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00434]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00434]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00434]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00434]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00434]\n",
            "Epoch 542: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=13.60, valid_loss=0.00434]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00434]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00434]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00434]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00434]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00434]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00434]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00434]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00434]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 556: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00434]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00434]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00434]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00434]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00434]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00434]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00434]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00434]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00434]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00434]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00434]\n",
            "Epoch 568: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.70, valid_loss=0.00434]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00434]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00434]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00434]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00434]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00434]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00434]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00434]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00434]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00434]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00434]\n",
            "Epoch 580: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=13.30, valid_loss=0.00434]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00434]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00434]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00434]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00434]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00434]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00434]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  2.48it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00434]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00434]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00434]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00434]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00434]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00434]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00434]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00434]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00434]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00434]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.37it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=12.70, valid_loss=0.00434]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.72it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00437]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00437]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00437]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00437]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00437]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00437]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00437]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00437]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00437]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00437]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00437]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00437]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00437]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00437]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00437]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00437]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00437]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00437]\n",
            "Epoch 622: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.80, valid_loss=0.00437]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00437]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00437]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.00437]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00437]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00437]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00437]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00437]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00437]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.00437]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00437]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00437]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00437]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00437]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00437]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00437]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00437]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00437]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00437]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00437]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00437]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00437]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00437]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00437]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00437]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00437]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00437]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00437]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00437]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00437]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00437]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00437]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00437]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00437]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00437]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00437]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00437]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00437]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00437]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.00437]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00437]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00437]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.00437]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 681: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00437]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00437]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00437]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00437]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00437]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00437]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00437]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00437]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00437]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00437]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00437]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=0.00437]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00437]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.00437]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00437]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00437]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00437]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=12.60, valid_loss=0.00437]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 100.25it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00443]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00443]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00443]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00443]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00443]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00443]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00443]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00443]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00443]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00443]\n",
            "Epoch 713: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=12.20, valid_loss=0.00443]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00443]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00443]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00443]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00443]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00443]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00443]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00443]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00443]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00443]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00443]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00443]\n",
            "Epoch 725: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=12.50, valid_loss=0.00443]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00443]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00443]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00443]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00443]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.00443]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00443]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00443]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00443]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00443]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00443]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00443]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00443]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00443]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00443]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00443]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00443]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00443]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00443]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00443]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00443]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00443]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.00443]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00443]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.00443]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00443]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00443]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00443]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00443]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00443]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00443]\n",
            "Epoch 766: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00443]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00443]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.00443]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00443]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00443]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00443]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00443]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00443]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00443]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00443]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00443]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00443]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00443]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00443]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00443]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00443]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00443]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00443]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00443]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00443]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.00443]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00443]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00443]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00443]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00443]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00443]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00443]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00443]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00443]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00443]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00443]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00443]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=14.40, valid_loss=0.00443]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.67it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0048]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.0048]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.0048]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.0048]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.0048]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.0048]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.0048]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.0048]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0048]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.0048]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.0048]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0048]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0048]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0048]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0048]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.0048]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0048]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.0048]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.0048]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.0048]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.0048]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.0048]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0048]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.0048]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.0048]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.0048]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0048]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.0048]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.0048]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=0.0048]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0048]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0048]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.0048]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0048]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0048]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=0.0048]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0048]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.0048]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.0048]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0048]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.0048]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.0048]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0048]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.0048]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.0048]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.0048]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0048]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.0048]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.0048]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.0048]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.0048]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.0048]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.0048]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.0048]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.0048]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0048]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0048]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.0048]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.0048]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.0048]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0048]\n",
            "Epoch 868: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.0048]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.0048]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.0048]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.0048]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.0048]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.0048]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0048]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=0.0048]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.0048]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.0048]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0048]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.0048]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.0048]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10, valid_loss=0.0048]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.0048]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0048]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.0048]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.0048]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.0048]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.0048]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.0048]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.0048]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.0048]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.0048]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.0048]\n",
            "Epoch 893: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.0048]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.0048]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.0048]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.0048]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0048]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0048]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 21:06:43,773\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (40, 20, 1), 'n_pool_kernel_size': (1, 1, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m `Trainer.fit` stopped: `max_steps=900.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0048]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.30, valid_loss=0.0048]\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.54it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=54810)\u001b[0m \r                                                                      \u001b[A\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.30, valid_loss=0.00467]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00467]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00467]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=56726)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 2025-06-15 21:06:58.125684: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m E0000 00:00:1750021618.157386   56820 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m E0000 00:00:1750021618.170033   56820 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 2025-06-15 21:06:58.200491: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 3 | blocks       | ModuleList    | 5.3 M  | train\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 5.3 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 5.3 M     Total params\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 21.384    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.326, train_loss_epoch=0.326]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+10, train_loss_epoch=1.96e+10]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.38e+12, train_loss_epoch=4.38e+12]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.61e+9, train_loss_epoch=4.61e+9]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+10, train_loss_epoch=2.62e+10]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.34e+12, train_loss_epoch=1.34e+12]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+12, train_loss_epoch=1.04e+12]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+11, train_loss_epoch=1.14e+11]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+9, train_loss_epoch=2.49e+9]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.84e+8, train_loss_epoch=5.84e+8]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.06e+8, train_loss_epoch=5.06e+8]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+8, train_loss_epoch=1.07e+8]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+11, train_loss_epoch=3.16e+11]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+10, train_loss_epoch=2.37e+10]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+9, train_loss_epoch=2.76e+9]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+11, train_loss_epoch=1.22e+11]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+12, train_loss_epoch=2.21e+12]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.09e+11, train_loss_epoch=2.09e+11]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+10, train_loss_epoch=2.96e+10]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.28e+11, train_loss_epoch=4.28e+11]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.04e+14, train_loss_epoch=2.04e+14]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.13e+11, train_loss_epoch=4.13e+11]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.9e+12, train_loss_epoch=6.9e+12]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+10, train_loss_epoch=1.01e+10]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.13e+9, train_loss_epoch=4.13e+9]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.65e+9, train_loss_epoch=7.65e+9]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.78e+11, train_loss_epoch=1.78e+11]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.14e+10, train_loss_epoch=6.14e+10]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.6e+10, train_loss_epoch=9.6e+10]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.14e+10, train_loss_epoch=8.14e+10]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.99e+11, train_loss_epoch=4.99e+11]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+12, train_loss_epoch=3.85e+12]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+13, train_loss_epoch=1.11e+13]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.56e+11, train_loss_epoch=3.56e+11]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.42e+11, train_loss_epoch=3.42e+11]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.28e+8, train_loss_epoch=5.28e+8]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.36e+11, train_loss_epoch=8.36e+11]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.27e+10, train_loss_epoch=1.27e+10]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.96e+11, train_loss_epoch=3.96e+11]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.27e+9, train_loss_epoch=9.27e+9]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+12, train_loss_epoch=1.11e+12]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.81e+10, train_loss_epoch=4.81e+10]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+11, train_loss_epoch=2.81e+11]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.3e+10, train_loss_epoch=9.3e+10]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.56e+10, train_loss_epoch=3.56e+10]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.23e+11, train_loss_epoch=4.23e+11]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.65e+11, train_loss_epoch=1.65e+11]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.99e+11, train_loss_epoch=3.99e+11]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.23e+11, train_loss_epoch=1.23e+11]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+10, train_loss_epoch=1.02e+10]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.44e+10, train_loss_epoch=2.44e+10]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.06e+9, train_loss_epoch=6.06e+9]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.4e+9, train_loss_epoch=6.4e+9]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+9, train_loss_epoch=2.34e+9]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.82e+9, train_loss_epoch=7.82e+9]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+9, train_loss_epoch=2.76e+9]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+10, train_loss_epoch=1.08e+10]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+10, train_loss_epoch=1.06e+10]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.99e+9, train_loss_epoch=4.99e+9]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.54e+9, train_loss_epoch=6.54e+9]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.72e+9, train_loss_epoch=6.72e+9]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+9, train_loss_epoch=1.64e+9]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.83e+9, train_loss_epoch=4.83e+9]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.58e+9, train_loss_epoch=5.58e+9]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.48e+9, train_loss_epoch=4.48e+9]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+9, train_loss_epoch=2.8e+9]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+9, train_loss_epoch=1.3e+9]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+8, train_loss_epoch=3.16e+8]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+8, train_loss_epoch=1.05e+8]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+8, train_loss_epoch=1.1e+8]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+8, train_loss_epoch=1.37e+8]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.93e+7, train_loss_epoch=7.93e+7]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.04e+7, train_loss_epoch=9.04e+7]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.21e+7, train_loss_epoch=8.21e+7]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.1e+7, train_loss_epoch=5.1e+7]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.42e+7, train_loss_epoch=6.42e+7]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.29e+7, train_loss_epoch=8.29e+7]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.34e+7, train_loss_epoch=7.34e+7]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.57e+7, train_loss_epoch=5.57e+7]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+7, train_loss_epoch=4.97e+7]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.73e+7, train_loss_epoch=5.73e+7]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.8e+7, train_loss_epoch=4.8e+7]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.38e+7, train_loss_epoch=3.38e+7]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+7, train_loss_epoch=3.24e+7]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.93e+7, train_loss_epoch=3.93e+7]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+7, train_loss_epoch=2.82e+7]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.2e+7, train_loss_epoch=2.2e+7]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+7, train_loss_epoch=2.37e+7]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+7, train_loss_epoch=1.96e+7]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+7, train_loss_epoch=2.71e+7]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+7, train_loss_epoch=2.55e+7]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.1e+7, train_loss_epoch=2.1e+7]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.28e+7, train_loss_epoch=2.28e+7]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.03e+7, train_loss_epoch=2.03e+7]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.83e+7, train_loss_epoch=1.83e+7]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.02e+7, train_loss_epoch=2.02e+7]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.87e+7, train_loss_epoch=1.87e+7]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.67e+7, train_loss_epoch=1.67e+7]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.84e+7, train_loss_epoch=1.84e+7]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=1.56e+7, train_loss_epoch=1.84e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 124.17it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.56e+7, train_loss_epoch=1.56e+7, valid_loss=1.59e+7]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.64e+7, train_loss_epoch=1.64e+7, valid_loss=1.59e+7]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+7, train_loss_epoch=1.59e+7, valid_loss=1.59e+7]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+7, train_loss_epoch=1.48e+7, valid_loss=1.59e+7]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.63e+7, train_loss_epoch=1.63e+7, valid_loss=1.59e+7]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+7, train_loss_epoch=1.48e+7, valid_loss=1.59e+7]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+7, train_loss_epoch=1.49e+7, valid_loss=1.59e+7]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.43e+7, train_loss_epoch=1.43e+7, valid_loss=1.59e+7]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+7, train_loss_epoch=1.37e+7, valid_loss=1.59e+7]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.42e+7, train_loss_epoch=1.42e+7, valid_loss=1.59e+7]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+7, train_loss_epoch=1.28e+7, valid_loss=1.59e+7]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+7, train_loss_epoch=1.15e+7, valid_loss=1.59e+7]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.3e+7, train_loss_epoch=1.3e+7, valid_loss=1.59e+7]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+7, train_loss_epoch=1.24e+7, valid_loss=1.59e+7]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.25e+7, train_loss_epoch=1.25e+7, valid_loss=1.59e+7]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+7, train_loss_epoch=1.12e+7, valid_loss=1.59e+7]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+7, train_loss_epoch=1.05e+7, valid_loss=1.59e+7]\n",
            "Epoch 116: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=0, train_loss_step=1.05e+7, train_loss_epoch=1.05e+7, valid_loss=1.59e+7]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+7, train_loss_epoch=1.16e+7, valid_loss=1.59e+7]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+7, train_loss_epoch=1.22e+7, valid_loss=1.59e+7]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+7, train_loss_epoch=1.02e+7, valid_loss=1.59e+7]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.39e+6, train_loss_epoch=9.39e+6, valid_loss=1.59e+7]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.99e+6, train_loss_epoch=8.99e+6, valid_loss=1.59e+7]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.53e+6, train_loss_epoch=9.53e+6, valid_loss=1.59e+7]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.67e+6, train_loss_epoch=9.67e+6, valid_loss=1.59e+7]\n",
            "Epoch 123: 100%|██████████| 1/1 [00:00<00:00,  3.65it/s, v_num=0, train_loss_step=9.02e+6, train_loss_epoch=9.02e+6, valid_loss=1.59e+7]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.02e+6, train_loss_epoch=9.02e+6, valid_loss=1.59e+7]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.79e+6, train_loss_epoch=8.79e+6, valid_loss=1.59e+7]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.67e+6, train_loss_epoch=8.67e+6, valid_loss=1.59e+7]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.42e+6, train_loss_epoch=8.42e+6, valid_loss=1.59e+7]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.15e+6, train_loss_epoch=8.15e+6, valid_loss=1.59e+7]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.99e+6, train_loss_epoch=8.99e+6, valid_loss=1.59e+7]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.39e+6, train_loss_epoch=8.39e+6, valid_loss=1.59e+7]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8e+6, train_loss_epoch=8e+6, valid_loss=1.59e+7]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.22e+6, train_loss_epoch=7.22e+6, valid_loss=1.59e+7]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.2e+6, train_loss_epoch=8.2e+6, valid_loss=1.59e+7]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.89e+6, train_loss_epoch=7.89e+6, valid_loss=1.59e+7]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.68e+6, train_loss_epoch=7.68e+6, valid_loss=1.59e+7]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.27e+6, train_loss_epoch=7.27e+6, valid_loss=1.59e+7]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.09e+6, train_loss_epoch=7.09e+6, valid_loss=1.59e+7]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  3.95it/s, v_num=0, train_loss_step=7.53e+6, train_loss_epoch=7.09e+6, valid_loss=1.59e+7]\n",
            "Epoch 137: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=0, train_loss_step=7.53e+6, train_loss_epoch=7.53e+6, valid_loss=1.59e+7]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.53e+6, train_loss_epoch=7.53e+6, valid_loss=1.59e+7]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.04e+6, train_loss_epoch=7.04e+6, valid_loss=1.59e+7]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.79e+6, train_loss_epoch=5.79e+6, valid_loss=1.59e+7]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.18e+6, train_loss_epoch=6.18e+6, valid_loss=1.59e+7]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.26e+6, train_loss_epoch=7.26e+6, valid_loss=1.59e+7]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.47e+6, train_loss_epoch=6.47e+6, valid_loss=1.59e+7]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.2e+6, train_loss_epoch=7.2e+6, valid_loss=1.59e+7]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.11e+6, train_loss_epoch=6.11e+6, valid_loss=1.59e+7]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.55e+6, train_loss_epoch=6.55e+6, valid_loss=1.59e+7]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.73e+6, train_loss_epoch=6.73e+6, valid_loss=1.59e+7]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.4e+6, train_loss_epoch=6.4e+6, valid_loss=1.59e+7]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.06e+6, train_loss_epoch=6.06e+6, valid_loss=1.59e+7]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.79e+6, train_loss_epoch=5.79e+6, valid_loss=1.59e+7]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.09e+6, train_loss_epoch=6.09e+6, valid_loss=1.59e+7]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.5e+6, train_loss_epoch=6.5e+6, valid_loss=1.59e+7]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.42e+6, train_loss_epoch=6.42e+6, valid_loss=1.59e+7]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.43e+6, train_loss_epoch=6.43e+6, valid_loss=1.59e+7]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.08e+6, train_loss_epoch=6.08e+6, valid_loss=1.59e+7]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+6, train_loss_epoch=5.87e+6, valid_loss=1.59e+7]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.86e+6, train_loss_epoch=5.86e+6, valid_loss=1.59e+7]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.98e+6, train_loss_epoch=5.98e+6, valid_loss=1.59e+7]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.69e+6, train_loss_epoch=5.69e+6, valid_loss=1.59e+7]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.71e+6, train_loss_epoch=5.71e+6, valid_loss=1.59e+7]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.36e+6, train_loss_epoch=5.36e+6, valid_loss=1.59e+7]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.77e+6, train_loss_epoch=5.77e+6, valid_loss=1.59e+7]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.04e+6, train_loss_epoch=6.04e+6, valid_loss=1.59e+7]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.57e+6, train_loss_epoch=5.57e+6, valid_loss=1.59e+7]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.75e+6, train_loss_epoch=4.75e+6, valid_loss=1.59e+7]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.03e+6, train_loss_epoch=5.03e+6, valid_loss=1.59e+7]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.78e+6, train_loss_epoch=4.78e+6, valid_loss=1.59e+7]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.63e+6, train_loss_epoch=5.63e+6, valid_loss=1.59e+7]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.09e+6, train_loss_epoch=6.09e+6, valid_loss=1.59e+7]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.31e+6, train_loss_epoch=5.31e+6, valid_loss=1.59e+7]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.88e+6, train_loss_epoch=5.88e+6, valid_loss=1.59e+7]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.9e+6, train_loss_epoch=5.9e+6, valid_loss=1.59e+7]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.42e+6, train_loss_epoch=5.42e+6, valid_loss=1.59e+7]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.35e+6, train_loss_epoch=6.35e+6, valid_loss=1.59e+7]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.2e+6, train_loss_epoch=6.2e+6, valid_loss=1.59e+7]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.91e+6, train_loss_epoch=5.91e+6, valid_loss=1.59e+7]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.9e+6, train_loss_epoch=5.9e+6, valid_loss=1.59e+7]        \n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.9e+6, train_loss_epoch=5.9e+6, valid_loss=1.59e+7]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.06e+6, train_loss_epoch=6.06e+6, valid_loss=1.59e+7]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.73e+6, train_loss_epoch=5.73e+6, valid_loss=1.59e+7]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.25e+6, train_loss_epoch=5.25e+6, valid_loss=1.59e+7]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.89e+6, train_loss_epoch=5.89e+6, valid_loss=1.59e+7]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.18e+6, train_loss_epoch=5.18e+6, valid_loss=1.59e+7]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  6.41it/s, v_num=0, train_loss_step=4.98e+6, train_loss_epoch=5.18e+6, valid_loss=1.59e+7]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.98e+6, train_loss_epoch=4.98e+6, valid_loss=1.59e+7]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.46e+6, train_loss_epoch=5.46e+6, valid_loss=1.59e+7]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.99e+6, train_loss_epoch=4.99e+6, valid_loss=1.59e+7]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.24e+6, train_loss_epoch=5.24e+6, valid_loss=1.59e+7]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.98e+6, train_loss_epoch=4.98e+6, valid_loss=1.59e+7]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  6.38it/s, v_num=0, train_loss_step=4.46e+6, train_loss_epoch=4.98e+6, valid_loss=1.59e+7]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.46e+6, train_loss_epoch=4.46e+6, valid_loss=1.59e+7]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.88e+6, train_loss_epoch=4.88e+6, valid_loss=1.59e+7]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.73e+6, train_loss_epoch=5.73e+6, valid_loss=1.59e+7]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.64e+6, train_loss_epoch=4.64e+6, valid_loss=1.59e+7]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.73e+6, train_loss_epoch=4.73e+6, valid_loss=1.59e+7]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.33e+6, train_loss_epoch=5.33e+6, valid_loss=1.59e+7]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.77e+6, train_loss_epoch=4.77e+6, valid_loss=1.59e+7]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.34e+6, train_loss_epoch=4.34e+6, valid_loss=1.59e+7]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.3e+6, train_loss_epoch=4.3e+6, valid_loss=1.59e+7]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.3e+6, train_loss_epoch=4.3e+6, valid_loss=1.59e+7]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.16e+6, train_loss_epoch=4.16e+6, valid_loss=1.59e+7]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.36e+6, train_loss_epoch=5.36e+6, valid_loss=1.59e+7]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  3.64it/s, v_num=0, train_loss_step=5.77e+6, train_loss_epoch=5.36e+6, valid_loss=1.59e+7]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.85it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.77e+6, train_loss_epoch=5.77e+6, valid_loss=4.6e+6]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.84e+6, train_loss_epoch=4.84e+6, valid_loss=4.6e+6]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.81e+6, train_loss_epoch=5.81e+6, valid_loss=4.6e+6]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.19e+6, train_loss_epoch=5.19e+6, valid_loss=4.6e+6]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.68e+6, train_loss_epoch=4.68e+6, valid_loss=4.6e+6]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.48e+6, train_loss_epoch=4.48e+6, valid_loss=4.6e+6]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.31e+6, train_loss_epoch=4.31e+6, valid_loss=4.6e+6]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.23e+6, train_loss_epoch=4.23e+6, valid_loss=4.6e+6]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.42e+6, train_loss_epoch=4.42e+6, valid_loss=4.6e+6]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.33e+6, train_loss_epoch=4.33e+6, valid_loss=4.6e+6]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.18e+6, train_loss_epoch=4.18e+6, valid_loss=4.6e+6]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.47e+6, train_loss_epoch=4.47e+6, valid_loss=4.6e+6]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.66e+6, train_loss_epoch=4.66e+6, valid_loss=4.6e+6]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.51e+6, train_loss_epoch=4.51e+6, valid_loss=4.6e+6]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.37e+6, train_loss_epoch=4.37e+6, valid_loss=4.6e+6]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.36e+6, train_loss_epoch=4.36e+6, valid_loss=4.6e+6]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.59e+6, train_loss_epoch=4.59e+6, valid_loss=4.6e+6]\n",
            "Epoch 216: 100%|██████████| 1/1 [00:00<00:00,  3.79it/s, v_num=0, train_loss_step=4.64e+6, train_loss_epoch=4.64e+6, valid_loss=4.6e+6]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.64e+6, train_loss_epoch=4.64e+6, valid_loss=4.6e+6]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.51e+6, train_loss_epoch=4.51e+6, valid_loss=4.6e+6]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.04e+6, train_loss_epoch=4.04e+6, valid_loss=4.6e+6]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.87e+6, train_loss_epoch=3.87e+6, valid_loss=4.6e+6]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.06e+6, train_loss_epoch=4.06e+6, valid_loss=4.6e+6]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.62e+6, train_loss_epoch=4.62e+6, valid_loss=4.6e+6]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.28e+6, train_loss_epoch=4.28e+6, valid_loss=4.6e+6]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.05e+6, train_loss_epoch=4.05e+6, valid_loss=4.6e+6]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.96e+6, train_loss_epoch=3.96e+6, valid_loss=4.6e+6]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.96e+6, train_loss_epoch=3.96e+6, valid_loss=4.6e+6]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.2e+6, train_loss_epoch=4.2e+6, valid_loss=4.6e+6]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.42e+6, train_loss_epoch=4.42e+6, valid_loss=4.6e+6]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.02e+6, train_loss_epoch=4.02e+6, valid_loss=4.6e+6]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.91e+6, train_loss_epoch=3.91e+6, valid_loss=4.6e+6]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.26e+6, train_loss_epoch=4.26e+6, valid_loss=4.6e+6]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.88e+6, train_loss_epoch=3.88e+6, valid_loss=4.6e+6]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.12e+6, train_loss_epoch=4.12e+6, valid_loss=4.6e+6]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.2e+6, train_loss_epoch=4.2e+6, valid_loss=4.6e+6]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.82e+6, train_loss_epoch=3.82e+6, valid_loss=4.6e+6]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+6, train_loss_epoch=3.85e+6, valid_loss=4.6e+6]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.92e+6, train_loss_epoch=3.92e+6, valid_loss=4.6e+6]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+6, train_loss_epoch=3.69e+6, valid_loss=4.6e+6]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.56e+6, train_loss_epoch=3.56e+6, valid_loss=4.6e+6]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.49e+6, train_loss_epoch=3.49e+6, valid_loss=4.6e+6]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.52e+6, train_loss_epoch=3.52e+6, valid_loss=4.6e+6]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.28e+6, train_loss_epoch=3.28e+6, valid_loss=4.6e+6]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.47e+6, train_loss_epoch=3.47e+6, valid_loss=4.6e+6]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+6, train_loss_epoch=3.45e+6, valid_loss=4.6e+6]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+6, train_loss_epoch=3.19e+6, valid_loss=4.6e+6]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.5e+6, train_loss_epoch=3.5e+6, valid_loss=4.6e+6]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.88e+6, train_loss_epoch=3.88e+6, valid_loss=4.6e+6]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.65e+6, train_loss_epoch=3.65e+6, valid_loss=4.6e+6]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.67e+6, train_loss_epoch=3.67e+6, valid_loss=4.6e+6]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.49e+6, train_loss_epoch=3.49e+6, valid_loss=4.6e+6]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.34e+6, train_loss_epoch=3.34e+6, valid_loss=4.6e+6]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.67e+6, train_loss_epoch=3.67e+6, valid_loss=4.6e+6]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+6, train_loss_epoch=3.69e+6, valid_loss=4.6e+6]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.95e+6, train_loss_epoch=3.95e+6, valid_loss=4.6e+6]\n",
            "Epoch 254: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=4.12e+6, train_loss_epoch=3.95e+6, valid_loss=4.6e+6]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.12e+6, train_loss_epoch=4.12e+6, valid_loss=4.6e+6]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.47e+6, train_loss_epoch=3.47e+6, valid_loss=4.6e+6]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.42e+6, train_loss_epoch=3.42e+6, valid_loss=4.6e+6]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.01e+6, train_loss_epoch=4.01e+6, valid_loss=4.6e+6]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.08e+6, train_loss_epoch=4.08e+6, valid_loss=4.6e+6]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+6, train_loss_epoch=3.76e+6, valid_loss=4.6e+6]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.32e+6, train_loss_epoch=3.32e+6, valid_loss=4.6e+6]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+6, train_loss_epoch=3.98e+6, valid_loss=4.6e+6]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.66e+6, train_loss_epoch=4.66e+6, valid_loss=4.6e+6]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.9e+6, train_loss_epoch=3.9e+6, valid_loss=4.6e+6]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.4e+6, train_loss_epoch=4.4e+6, valid_loss=4.6e+6]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.51e+6, train_loss_epoch=3.51e+6, valid_loss=4.6e+6]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.26e+6, train_loss_epoch=3.26e+6, valid_loss=4.6e+6]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.65e+6, train_loss_epoch=3.65e+6, valid_loss=4.6e+6]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.67e+6, train_loss_epoch=4.67e+6, valid_loss=4.6e+6]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.31e+6, train_loss_epoch=4.31e+6, valid_loss=4.6e+6]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+6, train_loss_epoch=3.69e+6, valid_loss=4.6e+6]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+6, train_loss_epoch=4.15e+6, valid_loss=4.6e+6]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.61e+6, train_loss_epoch=3.61e+6, valid_loss=4.6e+6]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.2e+6, train_loss_epoch=3.2e+6, valid_loss=4.6e+6]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.31e+6, train_loss_epoch=3.31e+6, valid_loss=4.6e+6]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.38e+6, train_loss_epoch=3.38e+6, valid_loss=4.6e+6]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+6, train_loss_epoch=3.07e+6, valid_loss=4.6e+6]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+6, train_loss_epoch=3.03e+6, valid_loss=4.6e+6]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.21e+6, train_loss_epoch=3.21e+6, valid_loss=4.6e+6]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.3e+6, train_loss_epoch=3.3e+6, valid_loss=4.6e+6]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.12e+6, train_loss_epoch=4.12e+6, valid_loss=4.6e+6]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+6, train_loss_epoch=3.6e+6, valid_loss=4.6e+6]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+6, train_loss_epoch=3.24e+6, valid_loss=4.6e+6]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.47e+6, train_loss_epoch=4.47e+6, valid_loss=4.6e+6]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.9e+6, train_loss_epoch=3.9e+6, valid_loss=4.6e+6]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.49e+6, train_loss_epoch=3.49e+6, valid_loss=4.6e+6]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.14e+6, train_loss_epoch=4.14e+6, valid_loss=4.6e+6]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.04e+6, train_loss_epoch=4.04e+6, valid_loss=4.6e+6]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.63e+6, train_loss_epoch=3.63e+6, valid_loss=4.6e+6]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.96e+6, train_loss_epoch=3.96e+6, valid_loss=4.6e+6]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+6, train_loss_epoch=3.6e+6, valid_loss=4.6e+6]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+6, train_loss_epoch=3.11e+6, valid_loss=4.6e+6]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+6, train_loss_epoch=3.98e+6, valid_loss=4.6e+6]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.94e+6, train_loss_epoch=3.94e+6, valid_loss=4.6e+6]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.48e+6, train_loss_epoch=3.48e+6, valid_loss=4.6e+6]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.65e+6, train_loss_epoch=3.65e+6, valid_loss=4.6e+6]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.74e+6, train_loss_epoch=3.74e+6, valid_loss=4.6e+6]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+6, train_loss_epoch=3.17e+6, valid_loss=4.6e+6]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+6, train_loss_epoch=3.4e+6, valid_loss=4.6e+6]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  6.04it/s, v_num=0, train_loss_step=3.78e+6, train_loss_epoch=3.4e+6, valid_loss=4.6e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 145.30it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.78e+6, train_loss_epoch=3.78e+6, valid_loss=3.22e+6]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+6, train_loss_epoch=3.18e+6, valid_loss=3.22e+6]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+6, train_loss_epoch=3.16e+6, valid_loss=3.22e+6]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.03e+6, train_loss_epoch=4.03e+6, valid_loss=3.22e+6]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.74e+6, train_loss_epoch=3.74e+6, valid_loss=3.22e+6]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.24e+6, train_loss_epoch=3.24e+6, valid_loss=3.22e+6]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.43e+6, train_loss_epoch=3.43e+6, valid_loss=3.22e+6]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.25e+6, train_loss_epoch=4.25e+6, valid_loss=3.22e+6]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.67e+6, train_loss_epoch=3.67e+6, valid_loss=3.22e+6]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+6, train_loss_epoch=3.16e+6, valid_loss=3.22e+6]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.44e+6, train_loss_epoch=3.44e+6, valid_loss=3.22e+6]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.5e+6, train_loss_epoch=3.5e+6, valid_loss=3.22e+6]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.79e+6, train_loss_epoch=3.79e+6, valid_loss=3.22e+6]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+6, train_loss_epoch=3.25e+6, valid_loss=3.22e+6]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+6, train_loss_epoch=2.74e+6, valid_loss=3.22e+6]\n",
            "Epoch 314: 100%|██████████| 1/1 [00:00<00:00,  6.25it/s, v_num=0, train_loss_step=2.96e+6, train_loss_epoch=2.74e+6, valid_loss=3.22e+6]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+6, train_loss_epoch=2.96e+6, valid_loss=3.22e+6]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.24e+6, train_loss_epoch=4.24e+6, valid_loss=3.22e+6]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.93e+6, train_loss_epoch=3.93e+6, valid_loss=3.22e+6]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.52e+6, train_loss_epoch=3.52e+6, valid_loss=3.22e+6]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+6, train_loss_epoch=3.4e+6, valid_loss=3.22e+6]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+6, train_loss_epoch=3.07e+6, valid_loss=3.22e+6]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.13e+6, train_loss_epoch=3.13e+6, valid_loss=3.22e+6]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+6, train_loss_epoch=3.1e+6, valid_loss=3.22e+6]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+6, train_loss_epoch=3e+6, valid_loss=3.22e+6]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+6, train_loss_epoch=2.79e+6, valid_loss=3.22e+6]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+6, train_loss_epoch=3.16e+6, valid_loss=3.22e+6]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.67e+6, train_loss_epoch=3.67e+6, valid_loss=3.22e+6]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+6, train_loss_epoch=3.03e+6, valid_loss=3.22e+6]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+6, train_loss_epoch=2.78e+6, valid_loss=3.22e+6]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.83e+6, train_loss_epoch=3.83e+6, valid_loss=3.22e+6]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.13e+6, train_loss_epoch=3.13e+6, valid_loss=3.22e+6]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+6, train_loss_epoch=3.01e+6, valid_loss=3.22e+6]\n",
            "Epoch 331: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s, v_num=0, train_loss_step=2.99e+6, train_loss_epoch=2.99e+6, valid_loss=3.22e+6]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+6, train_loss_epoch=2.99e+6, valid_loss=3.22e+6]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.55e+6, train_loss_epoch=3.55e+6, valid_loss=3.22e+6]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+6, train_loss_epoch=3.25e+6, valid_loss=3.22e+6]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+6, train_loss_epoch=3e+6, valid_loss=3.22e+6]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+6, train_loss_epoch=2.81e+6, valid_loss=3.22e+6]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+6, train_loss_epoch=2.67e+6, valid_loss=3.22e+6]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.61e+6, train_loss_epoch=3.61e+6, valid_loss=3.22e+6]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.44e+6, train_loss_epoch=3.44e+6, valid_loss=3.22e+6]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+6, train_loss_epoch=2.83e+6, valid_loss=3.22e+6]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.02e+6, train_loss_epoch=3.02e+6, valid_loss=3.22e+6]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.34e+6, train_loss_epoch=3.34e+6, valid_loss=3.22e+6]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+6, train_loss_epoch=3.17e+6, valid_loss=3.22e+6]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+6, train_loss_epoch=2.72e+6, valid_loss=3.22e+6]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+6, train_loss_epoch=2.59e+6, valid_loss=3.22e+6]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.92e+6, train_loss_epoch=3.92e+6, valid_loss=3.22e+6]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+6, train_loss_epoch=3.18e+6, valid_loss=3.22e+6]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.21e+6, train_loss_epoch=3.21e+6, valid_loss=3.22e+6]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+6, train_loss_epoch=3.03e+6, valid_loss=3.22e+6]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+6, train_loss_epoch=2.53e+6, valid_loss=3.22e+6]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+6, train_loss_epoch=2.34e+6, valid_loss=3.22e+6]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+6, train_loss_epoch=2.5e+6, valid_loss=3.22e+6]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+6, train_loss_epoch=2.42e+6, valid_loss=3.22e+6]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+6, train_loss_epoch=2.94e+6, valid_loss=3.22e+6]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+6, train_loss_epoch=3.19e+6, valid_loss=3.22e+6]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+6, train_loss_epoch=2.72e+6, valid_loss=3.22e+6]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+6, train_loss_epoch=2.35e+6, valid_loss=3.22e+6]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.18e+6, train_loss_epoch=2.18e+6, valid_loss=3.22e+6]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.91e+6, train_loss_epoch=1.91e+6, valid_loss=3.22e+6]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+6, train_loss_epoch=1.96e+6, valid_loss=3.22e+6]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+6, train_loss_epoch=2.7e+6, valid_loss=3.22e+6]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.35e+6, train_loss_epoch=3.35e+6, valid_loss=3.22e+6]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+6, train_loss_epoch=2.45e+6, valid_loss=3.22e+6]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+6, train_loss_epoch=2.47e+6, valid_loss=3.22e+6]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.27e+6, train_loss_epoch=3.27e+6, valid_loss=3.22e+6]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.75e+6, train_loss_epoch=3.75e+6, valid_loss=3.22e+6]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.47e+6, train_loss_epoch=2.47e+6, valid_loss=3.22e+6]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.37e+6, train_loss_epoch=4.37e+6, valid_loss=3.22e+6]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+6, train_loss_epoch=2.68e+6, valid_loss=3.22e+6]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+6, train_loss_epoch=2.35e+6, valid_loss=3.22e+6]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.05e+6, train_loss_epoch=4.05e+6, valid_loss=3.22e+6]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+6, train_loss_epoch=2.56e+6, valid_loss=3.22e+6]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.24e+6, train_loss_epoch=2.24e+6, valid_loss=3.22e+6]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.94e+6, train_loss_epoch=3.94e+6, valid_loss=3.22e+6]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+6, train_loss_epoch=2.56e+6, valid_loss=3.22e+6]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+6, train_loss_epoch=2.67e+6, valid_loss=3.22e+6]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+6, train_loss_epoch=3.1e+6, valid_loss=3.22e+6]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.11e+6, train_loss_epoch=2.11e+6, valid_loss=3.22e+6]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.95e+6, train_loss_epoch=1.95e+6, valid_loss=3.22e+6]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s, v_num=0, train_loss_step=2.89e+6, train_loss_epoch=1.95e+6, valid_loss=3.22e+6]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+6, train_loss_epoch=2.89e+6, valid_loss=3.22e+6]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.51e+6, train_loss_epoch=3.51e+6, valid_loss=3.22e+6]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+6, train_loss_epoch=2.64e+6, valid_loss=3.22e+6]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.96e+6, train_loss_epoch=3.96e+6, valid_loss=3.22e+6]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+6, train_loss_epoch=2.49e+6, valid_loss=3.22e+6]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+6, train_loss_epoch=2.25e+6, valid_loss=3.22e+6]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.16e+6, train_loss_epoch=5.16e+6, valid_loss=3.22e+6]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+6, train_loss_epoch=2.76e+6, valid_loss=3.22e+6]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+6, train_loss_epoch=5.85e+6, valid_loss=3.22e+6]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+6, train_loss_epoch=3.09e+6, valid_loss=3.22e+6]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.21e+6, train_loss_epoch=5.21e+6, valid_loss=3.22e+6]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.06e+6, train_loss_epoch=3.06e+6, valid_loss=3.22e+6]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+6, train_loss_epoch=5.85e+6, valid_loss=3.22e+6]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.27e+6, train_loss_epoch=3.27e+6, valid_loss=3.22e+6]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.97e+6, train_loss_epoch=6.97e+6, valid_loss=3.22e+6]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.55e+6, train_loss_epoch=5.55e+6, valid_loss=3.22e+6]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+6, train_loss_epoch=5.87e+6, valid_loss=3.22e+6]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.01e+6, train_loss_epoch=7.01e+6, valid_loss=3.22e+6]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.57e+6, train_loss_epoch=3.57e+6, valid_loss=3.22e+6]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.97e+6, train_loss_epoch=5.97e+6, valid_loss=3.22e+6]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  6.59it/s, v_num=0, train_loss_step=2.69e+6, train_loss_epoch=5.97e+6, valid_loss=3.22e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.54it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+6, train_loss_epoch=2.69e+6, valid_loss=6.4e+6]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.15e+6, train_loss_epoch=6.15e+6, valid_loss=6.4e+6]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.92e+6, train_loss_epoch=3.92e+6, valid_loss=6.4e+6]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.2e+6, train_loss_epoch=6.2e+6, valid_loss=6.4e+6]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.78e+6, train_loss_epoch=5.78e+6, valid_loss=6.4e+6]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.63e+6, train_loss_epoch=4.63e+6, valid_loss=6.4e+6]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.25e+6, train_loss_epoch=6.25e+6, valid_loss=6.4e+6]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.07e+6, train_loss_epoch=4.07e+6, valid_loss=6.4e+6]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.59e+6, train_loss_epoch=5.59e+6, valid_loss=6.4e+6]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+6, train_loss_epoch=2.82e+6, valid_loss=6.4e+6]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.11e+6, train_loss_epoch=5.11e+6, valid_loss=6.4e+6]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+6, train_loss_epoch=2.83e+6, valid_loss=6.4e+6]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.29e+6, train_loss_epoch=6.29e+6, valid_loss=6.4e+6]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.86e+6, train_loss_epoch=4.86e+6, valid_loss=6.4e+6]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.35e+6, train_loss_epoch=5.35e+6, valid_loss=6.4e+6]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.58e+6, train_loss_epoch=7.58e+6, valid_loss=6.4e+6]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.29e+6, train_loss_epoch=4.29e+6, valid_loss=6.4e+6]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.77e+6, train_loss_epoch=5.77e+6, valid_loss=6.4e+6]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.78e+6, train_loss_epoch=4.78e+6, valid_loss=6.4e+6]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.07e+6, train_loss_epoch=4.07e+6, valid_loss=6.4e+6]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.88e+6, train_loss_epoch=3.88e+6, valid_loss=6.4e+6]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.1e+6, train_loss_epoch=4.1e+6, valid_loss=6.4e+6]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.26e+6, train_loss_epoch=3.26e+6, valid_loss=6.4e+6]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.44e+6, train_loss_epoch=4.44e+6, valid_loss=6.4e+6]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.53e+6, train_loss_epoch=3.53e+6, valid_loss=6.4e+6]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.66e+6, train_loss_epoch=3.66e+6, valid_loss=6.4e+6]\n",
            "Epoch 425: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=3.36e+6, train_loss_epoch=3.66e+6, valid_loss=6.4e+6]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.36e+6, train_loss_epoch=3.36e+6, valid_loss=6.4e+6]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.79e+6, train_loss_epoch=3.79e+6, valid_loss=6.4e+6]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+6, train_loss_epoch=3.04e+6, valid_loss=6.4e+6]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.65e+6, train_loss_epoch=3.65e+6, valid_loss=6.4e+6]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+6, train_loss_epoch=2.8e+6, valid_loss=6.4e+6]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.95e+6, train_loss_epoch=3.95e+6, valid_loss=6.4e+6]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.92e+6, train_loss_epoch=2.92e+6, valid_loss=6.4e+6]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.88e+6, train_loss_epoch=3.88e+6, valid_loss=6.4e+6]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+6, train_loss_epoch=3.01e+6, valid_loss=6.4e+6]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.57e+6, train_loss_epoch=3.57e+6, valid_loss=6.4e+6]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+6, train_loss_epoch=2.73e+6, valid_loss=6.4e+6]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.78e+6, train_loss_epoch=3.78e+6, valid_loss=6.4e+6]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+6, train_loss_epoch=2.84e+6, valid_loss=6.4e+6]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.12e+6, train_loss_epoch=4.12e+6, valid_loss=6.4e+6]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+6, train_loss_epoch=3.19e+6, valid_loss=6.4e+6]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.05e+6, train_loss_epoch=4.05e+6, valid_loss=6.4e+6]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.63e+6, train_loss_epoch=3.63e+6, valid_loss=6.4e+6]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.57e+6, train_loss_epoch=3.57e+6, valid_loss=6.4e+6]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+6, train_loss_epoch=3.25e+6, valid_loss=6.4e+6]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.34e+6, train_loss_epoch=3.34e+6, valid_loss=6.4e+6]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+6, train_loss_epoch=2.66e+6, valid_loss=6.4e+6]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+6, train_loss_epoch=3.76e+6, valid_loss=6.4e+6]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+6, train_loss_epoch=2.45e+6, valid_loss=6.4e+6]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.25e+6, train_loss_epoch=4.25e+6, valid_loss=6.4e+6]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+6, train_loss_epoch=2.64e+6, valid_loss=6.4e+6]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.44e+6, train_loss_epoch=4.44e+6, valid_loss=6.4e+6]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+6, train_loss_epoch=3.08e+6, valid_loss=6.4e+6]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.51e+6, train_loss_epoch=3.51e+6, valid_loss=6.4e+6]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.31e+6, train_loss_epoch=3.31e+6, valid_loss=6.4e+6]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.48e+6, train_loss_epoch=3.48e+6, valid_loss=6.4e+6]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.14e+6, train_loss_epoch=3.14e+6, valid_loss=6.4e+6]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.22e+6, train_loss_epoch=3.22e+6, valid_loss=6.4e+6]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+6, train_loss_epoch=2.89e+6, valid_loss=6.4e+6]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+6, train_loss_epoch=3.45e+6, valid_loss=6.4e+6]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+6, train_loss_epoch=2.64e+6, valid_loss=6.4e+6]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.73e+6, train_loss_epoch=3.73e+6, valid_loss=6.4e+6]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+6, train_loss_epoch=2.38e+6, valid_loss=6.4e+6]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.38e+6, train_loss_epoch=4.38e+6, valid_loss=6.4e+6]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.57e+6, train_loss_epoch=3.57e+6, valid_loss=6.4e+6]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.31e+6, train_loss_epoch=3.31e+6, valid_loss=6.4e+6]\n",
            "Epoch 465: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s, v_num=0, train_loss_step=3.08e+6, train_loss_epoch=3.08e+6, valid_loss=6.4e+6]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+6, train_loss_epoch=3.08e+6, valid_loss=6.4e+6]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.22e+6, train_loss_epoch=3.22e+6, valid_loss=6.4e+6]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+6, train_loss_epoch=2.5e+6, valid_loss=6.4e+6]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.71e+6, train_loss_epoch=3.71e+6, valid_loss=6.4e+6]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+6, train_loss_epoch=2.36e+6, valid_loss=6.4e+6]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.64e+6, train_loss_epoch=3.64e+6, valid_loss=6.4e+6]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+6, train_loss_epoch=2.63e+6, valid_loss=6.4e+6]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+6, train_loss_epoch=3.6e+6, valid_loss=6.4e+6]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+6, train_loss_epoch=3.19e+6, valid_loss=6.4e+6]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.26e+6, train_loss_epoch=3.26e+6, valid_loss=6.4e+6]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+6, train_loss_epoch=2.94e+6, valid_loss=6.4e+6]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+6, train_loss_epoch=2.9e+6, valid_loss=6.4e+6]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+6, train_loss_epoch=2.3e+6, valid_loss=6.4e+6]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+6, train_loss_epoch=3.05e+6, valid_loss=6.4e+6]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.08e+6, train_loss_epoch=2.08e+6, valid_loss=6.4e+6]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.34e+6, train_loss_epoch=3.34e+6, valid_loss=6.4e+6]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.08e+6, train_loss_epoch=2.08e+6, valid_loss=6.4e+6]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.68e+6, train_loss_epoch=3.68e+6, valid_loss=6.4e+6]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.7e+6, train_loss_epoch=2.7e+6, valid_loss=6.4e+6]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+6, train_loss_epoch=3.01e+6, valid_loss=6.4e+6]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+6, train_loss_epoch=2.61e+6, valid_loss=6.4e+6]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.21e+6, train_loss_epoch=3.21e+6, valid_loss=6.4e+6]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.42e+6, train_loss_epoch=2.42e+6, valid_loss=6.4e+6]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+6, train_loss_epoch=3.11e+6, valid_loss=6.4e+6]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.26e+6, train_loss_epoch=2.26e+6, valid_loss=6.4e+6]\n",
            "Epoch 490: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=3.38e+6, train_loss_epoch=3.38e+6, valid_loss=6.4e+6]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.38e+6, train_loss_epoch=3.38e+6, valid_loss=6.4e+6]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+6, train_loss_epoch=2.53e+6, valid_loss=6.4e+6]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+6, train_loss_epoch=3.17e+6, valid_loss=6.4e+6]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+6, train_loss_epoch=2.4e+6, valid_loss=6.4e+6]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+6, train_loss_epoch=3.08e+6, valid_loss=6.4e+6]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.56e+6, train_loss_epoch=2.56e+6, valid_loss=6.4e+6]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+6, train_loss_epoch=2.81e+6, valid_loss=6.4e+6]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2e+6, train_loss_epoch=2e+6, valid_loss=6.4e+6]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+6, train_loss_epoch=2.64e+6, valid_loss=6.4e+6]        \n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+6, train_loss_epoch=2.64e+6, valid_loss=6.4e+6]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s, v_num=0, train_loss_step=1.54e+6, train_loss_epoch=2.64e+6, valid_loss=6.4e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.82it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.54e+6, train_loss_epoch=1.54e+6, valid_loss=2.74e+6]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+6, train_loss_epoch=2.61e+6, valid_loss=2.74e+6]\n",
            "Epoch 501: 100%|██████████| 1/1 [00:00<00:00,  5.53it/s, v_num=0, train_loss_step=1.62e+6, train_loss_epoch=2.61e+6, valid_loss=2.74e+6]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.62e+6, train_loss_epoch=1.62e+6, valid_loss=2.74e+6]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.18e+6, train_loss_epoch=2.18e+6, valid_loss=2.74e+6]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.22e+6, train_loss_epoch=2.22e+6, valid_loss=2.74e+6]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+6, train_loss_epoch=1.35e+6, valid_loss=2.74e+6]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.07e+6, train_loss_epoch=2.07e+6, valid_loss=2.74e+6]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+6, train_loss_epoch=1.08e+6, valid_loss=2.74e+6]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.96e+6, train_loss_epoch=1.96e+6, valid_loss=2.74e+6]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.46e+6, train_loss_epoch=1.46e+6, valid_loss=2.74e+6]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.69e+6, train_loss_epoch=1.69e+6, valid_loss=2.74e+6]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.75e+6, train_loss_epoch=1.75e+6, valid_loss=2.74e+6]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.44e+6, train_loss_epoch=1.44e+6, valid_loss=2.74e+6]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.94e+6, train_loss_epoch=1.94e+6, valid_loss=2.74e+6]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+6, train_loss_epoch=1.2e+6, valid_loss=2.74e+6]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.69e+6, train_loss_epoch=1.69e+6, valid_loss=2.74e+6]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+6, train_loss_epoch=1.05e+6, valid_loss=2.74e+6]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.76e+6, train_loss_epoch=1.76e+6, valid_loss=2.74e+6]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.36e+6, train_loss_epoch=1.36e+6, valid_loss=2.74e+6]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.47e+6, train_loss_epoch=1.47e+6, valid_loss=2.74e+6]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.59e+6, train_loss_epoch=1.59e+6, valid_loss=2.74e+6]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.23e+6, train_loss_epoch=1.23e+6, valid_loss=2.74e+6]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.35e+6, train_loss_epoch=1.35e+6, valid_loss=2.74e+6]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+6, train_loss_epoch=1.03e+6, valid_loss=2.74e+6]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.2e+5, train_loss_epoch=9.2e+5, valid_loss=2.74e+6]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.28e+6, train_loss_epoch=1.28e+6, valid_loss=2.74e+6]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.42e+5, train_loss_epoch=9.42e+5, valid_loss=2.74e+6]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+6, train_loss_epoch=1.19e+6, valid_loss=2.74e+6]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.82e+5, train_loss_epoch=9.82e+5, valid_loss=2.74e+6]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00,  3.83it/s, v_num=0, train_loss_step=9.82e+5, train_loss_epoch=9.82e+5, valid_loss=2.74e+6]\n",
            "Epoch 528: 100%|██████████| 1/1 [00:00<00:00,  3.69it/s, v_num=0, train_loss_step=9.99e+5, train_loss_epoch=9.82e+5, valid_loss=2.74e+6]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.99e+5, train_loss_epoch=9.99e+5, valid_loss=2.74e+6]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.68e+5, train_loss_epoch=8.68e+5, valid_loss=2.74e+6]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.37e+5, train_loss_epoch=7.37e+5, valid_loss=2.74e+6]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.09e+5, train_loss_epoch=8.09e+5, valid_loss=2.74e+6]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.2e+5, train_loss_epoch=8.2e+5, valid_loss=2.74e+6]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.05e+5, train_loss_epoch=8.05e+5, valid_loss=2.74e+6]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.42e+5, train_loss_epoch=7.42e+5, valid_loss=2.74e+6]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.38e+5, train_loss_epoch=7.38e+5, valid_loss=2.74e+6]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.71e+5, train_loss_epoch=6.71e+5, valid_loss=2.74e+6]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.4e+5, train_loss_epoch=6.4e+5, valid_loss=2.74e+6]\n",
            "Epoch 538: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s, v_num=0, train_loss_step=6.64e+5, train_loss_epoch=6.64e+5, valid_loss=2.74e+6]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.64e+5, train_loss_epoch=6.64e+5, valid_loss=2.74e+6]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.48e+5, train_loss_epoch=6.48e+5, valid_loss=2.74e+6]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.25e+5, train_loss_epoch=6.25e+5, valid_loss=2.74e+6]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.39e+5, train_loss_epoch=6.39e+5, valid_loss=2.74e+6]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.01e+5, train_loss_epoch=6.01e+5, valid_loss=2.74e+6]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.8e+5, train_loss_epoch=5.8e+5, valid_loss=2.74e+6]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.77e+5, train_loss_epoch=5.77e+5, valid_loss=2.74e+6]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.99e+5, train_loss_epoch=5.99e+5, valid_loss=2.74e+6]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.64e+5, train_loss_epoch=5.64e+5, valid_loss=2.74e+6]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.24e+5, train_loss_epoch=6.24e+5, valid_loss=2.74e+6]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.68e+5, train_loss_epoch=6.68e+5, valid_loss=2.74e+6]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.62e+5, train_loss_epoch=6.62e+5, valid_loss=2.74e+6]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.96e+5, train_loss_epoch=6.96e+5, valid_loss=2.74e+6]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.43e+5, train_loss_epoch=6.43e+5, valid_loss=2.74e+6]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.64e+5, train_loss_epoch=6.64e+5, valid_loss=2.74e+6]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.26e+5, train_loss_epoch=7.26e+5, valid_loss=2.74e+6]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.72e+5, train_loss_epoch=6.72e+5, valid_loss=2.74e+6]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.38e+5, train_loss_epoch=7.38e+5, valid_loss=2.74e+6]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.58e+5, train_loss_epoch=7.58e+5, valid_loss=2.74e+6]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.41e+5, train_loss_epoch=6.41e+5, valid_loss=2.74e+6]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.31e+5, train_loss_epoch=5.31e+5, valid_loss=2.74e+6]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.66e+5, train_loss_epoch=5.66e+5, valid_loss=2.74e+6]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.54e+5, train_loss_epoch=5.54e+5, valid_loss=2.74e+6]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.41e+5, train_loss_epoch=6.41e+5, valid_loss=2.74e+6]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.92e+5, train_loss_epoch=7.92e+5, valid_loss=2.74e+6]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.87e+5, train_loss_epoch=7.87e+5, valid_loss=2.74e+6]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.99e+5, train_loss_epoch=5.99e+5, valid_loss=2.74e+6]\n",
            "Epoch 565: 100%|██████████| 1/1 [00:00<00:00,  6.24it/s, v_num=0, train_loss_step=5.42e+5, train_loss_epoch=5.42e+5, valid_loss=2.74e+6]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.42e+5, train_loss_epoch=5.42e+5, valid_loss=2.74e+6]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.1e+5, train_loss_epoch=7.1e+5, valid_loss=2.74e+6]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.52e+5, train_loss_epoch=9.52e+5, valid_loss=2.74e+6]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.2e+5, train_loss_epoch=7.2e+5, valid_loss=2.74e+6]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.46e+5, train_loss_epoch=9.46e+5, valid_loss=2.74e+6]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.61e+5, train_loss_epoch=9.61e+5, valid_loss=2.74e+6]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.04e+5, train_loss_epoch=7.04e+5, valid_loss=2.74e+6]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.43e+5, train_loss_epoch=6.43e+5, valid_loss=2.74e+6]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.36e+5, train_loss_epoch=8.36e+5, valid_loss=2.74e+6]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.81e+5, train_loss_epoch=8.81e+5, valid_loss=2.74e+6]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.2e+5, train_loss_epoch=7.2e+5, valid_loss=2.74e+6]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.96e+5, train_loss_epoch=7.96e+5, valid_loss=2.74e+6]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.24e+5, train_loss_epoch=8.24e+5, valid_loss=2.74e+6]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.8e+5, train_loss_epoch=6.8e+5, valid_loss=2.74e+6]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.96e+5, train_loss_epoch=5.96e+5, valid_loss=2.74e+6]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.59e+5, train_loss_epoch=6.59e+5, valid_loss=2.74e+6]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.56e+5, train_loss_epoch=9.56e+5, valid_loss=2.74e+6]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.89e+5, train_loss_epoch=6.89e+5, valid_loss=2.74e+6]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.16e+5, train_loss_epoch=7.16e+5, valid_loss=2.74e+6]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.1e+6, train_loss_epoch=1.1e+6, valid_loss=2.74e+6]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.05e+5, train_loss_epoch=7.05e+5, valid_loss=2.74e+6]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.86e+5, train_loss_epoch=6.86e+5, valid_loss=2.74e+6]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+6, train_loss_epoch=1.22e+6, valid_loss=2.74e+6]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.73e+5, train_loss_epoch=7.73e+5, valid_loss=2.74e+6]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+6, train_loss_epoch=1.06e+6, valid_loss=2.74e+6]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+6, train_loss_epoch=1.26e+6, valid_loss=2.74e+6]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.14e+5, train_loss_epoch=8.14e+5, valid_loss=2.74e+6]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.48e+6, train_loss_epoch=1.48e+6, valid_loss=2.74e+6]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.66e+5, train_loss_epoch=7.66e+5, valid_loss=2.74e+6]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.49e+6, train_loss_epoch=1.49e+6, valid_loss=2.74e+6]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.15e+5, train_loss_epoch=8.15e+5, valid_loss=2.74e+6]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.43e+6, train_loss_epoch=1.43e+6, valid_loss=2.74e+6]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.49e+5, train_loss_epoch=7.49e+5, valid_loss=2.74e+6]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+6, train_loss_epoch=1.15e+6, valid_loss=2.74e+6]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  3.60it/s, v_num=0, train_loss_step=9.38e+5, train_loss_epoch=1.15e+6, valid_loss=2.74e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.28it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.38e+5, train_loss_epoch=9.38e+5, valid_loss=8.6e+5]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.16e+5, train_loss_epoch=8.16e+5, valid_loss=8.6e+5]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.81e+5, train_loss_epoch=8.81e+5, valid_loss=8.6e+5]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.62e+5, train_loss_epoch=6.62e+5, valid_loss=8.6e+5]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.4e+5, train_loss_epoch=6.4e+5, valid_loss=8.6e+5]\n",
            "Epoch 604: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s, v_num=0, train_loss_step=6.5e+5, train_loss_epoch=6.5e+5, valid_loss=8.6e+5]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.5e+5, train_loss_epoch=6.5e+5, valid_loss=8.6e+5]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.44e+5, train_loss_epoch=6.44e+5, valid_loss=8.6e+5]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.91e+5, train_loss_epoch=5.91e+5, valid_loss=8.6e+5]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+5, train_loss_epoch=5.85e+5, valid_loss=8.6e+5]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.63e+5, train_loss_epoch=5.63e+5, valid_loss=8.6e+5]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.58e+5, train_loss_epoch=5.58e+5, valid_loss=8.6e+5]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.35e+5, train_loss_epoch=5.35e+5, valid_loss=8.6e+5]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.49e+5, train_loss_epoch=5.49e+5, valid_loss=8.6e+5]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.26e+5, train_loss_epoch=6.26e+5, valid_loss=8.6e+5]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.25e+5, train_loss_epoch=9.25e+5, valid_loss=8.6e+5]\n",
            "Epoch 614: 100%|██████████| 1/1 [00:00<00:00,  6.18it/s, v_num=0, train_loss_step=7.8e+5, train_loss_epoch=9.25e+5, valid_loss=8.6e+5] \n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.8e+5, train_loss_epoch=7.8e+5, valid_loss=8.6e+5]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.15e+5, train_loss_epoch=7.15e+5, valid_loss=8.6e+5]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.68e+5, train_loss_epoch=7.68e+5, valid_loss=8.6e+5]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.29e+5, train_loss_epoch=6.29e+5, valid_loss=8.6e+5]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.34e+5, train_loss_epoch=6.34e+5, valid_loss=8.6e+5]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.87e+5, train_loss_epoch=6.87e+5, valid_loss=8.6e+5]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.94e+5, train_loss_epoch=6.94e+5, valid_loss=8.6e+5]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.58e+5, train_loss_epoch=5.58e+5, valid_loss=8.6e+5]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.69e+5, train_loss_epoch=5.69e+5, valid_loss=8.6e+5]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.56e+5, train_loss_epoch=8.56e+5, valid_loss=8.6e+5]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.04e+5, train_loss_epoch=9.04e+5, valid_loss=8.6e+5]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.24e+5, train_loss_epoch=7.24e+5, valid_loss=8.6e+5]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+6, train_loss_epoch=1.08e+6, valid_loss=8.6e+5]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.12e+5, train_loss_epoch=7.12e+5, valid_loss=8.6e+5]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.9e+5, train_loss_epoch=6.9e+5, valid_loss=8.6e+5]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+6, train_loss_epoch=1e+6, valid_loss=8.6e+5]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.14e+5, train_loss_epoch=8.14e+5, valid_loss=8.6e+5]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.45e+5, train_loss_epoch=7.45e+5, valid_loss=8.6e+5]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.49e+5, train_loss_epoch=8.49e+5, valid_loss=8.6e+5]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.61e+5, train_loss_epoch=7.61e+5, valid_loss=8.6e+5]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.87e+5, train_loss_epoch=6.87e+5, valid_loss=8.6e+5]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.45e+5, train_loss_epoch=9.45e+5, valid_loss=8.6e+5]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.1e+5, train_loss_epoch=8.1e+5, valid_loss=8.6e+5]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.56e+5, train_loss_epoch=7.56e+5, valid_loss=8.6e+5]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.14e+6, train_loss_epoch=1.14e+6, valid_loss=8.6e+5]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.96e+5, train_loss_epoch=7.96e+5, valid_loss=8.6e+5]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.84e+5, train_loss_epoch=9.84e+5, valid_loss=8.6e+5]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+6, train_loss_epoch=1.05e+6, valid_loss=8.6e+5]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.72e+5, train_loss_epoch=7.72e+5, valid_loss=8.6e+5]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+6, train_loss_epoch=1.03e+6, valid_loss=8.6e+5]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.1e+5, train_loss_epoch=8.1e+5, valid_loss=8.6e+5]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9e+5, train_loss_epoch=9e+5, valid_loss=8.6e+5]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+6, train_loss_epoch=1.19e+6, valid_loss=8.6e+5]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.24e+5, train_loss_epoch=8.24e+5, valid_loss=8.6e+5]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+6, train_loss_epoch=1.13e+6, valid_loss=8.6e+5]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.16e+5, train_loss_epoch=8.16e+5, valid_loss=8.6e+5]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.16e+5, train_loss_epoch=7.16e+5, valid_loss=8.6e+5]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+6, train_loss_epoch=1e+6, valid_loss=8.6e+5]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.69e+5, train_loss_epoch=7.69e+5, valid_loss=8.6e+5]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.78e+5, train_loss_epoch=7.78e+5, valid_loss=8.6e+5]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.67e+5, train_loss_epoch=8.67e+5, valid_loss=8.6e+5]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.19e+5, train_loss_epoch=8.19e+5, valid_loss=8.6e+5]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.93e+5, train_loss_epoch=6.93e+5, valid_loss=8.6e+5]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.5e+5, train_loss_epoch=6.5e+5, valid_loss=8.6e+5]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.1e+5, train_loss_epoch=7.1e+5, valid_loss=8.6e+5]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.56e+5, train_loss_epoch=7.56e+5, valid_loss=8.6e+5]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.53e+5, train_loss_epoch=6.53e+5, valid_loss=8.6e+5]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.93e+5, train_loss_epoch=5.93e+5, valid_loss=8.6e+5]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.69e+5, train_loss_epoch=5.69e+5, valid_loss=8.6e+5]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+5, train_loss_epoch=5.87e+5, valid_loss=8.6e+5]\n",
            "Epoch 664: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s, v_num=0, train_loss_step=6.29e+5, train_loss_epoch=6.29e+5, valid_loss=8.6e+5]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.29e+5, train_loss_epoch=6.29e+5, valid_loss=8.6e+5]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.87e+5, train_loss_epoch=7.87e+5, valid_loss=8.6e+5]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.16e+5, train_loss_epoch=7.16e+5, valid_loss=8.6e+5]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.06e+5, train_loss_epoch=6.06e+5, valid_loss=8.6e+5]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.69e+5, train_loss_epoch=5.69e+5, valid_loss=8.6e+5]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.77e+5, train_loss_epoch=6.77e+5, valid_loss=8.6e+5]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.3e+5, train_loss_epoch=9.3e+5, valid_loss=8.6e+5]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.89e+5, train_loss_epoch=7.89e+5, valid_loss=8.6e+5]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.63e+5, train_loss_epoch=6.63e+5, valid_loss=8.6e+5]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.25e+5, train_loss_epoch=6.25e+5, valid_loss=8.6e+5]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.42e+5, train_loss_epoch=6.42e+5, valid_loss=8.6e+5]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.28e+5, train_loss_epoch=7.28e+5, valid_loss=8.6e+5]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.25e+5, train_loss_epoch=7.25e+5, valid_loss=8.6e+5]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.54e+5, train_loss_epoch=6.54e+5, valid_loss=8.6e+5]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.98e+5, train_loss_epoch=5.98e+5, valid_loss=8.6e+5]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.72e+5, train_loss_epoch=5.72e+5, valid_loss=8.6e+5]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.64e+5, train_loss_epoch=5.64e+5, valid_loss=8.6e+5]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.54e+5, train_loss_epoch=6.54e+5, valid_loss=8.6e+5]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.66e+5, train_loss_epoch=6.66e+5, valid_loss=8.6e+5]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.31e+5, train_loss_epoch=7.31e+5, valid_loss=8.6e+5]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.68e+5, train_loss_epoch=7.68e+5, valid_loss=8.6e+5]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.93e+5, train_loss_epoch=6.93e+5, valid_loss=8.6e+5]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.81e+5, train_loss_epoch=5.81e+5, valid_loss=8.6e+5]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.78e+5, train_loss_epoch=5.78e+5, valid_loss=8.6e+5]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.84e+5, train_loss_epoch=6.84e+5, valid_loss=8.6e+5]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.32e+5, train_loss_epoch=8.32e+5, valid_loss=8.6e+5]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.66e+5, train_loss_epoch=7.66e+5, valid_loss=8.6e+5]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.53e+5, train_loss_epoch=6.53e+5, valid_loss=8.6e+5]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.42e+5, train_loss_epoch=6.42e+5, valid_loss=8.6e+5]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.19e+5, train_loss_epoch=9.19e+5, valid_loss=8.6e+5]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.44e+5, train_loss_epoch=9.44e+5, valid_loss=8.6e+5]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.05e+5, train_loss_epoch=9.05e+5, valid_loss=8.6e+5]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.56e+5, train_loss_epoch=8.56e+5, valid_loss=8.6e+5]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.73e+5, train_loss_epoch=6.73e+5, valid_loss=8.6e+5]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.36e+5, train_loss_epoch=8.36e+5, valid_loss=8.6e+5]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  4.52it/s, v_num=0, train_loss_step=9.95e+5, train_loss_epoch=8.36e+5, valid_loss=8.6e+5]\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 105.11it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.95e+5, train_loss_epoch=9.95e+5, valid_loss=8.58e+5]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.31e+5, train_loss_epoch=8.31e+5, valid_loss=8.58e+5]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+6, train_loss_epoch=1.06e+6, valid_loss=8.58e+5]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.35e+5, train_loss_epoch=8.35e+5, valid_loss=8.58e+5]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.24e+5, train_loss_epoch=9.24e+5, valid_loss=8.58e+5]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+6, train_loss_epoch=1.04e+6, valid_loss=8.58e+5]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.73e+5, train_loss_epoch=7.73e+5, valid_loss=8.58e+5]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+6, train_loss_epoch=1e+6, valid_loss=8.58e+5]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.36e+5, train_loss_epoch=7.36e+5, valid_loss=8.58e+5]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.02e+5, train_loss_epoch=7.02e+5, valid_loss=8.58e+5]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.48e+5, train_loss_epoch=9.48e+5, valid_loss=8.58e+5]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.12e+5, train_loss_epoch=8.12e+5, valid_loss=8.58e+5]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.5e+5, train_loss_epoch=7.5e+5, valid_loss=8.58e+5]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+5, train_loss_epoch=7.95e+5, valid_loss=8.58e+5]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.57e+5, train_loss_epoch=8.57e+5, valid_loss=8.58e+5]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.21e+5, train_loss_epoch=8.21e+5, valid_loss=8.58e+5]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.92e+5, train_loss_epoch=7.92e+5, valid_loss=8.58e+5]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.52e+5, train_loss_epoch=8.52e+5, valid_loss=8.58e+5]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.83e+5, train_loss_epoch=6.83e+5, valid_loss=8.58e+5]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.09e+5, train_loss_epoch=7.09e+5, valid_loss=8.58e+5]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.17e+5, train_loss_epoch=9.17e+5, valid_loss=8.58e+5]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.87e+5, train_loss_epoch=7.87e+5, valid_loss=8.58e+5]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.68e+5, train_loss_epoch=7.68e+5, valid_loss=8.58e+5]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.33e+5, train_loss_epoch=9.33e+5, valid_loss=8.58e+5]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.17e+5, train_loss_epoch=7.17e+5, valid_loss=8.58e+5]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.94e+5, train_loss_epoch=5.94e+5, valid_loss=8.58e+5]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.88e+5, train_loss_epoch=7.88e+5, valid_loss=8.58e+5]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.55e+5, train_loss_epoch=8.55e+5, valid_loss=8.58e+5]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.34e+5, train_loss_epoch=7.34e+5, valid_loss=8.58e+5]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.01e+5, train_loss_epoch=7.01e+5, valid_loss=8.58e+5]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.03e+5, train_loss_epoch=7.03e+5, valid_loss=8.58e+5]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.66e+5, train_loss_epoch=6.66e+5, valid_loss=8.58e+5]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.13e+5, train_loss_epoch=6.13e+5, valid_loss=8.58e+5]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.63e+5, train_loss_epoch=6.63e+5, valid_loss=8.58e+5]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.76e+5, train_loss_epoch=6.76e+5, valid_loss=8.58e+5]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.82e+5, train_loss_epoch=6.82e+5, valid_loss=8.58e+5]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.2e+5, train_loss_epoch=6.2e+5, valid_loss=8.58e+5]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.19e+5, train_loss_epoch=5.19e+5, valid_loss=8.58e+5]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.66e+5, train_loss_epoch=5.66e+5, valid_loss=8.58e+5]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.19e+5, train_loss_epoch=6.19e+5, valid_loss=8.58e+5]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.58e+5, train_loss_epoch=6.58e+5, valid_loss=8.58e+5]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.2e+5, train_loss_epoch=7.2e+5, valid_loss=8.58e+5]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.53e+5, train_loss_epoch=7.53e+5, valid_loss=8.58e+5]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.41e+5, train_loss_epoch=6.41e+5, valid_loss=8.58e+5]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.1e+5, train_loss_epoch=6.1e+5, valid_loss=8.58e+5]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.14e+5, train_loss_epoch=6.14e+5, valid_loss=8.58e+5]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.17e+5, train_loss_epoch=8.17e+5, valid_loss=8.58e+5]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.8e+5, train_loss_epoch=9.8e+5, valid_loss=8.58e+5]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.38e+5, train_loss_epoch=7.38e+5, valid_loss=8.58e+5]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.14e+5, train_loss_epoch=9.14e+5, valid_loss=8.58e+5]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+6, train_loss_epoch=1.01e+6, valid_loss=8.58e+5]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.13e+5, train_loss_epoch=6.13e+5, valid_loss=8.58e+5]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.25e+5, train_loss_epoch=6.25e+5, valid_loss=8.58e+5]\n",
            "Epoch 752: 100%|██████████| 1/1 [00:00<00:00,  4.82it/s, v_num=0, train_loss_step=1.12e+6, train_loss_epoch=1.12e+6, valid_loss=8.58e+5]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.12e+6, train_loss_epoch=1.12e+6, valid_loss=8.58e+5]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.86e+5, train_loss_epoch=7.86e+5, valid_loss=8.58e+5]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.73e+5, train_loss_epoch=9.73e+5, valid_loss=8.58e+5]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.07e+6, train_loss_epoch=1.07e+6, valid_loss=8.58e+5]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.03e+5, train_loss_epoch=6.03e+5, valid_loss=8.58e+5]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.29e+5, train_loss_epoch=8.29e+5, valid_loss=8.58e+5]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.13e+6, train_loss_epoch=1.13e+6, valid_loss=8.58e+5]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.34e+5, train_loss_epoch=7.34e+5, valid_loss=8.58e+5]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.39e+5, train_loss_epoch=9.39e+5, valid_loss=8.58e+5]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.17e+6, train_loss_epoch=1.17e+6, valid_loss=8.58e+5]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.52e+5, train_loss_epoch=6.52e+5, valid_loss=8.58e+5]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.91e+5, train_loss_epoch=9.91e+5, valid_loss=8.58e+5]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.18e+6, train_loss_epoch=1.18e+6, valid_loss=8.58e+5]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.28e+5, train_loss_epoch=7.28e+5, valid_loss=8.58e+5]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.37e+6, train_loss_epoch=1.37e+6, valid_loss=8.58e+5]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.22e+5, train_loss_epoch=7.22e+5, valid_loss=8.58e+5]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.26e+6, train_loss_epoch=1.26e+6, valid_loss=8.58e+5]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.13e+5, train_loss_epoch=8.13e+5, valid_loss=8.58e+5]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.55e+5, train_loss_epoch=7.55e+5, valid_loss=8.58e+5]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.29e+6, train_loss_epoch=1.29e+6, valid_loss=8.58e+5]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.05e+5, train_loss_epoch=7.05e+5, valid_loss=8.58e+5]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+6, train_loss_epoch=1.15e+6, valid_loss=8.58e+5]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.7e+5, train_loss_epoch=9.7e+5, valid_loss=8.58e+5]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.57e+5, train_loss_epoch=6.57e+5, valid_loss=8.58e+5]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+6, train_loss_epoch=1.05e+6, valid_loss=8.58e+5]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.34e+5, train_loss_epoch=9.34e+5, valid_loss=8.58e+5]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.86e+5, train_loss_epoch=6.86e+5, valid_loss=8.58e+5]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.37e+5, train_loss_epoch=8.37e+5, valid_loss=8.58e+5]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+6, train_loss_epoch=1.08e+6, valid_loss=8.58e+5]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.95e+5, train_loss_epoch=6.95e+5, valid_loss=8.58e+5]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.31e+5, train_loss_epoch=7.31e+5, valid_loss=8.58e+5]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.31e+6, train_loss_epoch=1.31e+6, valid_loss=8.58e+5]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.58e+5, train_loss_epoch=7.58e+5, valid_loss=8.58e+5]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.2e+6, train_loss_epoch=1.2e+6, valid_loss=8.58e+5]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.03e+5, train_loss_epoch=9.03e+5, valid_loss=8.58e+5]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.17e+5, train_loss_epoch=7.17e+5, valid_loss=8.58e+5]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.16e+6, train_loss_epoch=1.16e+6, valid_loss=8.58e+5]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.48e+5, train_loss_epoch=8.48e+5, valid_loss=8.58e+5]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+5, train_loss_epoch=7.95e+5, valid_loss=8.58e+5]\n",
            "Epoch 791: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s, v_num=0, train_loss_step=9.92e+5, train_loss_epoch=9.92e+5, valid_loss=8.58e+5]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.92e+5, train_loss_epoch=9.92e+5, valid_loss=8.58e+5]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.39e+5, train_loss_epoch=8.39e+5, valid_loss=8.58e+5]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.93e+5, train_loss_epoch=6.93e+5, valid_loss=8.58e+5]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.39e+5, train_loss_epoch=7.39e+5, valid_loss=8.58e+5]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.83e+5, train_loss_epoch=8.83e+5, valid_loss=8.58e+5]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+5, train_loss_epoch=7.95e+5, valid_loss=8.58e+5]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.48e+5, train_loss_epoch=8.48e+5, valid_loss=8.58e+5]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.35e+5, train_loss_epoch=9.35e+5, valid_loss=8.58e+5]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s, v_num=0, train_loss_step=6.9e+5, train_loss_epoch=9.35e+5, valid_loss=8.58e+5] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.56it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.9e+5, train_loss_epoch=6.9e+5, valid_loss=6.67e+5]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.35e+5, train_loss_epoch=6.35e+5, valid_loss=6.67e+5]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.91e+5, train_loss_epoch=6.91e+5, valid_loss=6.67e+5]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.66e+5, train_loss_epoch=7.66e+5, valid_loss=6.67e+5]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.39e+5, train_loss_epoch=8.39e+5, valid_loss=6.67e+5]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.04e+5, train_loss_epoch=8.04e+5, valid_loss=6.67e+5]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.35e+5, train_loss_epoch=7.35e+5, valid_loss=6.67e+5]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.75e+5, train_loss_epoch=6.75e+5, valid_loss=6.67e+5]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.37e+5, train_loss_epoch=8.37e+5, valid_loss=6.67e+5]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.84e+5, train_loss_epoch=8.84e+5, valid_loss=6.67e+5]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.02e+5, train_loss_epoch=8.02e+5, valid_loss=6.67e+5]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.32e+5, train_loss_epoch=8.32e+5, valid_loss=6.67e+5]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.81e+5, train_loss_epoch=7.81e+5, valid_loss=6.67e+5]\n",
            "Epoch 812: 100%|██████████| 1/1 [00:00<00:00,  3.26it/s, v_num=0, train_loss_step=7.13e+5, train_loss_epoch=7.13e+5, valid_loss=6.67e+5]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.13e+5, train_loss_epoch=7.13e+5, valid_loss=6.67e+5]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.51e+5, train_loss_epoch=7.51e+5, valid_loss=6.67e+5]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.31e+5, train_loss_epoch=7.31e+5, valid_loss=6.67e+5]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.95e+5, train_loss_epoch=6.95e+5, valid_loss=6.67e+5]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.01e+5, train_loss_epoch=6.01e+5, valid_loss=6.67e+5]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.2e+5, train_loss_epoch=6.2e+5, valid_loss=6.67e+5]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.11e+5, train_loss_epoch=6.11e+5, valid_loss=6.67e+5]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.58e+5, train_loss_epoch=6.58e+5, valid_loss=6.67e+5]\n",
            "Epoch 820: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s, v_num=0, train_loss_step=6.85e+5, train_loss_epoch=6.58e+5, valid_loss=6.67e+5]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.85e+5, train_loss_epoch=6.85e+5, valid_loss=6.67e+5]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.42e+5, train_loss_epoch=6.42e+5, valid_loss=6.67e+5]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.11e+5, train_loss_epoch=7.11e+5, valid_loss=6.67e+5]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.92e+5, train_loss_epoch=6.92e+5, valid_loss=6.67e+5]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.74e+5, train_loss_epoch=5.74e+5, valid_loss=6.67e+5]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.84e+5, train_loss_epoch=6.84e+5, valid_loss=6.67e+5]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.34e+5, train_loss_epoch=8.34e+5, valid_loss=6.67e+5]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.79e+5, train_loss_epoch=7.79e+5, valid_loss=6.67e+5]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.37e+5, train_loss_epoch=6.37e+5, valid_loss=6.67e+5]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.5e+5, train_loss_epoch=7.5e+5, valid_loss=6.67e+5]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.87e+5, train_loss_epoch=8.87e+5, valid_loss=6.67e+5]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.37e+5, train_loss_epoch=7.37e+5, valid_loss=6.67e+5]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.75e+5, train_loss_epoch=6.75e+5, valid_loss=6.67e+5]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.46e+5, train_loss_epoch=8.46e+5, valid_loss=6.67e+5]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.41e+5, train_loss_epoch=7.41e+5, valid_loss=6.67e+5]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.88e+5, train_loss_epoch=5.88e+5, valid_loss=6.67e+5]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.73e+5, train_loss_epoch=5.73e+5, valid_loss=6.67e+5]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.72e+5, train_loss_epoch=5.72e+5, valid_loss=6.67e+5]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.26e+5, train_loss_epoch=5.26e+5, valid_loss=6.67e+5]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.66e+5, train_loss_epoch=5.66e+5, valid_loss=6.67e+5]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+5, train_loss_epoch=7.95e+5, valid_loss=6.67e+5]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.8e+5, train_loss_epoch=9.8e+5, valid_loss=6.67e+5]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.88e+5, train_loss_epoch=6.88e+5, valid_loss=6.67e+5]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.5e+5, train_loss_epoch=9.5e+5, valid_loss=6.67e+5]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.54e+5, train_loss_epoch=8.54e+5, valid_loss=6.67e+5]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.69e+5, train_loss_epoch=5.69e+5, valid_loss=6.67e+5]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.52e+5, train_loss_epoch=5.52e+5, valid_loss=6.67e+5]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.53e+5, train_loss_epoch=9.53e+5, valid_loss=6.67e+5]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+6, train_loss_epoch=1.05e+6, valid_loss=6.67e+5]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.14e+5, train_loss_epoch=8.14e+5, valid_loss=6.67e+5]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.02e+6, train_loss_epoch=1.02e+6, valid_loss=6.67e+5]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.59e+5, train_loss_epoch=6.59e+5, valid_loss=6.67e+5]\n",
            "Epoch 852: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=0, train_loss_step=6.18e+5, train_loss_epoch=6.18e+5, valid_loss=6.67e+5]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.18e+5, train_loss_epoch=6.18e+5, valid_loss=6.67e+5]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.84e+5, train_loss_epoch=8.84e+5, valid_loss=6.67e+5]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.54e+5, train_loss_epoch=8.54e+5, valid_loss=6.67e+5]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.53e+5, train_loss_epoch=7.53e+5, valid_loss=6.67e+5]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.76e+5, train_loss_epoch=7.76e+5, valid_loss=6.67e+5]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.56e+5, train_loss_epoch=7.56e+5, valid_loss=6.67e+5]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.2e+5, train_loss_epoch=7.2e+5, valid_loss=6.67e+5]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.68e+5, train_loss_epoch=6.68e+5, valid_loss=6.67e+5]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.8e+5, train_loss_epoch=6.8e+5, valid_loss=6.67e+5]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.65e+5, train_loss_epoch=6.65e+5, valid_loss=6.67e+5]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.73e+5, train_loss_epoch=5.73e+5, valid_loss=6.67e+5]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.53e+5, train_loss_epoch=6.53e+5, valid_loss=6.67e+5]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.92e+5, train_loss_epoch=7.92e+5, valid_loss=6.67e+5]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.43e+5, train_loss_epoch=7.43e+5, valid_loss=6.67e+5]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.85e+5, train_loss_epoch=6.85e+5, valid_loss=6.67e+5]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.77e+5, train_loss_epoch=6.77e+5, valid_loss=6.67e+5]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.14e+5, train_loss_epoch=8.14e+5, valid_loss=6.67e+5]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.92e+5, train_loss_epoch=7.92e+5, valid_loss=6.67e+5]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.17e+5, train_loss_epoch=7.17e+5, valid_loss=6.67e+5]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.07e+5, train_loss_epoch=8.07e+5, valid_loss=6.67e+5]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.12e+5, train_loss_epoch=8.12e+5, valid_loss=6.67e+5]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.27e+5, train_loss_epoch=7.27e+5, valid_loss=6.67e+5]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.81e+5, train_loss_epoch=6.81e+5, valid_loss=6.67e+5]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.86e+5, train_loss_epoch=6.86e+5, valid_loss=6.67e+5]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.09e+5, train_loss_epoch=7.09e+5, valid_loss=6.67e+5]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.54e+5, train_loss_epoch=7.54e+5, valid_loss=6.67e+5]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.28e+5, train_loss_epoch=6.28e+5, valid_loss=6.67e+5]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.69e+5, train_loss_epoch=6.69e+5, valid_loss=6.67e+5]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.78e+5, train_loss_epoch=6.78e+5, valid_loss=6.67e+5]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.19e+5, train_loss_epoch=7.19e+5, valid_loss=6.67e+5]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.37e+5, train_loss_epoch=6.37e+5, valid_loss=6.67e+5]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+5, train_loss_epoch=4.97e+5, valid_loss=6.67e+5]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.37e+5, train_loss_epoch=6.37e+5, valid_loss=6.67e+5]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.59e+5, train_loss_epoch=8.59e+5, valid_loss=6.67e+5]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.01e+5, train_loss_epoch=8.01e+5, valid_loss=6.67e+5]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.47e+5, train_loss_epoch=6.47e+5, valid_loss=6.67e+5]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.15e+5, train_loss_epoch=8.15e+5, valid_loss=6.67e+5]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.05e+5, train_loss_epoch=9.05e+5, valid_loss=6.67e+5]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.75e+5, train_loss_epoch=6.75e+5, valid_loss=6.67e+5]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.23e+5, train_loss_epoch=7.23e+5, valid_loss=6.67e+5]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.3e+5, train_loss_epoch=9.3e+5, valid_loss=6.67e+5]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.51e+5, train_loss_epoch=8.51e+5, valid_loss=6.67e+5]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.93e+5, train_loss_epoch=6.93e+5, valid_loss=6.67e+5]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.05e+6, train_loss_epoch=1.05e+6, valid_loss=6.67e+5]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.95e+5, train_loss_epoch=6.95e+5, valid_loss=6.67e+5]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.58e+5, train_loss_epoch=7.58e+5, valid_loss=6.67e+5]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.21e+6, train_loss_epoch=1.21e+6, valid_loss=6.67e+5]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  4.04it/s, v_num=0, train_loss_step=7.94e+5, train_loss_epoch=1.21e+6, valid_loss=6.67e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.42it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.94e+5, train_loss_epoch=7.94e+5, valid_loss=1.3e+6]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.24e+6, train_loss_epoch=1.24e+6, valid_loss=1.3e+6]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.41e+5, train_loss_epoch=7.41e+5, valid_loss=1.3e+6]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.04e+6, train_loss_epoch=1.04e+6, valid_loss=1.3e+6]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.37e+5, train_loss_epoch=8.37e+5, valid_loss=1.3e+6]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.36e+5, train_loss_epoch=6.36e+5, valid_loss=1.3e+6]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.5e+5, train_loss_epoch=8.5e+5, valid_loss=1.3e+6]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.36e+5, train_loss_epoch=8.36e+5, valid_loss=1.3e+6]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.3e+5, train_loss_epoch=7.3e+5, valid_loss=1.3e+6]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.5e+5, train_loss_epoch=7.5e+5, valid_loss=1.3e+6]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8e+5, train_loss_epoch=8e+5, valid_loss=1.3e+6]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.36e+5, train_loss_epoch=7.36e+5, valid_loss=1.3e+6]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.19e+5, train_loss_epoch=6.19e+5, valid_loss=1.3e+6]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.26e+5, train_loss_epoch=6.26e+5, valid_loss=1.3e+6]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.42e+5, train_loss_epoch=7.42e+5, valid_loss=1.3e+6]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.9e+5, train_loss_epoch=8.9e+5, valid_loss=1.3e+6]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.75e+5, train_loss_epoch=7.75e+5, valid_loss=1.3e+6]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.24e+5, train_loss_epoch=7.24e+5, valid_loss=1.3e+6]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.91e+5, train_loss_epoch=5.91e+5, valid_loss=1.3e+6]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.63e+5, train_loss_epoch=6.63e+5, valid_loss=1.3e+6]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.95e+5, train_loss_epoch=7.95e+5, valid_loss=1.3e+6]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.31e+5, train_loss_epoch=7.31e+5, valid_loss=1.3e+6]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.58e+5, train_loss_epoch=7.58e+5, valid_loss=1.3e+6]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.01e+6, train_loss_epoch=1.01e+6, valid_loss=1.3e+6]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.94e+5, train_loss_epoch=7.94e+5, valid_loss=1.3e+6]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.41e+5, train_loss_epoch=7.41e+5, valid_loss=1.3e+6]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.22e+5, train_loss_epoch=9.22e+5, valid_loss=1.3e+6]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.64e+5, train_loss_epoch=6.64e+5, valid_loss=1.3e+6]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.62e+5, train_loss_epoch=6.62e+5, valid_loss=1.3e+6]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.59e+5, train_loss_epoch=8.59e+5, valid_loss=1.3e+6]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.31e+5, train_loss_epoch=7.31e+5, valid_loss=1.3e+6]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.59e+5, train_loss_epoch=6.59e+5, valid_loss=1.3e+6]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.36e+5, train_loss_epoch=8.36e+5, valid_loss=1.3e+6]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.65e+5, train_loss_epoch=7.65e+5, valid_loss=1.3e+6]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.22e+5, train_loss_epoch=6.22e+5, valid_loss=1.3e+6]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.48e+5, train_loss_epoch=6.48e+5, valid_loss=1.3e+6]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.62e+5, train_loss_epoch=7.62e+5, valid_loss=1.3e+6]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.46e+5, train_loss_epoch=9.46e+5, valid_loss=1.3e+6]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.59e+5, train_loss_epoch=6.59e+5, valid_loss=1.3e+6]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.69e+5, train_loss_epoch=8.69e+5, valid_loss=1.3e+6]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.03e+6, train_loss_epoch=1.03e+6, valid_loss=1.3e+6]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.76e+5, train_loss_epoch=6.76e+5, valid_loss=1.3e+6]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+6, train_loss_epoch=1.08e+6, valid_loss=1.3e+6]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.82e+5, train_loss_epoch=7.82e+5, valid_loss=1.3e+6]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.01e+5, train_loss_epoch=7.01e+5, valid_loss=1.3e+6]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1e+6, train_loss_epoch=1e+6, valid_loss=1.3e+6]\n",
            "Epoch 945: 100%|██████████| 1/1 [00:00<00:00,  3.72it/s, v_num=0, train_loss_step=6.46e+5, train_loss_epoch=6.46e+5, valid_loss=1.3e+6]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.46e+5, train_loss_epoch=6.46e+5, valid_loss=1.3e+6]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.82e+5, train_loss_epoch=7.82e+5, valid_loss=1.3e+6]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.25e+6, train_loss_epoch=1.25e+6, valid_loss=1.3e+6]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.09e+5, train_loss_epoch=7.09e+5, valid_loss=1.3e+6]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.33e+6, train_loss_epoch=1.33e+6, valid_loss=1.3e+6]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.97e+5, train_loss_epoch=6.97e+5, valid_loss=1.3e+6]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+6, train_loss_epoch=1.19e+6, valid_loss=1.3e+6]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.22e+5, train_loss_epoch=9.22e+5, valid_loss=1.3e+6]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.47e+5, train_loss_epoch=6.47e+5, valid_loss=1.3e+6]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.8e+5, train_loss_epoch=9.8e+5, valid_loss=1.3e+6]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.76e+5, train_loss_epoch=6.76e+5, valid_loss=1.3e+6]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.86e+5, train_loss_epoch=5.86e+5, valid_loss=1.3e+6]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.36e+5, train_loss_epoch=5.36e+5, valid_loss=1.3e+6]\n",
            "Epoch 958: 100%|██████████| 1/1 [00:00<00:00,  3.53it/s, v_num=0, train_loss_step=5.19e+5, train_loss_epoch=5.19e+5, valid_loss=1.3e+6]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.19e+5, train_loss_epoch=5.19e+5, valid_loss=1.3e+6]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.82e+5, train_loss_epoch=4.82e+5, valid_loss=1.3e+6]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.81e+5, train_loss_epoch=4.81e+5, valid_loss=1.3e+6]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.1e+5, train_loss_epoch=5.1e+5, valid_loss=1.3e+6]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.37e+5, train_loss_epoch=6.37e+5, valid_loss=1.3e+6]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.17e+5, train_loss_epoch=7.17e+5, valid_loss=1.3e+6]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.37e+5, train_loss_epoch=7.37e+5, valid_loss=1.3e+6]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.75e+5, train_loss_epoch=5.75e+5, valid_loss=1.3e+6]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.12e+5, train_loss_epoch=5.12e+5, valid_loss=1.3e+6]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.71e+5, train_loss_epoch=7.71e+5, valid_loss=1.3e+6]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.06e+6, train_loss_epoch=1.06e+6, valid_loss=1.3e+6]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.09e+5, train_loss_epoch=7.09e+5, valid_loss=1.3e+6]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+6, train_loss_epoch=1.19e+6, valid_loss=1.3e+6]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.5e+5, train_loss_epoch=6.5e+5, valid_loss=1.3e+6]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.15e+6, train_loss_epoch=1.15e+6, valid_loss=1.3e+6]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.21e+5, train_loss_epoch=8.21e+5, valid_loss=1.3e+6]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.21e+5, train_loss_epoch=6.21e+5, valid_loss=1.3e+6]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.68e+5, train_loss_epoch=8.68e+5, valid_loss=1.3e+6]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.26e+5, train_loss_epoch=7.26e+5, valid_loss=1.3e+6]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.58e+5, train_loss_epoch=5.58e+5, valid_loss=1.3e+6]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.93e+5, train_loss_epoch=4.93e+5, valid_loss=1.3e+6]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.33e+5, train_loss_epoch=9.33e+5, valid_loss=1.3e+6]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.1e+5, train_loss_epoch=8.1e+5, valid_loss=1.3e+6]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.92e+5, train_loss_epoch=8.92e+5, valid_loss=1.3e+6]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.08e+6, train_loss_epoch=1.08e+6, valid_loss=1.3e+6]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.65e+5, train_loss_epoch=6.65e+5, valid_loss=1.3e+6]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.19e+6, train_loss_epoch=1.19e+6, valid_loss=1.3e+6]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.85e+5, train_loss_epoch=7.85e+5, valid_loss=1.3e+6]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.86e+5, train_loss_epoch=6.86e+5, valid_loss=1.3e+6]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.42e+5, train_loss_epoch=9.42e+5, valid_loss=1.3e+6]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.21e+5, train_loss_epoch=8.21e+5, valid_loss=1.3e+6]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.71e+5, train_loss_epoch=6.71e+5, valid_loss=1.3e+6]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.48e+5, train_loss_epoch=8.48e+5, valid_loss=1.3e+6]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.93e+5, train_loss_epoch=6.93e+5, valid_loss=1.3e+6]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.43e+5, train_loss_epoch=6.43e+5, valid_loss=1.3e+6]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.32e+5, train_loss_epoch=6.32e+5, valid_loss=1.3e+6]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+5, train_loss_epoch=5.85e+5, valid_loss=1.3e+6]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.7e+5, train_loss_epoch=5.7e+5, valid_loss=1.3e+6]\n",
            "Epoch 996: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s, v_num=0, train_loss_step=6.2e+5, train_loss_epoch=5.7e+5, valid_loss=1.3e+6]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.2e+5, train_loss_epoch=6.2e+5, valid_loss=1.3e+6]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.77e+5, train_loss_epoch=6.77e+5, valid_loss=1.3e+6]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+5, train_loss_epoch=5.87e+5, valid_loss=1.3e+6]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  3.89it/s, v_num=0, train_loss_step=5.64e+5, train_loss_epoch=5.87e+5, valid_loss=1.3e+6]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 49.70it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.64e+5, train_loss_epoch=5.64e+5, valid_loss=5.98e+5]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.72e+5, train_loss_epoch=5.72e+5, valid_loss=5.98e+5]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.1e+5, train_loss_epoch=5.1e+5, valid_loss=5.98e+5]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.52e+5, train_loss_epoch=4.52e+5, valid_loss=5.98e+5]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.64e+5, train_loss_epoch=3.64e+5, valid_loss=5.98e+5]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.66e+5, train_loss_epoch=3.66e+5, valid_loss=5.98e+5]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.84e+5, train_loss_epoch=3.84e+5, valid_loss=5.98e+5]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.44e+5, train_loss_epoch=3.44e+5, valid_loss=5.98e+5]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+5, train_loss_epoch=3.09e+5, valid_loss=5.98e+5]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.22e+7, train_loss_epoch=1.22e+7, valid_loss=5.98e+5]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.37e+5, train_loss_epoch=4.37e+5, valid_loss=5.98e+5]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+5, train_loss_epoch=3.69e+5, valid_loss=5.98e+5]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.42e+5, train_loss_epoch=4.42e+5, valid_loss=5.98e+5]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.28e+5, train_loss_epoch=5.28e+5, valid_loss=5.98e+5]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.76e+5, train_loss_epoch=3.76e+5, valid_loss=5.98e+5]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+5, train_loss_epoch=3.16e+5, valid_loss=5.98e+5]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.02e+5, train_loss_epoch=3.02e+5, valid_loss=5.98e+5]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.89e+5, train_loss_epoch=4.89e+5, valid_loss=5.98e+5]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.11e+5, train_loss_epoch=5.11e+5, valid_loss=5.98e+5]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.33e+5, train_loss_epoch=4.33e+5, valid_loss=5.98e+5]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.63e+5, train_loss_epoch=4.63e+5, valid_loss=5.98e+5]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.99e+5, train_loss_epoch=3.99e+5, valid_loss=5.98e+5]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.35e+5, train_loss_epoch=3.35e+5, valid_loss=5.98e+5]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+5, train_loss_epoch=3.39e+5, valid_loss=5.98e+5]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.79e+5, train_loss_epoch=3.79e+5, valid_loss=5.98e+5]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.7e+5, train_loss_epoch=3.7e+5, valid_loss=5.98e+5]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.01e+5, train_loss_epoch=4.01e+5, valid_loss=5.98e+5]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+5, train_loss_epoch=3.85e+5, valid_loss=5.98e+5]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.38e+5, train_loss_epoch=3.38e+5, valid_loss=5.98e+5]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+5, train_loss_epoch=3e+5, valid_loss=5.98e+5]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.08e+5, valid_loss=5.98e+5]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.22e+5, train_loss_epoch=4.22e+5, valid_loss=5.98e+5]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.65e+5, train_loss_epoch=4.65e+5, valid_loss=5.98e+5]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.34e+5, train_loss_epoch=3.34e+5, valid_loss=5.98e+5]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+5, train_loss_epoch=3.16e+5, valid_loss=5.98e+5]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.03e+5, train_loss_epoch=5.03e+5, valid_loss=5.98e+5]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.24e+5, train_loss_epoch=5.24e+5, valid_loss=5.98e+5]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.77e+5, train_loss_epoch=3.77e+5, valid_loss=5.98e+5]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+5, train_loss_epoch=4.15e+5, valid_loss=5.98e+5]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.99e+5, train_loss_epoch=4.99e+5, valid_loss=5.98e+5]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.87e+5, train_loss_epoch=3.87e+5, valid_loss=5.98e+5]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+5, train_loss_epoch=2.88e+5, valid_loss=5.98e+5]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.12e+5, train_loss_epoch=3.12e+5, valid_loss=5.98e+5]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.55e+5, train_loss_epoch=4.55e+5, valid_loss=5.98e+5]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.95e+5, train_loss_epoch=4.95e+5, valid_loss=5.98e+5]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.91e+5, train_loss_epoch=3.91e+5, valid_loss=5.98e+5]\n",
            "Epoch 1045: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=0, train_loss_step=4.51e+5, train_loss_epoch=4.51e+5, valid_loss=5.98e+5]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.51e+5, train_loss_epoch=4.51e+5, valid_loss=5.98e+5]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.36e+5, train_loss_epoch=5.36e+5, valid_loss=5.98e+5]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.36e+5, train_loss_epoch=3.36e+5, valid_loss=5.98e+5]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=5.98e+5]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+5, train_loss_epoch=4.97e+5, valid_loss=5.98e+5]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.1e+5, train_loss_epoch=5.1e+5, valid_loss=5.98e+5]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.5e+5, train_loss_epoch=3.5e+5, valid_loss=5.98e+5]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.18e+5, train_loss_epoch=4.18e+5, valid_loss=5.98e+5]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.17e+5, train_loss_epoch=6.17e+5, valid_loss=5.98e+5]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+5, train_loss_epoch=3.69e+5, valid_loss=5.98e+5]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+5, train_loss_epoch=3.19e+5, valid_loss=5.98e+5]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4e+5, train_loss_epoch=4e+5, valid_loss=5.98e+5]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.97e+5, train_loss_epoch=4.97e+5, valid_loss=5.98e+5]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.25e+5, train_loss_epoch=4.25e+5, valid_loss=5.98e+5]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.95e+5, train_loss_epoch=3.95e+5, valid_loss=5.98e+5]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.79e+5, train_loss_epoch=3.79e+5, valid_loss=5.98e+5]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.35e+5, train_loss_epoch=3.35e+5, valid_loss=5.98e+5]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.41e+5, train_loss_epoch=4.41e+5, valid_loss=5.98e+5]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.48e+5, train_loss_epoch=4.48e+5, valid_loss=5.98e+5]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.87e+5, train_loss_epoch=3.87e+5, valid_loss=5.98e+5]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.16e+5, train_loss_epoch=4.16e+5, valid_loss=5.98e+5]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.06e+5, train_loss_epoch=4.06e+5, valid_loss=5.98e+5]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5e+5, train_loss_epoch=5e+5, valid_loss=5.98e+5]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.92e+5, train_loss_epoch=3.92e+5, valid_loss=5.98e+5]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.19e+5, train_loss_epoch=4.19e+5, valid_loss=5.98e+5]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.02e+5, train_loss_epoch=5.02e+5, valid_loss=5.98e+5]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.69e+5, train_loss_epoch=3.69e+5, valid_loss=5.98e+5]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+5, train_loss_epoch=3.16e+5, valid_loss=5.98e+5]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+5, train_loss_epoch=3.18e+5, valid_loss=5.98e+5]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.29e+5, train_loss_epoch=4.29e+5, valid_loss=5.98e+5]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.95e+5, train_loss_epoch=4.95e+5, valid_loss=5.98e+5]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.94e+5, train_loss_epoch=3.94e+5, valid_loss=5.98e+5]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.11e+5, train_loss_epoch=5.11e+5, valid_loss=5.98e+5]\n",
            "Epoch 1078: 100%|██████████| 1/1 [00:00<00:00,  2.87it/s, v_num=0, train_loss_step=5.11e+5, train_loss_epoch=5.11e+5, valid_loss=5.98e+5]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.26e+5, train_loss_epoch=5.26e+5, valid_loss=5.98e+5]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+5, train_loss_epoch=3.09e+5, valid_loss=5.98e+5]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.66e+5, train_loss_epoch=3.66e+5, valid_loss=5.98e+5]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.86e+5, train_loss_epoch=7.86e+5, valid_loss=5.98e+5]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.11e+5, train_loss_epoch=4.11e+5, valid_loss=5.98e+5]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.96e+5, train_loss_epoch=8.96e+5, valid_loss=5.98e+5]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.59e+5, train_loss_epoch=4.59e+5, valid_loss=5.98e+5]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.93e+5, train_loss_epoch=9.93e+5, valid_loss=5.98e+5]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.76e+5, train_loss_epoch=5.76e+5, valid_loss=5.98e+5]\n",
            "Epoch 1087: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s, v_num=0, train_loss_step=1.11e+6, train_loss_epoch=1.11e+6, valid_loss=5.98e+5]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.11e+6, train_loss_epoch=1.11e+6, valid_loss=5.98e+5]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.91e+5, train_loss_epoch=9.91e+5, valid_loss=5.98e+5]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.36e+5, train_loss_epoch=7.36e+5, valid_loss=5.98e+5]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.73e+5, train_loss_epoch=7.73e+5, valid_loss=5.98e+5]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.25e+5, train_loss_epoch=7.25e+5, valid_loss=5.98e+5]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.11e+5, train_loss_epoch=8.11e+5, valid_loss=5.98e+5]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.34e+5, train_loss_epoch=6.34e+5, valid_loss=5.98e+5]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.82e+5, train_loss_epoch=7.82e+5, valid_loss=5.98e+5]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.17e+5, train_loss_epoch=7.17e+5, valid_loss=5.98e+5]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.04e+5, train_loss_epoch=6.04e+5, valid_loss=5.98e+5]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.17e+5, train_loss_epoch=9.17e+5, valid_loss=5.98e+5]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.89e+5, train_loss_epoch=7.89e+5, valid_loss=5.98e+5]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s, v_num=0, train_loss_step=7.44e+5, train_loss_epoch=7.89e+5, valid_loss=5.98e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.63it/s]\u001b[A\n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.44e+5, train_loss_epoch=7.44e+5, valid_loss=5.89e+5]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.31e+5, train_loss_epoch=6.31e+5, valid_loss=5.89e+5]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.06e+5, train_loss_epoch=7.06e+5, valid_loss=5.89e+5]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.13e+5, train_loss_epoch=6.13e+5, valid_loss=5.89e+5]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.84e+5, train_loss_epoch=7.84e+5, valid_loss=5.89e+5]\n",
            "Epoch 1104: 100%|██████████| 1/1 [00:00<00:00,  4.09it/s, v_num=0, train_loss_step=5.08e+5, train_loss_epoch=5.08e+5, valid_loss=5.89e+5]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.08e+5, train_loss_epoch=5.08e+5, valid_loss=5.89e+5]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.88e+5, train_loss_epoch=9.88e+5, valid_loss=5.89e+5]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.3e+5, train_loss_epoch=9.3e+5, valid_loss=5.89e+5]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.51e+5, train_loss_epoch=7.51e+5, valid_loss=5.89e+5]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.84e+5, train_loss_epoch=8.84e+5, valid_loss=5.89e+5]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.4e+5, train_loss_epoch=6.4e+5, valid_loss=5.89e+5]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.64e+5, train_loss_epoch=7.64e+5, valid_loss=5.89e+5]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.7e+5, train_loss_epoch=4.7e+5, valid_loss=5.89e+5]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.68e+5, train_loss_epoch=4.68e+5, valid_loss=5.89e+5]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.67e+5, train_loss_epoch=7.67e+5, valid_loss=5.89e+5]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.77e+5, train_loss_epoch=4.77e+5, valid_loss=5.89e+5]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.93e+5, train_loss_epoch=8.93e+5, valid_loss=5.89e+5]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.55e+5, train_loss_epoch=6.55e+5, valid_loss=5.89e+5]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.36e+5, train_loss_epoch=8.36e+5, valid_loss=5.89e+5]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.83e+5, train_loss_epoch=7.83e+5, valid_loss=5.89e+5]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.06e+5, train_loss_epoch=7.06e+5, valid_loss=5.89e+5]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.66e+5, train_loss_epoch=6.66e+5, valid_loss=5.89e+5]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.08e+5, train_loss_epoch=7.08e+5, valid_loss=5.89e+5]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.59e+5, train_loss_epoch=5.59e+5, valid_loss=5.89e+5]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.83e+5, train_loss_epoch=7.83e+5, valid_loss=5.89e+5]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.42e+5, train_loss_epoch=5.42e+5, valid_loss=5.89e+5]\n",
            "Epoch 1125: 100%|██████████| 1/1 [00:00<00:00,  3.78it/s, v_num=0, train_loss_step=9.52e+5, train_loss_epoch=9.52e+5, valid_loss=5.89e+5]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.52e+5, train_loss_epoch=9.52e+5, valid_loss=5.89e+5]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.17e+5, train_loss_epoch=8.17e+5, valid_loss=5.89e+5]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.29e+5, train_loss_epoch=7.29e+5, valid_loss=5.89e+5]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.07e+5, train_loss_epoch=8.07e+5, valid_loss=5.89e+5]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.54e+5, train_loss_epoch=7.54e+5, valid_loss=5.89e+5]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.16e+5, train_loss_epoch=8.16e+5, valid_loss=5.89e+5]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.64e+5, train_loss_epoch=5.64e+5, valid_loss=5.89e+5]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.13e+5, train_loss_epoch=6.13e+5, valid_loss=5.89e+5]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.92e+5, train_loss_epoch=5.92e+5, valid_loss=5.89e+5]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.45e+5, train_loss_epoch=4.45e+5, valid_loss=5.89e+5]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.71e+5, train_loss_epoch=7.71e+5, valid_loss=5.89e+5]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.01e+5, train_loss_epoch=5.01e+5, valid_loss=5.89e+5]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.84e+5, train_loss_epoch=8.84e+5, valid_loss=5.89e+5]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.06e+5, train_loss_epoch=7.06e+5, valid_loss=5.89e+5]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.95e+5, train_loss_epoch=6.95e+5, valid_loss=5.89e+5]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.47e+5, train_loss_epoch=6.47e+5, valid_loss=5.89e+5]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.13e+5, train_loss_epoch=6.13e+5, valid_loss=5.89e+5]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.96e+5, train_loss_epoch=4.96e+5, valid_loss=5.89e+5]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.22e+5, train_loss_epoch=7.22e+5, valid_loss=5.89e+5]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.07e+5, train_loss_epoch=5.07e+5, valid_loss=5.89e+5]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.34e+5, train_loss_epoch=8.34e+5, valid_loss=5.89e+5]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.22e+5, train_loss_epoch=6.22e+5, valid_loss=5.89e+5]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.31e+5, train_loss_epoch=8.31e+5, valid_loss=5.89e+5]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.64e+5, train_loss_epoch=7.64e+5, valid_loss=5.89e+5]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.43e+5, train_loss_epoch=5.43e+5, valid_loss=5.89e+5]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.3e+5, train_loss_epoch=6.3e+5, valid_loss=5.89e+5]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.74e+5, train_loss_epoch=3.74e+5, valid_loss=5.89e+5]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.19e+5, train_loss_epoch=4.19e+5, valid_loss=5.89e+5]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.27e+5, train_loss_epoch=5.27e+5, valid_loss=5.89e+5]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.16e+5, train_loss_epoch=4.16e+5, valid_loss=5.89e+5]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.74e+5, train_loss_epoch=5.74e+5, valid_loss=5.89e+5]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.82e+5, train_loss_epoch=3.82e+5, valid_loss=5.89e+5]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6e+5, train_loss_epoch=6e+5, valid_loss=5.89e+5]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.27e+5, train_loss_epoch=3.27e+5, valid_loss=5.89e+5]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.87e+5, train_loss_epoch=5.87e+5, valid_loss=5.89e+5]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.72e+5, train_loss_epoch=3.72e+5, valid_loss=5.89e+5]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+5, train_loss_epoch=5.85e+5, valid_loss=5.89e+5]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.51e+5, train_loss_epoch=3.51e+5, valid_loss=5.89e+5]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.85e+5, train_loss_epoch=5.85e+5, valid_loss=5.89e+5]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.09e+5, train_loss_epoch=3.09e+5, valid_loss=5.89e+5]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.04e+5, train_loss_epoch=5.04e+5, valid_loss=5.89e+5]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.83e+5, train_loss_epoch=3.83e+5, valid_loss=5.89e+5]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.54e+5, train_loss_epoch=3.54e+5, valid_loss=5.89e+5]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.95e+5, train_loss_epoch=4.95e+5, valid_loss=5.89e+5]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+5, train_loss_epoch=3.11e+5, valid_loss=5.89e+5]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.02e+5, train_loss_epoch=4.02e+5, valid_loss=5.89e+5]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.52e+5, train_loss_epoch=4.52e+5, valid_loss=5.89e+5]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+5, train_loss_epoch=3.39e+5, valid_loss=5.89e+5]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.45e+5, train_loss_epoch=5.45e+5, valid_loss=5.89e+5]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.75e+5, train_loss_epoch=3.75e+5, valid_loss=5.89e+5]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.77e+5, train_loss_epoch=5.77e+5, valid_loss=5.89e+5]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.46e+5, train_loss_epoch=3.46e+5, valid_loss=5.89e+5]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.13e+5, train_loss_epoch=5.13e+5, valid_loss=5.89e+5]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.11e+5, train_loss_epoch=3.11e+5, valid_loss=5.89e+5]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.68e+5, train_loss_epoch=3.68e+5, valid_loss=5.89e+5]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.99e+5, train_loss_epoch=3.99e+5, valid_loss=5.89e+5]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.42e+5, train_loss_epoch=3.42e+5, valid_loss=5.89e+5]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.4e+5, train_loss_epoch=3.4e+5, valid_loss=5.89e+5]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.83e+5, train_loss_epoch=3.83e+5, valid_loss=5.89e+5]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+5, train_loss_epoch=3.16e+5, valid_loss=5.89e+5]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+5, train_loss_epoch=2.99e+5, valid_loss=5.89e+5]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.32e+5, train_loss_epoch=4.32e+5, valid_loss=5.89e+5]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.33e+5, train_loss_epoch=3.33e+5, valid_loss=5.89e+5]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.51e+5, train_loss_epoch=4.51e+5, valid_loss=5.89e+5]\n",
            "Epoch 1189: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s, v_num=0, train_loss_step=3.47e+5, train_loss_epoch=3.47e+5, valid_loss=5.89e+5]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.47e+5, train_loss_epoch=3.47e+5, valid_loss=5.89e+5]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.95e+5, train_loss_epoch=3.95e+5, valid_loss=5.89e+5]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.15e+5, train_loss_epoch=4.15e+5, valid_loss=5.89e+5]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.85e+5, train_loss_epoch=3.85e+5, valid_loss=5.89e+5]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.01e+5, train_loss_epoch=4.01e+5, valid_loss=5.89e+5]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.21e+5, train_loss_epoch=3.21e+5, valid_loss=5.89e+5]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+5, train_loss_epoch=2.95e+5, valid_loss=5.89e+5]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+5, train_loss_epoch=2.95e+5, valid_loss=5.89e+5]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+5, train_loss_epoch=2.95e+5, valid_loss=5.89e+5]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+5, train_loss_epoch=3.05e+5, valid_loss=5.89e+5]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s, v_num=0, train_loss_step=2.89e+5, train_loss_epoch=3.05e+5, valid_loss=5.89e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.86it/s]\u001b[A\n",
            "Epoch 1200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+5, train_loss_epoch=2.89e+5, valid_loss=2.64e+5]\n",
            "Epoch 1201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+5, train_loss_epoch=2.75e+5, valid_loss=2.64e+5]\n",
            "Epoch 1202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+5, train_loss_epoch=2.74e+5, valid_loss=2.64e+5]\n",
            "Epoch 1203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+5, train_loss_epoch=3.04e+5, valid_loss=2.64e+5]\n",
            "Epoch 1204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+5, train_loss_epoch=2.95e+5, valid_loss=2.64e+5]\n",
            "Epoch 1205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+5, train_loss_epoch=3.07e+5, valid_loss=2.64e+5]\n",
            "Epoch 1206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+5, train_loss_epoch=3.05e+5, valid_loss=2.64e+5]\n",
            "Epoch 1207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.97e+5, train_loss_epoch=2.97e+5, valid_loss=2.64e+5]\n",
            "Epoch 1208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+5, train_loss_epoch=3.01e+5, valid_loss=2.64e+5]\n",
            "Epoch 1209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+5, train_loss_epoch=2.87e+5, valid_loss=2.64e+5]\n",
            "Epoch 1210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+5, train_loss_epoch=2.76e+5, valid_loss=2.64e+5]\n",
            "Epoch 1211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+5, train_loss_epoch=2.66e+5, valid_loss=2.64e+5]\n",
            "Epoch 1212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+5, train_loss_epoch=2.51e+5, valid_loss=2.64e+5]\n",
            "Epoch 1213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+5, train_loss_epoch=2.73e+5, valid_loss=2.64e+5]\n",
            "Epoch 1214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+5, train_loss_epoch=2.94e+5, valid_loss=2.64e+5]\n",
            "Epoch 1214: 100%|██████████| 1/1 [00:00<00:00,  3.92it/s, v_num=0, train_loss_step=2.96e+5, train_loss_epoch=2.96e+5, valid_loss=2.64e+5]\n",
            "Epoch 1215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.96e+5, train_loss_epoch=2.96e+5, valid_loss=2.64e+5]\n",
            "Epoch 1216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+5, train_loss_epoch=3.04e+5, valid_loss=2.64e+5]\n",
            "Epoch 1217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.13e+5, train_loss_epoch=3.13e+5, valid_loss=2.64e+5]\n",
            "Epoch 1218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+5, train_loss_epoch=3.45e+5, valid_loss=2.64e+5]\n",
            "Epoch 1219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.06e+5, train_loss_epoch=3.06e+5, valid_loss=2.64e+5]\n",
            "Epoch 1220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+5, train_loss_epoch=2.81e+5, valid_loss=2.64e+5]\n",
            "Epoch 1221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.63e+5, train_loss_epoch=3.63e+5, valid_loss=2.64e+5]\n",
            "Epoch 1222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.46e+5, train_loss_epoch=3.46e+5, valid_loss=2.64e+5]\n",
            "Epoch 1223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+5, train_loss_epoch=3.03e+5, valid_loss=2.64e+5]\n",
            "Epoch 1224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.14e+5, train_loss_epoch=3.14e+5, valid_loss=2.64e+5]\n",
            "Epoch 1225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.35e+5, train_loss_epoch=3.35e+5, valid_loss=2.64e+5]\n",
            "Epoch 1226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=2.64e+5]\n",
            "Epoch 1227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+5, train_loss_epoch=2.58e+5, valid_loss=2.64e+5]\n",
            "Epoch 1228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+5, train_loss_epoch=2.99e+5, valid_loss=2.64e+5]\n",
            "Epoch 1229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+5, train_loss_epoch=3.17e+5, valid_loss=2.64e+5]\n",
            "Epoch 1230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+5, train_loss_epoch=2.81e+5, valid_loss=2.64e+5]\n",
            "Epoch 1231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+5, train_loss_epoch=2.75e+5, valid_loss=2.64e+5]\n",
            "Epoch 1232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.12e+5, train_loss_epoch=3.12e+5, valid_loss=2.64e+5]\n",
            "Epoch 1233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.72e+5, train_loss_epoch=3.72e+5, valid_loss=2.64e+5]\n",
            "Epoch 1234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+5, train_loss_epoch=3.05e+5, valid_loss=2.64e+5]\n",
            "Epoch 1235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.7e+5, train_loss_epoch=3.7e+5, valid_loss=2.64e+5]\n",
            "Epoch 1236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.47e+5, train_loss_epoch=3.47e+5, valid_loss=2.64e+5]\n",
            "Epoch 1237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+5, train_loss_epoch=2.74e+5, valid_loss=2.64e+5]\n",
            "Epoch 1238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.82e+5, train_loss_epoch=2.82e+5, valid_loss=2.64e+5]\n",
            "Epoch 1239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+5, train_loss_epoch=2.94e+5, valid_loss=2.64e+5]\n",
            "Epoch 1240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=2.64e+5]\n",
            "Epoch 1241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=2.64e+5]\n",
            "Epoch 1242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+5, train_loss_epoch=2.98e+5, valid_loss=2.64e+5]\n",
            "Epoch 1243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+5, train_loss_epoch=2.77e+5, valid_loss=2.64e+5]\n",
            "Epoch 1244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+5, train_loss_epoch=2.55e+5, valid_loss=2.64e+5]\n",
            "Epoch 1245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+5, train_loss_epoch=2.64e+5, valid_loss=2.64e+5]\n",
            "Epoch 1246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+5, train_loss_epoch=2.57e+5, valid_loss=2.64e+5]\n",
            "Epoch 1247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+5, train_loss_epoch=2.54e+5, valid_loss=2.64e+5]\n",
            "Epoch 1248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.72e+5, train_loss_epoch=2.72e+5, valid_loss=2.64e+5]\n",
            "Epoch 1249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+5, train_loss_epoch=2.62e+5, valid_loss=2.64e+5]\n",
            "Epoch 1250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+5, train_loss_epoch=2.53e+5, valid_loss=2.64e+5]\n",
            "Epoch 1250: 100%|██████████| 1/1 [00:00<00:00,  3.03it/s, v_num=0, train_loss_step=2.68e+5, train_loss_epoch=2.68e+5, valid_loss=2.64e+5]\n",
            "Epoch 1251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+5, train_loss_epoch=2.68e+5, valid_loss=2.64e+5]\n",
            "Epoch 1252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+5, train_loss_epoch=2.54e+5, valid_loss=2.64e+5]\n",
            "Epoch 1253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+5, train_loss_epoch=2.45e+5, valid_loss=2.64e+5]\n",
            "Epoch 1254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+5, train_loss_epoch=2.33e+5, valid_loss=2.64e+5]\n",
            "Epoch 1255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.09e+5, train_loss_epoch=2.09e+5, valid_loss=2.64e+5]\n",
            "Epoch 1256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.16e+5, train_loss_epoch=2.16e+5, valid_loss=2.64e+5]\n",
            "Epoch 1257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+5, train_loss_epoch=2.41e+5, valid_loss=2.64e+5]\n",
            "Epoch 1258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+5, train_loss_epoch=2.54e+5, valid_loss=2.64e+5]\n",
            "Epoch 1259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+5, train_loss_epoch=2.73e+5, valid_loss=2.64e+5]\n",
            "Epoch 1260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+5, train_loss_epoch=2.94e+5, valid_loss=2.64e+5]\n",
            "Epoch 1261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=2.64e+5]\n",
            "Epoch 1262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+5, train_loss_epoch=2.58e+5, valid_loss=2.64e+5]\n",
            "Epoch 1263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.62e+5, train_loss_epoch=2.62e+5, valid_loss=2.64e+5]\n",
            "Epoch 1264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+5, train_loss_epoch=2.9e+5, valid_loss=2.64e+5]\n",
            "Epoch 1265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+5, train_loss_epoch=2.67e+5, valid_loss=2.64e+5]\n",
            "Epoch 1266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.69e+5, train_loss_epoch=2.69e+5, valid_loss=2.64e+5]\n",
            "Epoch 1267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.9e+5, train_loss_epoch=2.9e+5, valid_loss=2.64e+5]\n",
            "Epoch 1268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+5, train_loss_epoch=3.01e+5, valid_loss=2.64e+5]\n",
            "Epoch 1269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=2.64e+5]\n",
            "Epoch 1270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+5, train_loss_epoch=2.59e+5, valid_loss=2.64e+5]\n",
            "Epoch 1271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=2.64e+5]\n",
            "Epoch 1272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+5, train_loss_epoch=3.18e+5, valid_loss=2.64e+5]\n",
            "Epoch 1273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+5, train_loss_epoch=2.76e+5, valid_loss=2.64e+5]\n",
            "Epoch 1274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=2.64e+5]\n",
            "Epoch 1275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+5, train_loss_epoch=2.99e+5, valid_loss=2.64e+5]\n",
            "Epoch 1276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.53e+5, train_loss_epoch=2.53e+5, valid_loss=2.64e+5]\n",
            "Epoch 1277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+5, train_loss_epoch=2.35e+5, valid_loss=2.64e+5]\n",
            "Epoch 1278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+5, train_loss_epoch=2.84e+5, valid_loss=2.64e+5]\n",
            "Epoch 1279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.2e+5, train_loss_epoch=3.2e+5, valid_loss=2.64e+5]\n",
            "Epoch 1280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+5, train_loss_epoch=3.01e+5, valid_loss=2.64e+5]\n",
            "Epoch 1280: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s, v_num=0, train_loss_step=2.57e+5, train_loss_epoch=2.57e+5, valid_loss=2.64e+5]\n",
            "Epoch 1281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+5, train_loss_epoch=2.57e+5, valid_loss=2.64e+5]\n",
            "Epoch 1282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+5, train_loss_epoch=2.49e+5, valid_loss=2.64e+5]\n",
            "Epoch 1283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+5, train_loss_epoch=2.74e+5, valid_loss=2.64e+5]\n",
            "Epoch 1284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+5, train_loss_epoch=2.68e+5, valid_loss=2.64e+5]\n",
            "Epoch 1285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.6e+5, train_loss_epoch=2.6e+5, valid_loss=2.64e+5]\n",
            "Epoch 1286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+5, train_loss_epoch=2.66e+5, valid_loss=2.64e+5]\n",
            "Epoch 1287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+5, train_loss_epoch=2.73e+5, valid_loss=2.64e+5]\n",
            "Epoch 1288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.75e+5, train_loss_epoch=2.75e+5, valid_loss=2.64e+5]\n",
            "Epoch 1288: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=0, train_loss_step=2.75e+5, train_loss_epoch=2.75e+5, valid_loss=2.64e+5]\n",
            "Epoch 1289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+5, train_loss_epoch=2.59e+5, valid_loss=2.64e+5]\n",
            "Epoch 1290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+5, train_loss_epoch=2.48e+5, valid_loss=2.64e+5]\n",
            "Epoch 1291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+5, train_loss_epoch=2.27e+5, valid_loss=2.64e+5]\n",
            "Epoch 1292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+5, train_loss_epoch=2.4e+5, valid_loss=2.64e+5]\n",
            "Epoch 1293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+5, train_loss_epoch=2.34e+5, valid_loss=2.64e+5]\n",
            "Epoch 1294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+5, train_loss_epoch=2.66e+5, valid_loss=2.64e+5]\n",
            "Epoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.33e+5, train_loss_epoch=3.33e+5, valid_loss=2.64e+5]\n",
            "Epoch 1296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+5, train_loss_epoch=2.88e+5, valid_loss=2.64e+5]\n",
            "Epoch 1297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+5, train_loss_epoch=2.34e+5, valid_loss=2.64e+5]\n",
            "Epoch 1297: 100%|██████████| 1/1 [00:00<00:00,  3.76it/s, v_num=0, train_loss_step=2.14e+5, train_loss_epoch=2.14e+5, valid_loss=2.64e+5]\n",
            "Epoch 1298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.14e+5, train_loss_epoch=2.14e+5, valid_loss=2.64e+5]\n",
            "Epoch 1299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.36e+5, train_loss_epoch=2.36e+5, valid_loss=2.64e+5]\n",
            "Epoch 1299: 100%|██████████| 1/1 [00:00<00:00,  3.01it/s, v_num=0, train_loss_step=2.27e+5, train_loss_epoch=2.36e+5, valid_loss=2.64e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.47it/s]\u001b[A\n",
            "Epoch 1300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.27e+5, train_loss_epoch=2.27e+5, valid_loss=2.32e+5]\n",
            "Epoch 1301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+5, train_loss_epoch=2.41e+5, valid_loss=2.32e+5]\n",
            "Epoch 1302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+5, train_loss_epoch=2.95e+5, valid_loss=2.32e+5]\n",
            "Epoch 1303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.33e+5, train_loss_epoch=3.33e+5, valid_loss=2.32e+5]\n",
            "Epoch 1304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+5, train_loss_epoch=3.1e+5, valid_loss=2.32e+5]\n",
            "Epoch 1305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+5, train_loss_epoch=2.5e+5, valid_loss=2.32e+5]\n",
            "Epoch 1306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3e+5, train_loss_epoch=3e+5, valid_loss=2.32e+5]\n",
            "Epoch 1307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.83e+5, train_loss_epoch=3.83e+5, valid_loss=2.32e+5]\n",
            "Epoch 1308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.31e+5, train_loss_epoch=3.31e+5, valid_loss=2.32e+5]\n",
            "Epoch 1309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+5, train_loss_epoch=3.05e+5, valid_loss=2.32e+5]\n",
            "Epoch 1310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.32e+5, train_loss_epoch=3.32e+5, valid_loss=2.32e+5]\n",
            "Epoch 1311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.57e+5, train_loss_epoch=3.57e+5, valid_loss=2.32e+5]\n",
            "Epoch 1312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+5, train_loss_epoch=3.39e+5, valid_loss=2.32e+5]\n",
            "Epoch 1313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.06e+5, train_loss_epoch=3.06e+5, valid_loss=2.32e+5]\n",
            "Epoch 1314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.48e+5, train_loss_epoch=3.48e+5, valid_loss=2.32e+5]\n",
            "Epoch 1315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.59e+5, train_loss_epoch=3.59e+5, valid_loss=2.32e+5]\n",
            "Epoch 1316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+5, train_loss_epoch=3.1e+5, valid_loss=2.32e+5]\n",
            "Epoch 1317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.13e+5, train_loss_epoch=3.13e+5, valid_loss=2.32e+5]\n",
            "Epoch 1318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.13e+5, train_loss_epoch=3.13e+5, valid_loss=2.32e+5]\n",
            "Epoch 1319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.88e+5, train_loss_epoch=2.88e+5, valid_loss=2.32e+5]\n",
            "Epoch 1320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=2.32e+5]\n",
            "Epoch 1321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+5, train_loss_epoch=2.73e+5, valid_loss=2.32e+5]\n",
            "Epoch 1322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+5, train_loss_epoch=2.43e+5, valid_loss=2.32e+5]\n",
            "Epoch 1323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+5, train_loss_epoch=3.04e+5, valid_loss=2.32e+5]\n",
            "Epoch 1324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.64e+5, train_loss_epoch=3.64e+5, valid_loss=2.32e+5]\n",
            "Epoch 1325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+5, train_loss_epoch=3.05e+5, valid_loss=2.32e+5]\n",
            "Epoch 1326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=2.32e+5]\n",
            "Epoch 1327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.17e+5, train_loss_epoch=4.17e+5, valid_loss=2.32e+5]\n",
            "Epoch 1328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+5, train_loss_epoch=3.25e+5, valid_loss=2.32e+5]\n",
            "Epoch 1329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+5, train_loss_epoch=3.62e+5, valid_loss=2.32e+5]\n",
            "Epoch 1330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.64e+5, train_loss_epoch=4.64e+5, valid_loss=2.32e+5]\n",
            "Epoch 1331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+5, train_loss_epoch=2.94e+5, valid_loss=2.32e+5]\n",
            "Epoch 1332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.91e+5, train_loss_epoch=4.91e+5, valid_loss=2.32e+5]\n",
            "Epoch 1333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.15e+5, train_loss_epoch=3.15e+5, valid_loss=2.32e+5]\n",
            "Epoch 1334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.99e+5, train_loss_epoch=3.99e+5, valid_loss=2.32e+5]\n",
            "Epoch 1335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.75e+5, train_loss_epoch=4.75e+5, valid_loss=2.32e+5]\n",
            "Epoch 1336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.47e+5, train_loss_epoch=3.47e+5, valid_loss=2.32e+5]\n",
            "Epoch 1337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.43e+5, train_loss_epoch=5.43e+5, valid_loss=2.32e+5]\n",
            "Epoch 1338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.37e+5, train_loss_epoch=3.37e+5, valid_loss=2.32e+5]\n",
            "Epoch 1339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5e+5, train_loss_epoch=5e+5, valid_loss=2.32e+5]\n",
            "Epoch 1340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.35e+5, train_loss_epoch=3.35e+5, valid_loss=2.32e+5]\n",
            "Epoch 1341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+5, train_loss_epoch=3.6e+5, valid_loss=2.32e+5]\n",
            "Epoch 1342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.66e+5, train_loss_epoch=4.66e+5, valid_loss=2.32e+5]\n",
            "Epoch 1343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+5, train_loss_epoch=3.25e+5, valid_loss=2.32e+5]\n",
            "Epoch 1344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.61e+5, train_loss_epoch=3.61e+5, valid_loss=2.32e+5]\n",
            "Epoch 1345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.29e+5, train_loss_epoch=3.29e+5, valid_loss=2.32e+5]\n",
            "Epoch 1346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.76e+5, train_loss_epoch=2.76e+5, valid_loss=2.32e+5]\n",
            "Epoch 1347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.08e+5, valid_loss=2.32e+5]\n",
            "Epoch 1348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.45e+5, train_loss_epoch=3.45e+5, valid_loss=2.32e+5]\n",
            "Epoch 1349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.15e+5, train_loss_epoch=3.15e+5, valid_loss=2.32e+5]\n",
            "Epoch 1350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+5, train_loss_epoch=2.79e+5, valid_loss=2.32e+5]\n",
            "Epoch 1351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+5, train_loss_epoch=2.98e+5, valid_loss=2.32e+5]\n",
            "Epoch 1352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=2.32e+5]\n",
            "Epoch 1353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+5, train_loss_epoch=2.68e+5, valid_loss=2.32e+5]\n",
            "Epoch 1354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.06e+5, train_loss_epoch=3.06e+5, valid_loss=2.32e+5]\n",
            "Epoch 1355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.13e+5, train_loss_epoch=3.13e+5, valid_loss=2.32e+5]\n",
            "Epoch 1356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+5, train_loss_epoch=2.63e+5, valid_loss=2.32e+5]\n",
            "Epoch 1357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=2.32e+5]\n",
            "Epoch 1358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.89e+5, train_loss_epoch=3.89e+5, valid_loss=2.32e+5]\n",
            "Epoch 1359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.23e+5, train_loss_epoch=3.23e+5, valid_loss=2.32e+5]\n",
            "Epoch 1360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+5, train_loss_epoch=3.07e+5, valid_loss=2.32e+5]\n",
            "Epoch 1361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.23e+5, train_loss_epoch=3.23e+5, valid_loss=2.32e+5]\n",
            "Epoch 1362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.03e+5, train_loss_epoch=3.03e+5, valid_loss=2.32e+5]\n",
            "Epoch 1363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+5, train_loss_epoch=2.93e+5, valid_loss=2.32e+5]\n",
            "Epoch 1364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.08e+5, valid_loss=2.32e+5]\n",
            "Epoch 1365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+5, train_loss_epoch=3.07e+5, valid_loss=2.32e+5]\n",
            "Epoch 1366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=2.32e+5]\n",
            "Epoch 1367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+5, train_loss_epoch=2.48e+5, valid_loss=2.32e+5]\n",
            "Epoch 1368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=2.32e+5]\n",
            "Epoch 1369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.51e+5, train_loss_epoch=3.51e+5, valid_loss=2.32e+5]\n",
            "Epoch 1370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.93e+5, train_loss_epoch=2.93e+5, valid_loss=2.32e+5]\n",
            "Epoch 1371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.92e+5, train_loss_epoch=2.92e+5, valid_loss=2.32e+5]\n",
            "Epoch 1372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.46e+5, train_loss_epoch=3.46e+5, valid_loss=2.32e+5]\n",
            "Epoch 1373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.19e+5, train_loss_epoch=3.19e+5, valid_loss=2.32e+5]\n",
            "Epoch 1374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+5, train_loss_epoch=2.79e+5, valid_loss=2.32e+5]\n",
            "Epoch 1375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+5, train_loss_epoch=2.79e+5, valid_loss=2.32e+5]\n",
            "Epoch 1376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+5, train_loss_epoch=2.78e+5, valid_loss=2.32e+5]\n",
            "Epoch 1377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+5, train_loss_epoch=2.78e+5, valid_loss=2.32e+5]\n",
            "Epoch 1378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+5, train_loss_epoch=2.66e+5, valid_loss=2.32e+5]\n",
            "Epoch 1379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.73e+5, train_loss_epoch=2.73e+5, valid_loss=2.32e+5]\n",
            "Epoch 1380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.68e+5, train_loss_epoch=2.68e+5, valid_loss=2.32e+5]\n",
            "Epoch 1381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+5, train_loss_epoch=2.63e+5, valid_loss=2.32e+5]\n",
            "Epoch 1382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+5, train_loss_epoch=2.55e+5, valid_loss=2.32e+5]\n",
            "Epoch 1383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+5, train_loss_epoch=2.54e+5, valid_loss=2.32e+5]\n",
            "Epoch 1384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+5, train_loss_epoch=3.05e+5, valid_loss=2.32e+5]\n",
            "Epoch 1385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+5, train_loss_epoch=3.18e+5, valid_loss=2.32e+5]\n",
            "Epoch 1386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=2.32e+5]\n",
            "Epoch 1387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+5, train_loss_epoch=2.4e+5, valid_loss=2.32e+5]\n",
            "Epoch 1388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.5e+5, train_loss_epoch=2.5e+5, valid_loss=2.32e+5]\n",
            "Epoch 1389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+5, train_loss_epoch=2.4e+5, valid_loss=2.32e+5]\n",
            "Epoch 1390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.48e+5, train_loss_epoch=2.48e+5, valid_loss=2.32e+5]\n",
            "Epoch 1391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.34e+5, train_loss_epoch=2.34e+5, valid_loss=2.32e+5]\n",
            "Epoch 1392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.21e+5, train_loss_epoch=2.21e+5, valid_loss=2.32e+5]\n",
            "Epoch 1392: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=2.32e+5]\n",
            "Epoch 1392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=2.32e+5]        \n",
            "Epoch 1393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=2.32e+5]\n",
            "Epoch 1394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.04e+5, train_loss_epoch=3.04e+5, valid_loss=2.32e+5]\n",
            "Epoch 1395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+5, train_loss_epoch=2.78e+5, valid_loss=2.32e+5]\n",
            "Epoch 1396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+5, train_loss_epoch=2.3e+5, valid_loss=2.32e+5]\n",
            "Epoch 1397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.3e+5, train_loss_epoch=2.3e+5, valid_loss=2.32e+5]\n",
            "Epoch 1398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+5, train_loss_epoch=2.51e+5, valid_loss=2.32e+5]\n",
            "Epoch 1399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+5, train_loss_epoch=2.57e+5, valid_loss=2.32e+5]\n",
            "Epoch 1399: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=3.17e+5, train_loss_epoch=2.57e+5, valid_loss=2.32e+5]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.96it/s]\u001b[A\n",
            "Epoch 1400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.17e+5, train_loss_epoch=3.17e+5, valid_loss=3.22e+5]\n",
            "Epoch 1401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.25e+5, train_loss_epoch=3.25e+5, valid_loss=3.22e+5]\n",
            "Epoch 1402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.57e+5, train_loss_epoch=2.57e+5, valid_loss=3.22e+5]\n",
            "Epoch 1403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.41e+5, train_loss_epoch=2.41e+5, valid_loss=3.22e+5]\n",
            "Epoch 1404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.05e+5, train_loss_epoch=3.05e+5, valid_loss=3.22e+5]\n",
            "Epoch 1405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.73e+5, train_loss_epoch=3.73e+5, valid_loss=3.22e+5]\n",
            "Epoch 1406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.07e+5, train_loss_epoch=3.07e+5, valid_loss=3.22e+5]\n",
            "Epoch 1407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+5, train_loss_epoch=3.1e+5, valid_loss=3.22e+5]\n",
            "Epoch 1408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.39e+5, train_loss_epoch=4.39e+5, valid_loss=3.22e+5]\n",
            "Epoch 1409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.18e+5, train_loss_epoch=3.18e+5, valid_loss=3.22e+5]\n",
            "Epoch 1410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+5, train_loss_epoch=3.6e+5, valid_loss=3.22e+5]\n",
            "Epoch 1411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.3e+5, train_loss_epoch=5.3e+5, valid_loss=3.22e+5]\n",
            "Epoch 1412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.71e+5, train_loss_epoch=3.71e+5, valid_loss=3.22e+5]\n",
            "Epoch 1413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.98e+5, train_loss_epoch=5.98e+5, valid_loss=3.22e+5]\n",
            "Epoch 1414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.8e+5, train_loss_epoch=3.8e+5, valid_loss=3.22e+5]\n",
            "Epoch 1415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.77e+5, train_loss_epoch=5.77e+5, valid_loss=3.22e+5]\n",
            "Epoch 1416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.62e+5, train_loss_epoch=3.62e+5, valid_loss=3.22e+5]\n",
            "Epoch 1417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.6e+5, train_loss_epoch=4.6e+5, valid_loss=3.22e+5]\n",
            "Epoch 1418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.2e+5, train_loss_epoch=3.2e+5, valid_loss=3.22e+5]\n",
            "Epoch 1419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.08e+5, train_loss_epoch=4.08e+5, valid_loss=3.22e+5]\n",
            "Epoch 1420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.04e+5, train_loss_epoch=4.04e+5, valid_loss=3.22e+5]\n",
            "Epoch 1421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.88e+5, train_loss_epoch=3.88e+5, valid_loss=3.22e+5]\n",
            "Epoch 1422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.47e+5, train_loss_epoch=4.47e+5, valid_loss=3.22e+5]\n",
            "Epoch 1423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.89e+5, train_loss_epoch=3.89e+5, valid_loss=3.22e+5]\n",
            "Epoch 1424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.95e+5, train_loss_epoch=3.95e+5, valid_loss=3.22e+5]\n",
            "Epoch 1425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.32e+5, train_loss_epoch=3.32e+5, valid_loss=3.22e+5]\n",
            "Epoch 1425: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=0, train_loss_step=3.58e+5, train_loss_epoch=3.32e+5, valid_loss=3.22e+5]\n",
            "Epoch 1426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.58e+5, train_loss_epoch=3.58e+5, valid_loss=3.22e+5]\n",
            "Epoch 1427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.61e+5, train_loss_epoch=3.61e+5, valid_loss=3.22e+5]\n",
            "Epoch 1428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.38e+5, train_loss_epoch=3.38e+5, valid_loss=3.22e+5]\n",
            "Epoch 1429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.6e+5, train_loss_epoch=3.6e+5, valid_loss=3.22e+5]\n",
            "Epoch 1430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+5, train_loss_epoch=3.16e+5, valid_loss=3.22e+5]\n",
            "Epoch 1431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.86e+5, train_loss_epoch=2.86e+5, valid_loss=3.22e+5]\n",
            "Epoch 1432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.79e+5, train_loss_epoch=2.79e+5, valid_loss=3.22e+5]\n",
            "Epoch 1433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.84e+5, train_loss_epoch=2.84e+5, valid_loss=3.22e+5]\n",
            "Epoch 1434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.92e+5, train_loss_epoch=2.92e+5, valid_loss=3.22e+5]\n",
            "Epoch 1434: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=3.22e+5] \n",
            "Epoch 1435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=3.22e+5]\n",
            "Epoch 1436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.89e+5, train_loss_epoch=2.89e+5, valid_loss=3.22e+5]\n",
            "Epoch 1437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+5, train_loss_epoch=2.99e+5, valid_loss=3.22e+5]\n",
            "Epoch 1438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=3.22e+5]\n",
            "Epoch 1439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.54e+5, train_loss_epoch=2.54e+5, valid_loss=3.22e+5]\n",
            "Epoch 1440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.25e+5, train_loss_epoch=2.25e+5, valid_loss=3.22e+5]\n",
            "Epoch 1441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.33e+5, train_loss_epoch=2.33e+5, valid_loss=3.22e+5]\n",
            "Epoch 1442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+5, train_loss_epoch=2.55e+5, valid_loss=3.22e+5]\n",
            "Epoch 1442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+5, train_loss_epoch=2.46e+5, valid_loss=3.22e+5]        \n",
            "Epoch 1443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.46e+5, train_loss_epoch=2.46e+5, valid_loss=3.22e+5]\n",
            "Epoch 1444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.38e+5, train_loss_epoch=2.38e+5, valid_loss=3.22e+5]\n",
            "Epoch 1445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.52e+5, train_loss_epoch=2.52e+5, valid_loss=3.22e+5]\n",
            "Epoch 1446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+5, train_loss_epoch=2.83e+5, valid_loss=3.22e+5]\n",
            "Epoch 1447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+5, train_loss_epoch=2.64e+5, valid_loss=3.22e+5]\n",
            "Epoch 1448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.35e+5, train_loss_epoch=2.35e+5, valid_loss=3.22e+5]\n",
            "Epoch 1449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.63e+5, train_loss_epoch=2.63e+5, valid_loss=3.22e+5]\n",
            "Epoch 1450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=3.22e+5]\n",
            "Epoch 1451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=3.22e+5]\n",
            "Epoch 1452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.74e+5, train_loss_epoch=2.74e+5, valid_loss=3.22e+5]\n",
            "Epoch 1453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.14e+5, train_loss_epoch=3.14e+5, valid_loss=3.22e+5]\n",
            "Epoch 1453: 100%|██████████| 1/1 [00:00<00:00,  4.05it/s, v_num=0, train_loss_step=3.1e+5, train_loss_epoch=3.14e+5, valid_loss=3.22e+5] \n",
            "Epoch 1454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+5, train_loss_epoch=3.1e+5, valid_loss=3.22e+5]\n",
            "Epoch 1455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.59e+5, train_loss_epoch=2.59e+5, valid_loss=3.22e+5]\n",
            "Epoch 1456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.19e+5, train_loss_epoch=2.19e+5, valid_loss=3.22e+5]\n",
            "Epoch 1457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+5, train_loss_epoch=2.45e+5, valid_loss=3.22e+5]\n",
            "Epoch 1458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+5, train_loss_epoch=2.77e+5, valid_loss=3.22e+5]\n",
            "Epoch 1459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.58e+5, train_loss_epoch=2.58e+5, valid_loss=3.22e+5]\n",
            "Epoch 1460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.43e+5, train_loss_epoch=2.43e+5, valid_loss=3.22e+5]\n",
            "Epoch 1461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.4e+5, train_loss_epoch=2.4e+5, valid_loss=3.22e+5]\n",
            "Epoch 1462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.02e+5, train_loss_epoch=3.02e+5, valid_loss=3.22e+5]\n",
            "Epoch 1463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.82e+5, train_loss_epoch=3.82e+5, valid_loss=3.22e+5]\n",
            "Epoch 1464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.02e+5, train_loss_epoch=3.02e+5, valid_loss=3.22e+5]\n",
            "Epoch 1465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.49e+5, train_loss_epoch=3.49e+5, valid_loss=3.22e+5]\n",
            "Epoch 1466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.41e+5, train_loss_epoch=3.41e+5, valid_loss=3.22e+5]\n",
            "Epoch 1467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.94e+5, train_loss_epoch=2.94e+5, valid_loss=3.22e+5]\n",
            "Epoch 1468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.99e+5, train_loss_epoch=2.99e+5, valid_loss=3.22e+5]\n",
            "Epoch 1469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.33e+5, train_loss_epoch=3.33e+5, valid_loss=3.22e+5]\n",
            "Epoch 1470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.81e+5, train_loss_epoch=2.81e+5, valid_loss=3.22e+5]\n",
            "Epoch 1471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.85e+5, train_loss_epoch=2.85e+5, valid_loss=3.22e+5]\n",
            "Epoch 1472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.83e+5, train_loss_epoch=2.83e+5, valid_loss=3.22e+5]\n",
            "Epoch 1473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.65e+5, train_loss_epoch=2.65e+5, valid_loss=3.22e+5]\n",
            "Epoch 1474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.01e+5, train_loss_epoch=3.01e+5, valid_loss=3.22e+5]\n",
            "Epoch 1475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.95e+5, train_loss_epoch=2.95e+5, valid_loss=3.22e+5]\n",
            "Epoch 1476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.64e+5, train_loss_epoch=2.64e+5, valid_loss=3.22e+5]\n",
            "Epoch 1477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.55e+5, train_loss_epoch=2.55e+5, valid_loss=3.22e+5]\n",
            "Epoch 1478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.67e+5, train_loss_epoch=2.67e+5, valid_loss=3.22e+5]\n",
            "Epoch 1479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.66e+5, train_loss_epoch=2.66e+5, valid_loss=3.22e+5]\n",
            "Epoch 1480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.78e+5, train_loss_epoch=2.78e+5, valid_loss=3.22e+5]\n",
            "Epoch 1481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.8e+5, train_loss_epoch=2.8e+5, valid_loss=3.22e+5]\n",
            "Epoch 1482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.51e+5, train_loss_epoch=2.51e+5, valid_loss=3.22e+5]\n",
            "Epoch 1483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.37e+5, train_loss_epoch=2.37e+5, valid_loss=3.22e+5]\n",
            "Epoch 1484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.45e+5, train_loss_epoch=2.45e+5, valid_loss=3.22e+5]\n",
            "Epoch 1485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.49e+5, train_loss_epoch=2.49e+5, valid_loss=3.22e+5]\n",
            "Epoch 1486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.71e+5, train_loss_epoch=2.71e+5, valid_loss=3.22e+5]\n",
            "Epoch 1487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.1e+5, train_loss_epoch=3.1e+5, valid_loss=3.22e+5]\n",
            "Epoch 1488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.39e+5, train_loss_epoch=3.39e+5, valid_loss=3.22e+5]\n",
            "Epoch 1489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.87e+5, train_loss_epoch=2.87e+5, valid_loss=3.22e+5]\n",
            "Epoch 1490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.77e+5, train_loss_epoch=2.77e+5, valid_loss=3.22e+5]\n",
            "Epoch 1491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.78e+5, train_loss_epoch=3.78e+5, valid_loss=3.22e+5]\n",
            "Epoch 1492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.9e+5, train_loss_epoch=3.9e+5, valid_loss=3.22e+5]\n",
            "Epoch 1493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.23e+5, train_loss_epoch=3.23e+5, valid_loss=3.22e+5]\n",
            "Epoch 1494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.98e+5, train_loss_epoch=3.98e+5, valid_loss=3.22e+5]\n",
            "Epoch 1495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.98e+5, train_loss_epoch=2.98e+5, valid_loss=3.22e+5]\n",
            "Epoch 1496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.61e+5, train_loss_epoch=2.61e+5, valid_loss=3.22e+5]\n",
            "Epoch 1497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.16e+5, train_loss_epoch=3.16e+5, valid_loss=3.22e+5]\n",
            "Epoch 1498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.65e+5, train_loss_epoch=3.65e+5, valid_loss=3.22e+5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 21:13:01,384\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (24, 12, 1), 'n_pool_kernel_size': (2, 2, 2), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=0, train_loss_step=3.65e+5, train_loss_epoch=3.65e+5, valid_loss=3.22e+5]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.65e+5, valid_loss=3.22e+5]\rEpoch 1498: 100%|██████████| 1/1 [00:00<00:00,  4.14it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.08e+5, valid_loss=3.22e+5]\rEpoch 1498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.08e+5, valid_loss=3.22e+5]        \rEpoch 1499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.08e+5, valid_loss=3.22e+5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=56726)\u001b[0m `Trainer.fit` stopped: `max_steps=1500.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s, v_num=0, train_loss_step=3.08e+5, train_loss_epoch=3.08e+5, valid_loss=3.22e+5]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s, v_num=0, train_loss_step=2.81e+5, train_loss_epoch=3.08e+5, valid_loss=3.22e+5]\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.15it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=56726)\u001b[0m \r                                                                       \u001b[A\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s, v_num=0, train_loss_step=2.81e+5, train_loss_epoch=3.08e+5, valid_loss=2.62e+5]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00,  3.73it/s, v_num=0, train_loss_step=2.81e+5, train_loss_epoch=2.81e+5, valid_loss=2.62e+5]\rEpoch 1499: 100%|██████████| 1/1 [00:00<00:00,  3.71it/s, v_num=0, train_loss_step=2.81e+5, train_loss_epoch=2.81e+5, valid_loss=2.62e+5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=58354)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 2025-06-15 21:13:15.957719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m E0000 00:00:1750021995.988454   58446 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m E0000 00:00:1750021995.997404   58446 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 2025-06-15 21:13:16.031002: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 3 | blocks       | ModuleList    | 5.2 M  | train\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 5.2 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 5.2 M     Total params\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 20.639    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.712, train_loss_epoch=0.712]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.582, train_loss_epoch=0.582]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.482, train_loss_epoch=0.482]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.474, train_loss_epoch=0.474]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.438, train_loss_epoch=0.438]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.361, train_loss_epoch=0.361]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.342, train_loss_epoch=0.342]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.307, train_loss_epoch=0.307]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.273, train_loss_epoch=0.273]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.251, train_loss_epoch=0.251]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.177, train_loss_epoch=0.177]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.153, train_loss_epoch=0.153]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.139, train_loss_epoch=0.139]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.130, train_loss_epoch=0.130]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124]\n",
            "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=0, train_loss_step=0.124, train_loss_epoch=0.124]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.118, train_loss_epoch=0.118]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.110, train_loss_epoch=0.110]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.102, train_loss_epoch=0.102]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0979, train_loss_epoch=0.0979]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0922, train_loss_epoch=0.0922]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0808, train_loss_epoch=0.0808]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0804, train_loss_epoch=0.0804]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0834, train_loss_epoch=0.0834]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.082, train_loss_epoch=0.082]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.079, train_loss_epoch=0.079]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0684, train_loss_epoch=0.0684]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0694, train_loss_epoch=0.0694]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0688, train_loss_epoch=0.0688]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0596, train_loss_epoch=0.0596]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0741, train_loss_epoch=0.0741]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0577, train_loss_epoch=0.0577]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0735, train_loss_epoch=0.0735]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.064, train_loss_epoch=0.064]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0592, train_loss_epoch=0.0592]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0606, train_loss_epoch=0.0606]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0583, train_loss_epoch=0.0583]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0518, train_loss_epoch=0.0518]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0534, train_loss_epoch=0.0534]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0642, train_loss_epoch=0.0642]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.063, train_loss_epoch=0.063]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0601, train_loss_epoch=0.0601]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0534, train_loss_epoch=0.0534]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0621, train_loss_epoch=0.0621]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.065, train_loss_epoch=0.065]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0704, train_loss_epoch=0.0704]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0568, train_loss_epoch=0.0568]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0644, train_loss_epoch=0.0644]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0538, train_loss_epoch=0.0538]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.058, train_loss_epoch=0.058]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0598, train_loss_epoch=0.0598]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0438, train_loss_epoch=0.0438]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0485, train_loss_epoch=0.0485]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0462, train_loss_epoch=0.0462]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0479, train_loss_epoch=0.0479]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0419, train_loss_epoch=0.0419]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0512, train_loss_epoch=0.0512]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0567, train_loss_epoch=0.0567]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0457, train_loss_epoch=0.0457]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0513, train_loss_epoch=0.0513]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0502, train_loss_epoch=0.0502]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0595, train_loss_epoch=0.0595]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0539, train_loss_epoch=0.0539]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0516, train_loss_epoch=0.0516]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0483, train_loss_epoch=0.0483]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0439, train_loss_epoch=0.0439]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0544, train_loss_epoch=0.0544]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0509, train_loss_epoch=0.0509]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.055, train_loss_epoch=0.055]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0519, train_loss_epoch=0.0519]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0445, train_loss_epoch=0.0445]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0504, train_loss_epoch=0.0504]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0469, train_loss_epoch=0.0469]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0458, train_loss_epoch=0.0458]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0461, train_loss_epoch=0.0461]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0444, train_loss_epoch=0.0444]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0486, train_loss_epoch=0.0486]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0357, train_loss_epoch=0.0357]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0393, train_loss_epoch=0.0393]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0371, train_loss_epoch=0.0371]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0425, train_loss_epoch=0.0425]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0425]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 123.93it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.0627]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0397, train_loss_epoch=0.0397, valid_loss=0.0627]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.0627]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0305, train_loss_epoch=0.0305, valid_loss=0.0627]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0399, train_loss_epoch=0.0399, valid_loss=0.0627]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.035, train_loss_epoch=0.035, valid_loss=0.0627]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0627]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=0.0627]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0306, train_loss_epoch=0.0306, valid_loss=0.0627]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.0627]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.0627]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.0627]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.0627]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.0627]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.0627]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=0.0627]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.0627]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.0627]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.0627]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0396, train_loss_epoch=0.0396, valid_loss=0.0627]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=0.0627]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.0627]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.0627]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0627]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0456, train_loss_epoch=0.0456, valid_loss=0.0627]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.0627]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0426, train_loss_epoch=0.0426, valid_loss=0.0627]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0405, train_loss_epoch=0.0405, valid_loss=0.0627]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0627]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0627]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=0.0627]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0377, train_loss_epoch=0.0377, valid_loss=0.0627]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.040, train_loss_epoch=0.040, valid_loss=0.0627]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0627]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0431, train_loss_epoch=0.0431, valid_loss=0.0627]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.0627]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=0.0627]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=0.0627]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0364, train_loss_epoch=0.0364, valid_loss=0.0627]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.0627]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=0.0627]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0353, train_loss_epoch=0.0353, valid_loss=0.0627]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.0627]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=0.0627]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.0627]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.0627]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0339, train_loss_epoch=0.0339, valid_loss=0.0627]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=0.0627]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.0627]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.0627]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0404, train_loss_epoch=0.0404, valid_loss=0.0627]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=0.0627]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=0.0627]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.0627]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=0.0627]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0478, train_loss_epoch=0.0478, valid_loss=0.0627]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.0627]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.049, train_loss_epoch=0.049, valid_loss=0.0627]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0363, train_loss_epoch=0.0363, valid_loss=0.0627]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0471, train_loss_epoch=0.0471, valid_loss=0.0627]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.043, train_loss_epoch=0.043, valid_loss=0.0627]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0356, train_loss_epoch=0.0356, valid_loss=0.0627]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0387, train_loss_epoch=0.0387, valid_loss=0.0627]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.0627]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0452, train_loss_epoch=0.0452, valid_loss=0.0627]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.042, train_loss_epoch=0.042, valid_loss=0.0627]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0317, train_loss_epoch=0.0317, valid_loss=0.0627]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0517, train_loss_epoch=0.0517, valid_loss=0.0627]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=0.0627]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.0627]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=0.0627]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=0.0627]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0342, train_loss_epoch=0.0342, valid_loss=0.0627]\n",
            "Epoch 172: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=0.0627]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0376, train_loss_epoch=0.0376, valid_loss=0.0627]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0447, train_loss_epoch=0.0447, valid_loss=0.0627]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.0627]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0473, train_loss_epoch=0.0473, valid_loss=0.0627]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0395, train_loss_epoch=0.0395, valid_loss=0.0627]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0394, train_loss_epoch=0.0394, valid_loss=0.0627]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0464, train_loss_epoch=0.0464, valid_loss=0.0627]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.0627]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0463, train_loss_epoch=0.0463, valid_loss=0.0627]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0459, train_loss_epoch=0.0459, valid_loss=0.0627]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.041, train_loss_epoch=0.041, valid_loss=0.0627]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0481, train_loss_epoch=0.0481, valid_loss=0.0627]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0492, train_loss_epoch=0.0492, valid_loss=0.0627]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.0627]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0348, train_loss_epoch=0.0348, valid_loss=0.0627]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.0627]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.0627]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.0627]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0293, train_loss_epoch=0.0293, valid_loss=0.0627]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.0627]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.0627]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.0627]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=0.0627]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=0.0627]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0627]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.0627]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=0.0627]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0283, valid_loss=0.0627]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.85it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.0574]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0265, train_loss_epoch=0.0265, valid_loss=0.0574]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0388, train_loss_epoch=0.0388, valid_loss=0.0574]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.0574]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0574]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0381, train_loss_epoch=0.0381, valid_loss=0.0574]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0574]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.0574]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.0574]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0258, train_loss_epoch=0.0258, valid_loss=0.0574]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.0574]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.0574]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.030, train_loss_epoch=0.030, valid_loss=0.0574]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0232, train_loss_epoch=0.0232, valid_loss=0.0574]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.0574]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0349, train_loss_epoch=0.0349, valid_loss=0.0574]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0288, train_loss_epoch=0.0288, valid_loss=0.0574]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0378, train_loss_epoch=0.0378, valid_loss=0.0574]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.0574]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.0574]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=0.0574]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0347, train_loss_epoch=0.0347, valid_loss=0.0574]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0323, train_loss_epoch=0.0323, valid_loss=0.0574]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.0574]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0328, train_loss_epoch=0.0328, valid_loss=0.0574]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.0574]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0372, train_loss_epoch=0.0372, valid_loss=0.0574]\n",
            "Epoch 226: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0372, valid_loss=0.0574]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0267, train_loss_epoch=0.0267, valid_loss=0.0574]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0414, train_loss_epoch=0.0414, valid_loss=0.0574]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=0.0574]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0451, train_loss_epoch=0.0451, valid_loss=0.0574]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0412, train_loss_epoch=0.0412, valid_loss=0.0574]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.0574]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0345, train_loss_epoch=0.0345, valid_loss=0.0574]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0574]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0574]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=0.0574]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0276, train_loss_epoch=0.0276, valid_loss=0.0574]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0574]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0283, train_loss_epoch=0.0283, valid_loss=0.0574]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0278, train_loss_epoch=0.0278, valid_loss=0.0574]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=0.0574]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.0574]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0325, train_loss_epoch=0.0325, valid_loss=0.0574]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0231, train_loss_epoch=0.0231, valid_loss=0.0574]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0326, train_loss_epoch=0.0326, valid_loss=0.0574]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0327, train_loss_epoch=0.0327, valid_loss=0.0574]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.027, train_loss_epoch=0.027, valid_loss=0.0574]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.0574]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.0574]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0343, train_loss_epoch=0.0343, valid_loss=0.0574]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.029, train_loss_epoch=0.029, valid_loss=0.0574]\n",
            "Epoch 251: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=0.0574]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0269, train_loss_epoch=0.0269, valid_loss=0.0574]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0375, train_loss_epoch=0.0375, valid_loss=0.0574]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0292, train_loss_epoch=0.0292, valid_loss=0.0574]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.0574]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0333, train_loss_epoch=0.0333, valid_loss=0.0574]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0263, train_loss_epoch=0.0263, valid_loss=0.0574]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.0574]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0361, train_loss_epoch=0.0361, valid_loss=0.0574]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=0.0574]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0383, train_loss_epoch=0.0383, valid_loss=0.0574]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0411, train_loss_epoch=0.0411, valid_loss=0.0574]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.0574]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.039, train_loss_epoch=0.039, valid_loss=0.0574]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0334, train_loss_epoch=0.0334, valid_loss=0.0574]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0322, train_loss_epoch=0.0322, valid_loss=0.0574]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.0574]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.0574]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.0574]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=0.0574]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0303, train_loss_epoch=0.0303, valid_loss=0.0574]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0291, train_loss_epoch=0.0291, valid_loss=0.0574]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0286, train_loss_epoch=0.0286, valid_loss=0.0574]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0574]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=0.0574]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0222, train_loss_epoch=0.0222, valid_loss=0.0574]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0351, train_loss_epoch=0.0351, valid_loss=0.0574]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0279, train_loss_epoch=0.0279, valid_loss=0.0574]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0574]\n",
            "Epoch 279: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.0574]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.0574]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=0.0574]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0309, train_loss_epoch=0.0309, valid_loss=0.0574]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.0574]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.0574]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0335, train_loss_epoch=0.0335, valid_loss=0.0574]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.0574]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.0574]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0352, train_loss_epoch=0.0352, valid_loss=0.0574]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0413, train_loss_epoch=0.0413, valid_loss=0.0574]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0332, train_loss_epoch=0.0332, valid_loss=0.0574]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0368, train_loss_epoch=0.0368, valid_loss=0.0574]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0422, train_loss_epoch=0.0422, valid_loss=0.0574]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=0.0574]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.037, train_loss_epoch=0.037, valid_loss=0.0574]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0409, train_loss_epoch=0.0409, valid_loss=0.0574]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0401, train_loss_epoch=0.0401, valid_loss=0.0574]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0312, train_loss_epoch=0.0312, valid_loss=0.0574]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0392, train_loss_epoch=0.0392, valid_loss=0.0574]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.032, train_loss_epoch=0.032, valid_loss=0.0574]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.032, valid_loss=0.0574]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.82it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=0.0604]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0382, train_loss_epoch=0.0382, valid_loss=0.0604]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0341, train_loss_epoch=0.0341, valid_loss=0.0604]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0604]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0365, train_loss_epoch=0.0365, valid_loss=0.0604]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0294, train_loss_epoch=0.0294, valid_loss=0.0604]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0302, train_loss_epoch=0.0302, valid_loss=0.0604]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0604]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0257, train_loss_epoch=0.0257, valid_loss=0.0604]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0256, train_loss_epoch=0.0256, valid_loss=0.0604]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.0604]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0604]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.026, train_loss_epoch=0.026, valid_loss=0.0604]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.0604]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0336, train_loss_epoch=0.0336, valid_loss=0.0604]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0261, train_loss_epoch=0.0261, valid_loss=0.0604]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.0604]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0604]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.0604]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0268, train_loss_epoch=0.0268, valid_loss=0.0604]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.0604]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0282, train_loss_epoch=0.0282, valid_loss=0.0604]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0259, train_loss_epoch=0.0259, valid_loss=0.0604]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.0604]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0213, train_loss_epoch=0.0213, valid_loss=0.0604]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.031, train_loss_epoch=0.031, valid_loss=0.0604]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0285, train_loss_epoch=0.0285, valid_loss=0.0604]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0299, train_loss_epoch=0.0299, valid_loss=0.0604]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0604]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.0604]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0301, train_loss_epoch=0.0301, valid_loss=0.0604]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0443, train_loss_epoch=0.0443, valid_loss=0.0604]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.0604]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.034, train_loss_epoch=0.034, valid_loss=0.0604]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0338, train_loss_epoch=0.0338, valid_loss=0.0604]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0366, train_loss_epoch=0.0366, valid_loss=0.0604]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0277, train_loss_epoch=0.0277, valid_loss=0.0604]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0604]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.0604]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0604]\n",
            "Epoch 339: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0314, valid_loss=0.0604]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0287, train_loss_epoch=0.0287, valid_loss=0.0604]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0324, train_loss_epoch=0.0324, valid_loss=0.0604]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0273, train_loss_epoch=0.0273, valid_loss=0.0604]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0355, train_loss_epoch=0.0355, valid_loss=0.0604]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.036, train_loss_epoch=0.036, valid_loss=0.0604]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.0604]\n",
            "Epoch 345: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s, v_num=0, train_loss_step=0.0359, train_loss_epoch=0.0359, valid_loss=0.0604]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.028, train_loss_epoch=0.028, valid_loss=0.0604]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.033, train_loss_epoch=0.033, valid_loss=0.0604]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=0.0604]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0331, train_loss_epoch=0.0331, valid_loss=0.0604]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0316, train_loss_epoch=0.0316, valid_loss=0.0604]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0272, train_loss_epoch=0.0272, valid_loss=0.0604]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.0604]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0225, train_loss_epoch=0.0225, valid_loss=0.0604]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0358, train_loss_epoch=0.0358, valid_loss=0.0604]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=0.0604]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0266, train_loss_epoch=0.0266, valid_loss=0.0604]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0314, train_loss_epoch=0.0314, valid_loss=0.0604]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0275, train_loss_epoch=0.0275, valid_loss=0.0604]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0604]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0346, train_loss_epoch=0.0346, valid_loss=0.0604]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0249, train_loss_epoch=0.0249, valid_loss=0.0604]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0337, train_loss_epoch=0.0337, valid_loss=0.0604]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0304, train_loss_epoch=0.0304, valid_loss=0.0604]\n",
            "Epoch 363: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.0604]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0313, train_loss_epoch=0.0313, valid_loss=0.0604]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0284, train_loss_epoch=0.0284, valid_loss=0.0604]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0233, train_loss_epoch=0.0233, valid_loss=0.0604]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0321, train_loss_epoch=0.0321, valid_loss=0.0604]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0281, train_loss_epoch=0.0281, valid_loss=0.0604]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.0604]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0295, train_loss_epoch=0.0295, valid_loss=0.0604]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0244, train_loss_epoch=0.0244, valid_loss=0.0604]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.0604]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0227, train_loss_epoch=0.0227, valid_loss=0.0604]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0604]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0226, train_loss_epoch=0.0226, valid_loss=0.0604]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0209, train_loss_epoch=0.0209, valid_loss=0.0604]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0604]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.0604]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.0604]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.0604]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.0604]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0604]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0604]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.0604]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0604]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0604]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0604]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.0604]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.0604]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.0604]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00875, train_loss_epoch=0.00875, valid_loss=0.0604]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.0604]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0091, train_loss_epoch=0.0091, valid_loss=0.0604]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.0604]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0604]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.0604]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.0604]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.0604]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.0604]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0121, valid_loss=0.0604]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 111.90it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.0597]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.0597]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0108, train_loss_epoch=0.0108, valid_loss=0.0597]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0597]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.0597]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0597]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.0597]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.0597]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.0597]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.0597]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.0597]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.0597]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.0597]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0199, train_loss_epoch=0.0199, valid_loss=0.0597]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0165, train_loss_epoch=0.0165, valid_loss=0.0597]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.0597]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.0597]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.0597]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.0597]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0188, train_loss_epoch=0.0188, valid_loss=0.0597]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.0597]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.0597]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0597]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.0597]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.0597]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.0597]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0597]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0597]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0111, train_loss_epoch=0.0111, valid_loss=0.0597]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.0597]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.0597]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0597]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.0597]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.0597]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0597]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.0597]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0597]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0154, train_loss_epoch=0.0154, valid_loss=0.0597]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0597]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.0597]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.0597]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0597]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.0597]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0597]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0597]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0597]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0597]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0597]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.0597]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.0597]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.0597]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0597]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.0597]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0597]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.0597]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.0597]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.0597]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.0597]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.0597]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0597]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.0597]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.0597]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.0597]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.0597]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.0597]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.0597]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0143, train_loss_epoch=0.0143, valid_loss=0.0597]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.0597]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.0597]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0597]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.0597]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0597]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.0597]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.0597]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.0597]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.0597]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.0597]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.0597]\n",
            "Epoch 477: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0597]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0597]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.0597]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.0597]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163, valid_loss=0.0597]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.0597]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.0597]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0597]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.0597]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0597]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.0597]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.0597]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.0597]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0597]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.0597]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0597]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.0597]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0597]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.0597]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.0597]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.0597]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=0.0597]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.0597]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0189, train_loss_epoch=0.0189, valid_loss=0.0597]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0189, valid_loss=0.0597]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.42it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.058]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.058]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0201, train_loss_epoch=0.0201, valid_loss=0.058]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.058]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0204, train_loss_epoch=0.0204, valid_loss=0.058]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.058]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.058]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.058]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.058]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.058]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.058]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.058]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0177, train_loss_epoch=0.0177, valid_loss=0.058]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.058]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.058]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0178, train_loss_epoch=0.0178, valid_loss=0.058]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.058]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0197, train_loss_epoch=0.0197, valid_loss=0.058]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.058]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.058]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.058]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.058]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.058]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.058]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.016, train_loss_epoch=0.016, valid_loss=0.058]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.058]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0181, train_loss_epoch=0.0181, valid_loss=0.058]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.058]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0176, train_loss_epoch=0.0176, valid_loss=0.058]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.058]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.058]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0145, train_loss_epoch=0.0145, valid_loss=0.058]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.058]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.058]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.058]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.058]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.058]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.058]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.058]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.058]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0156, train_loss_epoch=0.0156, valid_loss=0.058]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.058]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0166, train_loss_epoch=0.0166, valid_loss=0.058]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0129, train_loss_epoch=0.0129, valid_loss=0.058]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.058]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.058]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0171, train_loss_epoch=0.0171, valid_loss=0.058]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.058]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.058]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.058]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.058]\n",
            "Epoch 550: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0124, valid_loss=0.058]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.058]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.058]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.058]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0146, train_loss_epoch=0.0146, valid_loss=0.058]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.058]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.058]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0173, train_loss_epoch=0.0173, valid_loss=0.058]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.058]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0159, train_loss_epoch=0.0159, valid_loss=0.058]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.058]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.058]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.058]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0165, train_loss_epoch=0.0165, valid_loss=0.058]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.058]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0165, train_loss_epoch=0.0165, valid_loss=0.058]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.058]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.058]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.058]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.058]\n",
            "Epoch 569: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0113, valid_loss=0.058]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.058]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0101, train_loss_epoch=0.0101, valid_loss=0.058]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.058]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.058]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.058]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.058]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0121, train_loss_epoch=0.0121, valid_loss=0.058]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.058]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0104, train_loss_epoch=0.0104, valid_loss=0.058]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.058]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.058]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0103, train_loss_epoch=0.0103, valid_loss=0.058]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0147, train_loss_epoch=0.0147, valid_loss=0.058]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.058]\n",
            "Epoch 583: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.058]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.058]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.058]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.058]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.058]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.058]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.058]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0168, train_loss_epoch=0.0168, valid_loss=0.058]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.058]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0177, train_loss_epoch=0.0177, valid_loss=0.058]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.058]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.058]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0174, train_loss_epoch=0.0174, valid_loss=0.058]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.058]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.058]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.011, train_loss_epoch=0.011, valid_loss=0.058]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.058]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0135, valid_loss=0.058]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 74.22it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163, valid_loss=0.057]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0097, train_loss_epoch=0.0097, valid_loss=0.057]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.057]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.057]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.057]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.057]\n",
            "Epoch 605: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.057]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.057]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0124, train_loss_epoch=0.0124, valid_loss=0.057]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.057]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0149, train_loss_epoch=0.0149, valid_loss=0.057]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.057]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.057]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.057]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.057]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.057]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.057]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.057]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0139, train_loss_epoch=0.0139, valid_loss=0.057]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.057]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.057]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.057]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.057]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.057]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.057]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.057]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.057]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.057]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.057]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.057]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.057]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.057]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0116, train_loss_epoch=0.0116, valid_loss=0.057]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0132, train_loss_epoch=0.0132, valid_loss=0.057]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.057]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.057]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.057]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.057]        \n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.057]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.057]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.057]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.057]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.057]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.057]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.057]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.057]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.057]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.057]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.057]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.057]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.057]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.057]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.013, train_loss_epoch=0.013, valid_loss=0.057]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.057]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.057]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.057]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0131, train_loss_epoch=0.0131, valid_loss=0.057]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.057]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.057]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0184, train_loss_epoch=0.0184, valid_loss=0.057]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0109, train_loss_epoch=0.0109, valid_loss=0.057]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0167, train_loss_epoch=0.0167, valid_loss=0.057]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0198, train_loss_epoch=0.0198, valid_loss=0.057]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.018, train_loss_epoch=0.018, valid_loss=0.057]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.057]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0186, train_loss_epoch=0.0186, valid_loss=0.057]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0169, train_loss_epoch=0.0169, valid_loss=0.057]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0177, train_loss_epoch=0.0177, valid_loss=0.057]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0182, train_loss_epoch=0.0182, valid_loss=0.057]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.057]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.057]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0152, train_loss_epoch=0.0152, valid_loss=0.057]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.057]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.057]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0207, train_loss_epoch=0.0207, valid_loss=0.057]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.057]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0174, train_loss_epoch=0.0174, valid_loss=0.057]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0195, train_loss_epoch=0.0195, valid_loss=0.057]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.057]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.057]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0172, train_loss_epoch=0.0172, valid_loss=0.057]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.057]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.017, train_loss_epoch=0.017, valid_loss=0.057]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0157, train_loss_epoch=0.0157, valid_loss=0.057]\n",
            "Epoch 681: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0157, valid_loss=0.057]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.057]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.057]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.057]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0117, train_loss_epoch=0.0117, valid_loss=0.057]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0163, train_loss_epoch=0.0163, valid_loss=0.057]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0161, train_loss_epoch=0.0161, valid_loss=0.057]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0112, train_loss_epoch=0.0112, valid_loss=0.057]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0206, train_loss_epoch=0.0206, valid_loss=0.057]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0175, train_loss_epoch=0.0175, valid_loss=0.057]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0126, train_loss_epoch=0.0126, valid_loss=0.057]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0187, train_loss_epoch=0.0187, valid_loss=0.057]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.057]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.057]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0148, train_loss_epoch=0.0148, valid_loss=0.057]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0134, train_loss_epoch=0.0134, valid_loss=0.057]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.057]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0137, train_loss_epoch=0.0137, valid_loss=0.057]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00992, train_loss_epoch=0.00992, valid_loss=0.057]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.00992, valid_loss=0.057] \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 131.06it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0562]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0144, train_loss_epoch=0.0144, valid_loss=0.0562]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0136, train_loss_epoch=0.0136, valid_loss=0.0562]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0562]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.0562]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0162, train_loss_epoch=0.0162, valid_loss=0.0562]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00995, train_loss_epoch=0.00995, valid_loss=0.0562]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0164, train_loss_epoch=0.0164, valid_loss=0.0562]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0155, train_loss_epoch=0.0155, valid_loss=0.0562]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0158, train_loss_epoch=0.0158, valid_loss=0.0562]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0142, train_loss_epoch=0.0142, valid_loss=0.0562]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.0562]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0153, train_loss_epoch=0.0153, valid_loss=0.0562]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00939, train_loss_epoch=0.00939, valid_loss=0.0562]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.014, train_loss_epoch=0.014, valid_loss=0.0562]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0118, train_loss_epoch=0.0118, valid_loss=0.0562]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0123, train_loss_epoch=0.0123, valid_loss=0.0562]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0562]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0138, train_loss_epoch=0.0138, valid_loss=0.0562]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0122, train_loss_epoch=0.0122, valid_loss=0.0562]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0114, train_loss_epoch=0.0114, valid_loss=0.0562]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0133, train_loss_epoch=0.0133, valid_loss=0.0562]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0135, train_loss_epoch=0.0135, valid_loss=0.0562]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0562]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0562]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0113, train_loss_epoch=0.0113, valid_loss=0.0562]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0141, train_loss_epoch=0.0141, valid_loss=0.0562]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00876, train_loss_epoch=0.00876, valid_loss=0.0562]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0128, train_loss_epoch=0.0128, valid_loss=0.0562]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0115, train_loss_epoch=0.0115, valid_loss=0.0562]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00871, train_loss_epoch=0.00871, valid_loss=0.0562]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.015, train_loss_epoch=0.015, valid_loss=0.0562]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0125, train_loss_epoch=0.0125, valid_loss=0.0562]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0127, train_loss_epoch=0.0127, valid_loss=0.0562]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0119, train_loss_epoch=0.0119, valid_loss=0.0562]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.0562]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.0562]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0105, train_loss_epoch=0.0105, valid_loss=0.0562]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0107, train_loss_epoch=0.0107, valid_loss=0.0562]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00912, train_loss_epoch=0.00912, valid_loss=0.0562]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00785, train_loss_epoch=0.00785, valid_loss=0.0562]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00987, train_loss_epoch=0.00987, valid_loss=0.0562]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00801, train_loss_epoch=0.00801, valid_loss=0.0562]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00716, valid_loss=0.0562]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00763, train_loss_epoch=0.00763, valid_loss=0.0562]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00707, train_loss_epoch=0.00707, valid_loss=0.0562]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00722, train_loss_epoch=0.00722, valid_loss=0.0562]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00679, train_loss_epoch=0.00679, valid_loss=0.0562]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00676, train_loss_epoch=0.00676, valid_loss=0.0562]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00714, train_loss_epoch=0.00714, valid_loss=0.0562]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00651, train_loss_epoch=0.00651, valid_loss=0.0562]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0562]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00659, train_loss_epoch=0.00659, valid_loss=0.0562]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00489, train_loss_epoch=0.00489, valid_loss=0.0562]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00575, train_loss_epoch=0.00575, valid_loss=0.0562]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00613, train_loss_epoch=0.00613, valid_loss=0.0562]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00499, train_loss_epoch=0.00499, valid_loss=0.0562]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.0562]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00568, train_loss_epoch=0.00568, valid_loss=0.0562]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00492, train_loss_epoch=0.00492, valid_loss=0.0562]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00561, train_loss_epoch=0.00561, valid_loss=0.0562]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00562, train_loss_epoch=0.00562, valid_loss=0.0562]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0562]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00625, train_loss_epoch=0.00625, valid_loss=0.0562]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.006, train_loss_epoch=0.006, valid_loss=0.0562]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00725, train_loss_epoch=0.00725, valid_loss=0.0562]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00747, train_loss_epoch=0.00747, valid_loss=0.0562]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.0562]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00687, train_loss_epoch=0.00687, valid_loss=0.0562]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=0.0562]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00542, train_loss_epoch=0.00542, valid_loss=0.0562]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00608, train_loss_epoch=0.00608, valid_loss=0.0562]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00519, valid_loss=0.0562]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=0.0562]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00498, train_loss_epoch=0.00498, valid_loss=0.0562]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00667, train_loss_epoch=0.00667, valid_loss=0.0562]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0562]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.0562]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.0562]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00759, train_loss_epoch=0.00759, valid_loss=0.0562]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00639, train_loss_epoch=0.00639, valid_loss=0.0562]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0562]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00687, train_loss_epoch=0.00687, valid_loss=0.0562]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0562]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=0.0562]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00561, train_loss_epoch=0.00561, valid_loss=0.0562]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0562]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00661, train_loss_epoch=0.00661, valid_loss=0.0562]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0058, train_loss_epoch=0.0058, valid_loss=0.0562]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00721, train_loss_epoch=0.00721, valid_loss=0.0562]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00568, train_loss_epoch=0.00568, valid_loss=0.0562]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00719, train_loss_epoch=0.00719, valid_loss=0.0562]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0065, train_loss_epoch=0.0065, valid_loss=0.0562]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00537, train_loss_epoch=0.00537, valid_loss=0.0562]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00699, train_loss_epoch=0.00699, valid_loss=0.0562]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0089, train_loss_epoch=0.0089, valid_loss=0.0562]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00657, train_loss_epoch=0.00657, valid_loss=0.0562]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00772, train_loss_epoch=0.00772, valid_loss=0.0562]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0065, train_loss_epoch=0.0065, valid_loss=0.0562]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00644, train_loss_epoch=0.00644, valid_loss=0.0562]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00516, train_loss_epoch=0.00516, valid_loss=0.0562]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s, v_num=0, train_loss_step=0.00541, train_loss_epoch=0.00516, valid_loss=0.0562]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.77it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00541, train_loss_epoch=0.00541, valid_loss=0.0575]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00524, train_loss_epoch=0.00524, valid_loss=0.0575]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00633, train_loss_epoch=0.00633, valid_loss=0.0575]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00553, train_loss_epoch=0.00553, valid_loss=0.0575]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0049, train_loss_epoch=0.0049, valid_loss=0.0575]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00605, train_loss_epoch=0.00605, valid_loss=0.0575]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00414, train_loss_epoch=0.00414, valid_loss=0.0575]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00699, train_loss_epoch=0.00699, valid_loss=0.0575]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00547, train_loss_epoch=0.00547, valid_loss=0.0575]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00722, train_loss_epoch=0.00722, valid_loss=0.0575]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00691, train_loss_epoch=0.00691, valid_loss=0.0575]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00615, train_loss_epoch=0.00615, valid_loss=0.0575]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00744, train_loss_epoch=0.00744, valid_loss=0.0575]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00822, train_loss_epoch=0.00822, valid_loss=0.0575]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00734, train_loss_epoch=0.00734, valid_loss=0.0575]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00796, train_loss_epoch=0.00796, valid_loss=0.0575]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00748, train_loss_epoch=0.00748, valid_loss=0.0575]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00721, train_loss_epoch=0.00721, valid_loss=0.0575]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00829, train_loss_epoch=0.00829, valid_loss=0.0575]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00603, train_loss_epoch=0.00603, valid_loss=0.0575]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00716, valid_loss=0.0575]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00694, train_loss_epoch=0.00694, valid_loss=0.0575]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=0.0575]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00604, train_loss_epoch=0.00604, valid_loss=0.0575]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00716, train_loss_epoch=0.00716, valid_loss=0.0575]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0063, train_loss_epoch=0.0063, valid_loss=0.0575]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.0575]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00711, train_loss_epoch=0.00711, valid_loss=0.0575]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00614, train_loss_epoch=0.00614, valid_loss=0.0575]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00756, train_loss_epoch=0.00756, valid_loss=0.0575]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00455, train_loss_epoch=0.00455, valid_loss=0.0575]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00852, train_loss_epoch=0.00852, valid_loss=0.0575]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00766, train_loss_epoch=0.00766, valid_loss=0.0575]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00686, train_loss_epoch=0.00686, valid_loss=0.0575]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=0.0575]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00887, train_loss_epoch=0.00887, valid_loss=0.0575]\n",
            "Epoch 835: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=0.0076, train_loss_epoch=0.0076, valid_loss=0.0575] \n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0076, train_loss_epoch=0.0076, valid_loss=0.0575]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00797, train_loss_epoch=0.00797, valid_loss=0.0575]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00801, train_loss_epoch=0.00801, valid_loss=0.0575]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.0575]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00913, train_loss_epoch=0.00913, valid_loss=0.0575]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.0575]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00698, train_loss_epoch=0.00698, valid_loss=0.0575]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00771, train_loss_epoch=0.00771, valid_loss=0.0575]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00609, train_loss_epoch=0.00609, valid_loss=0.0575]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00878, train_loss_epoch=0.00878, valid_loss=0.0575]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00859, train_loss_epoch=0.00859, valid_loss=0.0575]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00643, train_loss_epoch=0.00643, valid_loss=0.0575]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00719, train_loss_epoch=0.00719, valid_loss=0.0575]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00709, train_loss_epoch=0.00709, valid_loss=0.0575]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00865, train_loss_epoch=0.00865, valid_loss=0.0575]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00631, train_loss_epoch=0.00631, valid_loss=0.0575]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00875, train_loss_epoch=0.00875, valid_loss=0.0575]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00793, train_loss_epoch=0.00793, valid_loss=0.0575]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00697, train_loss_epoch=0.00697, valid_loss=0.0575]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00703, train_loss_epoch=0.00703, valid_loss=0.0575]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00617, train_loss_epoch=0.00617, valid_loss=0.0575]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00645, train_loss_epoch=0.00645, valid_loss=0.0575]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00649, train_loss_epoch=0.00649, valid_loss=0.0575]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00616, train_loss_epoch=0.00616, valid_loss=0.0575]\n",
            "Epoch 859: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=0, train_loss_step=0.00671, train_loss_epoch=0.00671, valid_loss=0.0575]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00671, train_loss_epoch=0.00671, valid_loss=0.0575]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00594, train_loss_epoch=0.00594, valid_loss=0.0575]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00535, train_loss_epoch=0.00535, valid_loss=0.0575]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00566, train_loss_epoch=0.00566, valid_loss=0.0575]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=0.0575]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00633, train_loss_epoch=0.00633, valid_loss=0.0575]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=0.0575]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00764, train_loss_epoch=0.00764, valid_loss=0.0575]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0575]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0575]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00702, train_loss_epoch=0.00702, valid_loss=0.0575]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00639, train_loss_epoch=0.00639, valid_loss=0.0575]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00692, train_loss_epoch=0.00692, valid_loss=0.0575]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00632, train_loss_epoch=0.00632, valid_loss=0.0575]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00613, train_loss_epoch=0.00613, valid_loss=0.0575]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00579, train_loss_epoch=0.00579, valid_loss=0.0575]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00475, train_loss_epoch=0.00475, valid_loss=0.0575]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00491, train_loss_epoch=0.00491, valid_loss=0.0575]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00705, train_loss_epoch=0.00705, valid_loss=0.0575]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0052, train_loss_epoch=0.0052, valid_loss=0.0575]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00696, train_loss_epoch=0.00696, valid_loss=0.0575]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00586, train_loss_epoch=0.00586, valid_loss=0.0575]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00569, train_loss_epoch=0.00569, valid_loss=0.0575]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=0.0575]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00522, train_loss_epoch=0.00522, valid_loss=0.0575]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.006, train_loss_epoch=0.006, valid_loss=0.0575]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00567, train_loss_epoch=0.00567, valid_loss=0.0575]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00581, train_loss_epoch=0.00581, valid_loss=0.0575]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00649, train_loss_epoch=0.00649, valid_loss=0.0575]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00628, train_loss_epoch=0.00628, valid_loss=0.0575]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00616, train_loss_epoch=0.00616, valid_loss=0.0575]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00738, train_loss_epoch=0.00738, valid_loss=0.0575]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00681, train_loss_epoch=0.00681, valid_loss=0.0575]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00534, train_loss_epoch=0.00534, valid_loss=0.0575]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00705, train_loss_epoch=0.00705, valid_loss=0.0575]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=0.0575]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00604, train_loss_epoch=0.00604, valid_loss=0.0575]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0083, train_loss_epoch=0.0083, valid_loss=0.0575]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00699, train_loss_epoch=0.00699, valid_loss=0.0575]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0575]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, v_num=0, train_loss_step=0.00751, train_loss_epoch=0.00648, valid_loss=0.0575]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 75.81it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00751, train_loss_epoch=0.00751, valid_loss=0.0574]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0574]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00701, train_loss_epoch=0.00701, valid_loss=0.0574]\n",
            "Epoch 902: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00701, valid_loss=0.0574]\n",
            "Epoch 902: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0574]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0574]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00638, train_loss_epoch=0.00638, valid_loss=0.0574]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00544, train_loss_epoch=0.00544, valid_loss=0.0574]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00601, train_loss_epoch=0.00601, valid_loss=0.0574]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00677, train_loss_epoch=0.00677, valid_loss=0.0574]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.0574]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00706, train_loss_epoch=0.00706, valid_loss=0.0574]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0053, train_loss_epoch=0.0053, valid_loss=0.0574]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00698, train_loss_epoch=0.00698, valid_loss=0.0574]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00671, train_loss_epoch=0.00671, valid_loss=0.0574]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00533, train_loss_epoch=0.00533, valid_loss=0.0574]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00673, train_loss_epoch=0.00673, valid_loss=0.0574]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00529, train_loss_epoch=0.00529, valid_loss=0.0574]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00556, train_loss_epoch=0.00556, valid_loss=0.0574]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00548, train_loss_epoch=0.00548, valid_loss=0.0574]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00543, train_loss_epoch=0.00543, valid_loss=0.0574]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00625, train_loss_epoch=0.00625, valid_loss=0.0574]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00724, valid_loss=0.0574]\n",
            "Epoch 920: 100%|██████████| 1/1 [00:00<00:00,  1.89it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.0574]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00629, train_loss_epoch=0.00629, valid_loss=0.0574]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00729, train_loss_epoch=0.00729, valid_loss=0.0574]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00674, train_loss_epoch=0.00674, valid_loss=0.0574]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00729, train_loss_epoch=0.00729, valid_loss=0.0574]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00767, train_loss_epoch=0.00767, valid_loss=0.0574]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00625, train_loss_epoch=0.00625, valid_loss=0.0574]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00675, train_loss_epoch=0.00675, valid_loss=0.0574]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00742, train_loss_epoch=0.00742, valid_loss=0.0574]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00836, train_loss_epoch=0.00836, valid_loss=0.0574]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00585, train_loss_epoch=0.00585, valid_loss=0.0574]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00732, train_loss_epoch=0.00732, valid_loss=0.0574]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00702, train_loss_epoch=0.00702, valid_loss=0.0574]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00698, train_loss_epoch=0.00698, valid_loss=0.0574]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00536, train_loss_epoch=0.00536, valid_loss=0.0574]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00765, train_loss_epoch=0.00765, valid_loss=0.0574]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00539, train_loss_epoch=0.00539, valid_loss=0.0574]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00847, train_loss_epoch=0.00847, valid_loss=0.0574]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00584, train_loss_epoch=0.00584, valid_loss=0.0574]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00966, train_loss_epoch=0.00966, valid_loss=0.0574]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00983, train_loss_epoch=0.00983, valid_loss=0.0574]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00717, train_loss_epoch=0.00717, valid_loss=0.0574]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0078, train_loss_epoch=0.0078, valid_loss=0.0574]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.012, train_loss_epoch=0.012, valid_loss=0.0574]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00982, train_loss_epoch=0.00982, valid_loss=0.0574]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00833, train_loss_epoch=0.00833, valid_loss=0.0574]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00969, train_loss_epoch=0.00969, valid_loss=0.0574]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00938, train_loss_epoch=0.00938, valid_loss=0.0574]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00935, train_loss_epoch=0.00935, valid_loss=0.0574]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00933, train_loss_epoch=0.00933, valid_loss=0.0574]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00864, train_loss_epoch=0.00864, valid_loss=0.0574]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00749, train_loss_epoch=0.00749, valid_loss=0.0574]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00994, train_loss_epoch=0.00994, valid_loss=0.0574]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00813, train_loss_epoch=0.00813, valid_loss=0.0574]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00879, train_loss_epoch=0.00879, valid_loss=0.0574]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00975, train_loss_epoch=0.00975, valid_loss=0.0574]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00792, train_loss_epoch=0.00792, valid_loss=0.0574]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00713, train_loss_epoch=0.00713, valid_loss=0.0574]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0574]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00727, train_loss_epoch=0.00727, valid_loss=0.0574]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00677, train_loss_epoch=0.00677, valid_loss=0.0574]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00779, train_loss_epoch=0.00779, valid_loss=0.0574]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00829, train_loss_epoch=0.00829, valid_loss=0.0574]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.0574]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00605, train_loss_epoch=0.00605, valid_loss=0.0574]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00666, train_loss_epoch=0.00666, valid_loss=0.0574]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00663, train_loss_epoch=0.00663, valid_loss=0.0574]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00533, train_loss_epoch=0.00533, valid_loss=0.0574]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00584, train_loss_epoch=0.00584, valid_loss=0.0574]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00609, train_loss_epoch=0.00609, valid_loss=0.0574]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00609, train_loss_epoch=0.00609, valid_loss=0.0574]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00581, train_loss_epoch=0.00581, valid_loss=0.0574]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00728, train_loss_epoch=0.00728, valid_loss=0.0574]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00524, train_loss_epoch=0.00524, valid_loss=0.0574]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00705, train_loss_epoch=0.00705, valid_loss=0.0574]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00582, train_loss_epoch=0.00582, valid_loss=0.0574]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0574]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00521, train_loss_epoch=0.00521, valid_loss=0.0574]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00783, train_loss_epoch=0.00783, valid_loss=0.0574]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00574, train_loss_epoch=0.00574, valid_loss=0.0574]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00621, train_loss_epoch=0.00621, valid_loss=0.0574]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0069, train_loss_epoch=0.0069, valid_loss=0.0574]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00762, train_loss_epoch=0.00762, valid_loss=0.0574]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00654, train_loss_epoch=0.00654, valid_loss=0.0574]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0065, train_loss_epoch=0.0065, valid_loss=0.0574]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00592, train_loss_epoch=0.00592, valid_loss=0.0574]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.0574]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00491, train_loss_epoch=0.00491, valid_loss=0.0574]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00589, train_loss_epoch=0.00589, valid_loss=0.0574]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00554, train_loss_epoch=0.00554, valid_loss=0.0574]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00602, train_loss_epoch=0.00602, valid_loss=0.0574]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00508, train_loss_epoch=0.00508, valid_loss=0.0574]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00572, train_loss_epoch=0.00572, valid_loss=0.0574]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00573, train_loss_epoch=0.00573, valid_loss=0.0574]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00597, train_loss_epoch=0.00597, valid_loss=0.0574]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00676, train_loss_epoch=0.00676, valid_loss=0.0574]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00472, train_loss_epoch=0.00472, valid_loss=0.0574]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00685, train_loss_epoch=0.00685, valid_loss=0.0574]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00642, train_loss_epoch=0.00642, valid_loss=0.0574]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00685, train_loss_epoch=0.00685, valid_loss=0.0574]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s, v_num=0, train_loss_step=0.00829, train_loss_epoch=0.00685, valid_loss=0.0574]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 70.29it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00829, train_loss_epoch=0.00829, valid_loss=0.0573]\n",
            "Epoch 1000: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, v_num=0, train_loss_step=0.00802, train_loss_epoch=0.00829, valid_loss=0.0573]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00802, train_loss_epoch=0.00802, valid_loss=0.0573]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00768, train_loss_epoch=0.00768, valid_loss=0.0573]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00757, train_loss_epoch=0.00757, valid_loss=0.0573]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0075, train_loss_epoch=0.0075, valid_loss=0.0573]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00728, train_loss_epoch=0.00728, valid_loss=0.0573]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00714, train_loss_epoch=0.00714, valid_loss=0.0573]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00745, train_loss_epoch=0.00745, valid_loss=0.0573]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0573]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0063, train_loss_epoch=0.0063, valid_loss=0.0573]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00705, train_loss_epoch=0.00705, valid_loss=0.0573]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00646, train_loss_epoch=0.00646, valid_loss=0.0573]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00774, train_loss_epoch=0.00774, valid_loss=0.0573]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0573]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00811, train_loss_epoch=0.00811, valid_loss=0.0573]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0078, train_loss_epoch=0.0078, valid_loss=0.0573]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00619, train_loss_epoch=0.00619, valid_loss=0.0573]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00737, train_loss_epoch=0.00737, valid_loss=0.0573]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00589, train_loss_epoch=0.00589, valid_loss=0.0573]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00637, train_loss_epoch=0.00637, valid_loss=0.0573]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00524, train_loss_epoch=0.00524, valid_loss=0.0573]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00734, train_loss_epoch=0.00734, valid_loss=0.0573]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00687, train_loss_epoch=0.00687, valid_loss=0.0573]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00631, train_loss_epoch=0.00631, valid_loss=0.0573]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00691, train_loss_epoch=0.00691, valid_loss=0.0573]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00603, train_loss_epoch=0.00603, valid_loss=0.0573]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00812, train_loss_epoch=0.00812, valid_loss=0.0573]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00682, train_loss_epoch=0.00682, valid_loss=0.0573]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00519, train_loss_epoch=0.00519, valid_loss=0.0573]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00686, train_loss_epoch=0.00686, valid_loss=0.0573]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00719, train_loss_epoch=0.00719, valid_loss=0.0573]\n",
            "Epoch 1030: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00719, valid_loss=0.0573]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00622, train_loss_epoch=0.00622, valid_loss=0.0573]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00762, train_loss_epoch=0.00762, valid_loss=0.0573]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00661, train_loss_epoch=0.00661, valid_loss=0.0573]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00599, train_loss_epoch=0.00599, valid_loss=0.0573]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00707, train_loss_epoch=0.00707, valid_loss=0.0573]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00648, train_loss_epoch=0.00648, valid_loss=0.0573]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0062, train_loss_epoch=0.0062, valid_loss=0.0573]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00568, train_loss_epoch=0.00568, valid_loss=0.0573]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00712, train_loss_epoch=0.00712, valid_loss=0.0573]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=0.0573]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00604, train_loss_epoch=0.00604, valid_loss=0.0573]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00723, train_loss_epoch=0.00723, valid_loss=0.0573]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0061, train_loss_epoch=0.0061, valid_loss=0.0573]\n",
            "Epoch 1043: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=0.00686, train_loss_epoch=0.00686, valid_loss=0.0573]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00686, train_loss_epoch=0.00686, valid_loss=0.0573]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00685, train_loss_epoch=0.00685, valid_loss=0.0573]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00558, train_loss_epoch=0.00558, valid_loss=0.0573]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00707, train_loss_epoch=0.00707, valid_loss=0.0573]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00461, train_loss_epoch=0.00461, valid_loss=0.0573]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0065, train_loss_epoch=0.0065, valid_loss=0.0573]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00518, train_loss_epoch=0.00518, valid_loss=0.0573]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00677, train_loss_epoch=0.00677, valid_loss=0.0573]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00552, train_loss_epoch=0.00552, valid_loss=0.0573]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00693, train_loss_epoch=0.00693, valid_loss=0.0573]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00772, train_loss_epoch=0.00772, valid_loss=0.0573]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00559, train_loss_epoch=0.00559, valid_loss=0.0573]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00758, train_loss_epoch=0.00758, valid_loss=0.0573]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00501, train_loss_epoch=0.00501, valid_loss=0.0573]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00888, train_loss_epoch=0.00888, valid_loss=0.0573]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00903, train_loss_epoch=0.00903, valid_loss=0.0573]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00667, train_loss_epoch=0.00667, valid_loss=0.0573]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00888, train_loss_epoch=0.00888, valid_loss=0.0573]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00817, train_loss_epoch=0.00817, valid_loss=0.0573]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00855, train_loss_epoch=0.00855, valid_loss=0.0573]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00675, train_loss_epoch=0.00675, valid_loss=0.0573]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00751, train_loss_epoch=0.00751, valid_loss=0.0573]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00649, train_loss_epoch=0.00649, valid_loss=0.0573]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00615, train_loss_epoch=0.00615, valid_loss=0.0573]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00631, train_loss_epoch=0.00631, valid_loss=0.0573]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00513, train_loss_epoch=0.00513, valid_loss=0.0573]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00627, train_loss_epoch=0.00627, valid_loss=0.0573]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0573]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00688, train_loss_epoch=0.00688, valid_loss=0.0573]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00618, train_loss_epoch=0.00618, valid_loss=0.0573]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00606, train_loss_epoch=0.00606, valid_loss=0.0573]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00572, train_loss_epoch=0.00572, valid_loss=0.0573]\n",
            "Epoch 1075: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00572, valid_loss=0.0573]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00626, train_loss_epoch=0.00626, valid_loss=0.0573]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0056, train_loss_epoch=0.0056, valid_loss=0.0573]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00654, train_loss_epoch=0.00654, valid_loss=0.0573]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00635, train_loss_epoch=0.00635, valid_loss=0.0573]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00595, train_loss_epoch=0.00595, valid_loss=0.0573]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00731, train_loss_epoch=0.00731, valid_loss=0.0573]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00642, train_loss_epoch=0.00642, valid_loss=0.0573]\n",
            "Epoch 1082: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s, v_num=0, train_loss_step=0.0063, train_loss_epoch=0.00642, valid_loss=0.0573] \n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0063, train_loss_epoch=0.0063, valid_loss=0.0573]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00762, train_loss_epoch=0.00762, valid_loss=0.0573]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00532, train_loss_epoch=0.00532, valid_loss=0.0573]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.0573]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00639, train_loss_epoch=0.00639, valid_loss=0.0573]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00503, train_loss_epoch=0.00503, valid_loss=0.0573]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00636, train_loss_epoch=0.00636, valid_loss=0.0573]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00482, train_loss_epoch=0.00482, valid_loss=0.0573]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00738, train_loss_epoch=0.00738, valid_loss=0.0573]\n",
            "Epoch 1091: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=0, train_loss_step=0.00662, train_loss_epoch=0.00662, valid_loss=0.0573]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00662, train_loss_epoch=0.00662, valid_loss=0.0573]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.0071, train_loss_epoch=0.0071, valid_loss=0.0573]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00889, train_loss_epoch=0.00889, valid_loss=0.0573]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00557, train_loss_epoch=0.00557, valid_loss=0.0573]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00892, train_loss_epoch=0.00892, valid_loss=0.0573]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00843, train_loss_epoch=0.00843, valid_loss=0.0573]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00734, train_loss_epoch=0.00734, valid_loss=0.0573]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.00803, train_loss_epoch=0.00803, valid_loss=0.0573]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 21:24:06,856\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (60, 8, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m `Trainer.fit` stopped: `max_steps=1100.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s, v_num=0, train_loss_step=0.00803, train_loss_epoch=0.00803, valid_loss=0.0573]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00803, valid_loss=0.0573]\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 108.30it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=58354)\u001b[0m \r                                                                       \u001b[A\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00803, valid_loss=0.0569]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00724, valid_loss=0.0569]\rEpoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s, v_num=0, train_loss_step=0.00724, train_loss_epoch=0.00724, valid_loss=0.0569]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=61152)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 2025-06-15 21:24:21.141754: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m E0000 00:00:1750022661.209841   61240 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m E0000 00:00:1750022661.229677   61240 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 2025-06-15 21:24:21.306739: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 3 | blocks       | ModuleList    | 9.4 M  | train\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 9.4 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 9.4 M     Total params\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 37.439    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 33.26it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=39.10, train_loss_epoch=39.10]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.80, train_loss_epoch=38.80]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.70, train_loss_epoch=38.70]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.50, train_loss_epoch=38.50]\n",
            "Epoch 4: 100%|██████████| 1/1 [00:01<00:00,  0.88it/s, v_num=0, train_loss_step=38.60, train_loss_epoch=38.60]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.60, train_loss_epoch=38.60]        \n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.60, train_loss_epoch=38.60]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.40, train_loss_epoch=38.40]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=38.10]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.40, train_loss_epoch=37.40]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.40, train_loss_epoch=37.40]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.20, train_loss_epoch=37.20]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.20, train_loss_epoch=36.20]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.00, train_loss_epoch=35.00]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.10, train_loss_epoch=34.10]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.20, train_loss_epoch=33.20]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:01<00:00,  0.98it/s, v_num=0, train_loss_step=31.90, train_loss_epoch=33.20]\n",
            "Epoch 15: 100%|██████████| 1/1 [00:01<00:00,  0.97it/s, v_num=0, train_loss_step=31.90, train_loss_epoch=31.90]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.90, train_loss_epoch=31.90]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.90, train_loss_epoch=26.90]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.80, train_loss_epoch=25.80]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.00, train_loss_epoch=25.00]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.10, train_loss_epoch=24.10]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.20, train_loss_epoch=21.20]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.00, train_loss_epoch=20.00]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.410, train_loss_epoch=9.410]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:01<00:00,  0.93it/s, v_num=0, train_loss_step=8.900, train_loss_epoch=9.410]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.900, train_loss_epoch=8.900]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.560, train_loss_epoch=8.560]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.770, train_loss_epoch=7.770]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.090, train_loss_epoch=7.090]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.080, train_loss_epoch=6.080]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.470, train_loss_epoch=5.470]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.540, train_loss_epoch=4.540]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.230, train_loss_epoch=4.230]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.000, train_loss_epoch=4.000]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=3.430]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.820, train_loss_epoch=1.820]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]\n",
            "Epoch 77: 100%|██████████| 1/1 [00:01<00:00,  0.96it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.740]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.510]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:01<00:00,  0.60it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=1.850]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 59.58it/s]\u001b[A\n",
            "Epoch 99: 100%|██████████| 1/1 [00:01<00:00,  0.59it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=1.850, valid_loss=0.0156]\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0156]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.0156]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.0156]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.0156]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.0156]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.0156]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.0156]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=0.0156]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.0156]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.0156]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.0156]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0156]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.010, valid_loss=0.0156]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=0.0156]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.070, train_loss_epoch=1.070, valid_loss=0.0156]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0156]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.998, train_loss_epoch=0.998, valid_loss=0.0156]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.989, train_loss_epoch=0.989, valid_loss=0.0156]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=0.0156]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.0156]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.0156]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.0156]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.0156]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.0156]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0156]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.150, train_loss_epoch=1.150, valid_loss=0.0156]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.140, train_loss_epoch=1.140, valid_loss=0.0156]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.913, train_loss_epoch=0.913, valid_loss=0.0156]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.0156]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.120, train_loss_epoch=1.120, valid_loss=0.0156]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.0156]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0156]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.0156]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.0156]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.997, train_loss_epoch=0.997, valid_loss=0.0156]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.190, train_loss_epoch=1.190, valid_loss=0.0156]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=0.0156]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.170, train_loss_epoch=1.170, valid_loss=0.0156]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.988, train_loss_epoch=0.988, valid_loss=0.0156]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=0.0156]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.992, train_loss_epoch=0.992, valid_loss=0.0156]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.250, train_loss_epoch=1.250, valid_loss=0.0156]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.110, train_loss_epoch=1.110, valid_loss=0.0156]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.0156]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.0156]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.0156]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.0156]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.964, train_loss_epoch=0.964, valid_loss=0.0156]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.0156]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.280, train_loss_epoch=1.280, valid_loss=0.0156]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.0156]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.0156]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0156]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.0156]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.970, train_loss_epoch=0.970, valid_loss=0.0156]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.0156]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0156]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.010, valid_loss=0.0156]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.0156]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.0156]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0156]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.0156]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.0156]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.080, train_loss_epoch=1.080, valid_loss=0.0156]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.0156]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.0156]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.0156]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.0156]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.994, train_loss_epoch=0.994, valid_loss=0.0156]\n",
            "Epoch 166: 100%|██████████| 1/1 [00:01<00:00,  0.97it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0156]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.0156]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.0156]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.0156]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.0156]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0156]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=2.200, valid_loss=0.0156]\n",
            "Epoch 171: 100%|██████████| 1/1 [00:01<00:00,  1.00it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.0156]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.0156]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.0156]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.0156]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.0156]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.0156]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.0156]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.210, train_loss_epoch=1.210, valid_loss=0.0156]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.0156]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.0156]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.0156]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.0156]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.0156]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0156]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.0156]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0156]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=0.0156]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=0.0156]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.973, train_loss_epoch=0.973, valid_loss=0.0156]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0156]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.948, train_loss_epoch=0.948, valid_loss=0.0156]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.0156]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.0156]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.837, train_loss_epoch=0.837, valid_loss=0.0156]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0156]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.881, train_loss_epoch=0.881, valid_loss=0.0156]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.866, train_loss_epoch=0.866, valid_loss=0.0156]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.963, train_loss_epoch=0.963, valid_loss=0.0156]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.860, train_loss_epoch=0.860, valid_loss=0.0156]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:01<00:00,  0.81it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.860, valid_loss=0.0156]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 68.75it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.952, train_loss_epoch=0.952, valid_loss=0.0154]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.922, train_loss_epoch=0.922, valid_loss=0.0154]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.825, train_loss_epoch=0.825, valid_loss=0.0154]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.050, train_loss_epoch=1.050, valid_loss=0.0154]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.850, train_loss_epoch=0.850, valid_loss=0.0154]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.200, train_loss_epoch=1.200, valid_loss=0.0154]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.020, train_loss_epoch=1.020, valid_loss=0.0154]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.160, train_loss_epoch=1.160, valid_loss=0.0154]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.0154]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.0154]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.0154]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.220, train_loss_epoch=1.220, valid_loss=0.0154]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.937, train_loss_epoch=0.937, valid_loss=0.0154]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.060, train_loss_epoch=1.060, valid_loss=0.0154]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.813, train_loss_epoch=0.813, valid_loss=0.0154]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.130, train_loss_epoch=1.130, valid_loss=0.0154]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.869, train_loss_epoch=0.869, valid_loss=0.0154]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.180, train_loss_epoch=1.180, valid_loss=0.0154]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.0154]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.010, train_loss_epoch=1.010, valid_loss=0.0154]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.0154]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.0154]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.040, train_loss_epoch=1.040, valid_loss=0.0154]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.0154]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.0154]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.0154]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.908, train_loss_epoch=0.908, valid_loss=0.0154]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.0154]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.0154]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.090, train_loss_epoch=1.090, valid_loss=0.0154]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.0154]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.0154]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.230, train_loss_epoch=1.230, valid_loss=0.0154]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.290, train_loss_epoch=1.290, valid_loss=0.0154]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=0.0154]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.928, train_loss_epoch=0.928, valid_loss=0.0154]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.753, train_loss_epoch=0.753, valid_loss=0.0154]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.919, train_loss_epoch=0.919, valid_loss=0.0154]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.838, train_loss_epoch=0.838, valid_loss=0.0154]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.609, train_loss_epoch=0.609, valid_loss=0.0154]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.822, train_loss_epoch=0.822, valid_loss=0.0154]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.901, train_loss_epoch=0.901, valid_loss=0.0154]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0154]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.780, train_loss_epoch=0.780, valid_loss=0.0154]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.821, train_loss_epoch=0.821, valid_loss=0.0154]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.665, train_loss_epoch=0.665, valid_loss=0.0154]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.595, train_loss_epoch=0.595, valid_loss=0.0154]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.677, train_loss_epoch=0.677, valid_loss=0.0154]\n",
            "Epoch 247: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0154]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.555, train_loss_epoch=0.555, valid_loss=0.0154]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.646, train_loss_epoch=0.646, valid_loss=0.0154]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0154]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.610, train_loss_epoch=0.610, valid_loss=0.0154]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.626, train_loss_epoch=0.626, valid_loss=0.0154]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0154]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.641, train_loss_epoch=0.641, valid_loss=0.0154]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.724, train_loss_epoch=0.724, valid_loss=0.0154]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0154]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.742, train_loss_epoch=0.742, valid_loss=0.0154]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.672, train_loss_epoch=0.672, valid_loss=0.0154]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0154]\n",
            "Epoch 259: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0154]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.668, train_loss_epoch=0.668, valid_loss=0.0154]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.493, train_loss_epoch=0.493, valid_loss=0.0154]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.577, train_loss_epoch=0.577, valid_loss=0.0154]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.565, train_loss_epoch=0.565, valid_loss=0.0154]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.603, train_loss_epoch=0.603, valid_loss=0.0154]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.752, train_loss_epoch=0.752, valid_loss=0.0154]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.550, train_loss_epoch=0.550, valid_loss=0.0154]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.593, train_loss_epoch=0.593, valid_loss=0.0154]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0154]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.568, train_loss_epoch=0.568, valid_loss=0.0154]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0154]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.604, train_loss_epoch=0.604, valid_loss=0.0154]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0154]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.590, train_loss_epoch=0.590, valid_loss=0.0154]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.528, train_loss_epoch=0.528, valid_loss=0.0154]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.552, train_loss_epoch=0.552, valid_loss=0.0154]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0154]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0154]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.501, train_loss_epoch=0.501, valid_loss=0.0154]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0154]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0154]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.517, train_loss_epoch=0.517, valid_loss=0.0154]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0154]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.527, train_loss_epoch=0.527, valid_loss=0.0154]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.462, train_loss_epoch=0.462, valid_loss=0.0154]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.567, train_loss_epoch=0.567, valid_loss=0.0154]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0154]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0154]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0154]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0154]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.521, train_loss_epoch=0.521, valid_loss=0.0154]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.478, train_loss_epoch=0.478, valid_loss=0.0154]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.596, train_loss_epoch=0.596, valid_loss=0.0154]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0154]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.647, train_loss_epoch=0.647, valid_loss=0.0154]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.605, train_loss_epoch=0.605, valid_loss=0.0154]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.525, train_loss_epoch=0.525, valid_loss=0.0154]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0154]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.456, train_loss_epoch=0.456, valid_loss=0.0154]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0154]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:01<00:00,  0.95it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.519, valid_loss=0.0154]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.33it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.560, train_loss_epoch=0.560, valid_loss=0.0154]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0154]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.614, train_loss_epoch=0.614, valid_loss=0.0154]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0154]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.572, train_loss_epoch=0.572, valid_loss=0.0154]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0154]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.418, train_loss_epoch=0.418, valid_loss=0.0154]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.476, train_loss_epoch=0.476, valid_loss=0.0154]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0154]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.396, train_loss_epoch=0.396, valid_loss=0.0154]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0154]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0154]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.571, train_loss_epoch=0.571, valid_loss=0.0154]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0154]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0154]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.520, train_loss_epoch=0.520, valid_loss=0.0154]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0154]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0154]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.448, train_loss_epoch=0.448, valid_loss=0.0154]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0154]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.437, train_loss_epoch=0.437, valid_loss=0.0154]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0154]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0154]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0154]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.371, train_loss_epoch=0.371, valid_loss=0.0154]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.398, train_loss_epoch=0.398, valid_loss=0.0154]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.436, train_loss_epoch=0.436, valid_loss=0.0154]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.424, train_loss_epoch=0.424, valid_loss=0.0154]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.411, train_loss_epoch=0.411, valid_loss=0.0154]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0154]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0154]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0154]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.430, train_loss_epoch=0.430, valid_loss=0.0154]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.479, train_loss_epoch=0.479, valid_loss=0.0154]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.415, train_loss_epoch=0.415, valid_loss=0.0154]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.561, train_loss_epoch=0.561, valid_loss=0.0154]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.492, train_loss_epoch=0.492, valid_loss=0.0154]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0154]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0154]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.414, train_loss_epoch=0.414, valid_loss=0.0154]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.463, train_loss_epoch=0.463, valid_loss=0.0154]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0154]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.364, train_loss_epoch=0.364, valid_loss=0.0154]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.435, train_loss_epoch=0.435, valid_loss=0.0154]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0154]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0154]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.498, train_loss_epoch=0.498, valid_loss=0.0154]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0154]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0154]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0154]        \n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.452, train_loss_epoch=0.452, valid_loss=0.0154]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.488, train_loss_epoch=0.488, valid_loss=0.0154]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.473, train_loss_epoch=0.473, valid_loss=0.0154]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0154]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0154]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0154]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.440, train_loss_epoch=0.440, valid_loss=0.0154]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.426, train_loss_epoch=0.426, valid_loss=0.0154]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0154]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0154]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.380, train_loss_epoch=0.380, valid_loss=0.0154]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0154]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0154]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.419, train_loss_epoch=0.419, valid_loss=0.0154]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.434, train_loss_epoch=0.434, valid_loss=0.0154]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.422, train_loss_epoch=0.422, valid_loss=0.0154]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0154]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.407, train_loss_epoch=0.407, valid_loss=0.0154]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.480, train_loss_epoch=0.480, valid_loss=0.0154]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0154]\n",
            "Epoch 368: 100%|██████████| 1/1 [00:01<00:00,  0.59it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0154]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.547, train_loss_epoch=0.547, valid_loss=0.0154]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.446, train_loss_epoch=0.446, valid_loss=0.0154]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.469, train_loss_epoch=0.469, valid_loss=0.0154]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.481, train_loss_epoch=0.481, valid_loss=0.0154]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0154]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.504, train_loss_epoch=0.504, valid_loss=0.0154]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.385, train_loss_epoch=0.385, valid_loss=0.0154]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.450, train_loss_epoch=0.450, valid_loss=0.0154]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0154]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0154]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.519, train_loss_epoch=0.519, valid_loss=0.0154]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.388, train_loss_epoch=0.388, valid_loss=0.0154]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.591, train_loss_epoch=0.591, valid_loss=0.0154]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.455, train_loss_epoch=0.455, valid_loss=0.0154]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.566, train_loss_epoch=0.566, valid_loss=0.0154]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.535, train_loss_epoch=0.535, valid_loss=0.0154]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.490, train_loss_epoch=0.490, valid_loss=0.0154]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0154]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0154]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0154]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.410, train_loss_epoch=0.410, valid_loss=0.0154]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0154]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0154]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.399, train_loss_epoch=0.399, valid_loss=0.0154]\n",
            "Epoch 392: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0154]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0154]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.397, train_loss_epoch=0.397, valid_loss=0.0154]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.529, train_loss_epoch=0.529, valid_loss=0.0154]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.395, train_loss_epoch=0.395, valid_loss=0.0154]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.615, train_loss_epoch=0.615, valid_loss=0.0154]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.508, train_loss_epoch=0.508, valid_loss=0.0154]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.569, train_loss_epoch=0.569, valid_loss=0.0154]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:01<00:00,  0.98it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.569, valid_loss=0.0154]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 98.55it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.549, train_loss_epoch=0.549, valid_loss=0.0154]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  1.00it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.549, valid_loss=0.0154]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.468, train_loss_epoch=0.468, valid_loss=0.0154]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0154]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.513, train_loss_epoch=0.513, valid_loss=0.0154]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0154]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0154]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.487, train_loss_epoch=0.487, valid_loss=0.0154]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.536, train_loss_epoch=0.536, valid_loss=0.0154]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.499, train_loss_epoch=0.499, valid_loss=0.0154]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.546, train_loss_epoch=0.546, valid_loss=0.0154]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0154]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.470, train_loss_epoch=0.470, valid_loss=0.0154]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0154]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.486, train_loss_epoch=0.486, valid_loss=0.0154]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.489, train_loss_epoch=0.489, valid_loss=0.0154]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.526, train_loss_epoch=0.526, valid_loss=0.0154]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.628, train_loss_epoch=0.628, valid_loss=0.0154]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.556, train_loss_epoch=0.556, valid_loss=0.0154]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.592, train_loss_epoch=0.592, valid_loss=0.0154]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0154]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.553, train_loss_epoch=0.553, valid_loss=0.0154]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.524, train_loss_epoch=0.524, valid_loss=0.0154]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0154]\n",
            "Epoch 422: 100%|██████████| 1/1 [00:01<00:00,  0.97it/s, v_num=0, train_loss_step=0.484, train_loss_epoch=0.484, valid_loss=0.0154]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.515, train_loss_epoch=0.515, valid_loss=0.0154]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.491, train_loss_epoch=0.491, valid_loss=0.0154]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.509, train_loss_epoch=0.509, valid_loss=0.0154]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.472, train_loss_epoch=0.472, valid_loss=0.0154]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.428, train_loss_epoch=0.428, valid_loss=0.0154]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.477, train_loss_epoch=0.477, valid_loss=0.0154]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.420, train_loss_epoch=0.420, valid_loss=0.0154]\n",
            "Epoch 429: 100%|██████████| 1/1 [00:01<00:00,  0.89it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.420, valid_loss=0.0154]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.454, train_loss_epoch=0.454, valid_loss=0.0154]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.421, train_loss_epoch=0.421, valid_loss=0.0154]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0154]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.358, train_loss_epoch=0.358, valid_loss=0.0154]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.458, train_loss_epoch=0.458, valid_loss=0.0154]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.387, train_loss_epoch=0.387, valid_loss=0.0154]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.460, train_loss_epoch=0.460, valid_loss=0.0154]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.404, train_loss_epoch=0.404, valid_loss=0.0154]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.506, train_loss_epoch=0.506, valid_loss=0.0154]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.425, train_loss_epoch=0.425, valid_loss=0.0154]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0154]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.461, train_loss_epoch=0.461, valid_loss=0.0154]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.432, train_loss_epoch=0.432, valid_loss=0.0154]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.449, train_loss_epoch=0.449, valid_loss=0.0154]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.394, train_loss_epoch=0.394, valid_loss=0.0154]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0154]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.386, train_loss_epoch=0.386, valid_loss=0.0154]\n",
            "Epoch 446: 100%|██████████| 1/1 [00:01<00:00,  0.96it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0154]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0154]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.443, train_loss_epoch=0.443, valid_loss=0.0154]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.445, train_loss_epoch=0.445, valid_loss=0.0154]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.433, train_loss_epoch=0.433, valid_loss=0.0154]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.401, train_loss_epoch=0.401, valid_loss=0.0154]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.416, train_loss_epoch=0.416, valid_loss=0.0154]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.389, train_loss_epoch=0.389, valid_loss=0.0154]\n",
            "Epoch 453: 100%|██████████| 1/1 [00:01<00:00,  0.94it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0154]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0154]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.382, train_loss_epoch=0.382, valid_loss=0.0154]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.403, train_loss_epoch=0.403, valid_loss=0.0154]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.366, train_loss_epoch=0.366, valid_loss=0.0154]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.390, train_loss_epoch=0.390, valid_loss=0.0154]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.357, train_loss_epoch=0.357, valid_loss=0.0154]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.402, train_loss_epoch=0.402, valid_loss=0.0154]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.423, train_loss_epoch=0.423, valid_loss=0.0154]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.367, train_loss_epoch=0.367, valid_loss=0.0154]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.444, train_loss_epoch=0.444, valid_loss=0.0154]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.360, train_loss_epoch=0.360, valid_loss=0.0154]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.383, train_loss_epoch=0.383, valid_loss=0.0154]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.441, train_loss_epoch=0.441, valid_loss=0.0154]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.352, train_loss_epoch=0.352, valid_loss=0.0154]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.338, train_loss_epoch=0.338, valid_loss=0.0154]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:01<00:00,  0.59it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.338, valid_loss=0.0154]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.284, train_loss_epoch=0.284, valid_loss=0.0154]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0154]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.267, train_loss_epoch=0.267, valid_loss=0.0154]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0154]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0154]        \n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0154]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.0154]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.274, train_loss_epoch=0.274, valid_loss=0.0154]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0154]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0154]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.0154]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.0154]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0154]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0154]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0154]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0154]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0154]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0154]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:01<00:00,  0.87it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.197, valid_loss=0.0154]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0154]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0154]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0154]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0154]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0154]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.0154]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0154]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0154]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0154]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0154]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0154]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.180, valid_loss=0.0154]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.96it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0154]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0154]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.195, train_loss_epoch=0.195, valid_loss=0.0154]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0154]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0154]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0154]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0154]\n",
            "Epoch 506: 100%|██████████| 1/1 [00:01<00:00,  0.59it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0154]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0154]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.179, train_loss_epoch=0.179, valid_loss=0.0154]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0154]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0154]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0154]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0154]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0154]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.197, train_loss_epoch=0.197, valid_loss=0.0154]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.191, train_loss_epoch=0.191, valid_loss=0.0154]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0154]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0154]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0154]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0154]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0154]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0154]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0154]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0154]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.182, train_loss_epoch=0.182, valid_loss=0.0154]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.205, train_loss_epoch=0.205, valid_loss=0.0154]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.166, train_loss_epoch=0.166, valid_loss=0.0154]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0154]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.187, train_loss_epoch=0.187, valid_loss=0.0154]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0154]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.169, train_loss_epoch=0.169, valid_loss=0.0154]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0154]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0154]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0154]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0154]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0154]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.283, train_loss_epoch=0.283, valid_loss=0.0154]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0154]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0154]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0154]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.0154]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0154]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0154]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.0154]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0154]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.231, train_loss_epoch=0.231, valid_loss=0.0154]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.0154]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0154]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.225, train_loss_epoch=0.225, valid_loss=0.0154]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0154]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0154]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.189, train_loss_epoch=0.189, valid_loss=0.0154]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.0154]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0154]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.0154]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.202, train_loss_epoch=0.202, valid_loss=0.0154]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0154]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.172, train_loss_epoch=0.172, valid_loss=0.0154]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0154]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.215, valid_loss=0.0154]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.194, train_loss_epoch=0.194, valid_loss=0.0154]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.0154]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0154]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.181, train_loss_epoch=0.181, valid_loss=0.0154]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.204, train_loss_epoch=0.204, valid_loss=0.0154]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0154]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.215, train_loss_epoch=0.215, valid_loss=0.0154]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0154]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.226, train_loss_epoch=0.226, valid_loss=0.0154]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0154]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0154]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0154]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.203, train_loss_epoch=0.203, valid_loss=0.0154]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0154]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0154]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0154]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0154]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.238, train_loss_epoch=0.238, valid_loss=0.0154]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0154]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0154]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.0154]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0154]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.192, train_loss_epoch=0.192, valid_loss=0.0154]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0154]\n",
            "Epoch 586: 100%|██████████| 1/1 [00:01<00:00,  0.96it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.0154]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.234, train_loss_epoch=0.234, valid_loss=0.0154]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.245, train_loss_epoch=0.245, valid_loss=0.0154]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.227, train_loss_epoch=0.227, valid_loss=0.0154]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0154]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0154]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0154]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.0154]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0154]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.201, train_loss_epoch=0.201, valid_loss=0.0154]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.0154]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0154]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.97it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.236, valid_loss=0.0154]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.95it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0154]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.0154]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0154]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0154]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0154]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0154]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.256, train_loss_epoch=0.256, valid_loss=0.0154]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.254, train_loss_epoch=0.254, valid_loss=0.0154]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.276, train_loss_epoch=0.276, valid_loss=0.0154]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0154]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.257, train_loss_epoch=0.257, valid_loss=0.0154]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0154]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.269, train_loss_epoch=0.269, valid_loss=0.0154]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.250, train_loss_epoch=0.250, valid_loss=0.0154]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0154]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0154]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0154]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.244, train_loss_epoch=0.244, valid_loss=0.0154]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0154]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0154]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0154]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.248, train_loss_epoch=0.248, valid_loss=0.0154]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0154]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.0154]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.260, train_loss_epoch=0.260, valid_loss=0.0154]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.0154]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.281, train_loss_epoch=0.281, valid_loss=0.0154]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.288, train_loss_epoch=0.288, valid_loss=0.0154]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0154]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.264, train_loss_epoch=0.264, valid_loss=0.0154]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0154]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0154]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.272, train_loss_epoch=0.272, valid_loss=0.0154]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.206, train_loss_epoch=0.206, valid_loss=0.0154]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.258, train_loss_epoch=0.258, valid_loss=0.0154]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0154]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.265, train_loss_epoch=0.265, valid_loss=0.0154]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.228, train_loss_epoch=0.228, valid_loss=0.0154]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.298, train_loss_epoch=0.298, valid_loss=0.0154]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0154]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.232, train_loss_epoch=0.232, valid_loss=0.0154]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0154]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.220, train_loss_epoch=0.220, valid_loss=0.0154]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0154]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0154]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.279, train_loss_epoch=0.279, valid_loss=0.0154]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0154]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.259, train_loss_epoch=0.259, valid_loss=0.0154]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.252, train_loss_epoch=0.252, valid_loss=0.0154]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.261, train_loss_epoch=0.261, valid_loss=0.0154]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:01<00:00,  0.95it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.222, train_loss_epoch=0.222, valid_loss=0.0154]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.243, train_loss_epoch=0.243, valid_loss=0.0154]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.224, train_loss_epoch=0.224, valid_loss=0.0154]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.223, train_loss_epoch=0.223, valid_loss=0.0154]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.211, train_loss_epoch=0.211, valid_loss=0.0154]\n",
            "Epoch 656: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0154]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.210, train_loss_epoch=0.210, valid_loss=0.0154]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.208, train_loss_epoch=0.208, valid_loss=0.0154]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.213, train_loss_epoch=0.213, valid_loss=0.0154]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0154]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0154]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.221, train_loss_epoch=0.221, valid_loss=0.0154]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.212, train_loss_epoch=0.212, valid_loss=0.0154]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.219, train_loss_epoch=0.219, valid_loss=0.0154]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.239, train_loss_epoch=0.239, valid_loss=0.0154]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.233, train_loss_epoch=0.233, valid_loss=0.0154]\n",
            "Epoch 667: 100%|██████████| 1/1 [00:01<00:00,  0.94it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.233, valid_loss=0.0154]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.240, train_loss_epoch=0.240, valid_loss=0.0154]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.235, train_loss_epoch=0.235, valid_loss=0.0154]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.292, train_loss_epoch=0.292, valid_loss=0.0154]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.253, train_loss_epoch=0.253, valid_loss=0.0154]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.280, train_loss_epoch=0.280, valid_loss=0.0154]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.295, train_loss_epoch=0.295, valid_loss=0.0154]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.230, train_loss_epoch=0.230, valid_loss=0.0154]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.282, train_loss_epoch=0.282, valid_loss=0.0154]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.216, train_loss_epoch=0.216, valid_loss=0.0154]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.315, train_loss_epoch=0.315, valid_loss=0.0154]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.270, train_loss_epoch=0.270, valid_loss=0.0154]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.263, train_loss_epoch=0.263, valid_loss=0.0154]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.266, train_loss_epoch=0.266, valid_loss=0.0154]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.218, train_loss_epoch=0.218, valid_loss=0.0154]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.241, train_loss_epoch=0.241, valid_loss=0.0154]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]        \n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.209, train_loss_epoch=0.209, valid_loss=0.0154]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.190, train_loss_epoch=0.190, valid_loss=0.0154]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.186, train_loss_epoch=0.186, valid_loss=0.0154]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.188, train_loss_epoch=0.188, valid_loss=0.0154]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.214, train_loss_epoch=0.214, valid_loss=0.0154]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.180, train_loss_epoch=0.180, valid_loss=0.0154]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.193, train_loss_epoch=0.193, valid_loss=0.0154]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.199, train_loss_epoch=0.199, valid_loss=0.0154]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.185, train_loss_epoch=0.185, valid_loss=0.0154]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.242, train_loss_epoch=0.242, valid_loss=0.0154]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.184, train_loss_epoch=0.184, valid_loss=0.0154]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.236, train_loss_epoch=0.236, valid_loss=0.0154]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.207, train_loss_epoch=0.207, valid_loss=0.0154]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.246, train_loss_epoch=0.246, valid_loss=0.0154]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.229, train_loss_epoch=0.229, valid_loss=0.0154]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 21:38:19,115\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (1, 1, 1), 'n_pool_kernel_size': (8, 4, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \rEpoch 699: 100%|██████████| 1/1 [00:01<00:00,  0.93it/s, v_num=0, train_loss_step=0.247, train_loss_epoch=0.247, valid_loss=0.0154]\rEpoch 699: 100%|██████████| 1/1 [00:01<00:00,  0.93it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.247, valid_loss=0.0154]\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.79it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=61152)\u001b[0m \r                                                                      \u001b[A\rEpoch 699: 100%|██████████| 1/1 [00:01<00:00,  0.91it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.247, valid_loss=0.0154]\rEpoch 699: 100%|██████████| 1/1 [00:01<00:00,  0.90it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0154]\rEpoch 699: 100%|██████████| 1/1 [00:01<00:00,  0.90it/s, v_num=0, train_loss_step=0.237, train_loss_epoch=0.237, valid_loss=0.0154]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=61152)\u001b[0m `Trainer.fit` stopped: `max_steps=700.0` reached.\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 2025-06-15 21:38:32.643983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m E0000 00:00:1750023512.679663   64824 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m E0000 00:00:1750023512.689970   64824 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 2025-06-15 21:38:32.721063: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 3 | blocks       | ModuleList    | 7.9 M  | train\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 7.9 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 7.9 M     Total params\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 31.706    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.30, train_loss_epoch=38.30]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.00, train_loss_epoch=33.00]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]\n",
            "Epoch 5: 100%|██████████| 1/1 [00:01<00:00,  0.80it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=32.90]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.10, train_loss_epoch=27.10]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.70, train_loss_epoch=25.70]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.40, train_loss_epoch=25.40]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.10, train_loss_epoch=25.10]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.30, train_loss_epoch=24.30]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.60, train_loss_epoch=23.60]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.90, train_loss_epoch=22.90]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=21.50]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=21.50]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.30, train_loss_epoch=19.30]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.00, train_loss_epoch=20.00]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:01<00:00,  0.76it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 70: 100%|██████████| 1/1 [00:01<00:00,  0.76it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.750, train_loss_epoch=9.750]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.970, train_loss_epoch=9.970]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 79: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.810, train_loss_epoch=9.810]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.620, train_loss_epoch=9.620]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.170, train_loss_epoch=9.170]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.300, train_loss_epoch=9.300]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.010, train_loss_epoch=9.010]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.430, train_loss_epoch=9.430]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.740, train_loss_epoch=8.740]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.730, train_loss_epoch=8.730]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.450, train_loss_epoch=9.450]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.330, train_loss_epoch=9.330]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.200, train_loss_epoch=9.200]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.080, train_loss_epoch=9.080]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.440, train_loss_epoch=9.440]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.320, train_loss_epoch=9.320]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.570, train_loss_epoch=8.570]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.690, train_loss_epoch=9.690]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=9.630, train_loss_epoch=9.690]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.89it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.630, train_loss_epoch=9.630, valid_loss=0.00371]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.500, train_loss_epoch=9.500, valid_loss=0.00371]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.270, train_loss_epoch=8.270, valid_loss=0.00371]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.770, valid_loss=0.00371]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.690, train_loss_epoch=8.690, valid_loss=0.00371]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.250, train_loss_epoch=8.250, valid_loss=0.00371]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=8.790, valid_loss=0.00371]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=0.00371]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.400, train_loss_epoch=8.400, valid_loss=0.00371]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.960, train_loss_epoch=7.960, valid_loss=0.00371]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00371]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.00371]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00371]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.010, train_loss_epoch=8.010, valid_loss=0.00371]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.00371]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.350, train_loss_epoch=7.350, valid_loss=0.00371]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.680, train_loss_epoch=7.680, valid_loss=0.00371]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.770, train_loss_epoch=7.770, valid_loss=0.00371]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.890, train_loss_epoch=7.890, valid_loss=0.00371]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.00371]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.650, train_loss_epoch=8.650, valid_loss=0.00371]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.270, train_loss_epoch=7.270, valid_loss=0.00371]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00371]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00371]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540, valid_loss=0.00371]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.00371]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.130, train_loss_epoch=9.130, valid_loss=0.00371]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.750, train_loss_epoch=8.750, valid_loss=0.00371]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.00371]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.00371]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.750, train_loss_epoch=7.750, valid_loss=0.00371]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.00371]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.960, train_loss_epoch=7.960, valid_loss=0.00371]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.390, train_loss_epoch=7.390, valid_loss=0.00371]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.830, train_loss_epoch=7.830, valid_loss=0.00371]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.170, train_loss_epoch=7.170, valid_loss=0.00371]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.00371]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.00371]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.940, train_loss_epoch=6.940, valid_loss=0.00371]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.00371]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.960, train_loss_epoch=6.960, valid_loss=0.00371]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.940, train_loss_epoch=6.940, valid_loss=0.00371]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180, valid_loss=0.00371]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460, valid_loss=0.00371]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.150, train_loss_epoch=7.150, valid_loss=0.00371]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.710, train_loss_epoch=6.710, valid_loss=0.00371]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180, valid_loss=0.00371]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.050, train_loss_epoch=7.050, valid_loss=0.00371]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=6.550, valid_loss=0.00371]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.980, train_loss_epoch=6.980, valid_loss=0.00371]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.480, train_loss_epoch=6.480, valid_loss=0.00371]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460, valid_loss=0.00371]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.630, train_loss_epoch=6.630, valid_loss=0.00371]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.710, train_loss_epoch=6.710, valid_loss=0.00371]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.250, train_loss_epoch=6.250, valid_loss=0.00371]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.00371]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.410, train_loss_epoch=6.410, valid_loss=0.00371]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.540, train_loss_epoch=6.540, valid_loss=0.00371]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=0.00371]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.160, valid_loss=0.00371]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=0.00371]\n",
            "Epoch 160: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.160, valid_loss=0.00371]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.160, train_loss_epoch=6.160, valid_loss=0.00371]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.640, train_loss_epoch=6.640, valid_loss=0.00371]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.040, train_loss_epoch=6.040, valid_loss=0.00371]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.400, train_loss_epoch=6.400, valid_loss=0.00371]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=0.00371]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.860, train_loss_epoch=6.860, valid_loss=0.00371]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460, valid_loss=0.00371]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=6.440, valid_loss=0.00371]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.570, train_loss_epoch=6.570, valid_loss=0.00371]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.270, train_loss_epoch=6.270, valid_loss=0.00371]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.350, train_loss_epoch=6.350, valid_loss=0.00371]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.320, train_loss_epoch=6.320, valid_loss=0.00371]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.00371]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.730, train_loss_epoch=6.730, valid_loss=0.00371]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960, valid_loss=0.00371]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.00371]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.510, train_loss_epoch=6.510, valid_loss=0.00371]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.990, train_loss_epoch=5.990, valid_loss=0.00371]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.00371]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.300, train_loss_epoch=6.300, valid_loss=0.00371]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.680, train_loss_epoch=5.680, valid_loss=0.00371]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.720, train_loss_epoch=6.720, valid_loss=0.00371]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.020, train_loss_epoch=6.020, valid_loss=0.00371]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.130, train_loss_epoch=6.130, valid_loss=0.00371]\n",
            "Epoch 184: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=6.130, train_loss_epoch=6.130, valid_loss=0.00371]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.130, train_loss_epoch=6.130, valid_loss=0.00371]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.140, train_loss_epoch=6.140, valid_loss=0.00371]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000, valid_loss=0.00371]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.950, train_loss_epoch=5.950, valid_loss=0.00371]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.240, train_loss_epoch=6.240, valid_loss=0.00371]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.980, train_loss_epoch=5.980, valid_loss=0.00371]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.200, train_loss_epoch=6.200, valid_loss=0.00371]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.290, train_loss_epoch=6.290, valid_loss=0.00371]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=6.780, valid_loss=0.00371]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.200, train_loss_epoch=6.200, valid_loss=0.00371]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00371]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.00371]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.050, train_loss_epoch=7.050, valid_loss=0.00371]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=6.970, valid_loss=0.00371]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180, valid_loss=0.00371]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s, v_num=0, train_loss_step=7.290, train_loss_epoch=7.180, valid_loss=0.00371]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.26it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.290, train_loss_epoch=7.290, valid_loss=0.00319]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.510, train_loss_epoch=6.510, valid_loss=0.00319]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.510, train_loss_epoch=6.510, valid_loss=0.00319]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.540, train_loss_epoch=6.540, valid_loss=0.00319]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.380, train_loss_epoch=6.380, valid_loss=0.00319]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.260, train_loss_epoch=6.260, valid_loss=0.00319]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.830, train_loss_epoch=5.830, valid_loss=0.00319]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.130, train_loss_epoch=6.130, valid_loss=0.00319]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780, valid_loss=0.00319]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=0.00319]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.990, train_loss_epoch=5.990, valid_loss=0.00319]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00319]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=0.00319]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.630, train_loss_epoch=5.630, valid_loss=0.00319]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.340, train_loss_epoch=5.340, valid_loss=0.00319]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.330, train_loss_epoch=5.330, valid_loss=0.00319]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.030, train_loss_epoch=5.030, valid_loss=0.00319]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.440, train_loss_epoch=5.440, valid_loss=0.00319]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.100, train_loss_epoch=5.100, valid_loss=0.00319]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.430, train_loss_epoch=5.430, valid_loss=0.00319]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.960, train_loss_epoch=4.960, valid_loss=0.00319]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.650, train_loss_epoch=5.650, valid_loss=0.00319]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.140, train_loss_epoch=5.140, valid_loss=0.00319]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:01<00:00,  0.91it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.140, valid_loss=0.00319]\n",
            "Epoch 222: 100%|██████████| 1/1 [00:01<00:00,  0.90it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.190, valid_loss=0.00319]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.190, valid_loss=0.00319]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.240, train_loss_epoch=5.240, valid_loss=0.00319]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00319]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.370, train_loss_epoch=5.370, valid_loss=0.00319]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00319]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.300, train_loss_epoch=5.300, valid_loss=0.00319]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.960, train_loss_epoch=4.960, valid_loss=0.00319]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.700, train_loss_epoch=5.700, valid_loss=0.00319]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.940, train_loss_epoch=4.940, valid_loss=0.00319]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.340, train_loss_epoch=5.340, valid_loss=0.00319]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350, valid_loss=0.00319]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.120, train_loss_epoch=5.120, valid_loss=0.00319]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.980, train_loss_epoch=4.980, valid_loss=0.00319]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.940, train_loss_epoch=4.940, valid_loss=0.00319]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=0.00319]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=0.00319]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.00319]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.950, train_loss_epoch=4.950, valid_loss=0.00319]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.590, train_loss_epoch=5.590, valid_loss=0.00319]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=0.00319]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750, valid_loss=0.00319]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.850, train_loss_epoch=5.850, valid_loss=0.00319]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.340, train_loss_epoch=5.340, valid_loss=0.00319]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.450, train_loss_epoch=5.450, valid_loss=0.00319]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00319]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090, valid_loss=0.00319]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.520, train_loss_epoch=5.520, valid_loss=0.00319]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.290, train_loss_epoch=5.290, valid_loss=0.00319]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00319]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00319]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.00319]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.830, train_loss_epoch=5.830, valid_loss=0.00319]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.430, train_loss_epoch=5.430, valid_loss=0.00319]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.500, train_loss_epoch=5.500, valid_loss=0.00319]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.420, train_loss_epoch=5.420, valid_loss=0.00319]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210, valid_loss=0.00319]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.220, train_loss_epoch=5.220, valid_loss=0.00319]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.490, valid_loss=0.00319]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.490, valid_loss=0.00319]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00319]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.00319]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.240, train_loss_epoch=5.240, valid_loss=0.00319]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=0.00319]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.290, train_loss_epoch=5.290, valid_loss=0.00319]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.170, train_loss_epoch=5.170, valid_loss=0.00319]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.590, train_loss_epoch=4.590, valid_loss=0.00319]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.500, train_loss_epoch=4.500, valid_loss=0.00319]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.600, train_loss_epoch=4.600, valid_loss=0.00319]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.370, train_loss_epoch=4.370, valid_loss=0.00319]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.250, train_loss_epoch=4.250, valid_loss=0.00319]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.150, train_loss_epoch=4.150, valid_loss=0.00319]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.150, train_loss_epoch=4.150, valid_loss=0.00319]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=0.00319]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00319]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.190, train_loss_epoch=4.190, valid_loss=0.00319]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00319]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=0.00319]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.000, train_loss_epoch=4.000, valid_loss=0.00319]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=0.00319]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=0.00319]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=0.00319]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00319]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=0.00319]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=0.00319]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=0.00319]\n",
            "Epoch 287: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.700, valid_loss=0.00319]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00319]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=0.00319]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.500, valid_loss=0.00319]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=0.00319]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00319]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00319]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470, valid_loss=0.00319]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00319]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=0.00319]\n",
            "Epoch 296: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00319]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00319]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00319]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00319]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.360, valid_loss=0.00319]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.24it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270, valid_loss=0.00245]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300, valid_loss=0.00245]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00245]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=0.00245]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=0.00245]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00245]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340, valid_loss=0.00245]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00245]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00245]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00245]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00245]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00245]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=0.00245]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00245]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00245]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00245]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00245]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00245]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00245]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00245]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00245]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00245]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00245]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00245]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00245]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00245]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00245]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00245]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00245]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00245]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00245]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00245]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.130, train_loss_epoch=3.130, valid_loss=0.00245]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00245]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00245]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00245]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00245]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00245]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00245]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.060, train_loss_epoch=3.060, valid_loss=0.00245]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00245]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00245]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00245]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00245]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00245]\n",
            "Epoch 344: 100%|██████████| 1/1 [00:01<00:00,  0.85it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=3.000, valid_loss=0.00245]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00245]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00245]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00245]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00245]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00245]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00245]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00245]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00245]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00245]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00245]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00245]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00245]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00245]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00245]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00245]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00245]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00245]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00245]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00245]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00245]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00245]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00245]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00245]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.00245]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00245]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00245]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00245]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00245]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00245]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00245]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00245]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00245]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00245]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00245]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00245]\n",
            "Epoch 379: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00245]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00245]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00245]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00245]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00245]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00245]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00245]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00245]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00245]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00245]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00245]\n",
            "Epoch 389: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00245]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00245]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00245]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00245]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00245]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00245]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00245]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00245]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00245]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00245]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00245]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.460, valid_loss=0.00245]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.63it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0024]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0024]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0024]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0024]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0024]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0024]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0024]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0024]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0024]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0024]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0024]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0024]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0024]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0024]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0024]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0024]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0024]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0024]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0024]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0024]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0024]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0024]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0024]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0024]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0024]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0024]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.0024]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0024]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0024]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0024]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0024]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0024]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0024]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0024]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0024]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0024]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0024]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0024]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0024]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0024]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0024]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0024]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0024]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.0024]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0024]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.0024]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0024]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0024]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0024]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0024]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0024]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0024]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0024]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0024]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0024]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.0024]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0024]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0024]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0024]        \n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0024]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0024]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0024]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0024]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0024]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0024]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0024]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.0024]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0024]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0024]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0024]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0024]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.0024]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0024]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0024]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0024]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0024]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.0024]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0024]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0024]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0024]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0024]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0024]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0024]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0024]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0024]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0024]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0024]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0024]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0024]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0024]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0024]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0024]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0024]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0024]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0024]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0024]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0024]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0024]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0024]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0024]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0024]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.720, valid_loss=0.0024]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.35it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00182]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00182]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00182]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00182]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00182]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00182]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00182]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00182]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00182]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00182]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00182]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00182]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00182]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00182]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00182]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00182]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00182]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00182]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00182]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00182]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00182]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00182]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00182]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00182]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00182]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00182]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00182]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00182]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00182]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00182]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00182]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00182]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00182]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00182]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00182]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00182]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00182]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00182]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00182]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00182]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00182]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00182]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.920, train_loss_epoch=1.920, valid_loss=0.00182]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00182]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00182]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00182]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00182]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00182]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00182]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.850, train_loss_epoch=1.850, valid_loss=0.00182]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00182]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.880, train_loss_epoch=1.880, valid_loss=0.00182]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00182]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00182]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00182]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00182]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00182]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00182]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00182]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00182]\n",
            "Epoch 559: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00182]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00182]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00182]\n",
            "Epoch 561: 100%|██████████| 1/1 [00:01<00:00,  0.77it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00182]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.760, train_loss_epoch=1.760, valid_loss=0.00182]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00182]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00182]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.770, train_loss_epoch=1.770, valid_loss=0.00182]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00182]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.790, train_loss_epoch=1.790, valid_loss=0.00182]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00182]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00182]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00182]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.750, train_loss_epoch=1.750, valid_loss=0.00182]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00182]\n",
            "Epoch 572: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00182]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00182]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00182]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00182]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00182]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00182]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.730, train_loss_epoch=1.730, valid_loss=0.00182]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00182]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00182]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00182]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00182]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00182]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00182]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00182]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00182]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00182]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00182]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00182]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00182]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00182]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00182]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00182]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00182]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00182]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00182]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00182]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00182]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00182]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.630, valid_loss=0.00182]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.68it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00175]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00175]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00175]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00175]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00175]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00175]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00175]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00175]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00175]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00175]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00175]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00175]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00175]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00175]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00175]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00175]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00175]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00175]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00175]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 650: 100%|██████████| 1/1 [00:00<00:00,  1.26it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00175]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00175]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00175]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00175]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00175]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00175]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00175]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.690, train_loss_epoch=1.690, valid_loss=0.00175]\n",
            "Epoch 669: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.690, valid_loss=0.00175]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00175]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.660, train_loss_epoch=1.660, valid_loss=0.00175]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00175]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00175]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00175]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.650, train_loss_epoch=1.650, valid_loss=0.00175]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00175]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00175]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00175]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00175]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00175]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00175]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00175]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00175]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00175]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00175]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00175]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00175]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00175]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00175]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00175]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00175]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.580, valid_loss=0.00175]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 114.05it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00164]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00164]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00164]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00164]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00164]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 711: 100%|██████████| 1/1 [00:01<00:00,  0.72it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00164]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00164]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00164]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00164]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00164]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00164]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00164]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00164]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00164]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00164]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 753: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00164]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00164]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 762: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00164]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00164]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00164]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00164]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00164]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00164]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00164]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00164]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00164]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00164]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00164]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00164]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00164]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00164]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00164]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00164]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00164]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=64732)\u001b[0m `Trainer.fit` stopped: `max_steps=800.0` reached.\n",
            "2025-06-15 21:50:42,518\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=64732)\u001b[0m \rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00164]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.540, valid_loss=0.00164]\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.11it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=64732)\u001b[0m \r                                                                       \u001b[A\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.540, valid_loss=0.00131]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00131]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00131]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=67858)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 2025-06-15 21:51:03.029640: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m E0000 00:00:1750024263.082217   67977 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m E0000 00:00:1750024263.101975   67977 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 2025-06-15 21:51:03.157991: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 3 | blocks       | ModuleList    | 4.3 M  | train\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 4.3 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 4.3 M     Total params\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 17.149    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \rSanity Checking: |          | 0/? [00:00<?, ?it/s]\rSanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]\rSanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\n",
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.70, train_loss_epoch=34.70]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.10, train_loss_epoch=36.10]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.60, train_loss_epoch=34.60]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.00, train_loss_epoch=36.00]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.00, train_loss_epoch=34.00]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.70, train_loss_epoch=37.70]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.10, train_loss_epoch=35.10]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.60, train_loss_epoch=34.60]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.50, train_loss_epoch=33.50]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.20, train_loss_epoch=34.20]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.20, train_loss_epoch=34.20]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.70, train_loss_epoch=34.70]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.20, train_loss_epoch=33.20]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.10, train_loss_epoch=35.10]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.10, train_loss_epoch=34.10]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.10, train_loss_epoch=35.10]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.30, train_loss_epoch=35.30]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.00, train_loss_epoch=33.00]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.30, train_loss_epoch=33.30]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.40, train_loss_epoch=32.40]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.00, train_loss_epoch=33.00]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.30, train_loss_epoch=33.30]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.40, train_loss_epoch=33.40]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.80, train_loss_epoch=33.80]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00]\n",
            "Epoch 33: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=32.00]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=31.50]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.70, train_loss_epoch=31.70]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.60, train_loss_epoch=31.60]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 44: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]\n",
            "Epoch 53: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.80, train_loss_epoch=26.80]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.00, train_loss_epoch=26.00]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.20, train_loss_epoch=27.20]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.40, train_loss_epoch=26.40]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.70, train_loss_epoch=26.70]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.90, train_loss_epoch=26.90]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.60, train_loss_epoch=26.60]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.70, train_loss_epoch=25.70]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.60, train_loss_epoch=25.60]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.70, train_loss_epoch=27.70]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.30, train_loss_epoch=26.30]\n",
            "Epoch 75: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=26.80, train_loss_epoch=26.30]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.80, train_loss_epoch=26.80]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.40, train_loss_epoch=26.40]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.20, train_loss_epoch=27.20]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.50, train_loss_epoch=26.50]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.60, train_loss_epoch=24.60]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.60, train_loss_epoch=25.60]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.00, train_loss_epoch=25.00]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.10, train_loss_epoch=26.10]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.20, train_loss_epoch=24.20]\n",
            "Epoch 84: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=0, train_loss_step=25.80, train_loss_epoch=25.80]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.80, train_loss_epoch=25.80]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.80, train_loss_epoch=23.80]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.00, train_loss_epoch=25.00]\n",
            "Epoch 87: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, v_num=0, train_loss_step=26.20, train_loss_epoch=26.20]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.20, train_loss_epoch=26.20]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.80, train_loss_epoch=24.80]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.20, train_loss_epoch=24.20]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.60, train_loss_epoch=23.60]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.60, train_loss_epoch=24.60]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.60, train_loss_epoch=23.60]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.20, train_loss_epoch=23.20]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.50, train_loss_epoch=24.50]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.50, train_loss_epoch=23.50]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.00, train_loss_epoch=24.00]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.40, train_loss_epoch=23.40]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.00, train_loss_epoch=23.00]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=23.00]\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 135.23it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70, valid_loss=0.0126]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.00, train_loss_epoch=23.00, valid_loss=0.0126]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.90, train_loss_epoch=23.90, valid_loss=0.0126]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.60, train_loss_epoch=22.60, valid_loss=0.0126]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10, valid_loss=0.0126]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.40, train_loss_epoch=23.40, valid_loss=0.0126]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=22.50, valid_loss=0.0126]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90, valid_loss=0.0126]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.10, train_loss_epoch=23.10, valid_loss=0.0126]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.20, train_loss_epoch=22.20, valid_loss=0.0126]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80, valid_loss=0.0126]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.80, train_loss_epoch=22.80, valid_loss=0.0126]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=22.50, valid_loss=0.0126]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=22.50, valid_loss=0.0126]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.60, train_loss_epoch=21.60, valid_loss=0.0126]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90, valid_loss=0.0126]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.90, train_loss_epoch=21.90, valid_loss=0.0126]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10, valid_loss=0.0126]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.20, train_loss_epoch=21.20, valid_loss=0.0126]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.60, train_loss_epoch=20.60, valid_loss=0.0126]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10, valid_loss=0.0126]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80, valid_loss=0.0126]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80, valid_loss=0.0126]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.00, train_loss_epoch=22.00, valid_loss=0.0126]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.60, train_loss_epoch=21.60, valid_loss=0.0126]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.40, train_loss_epoch=20.40, valid_loss=0.0126]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.00, train_loss_epoch=22.00, valid_loss=0.0126]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.40, train_loss_epoch=21.40, valid_loss=0.0126]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.10, train_loss_epoch=21.10, valid_loss=0.0126]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.50, train_loss_epoch=22.50, valid_loss=0.0126]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=21.70, valid_loss=0.0126]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.20, train_loss_epoch=22.20, valid_loss=0.0126]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80, valid_loss=0.0126]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10, valid_loss=0.0126]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.30, train_loss_epoch=21.30, valid_loss=0.0126]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.60, train_loss_epoch=21.60, valid_loss=0.0126]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.30, train_loss_epoch=21.30, valid_loss=0.0126]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.80, train_loss_epoch=20.80, valid_loss=0.0126]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.60, train_loss_epoch=21.60, valid_loss=0.0126]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.30, train_loss_epoch=21.30, valid_loss=0.0126]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50, valid_loss=0.0126]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50, valid_loss=0.0126]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90, valid_loss=0.0126]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.80, train_loss_epoch=20.80, valid_loss=0.0126]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.40, train_loss_epoch=20.40, valid_loss=0.0126]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.50, train_loss_epoch=21.50, valid_loss=0.0126]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.70, train_loss_epoch=21.70, valid_loss=0.0126]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.50, train_loss_epoch=20.50, valid_loss=0.0126]\n",
            "Epoch 146: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=0.0126]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=0.0126]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90, valid_loss=0.0126]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10, valid_loss=0.0126]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90, valid_loss=0.0126]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.10, train_loss_epoch=21.10, valid_loss=0.0126]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20, valid_loss=0.0126]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.80, train_loss_epoch=20.80, valid_loss=0.0126]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70, valid_loss=0.0126]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30, valid_loss=0.0126]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=0.0126]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10, valid_loss=0.0126]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70, valid_loss=0.0126]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40, valid_loss=0.0126]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=0.0126]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80, valid_loss=0.0126]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10, valid_loss=0.0126]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.90, train_loss_epoch=20.90, valid_loss=0.0126]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90, valid_loss=0.0126]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20, valid_loss=0.0126]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=0.0126]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.40, train_loss_epoch=20.40, valid_loss=0.0126]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20, valid_loss=0.0126]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.60, train_loss_epoch=19.60, valid_loss=0.0126]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90, valid_loss=0.0126]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30, valid_loss=0.0126]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10, valid_loss=0.0126]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.10, train_loss_epoch=20.10, valid_loss=0.0126]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60, valid_loss=0.0126]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=0.0126]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70, valid_loss=0.0126]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.80, train_loss_epoch=19.80, valid_loss=0.0126]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20, valid_loss=0.0126]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.50, train_loss_epoch=19.50, valid_loss=0.0126]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00, valid_loss=0.0126]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.0126]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40, valid_loss=0.0126]\n",
            "Epoch 182: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00, valid_loss=0.0126]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.00, train_loss_epoch=19.00, valid_loss=0.0126]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.60, train_loss_epoch=18.60, valid_loss=0.0126]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90, valid_loss=0.0126]\n",
            "Epoch 185: 100%|██████████| 1/1 [00:00<00:00,  2.04it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.0126]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.0126]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=0.0126]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=0.0126]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40, valid_loss=0.0126]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=0.0126]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10, valid_loss=0.0126]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40, valid_loss=0.0126]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90, valid_loss=0.0126]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=0.0126]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20, valid_loss=0.0126]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.90, train_loss_epoch=18.90, valid_loss=0.0126]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50, valid_loss=0.0126]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.10, train_loss_epoch=19.10, valid_loss=0.0126]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=0.0126]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.70, valid_loss=0.0126]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.80it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30, valid_loss=0.00484]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80, valid_loss=0.00484]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50, valid_loss=0.00484]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00, valid_loss=0.00484]\n",
            "Epoch 203: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.00, valid_loss=0.00484]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30, valid_loss=0.00484]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70, valid_loss=0.00484]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20, valid_loss=0.00484]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00, valid_loss=0.00484]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00484]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.80, train_loss_epoch=17.80, valid_loss=0.00484]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20, valid_loss=0.00484]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90, valid_loss=0.00484]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60, valid_loss=0.00484]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.10, train_loss_epoch=18.10, valid_loss=0.00484]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00484]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=0.00484]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.40, train_loss_epoch=18.40, valid_loss=0.00484]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90, valid_loss=0.00484]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.00, train_loss_epoch=18.00, valid_loss=0.00484]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00484]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.30, train_loss_epoch=17.30, valid_loss=0.00484]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00484]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00484]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.50, train_loss_epoch=17.50, valid_loss=0.00484]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00484]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40, valid_loss=0.00484]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.70, train_loss_epoch=17.70, valid_loss=0.00484]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=0.00484]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=0.00484]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40, valid_loss=0.00484]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.50, train_loss_epoch=16.50, valid_loss=0.00484]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30, valid_loss=0.00484]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00484]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80, valid_loss=0.00484]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=0.00484]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90, valid_loss=0.00484]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00484]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40, valid_loss=0.00484]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=0.00484]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10, valid_loss=0.00484]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20, valid_loss=0.00484]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00484]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70, valid_loss=0.00484]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.80, train_loss_epoch=16.80, valid_loss=0.00484]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00, valid_loss=0.00484]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=0.00484]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60, valid_loss=0.00484]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00484]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00484]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.10, train_loss_epoch=16.10, valid_loss=0.00484]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00484]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00484]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30, valid_loss=0.00484]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40, valid_loss=0.00484]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00484]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30, valid_loss=0.00484]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00484]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00484]\n",
            "Epoch 257: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.60, valid_loss=0.00484]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00484]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00484]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00484]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00484]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00, valid_loss=0.00484]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.90, train_loss_epoch=15.90, valid_loss=0.00484]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00484]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.70, train_loss_epoch=15.70, valid_loss=0.00484]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00484]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00484]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00484]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00484]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80, valid_loss=0.00484]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00484]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00484]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00484]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40, valid_loss=0.00484]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00484]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60, valid_loss=0.00484]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50, valid_loss=0.00484]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.20, train_loss_epoch=15.20, valid_loss=0.00484]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00484]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10, valid_loss=0.00484]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00484]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00484]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80, valid_loss=0.00484]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00, valid_loss=0.00484]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00484]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00484]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.90, train_loss_epoch=14.90, valid_loss=0.00484]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00484]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00484]\n",
            "Epoch 289: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00484]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00484]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00484]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00484]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00484]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00484]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00484]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00484]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00484]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00484]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00484]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00484]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 115.71it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00414]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00414]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00, valid_loss=0.00414]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30, valid_loss=0.00414]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00414]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70, valid_loss=0.00414]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20, valid_loss=0.00414]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00414]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00414]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10, valid_loss=0.00414]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00414]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00414]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00414]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40, valid_loss=0.00414]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00414]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00414]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00414]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60, valid_loss=0.00414]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00414]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00414]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00414]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00414]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00414]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.80, train_loss_epoch=13.80, valid_loss=0.00414]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00414]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00414]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70, valid_loss=0.00414]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.50, train_loss_epoch=14.50, valid_loss=0.00414]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90, valid_loss=0.00414]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00414]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00414]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00414]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00414]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00414]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00414]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00414]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.60, train_loss_epoch=13.60, valid_loss=0.00414]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00414]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00414]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00414]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00414]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00414]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00414]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00414]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00414]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00414]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00414]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20, valid_loss=0.00414]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00414]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00414]\n",
            "Epoch 359: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=12.60, valid_loss=0.00414]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.50, train_loss_epoch=13.50, valid_loss=0.00414]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00414]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00414]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.40, train_loss_epoch=13.40, valid_loss=0.00414]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60, valid_loss=0.00414]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00414]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00414]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00414]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00, valid_loss=0.00414]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00414]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.00414]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00414]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00414]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30, valid_loss=0.00414]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00414]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.00414]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.80, train_loss_epoch=12.80, valid_loss=0.00414]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.00414]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00414]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00414]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00414]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.00414]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.00414]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.00414]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40, valid_loss=0.00414]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70, valid_loss=0.00414]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.00414]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.00414]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.20, valid_loss=0.00414]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 136.90it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0043]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0043]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0043]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90, valid_loss=0.0043]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0043]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0043]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0043]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0043]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20, valid_loss=0.0043]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0043]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.0043]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0043]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.30, train_loss_epoch=12.30, valid_loss=0.0043]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0043]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0043]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.50, train_loss_epoch=12.50, valid_loss=0.0043]\n",
            "Epoch 416: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=12.50, valid_loss=0.0043]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.0043]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0043]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0043]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0043]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0043]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.0043]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.0043]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90, valid_loss=0.0043]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10, valid_loss=0.0043]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0043]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00, valid_loss=0.0043]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=0.0043]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0043]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.0043]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.0043]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80, valid_loss=0.0043]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 458: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.0043]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.0043]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 468: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=0.0043]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.0043]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50, valid_loss=0.0043]\n",
            "Epoch 474: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.0043]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.0043]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.0043]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=0.0043]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 478: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=0.0043]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0043]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.0043]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.0043]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40, valid_loss=0.0043]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.0043]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.0043]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70, valid_loss=0.0043]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.0043]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.0043]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60, valid_loss=0.0043]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.0043]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.0043]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.0043]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.0043]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.0043]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.09it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.00417]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30, valid_loss=0.00417]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.00417]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00417]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00417]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00417]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.00417]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.00417]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00417]        \n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00417]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.00417]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.20, train_loss_epoch=11.20, valid_loss=0.00417]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.00417]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.00417]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00417]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.00417]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00417]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.00, train_loss_epoch=11.00, valid_loss=0.00417]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00417]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00417]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10, valid_loss=0.00417]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00417]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00417]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00417]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00417]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00417]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00417]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00417]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00417]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00417]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00417]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00417]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00417]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00417]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00417]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00417]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00417]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.950, train_loss_epoch=9.950, valid_loss=0.00417]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.920, train_loss_epoch=9.920, valid_loss=0.00417]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.970, train_loss_epoch=9.970, valid_loss=0.00417]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.790, train_loss_epoch=9.790, valid_loss=0.00417]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00417]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60, valid_loss=0.00417]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00417]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.860, train_loss_epoch=9.860, valid_loss=0.00417]\n",
            "Epoch 582: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00417]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00417]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80, valid_loss=0.00417]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00417]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00417]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00417]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.860, train_loss_epoch=9.860, valid_loss=0.00417]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00417]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.540, train_loss_epoch=9.540, valid_loss=0.00417]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00417]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90, valid_loss=0.00417]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00417]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00417]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00417]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.740, train_loss_epoch=9.740, valid_loss=0.00417]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00417]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.890, train_loss_epoch=9.890, valid_loss=0.00417]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=9.890, valid_loss=0.00417]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 137.26it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.70, train_loss_epoch=10.70, valid_loss=0.00414]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.940, train_loss_epoch=9.940, valid_loss=0.00414]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.990, train_loss_epoch=9.990, valid_loss=0.00414]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.800, train_loss_epoch=9.800, valid_loss=0.00414]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.600, train_loss_epoch=9.600, valid_loss=0.00414]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.890, train_loss_epoch=9.890, valid_loss=0.00414]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50, valid_loss=0.00414]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40, valid_loss=0.00414]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.940, train_loss_epoch=9.940, valid_loss=0.00414]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.760, train_loss_epoch=9.760, valid_loss=0.00414]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00414]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.710, train_loss_epoch=9.710, valid_loss=0.00414]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00414]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00414]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.590, train_loss_epoch=9.590, valid_loss=0.00414]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.900, train_loss_epoch=9.900, valid_loss=0.00414]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00414]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00414]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00414]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.950, train_loss_epoch=9.950, valid_loss=0.00414]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.870, train_loss_epoch=9.870, valid_loss=0.00414]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.640, train_loss_epoch=9.640, valid_loss=0.00414]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.440, train_loss_epoch=9.440, valid_loss=0.00414]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00414]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.960, train_loss_epoch=9.960, valid_loss=0.00414]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00414]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00414]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.990, train_loss_epoch=9.990, valid_loss=0.00414]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00414]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.870, train_loss_epoch=9.870, valid_loss=0.00414]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.920, train_loss_epoch=9.920, valid_loss=0.00414]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.870, train_loss_epoch=9.870, valid_loss=0.00414]\n",
            "Epoch 631: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=9.660, train_loss_epoch=9.660, valid_loss=0.00414]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.660, train_loss_epoch=9.660, valid_loss=0.00414]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.720, train_loss_epoch=9.720, valid_loss=0.00414]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.960, train_loss_epoch=9.960, valid_loss=0.00414]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.790, train_loss_epoch=9.790, valid_loss=0.00414]\n",
            "Epoch 635: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00414]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00414]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.790, train_loss_epoch=9.790, valid_loss=0.00414]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.830, train_loss_epoch=9.830, valid_loss=0.00414]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.790, train_loss_epoch=9.790, valid_loss=0.00414]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.510, train_loss_epoch=9.510, valid_loss=0.00414]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.480, train_loss_epoch=9.480, valid_loss=0.00414]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.810, train_loss_epoch=9.810, valid_loss=0.00414]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10, valid_loss=0.00414]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.800, train_loss_epoch=9.800, valid_loss=0.00414]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00414]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.780, train_loss_epoch=9.780, valid_loss=0.00414]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.980, train_loss_epoch=9.980, valid_loss=0.00414]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.220, train_loss_epoch=9.220, valid_loss=0.00414]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.490, train_loss_epoch=9.490, valid_loss=0.00414]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.740, train_loss_epoch=9.740, valid_loss=0.00414]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.510, train_loss_epoch=9.510, valid_loss=0.00414]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.470, train_loss_epoch=9.470, valid_loss=0.00414]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.570, train_loss_epoch=9.570, valid_loss=0.00414]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.740, train_loss_epoch=9.740, valid_loss=0.00414]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.630, train_loss_epoch=9.630, valid_loss=0.00414]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.890, train_loss_epoch=9.890, valid_loss=0.00414]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.870, train_loss_epoch=9.870, valid_loss=0.00414]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.510, train_loss_epoch=9.510, valid_loss=0.00414]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00, valid_loss=0.00414]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.860, train_loss_epoch=9.860, valid_loss=0.00414]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.760, train_loss_epoch=9.760, valid_loss=0.00414]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.280, train_loss_epoch=9.280, valid_loss=0.00414]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.710, train_loss_epoch=9.710, valid_loss=0.00414]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.600, train_loss_epoch=9.600, valid_loss=0.00414]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.920, train_loss_epoch=9.920, valid_loss=0.00414]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.850, train_loss_epoch=9.850, valid_loss=0.00414]\n",
            "Epoch 666: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s, v_num=0, train_loss_step=9.670, train_loss_epoch=9.670, valid_loss=0.00414]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.670, train_loss_epoch=9.670, valid_loss=0.00414]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.630, train_loss_epoch=9.630, valid_loss=0.00414]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.600, train_loss_epoch=9.600, valid_loss=0.00414]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.400, train_loss_epoch=9.400, valid_loss=0.00414]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30, valid_loss=0.00414]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.660, train_loss_epoch=9.660, valid_loss=0.00414]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20, valid_loss=0.00414]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.520, train_loss_epoch=9.520, valid_loss=0.00414]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.270, valid_loss=0.00414]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.600, train_loss_epoch=9.600, valid_loss=0.00414]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.110, train_loss_epoch=9.110, valid_loss=0.00414]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.730, train_loss_epoch=9.730, valid_loss=0.00414]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.720, train_loss_epoch=9.720, valid_loss=0.00414]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.740, train_loss_epoch=9.740, valid_loss=0.00414]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.300, train_loss_epoch=9.300, valid_loss=0.00414]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.900, train_loss_epoch=9.900, valid_loss=0.00414]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.700, train_loss_epoch=9.700, valid_loss=0.00414]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.430, train_loss_epoch=9.430, valid_loss=0.00414]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.190, train_loss_epoch=9.190, valid_loss=0.00414]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.510, train_loss_epoch=9.510, valid_loss=0.00414]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.270, valid_loss=0.00414]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.310, train_loss_epoch=9.310, valid_loss=0.00414]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.490, train_loss_epoch=9.490, valid_loss=0.00414]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.330, train_loss_epoch=9.330, valid_loss=0.00414]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.590, train_loss_epoch=9.590, valid_loss=0.00414]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.780, train_loss_epoch=9.780, valid_loss=0.00414]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.190, train_loss_epoch=9.190, valid_loss=0.00414]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.350, train_loss_epoch=9.350, valid_loss=0.00414]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.160, train_loss_epoch=9.160, valid_loss=0.00414]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.420, train_loss_epoch=9.420, valid_loss=0.00414]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.380, train_loss_epoch=9.380, valid_loss=0.00414]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.660, train_loss_epoch=9.660, valid_loss=0.00414]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=9.150, valid_loss=0.00414]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=0, train_loss_step=9.510, train_loss_epoch=9.150, valid_loss=0.00414]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.17it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.510, train_loss_epoch=9.510, valid_loss=0.00409]\n",
            "Epoch 700: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s, v_num=0, train_loss_step=9.600, train_loss_epoch=9.600, valid_loss=0.00409]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.600, train_loss_epoch=9.600, valid_loss=0.00409]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.500, train_loss_epoch=9.500, valid_loss=0.00409]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.570, train_loss_epoch=9.570, valid_loss=0.00409]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.240, train_loss_epoch=9.240, valid_loss=0.00409]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.500, train_loss_epoch=9.500, valid_loss=0.00409]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.800, train_loss_epoch=9.800, valid_loss=0.00409]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.510, train_loss_epoch=9.510, valid_loss=0.00409]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.290, train_loss_epoch=9.290, valid_loss=0.00409]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.320, train_loss_epoch=9.320, valid_loss=0.00409]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.450, train_loss_epoch=9.450, valid_loss=0.00409]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.860, train_loss_epoch=8.860, valid_loss=0.00409]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.910, train_loss_epoch=9.910, valid_loss=0.00409]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.260, train_loss_epoch=9.260, valid_loss=0.00409]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.220, train_loss_epoch=9.220, valid_loss=0.00409]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.550, train_loss_epoch=9.550, valid_loss=0.00409]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.460, train_loss_epoch=9.460, valid_loss=0.00409]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.080, train_loss_epoch=9.080, valid_loss=0.00409]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s, v_num=0, train_loss_step=8.700, train_loss_epoch=9.080, valid_loss=0.00409]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.700, train_loss_epoch=8.700, valid_loss=0.00409]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.570, train_loss_epoch=9.570, valid_loss=0.00409]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.020, train_loss_epoch=9.020, valid_loss=0.00409]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.110, train_loss_epoch=9.110, valid_loss=0.00409]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.340, train_loss_epoch=9.340, valid_loss=0.00409]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.130, train_loss_epoch=9.130, valid_loss=0.00409]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.220, train_loss_epoch=9.220, valid_loss=0.00409]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.640, train_loss_epoch=8.640, valid_loss=0.00409]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.480, train_loss_epoch=9.480, valid_loss=0.00409]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.000, train_loss_epoch=9.000, valid_loss=0.00409]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.420, train_loss_epoch=9.420, valid_loss=0.00409]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950, valid_loss=0.00409]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=8.910, valid_loss=0.00409]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.120, train_loss_epoch=9.120, valid_loss=0.00409]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.280, train_loss_epoch=9.280, valid_loss=0.00409]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.890, train_loss_epoch=8.890, valid_loss=0.00409]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.460, train_loss_epoch=8.460, valid_loss=0.00409]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.830, train_loss_epoch=8.830, valid_loss=0.00409]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.960, train_loss_epoch=8.960, valid_loss=0.00409]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.690, train_loss_epoch=9.690, valid_loss=0.00409]\n",
            "Epoch 737: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=9.240, train_loss_epoch=9.240, valid_loss=0.00409]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.240, train_loss_epoch=9.240, valid_loss=0.00409]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.850, train_loss_epoch=8.850, valid_loss=0.00409]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.120, train_loss_epoch=9.120, valid_loss=0.00409]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.010, train_loss_epoch=9.010, valid_loss=0.00409]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.270, valid_loss=0.00409]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.200, train_loss_epoch=9.200, valid_loss=0.00409]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.470, train_loss_epoch=9.470, valid_loss=0.00409]\n",
            "Epoch 744: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=9.470, valid_loss=0.00409]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=8.910, valid_loss=0.00409]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.000, train_loss_epoch=9.000, valid_loss=0.00409]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.310, train_loss_epoch=9.310, valid_loss=0.00409]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=9.150, valid_loss=0.00409]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.220, train_loss_epoch=9.220, valid_loss=0.00409]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.130, train_loss_epoch=9.130, valid_loss=0.00409]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.080, train_loss_epoch=9.080, valid_loss=0.00409]\n",
            "Epoch 751: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s, v_num=0, train_loss_step=9.110, train_loss_epoch=9.110, valid_loss=0.00409]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.110, train_loss_epoch=9.110, valid_loss=0.00409]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.810, train_loss_epoch=8.810, valid_loss=0.00409]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.310, train_loss_epoch=9.310, valid_loss=0.00409]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.730, train_loss_epoch=8.730, valid_loss=0.00409]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.110, train_loss_epoch=9.110, valid_loss=0.00409]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.940, train_loss_epoch=8.940, valid_loss=0.00409]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.740, train_loss_epoch=8.740, valid_loss=0.00409]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.060, train_loss_epoch=9.060, valid_loss=0.00409]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=8.910, valid_loss=0.00409]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.930, train_loss_epoch=8.930, valid_loss=0.00409]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.080, train_loss_epoch=9.080, valid_loss=0.00409]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.130, train_loss_epoch=9.130, valid_loss=0.00409]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.040, train_loss_epoch=9.040, valid_loss=0.00409]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.850, train_loss_epoch=8.850, valid_loss=0.00409]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.030, train_loss_epoch=9.030, valid_loss=0.00409]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.120, train_loss_epoch=9.120, valid_loss=0.00409]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.590, train_loss_epoch=8.590, valid_loss=0.00409]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.960, train_loss_epoch=8.960, valid_loss=0.00409]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.880, train_loss_epoch=8.880, valid_loss=0.00409]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.810, train_loss_epoch=8.810, valid_loss=0.00409]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.340, train_loss_epoch=9.340, valid_loss=0.00409]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.790, train_loss_epoch=8.790, valid_loss=0.00409]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.600, train_loss_epoch=8.600, valid_loss=0.00409]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.800, train_loss_epoch=8.800, valid_loss=0.00409]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.850, train_loss_epoch=8.850, valid_loss=0.00409]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.490, train_loss_epoch=8.490, valid_loss=0.00409]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950, valid_loss=0.00409]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.980, train_loss_epoch=8.980, valid_loss=0.00409]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.920, train_loss_epoch=8.920, valid_loss=0.00409]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.980, train_loss_epoch=8.980, valid_loss=0.00409]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.750, train_loss_epoch=8.750, valid_loss=0.00409]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.470, train_loss_epoch=8.470, valid_loss=0.00409]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.650, train_loss_epoch=8.650, valid_loss=0.00409]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.920, train_loss_epoch=8.920, valid_loss=0.00409]\n",
            "Epoch 785: 100%|██████████| 1/1 [00:01<00:00,  0.99it/s, v_num=0, train_loss_step=9.070, train_loss_epoch=8.920, valid_loss=0.00409]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.070, train_loss_epoch=9.070, valid_loss=0.00409]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.100, train_loss_epoch=9.100, valid_loss=0.00409]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.930, train_loss_epoch=8.930, valid_loss=0.00409]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.260, train_loss_epoch=9.260, valid_loss=0.00409]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.230, train_loss_epoch=9.230, valid_loss=0.00409]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.750, train_loss_epoch=8.750, valid_loss=0.00409]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.660, train_loss_epoch=8.660, valid_loss=0.00409]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.270, valid_loss=0.00409]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=8.910, valid_loss=0.00409]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.650, train_loss_epoch=8.650, valid_loss=0.00409]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.980, train_loss_epoch=8.980, valid_loss=0.00409]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.710, train_loss_epoch=8.710, valid_loss=0.00409]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.500, train_loss_epoch=8.500, valid_loss=0.00409]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.900, train_loss_epoch=8.900, valid_loss=0.00409]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=8.970, train_loss_epoch=8.900, valid_loss=0.00409]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.29it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.970, train_loss_epoch=8.970, valid_loss=0.00398]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.820, train_loss_epoch=8.820, valid_loss=0.00398]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.590, train_loss_epoch=8.590, valid_loss=0.00398]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.830, train_loss_epoch=8.830, valid_loss=0.00398]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.990, train_loss_epoch=8.990, valid_loss=0.00398]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540, valid_loss=0.00398]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.610, train_loss_epoch=8.610, valid_loss=0.00398]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.770, valid_loss=0.00398]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.470, train_loss_epoch=8.470, valid_loss=0.00398]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.810, train_loss_epoch=8.810, valid_loss=0.00398]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.00398]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.910, train_loss_epoch=8.910, valid_loss=0.00398]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.550, train_loss_epoch=8.550, valid_loss=0.00398]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.820, train_loss_epoch=8.820, valid_loss=0.00398]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.730, train_loss_epoch=8.730, valid_loss=0.00398]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.750, train_loss_epoch=8.750, valid_loss=0.00398]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.440, train_loss_epoch=8.440, valid_loss=0.00398]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.260, train_loss_epoch=8.260, valid_loss=0.00398]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.310, train_loss_epoch=8.310, valid_loss=0.00398]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.450, train_loss_epoch=8.450, valid_loss=0.00398]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.740, train_loss_epoch=8.740, valid_loss=0.00398]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.340, train_loss_epoch=8.340, valid_loss=0.00398]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.670, train_loss_epoch=8.670, valid_loss=0.00398]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.640, train_loss_epoch=8.640, valid_loss=0.00398]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.780, train_loss_epoch=8.780, valid_loss=0.00398]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.480, train_loss_epoch=8.480, valid_loss=0.00398]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.370, train_loss_epoch=8.370, valid_loss=0.00398]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.730, train_loss_epoch=8.730, valid_loss=0.00398]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.820, train_loss_epoch=8.820, valid_loss=0.00398]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.970, train_loss_epoch=7.970, valid_loss=0.00398]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.630, train_loss_epoch=8.630, valid_loss=0.00398]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.930, train_loss_epoch=8.930, valid_loss=0.00398]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.730, train_loss_epoch=8.730, valid_loss=0.00398]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.470, train_loss_epoch=8.470, valid_loss=0.00398]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.660, train_loss_epoch=8.660, valid_loss=0.00398]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.050, train_loss_epoch=8.050, valid_loss=0.00398]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.770, train_loss_epoch=8.770, valid_loss=0.00398]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.760, train_loss_epoch=8.760, valid_loss=0.00398]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.220, train_loss_epoch=8.220, valid_loss=0.00398]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.470, train_loss_epoch=8.470, valid_loss=0.00398]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.360, train_loss_epoch=8.360, valid_loss=0.00398]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350, valid_loss=0.00398]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.400, train_loss_epoch=8.400, valid_loss=0.00398]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.00398]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.490, train_loss_epoch=8.490, valid_loss=0.00398]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.240, train_loss_epoch=8.240, valid_loss=0.00398]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.850, train_loss_epoch=8.850, valid_loss=0.00398]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.410, train_loss_epoch=8.410, valid_loss=0.00398]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.550, train_loss_epoch=8.550, valid_loss=0.00398]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.450, train_loss_epoch=8.450, valid_loss=0.00398]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.700, train_loss_epoch=8.700, valid_loss=0.00398]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.340, train_loss_epoch=8.340, valid_loss=0.00398]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.260, train_loss_epoch=8.260, valid_loss=0.00398]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.590, train_loss_epoch=8.590, valid_loss=0.00398]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.480, train_loss_epoch=8.480, valid_loss=0.00398]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.710, train_loss_epoch=8.710, valid_loss=0.00398]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.570, train_loss_epoch=8.570, valid_loss=0.00398]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.630, train_loss_epoch=8.630, valid_loss=0.00398]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00398]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.470, train_loss_epoch=8.470, valid_loss=0.00398]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.300, train_loss_epoch=8.300, valid_loss=0.00398]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.850, train_loss_epoch=8.850, valid_loss=0.00398]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00398]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540, valid_loss=0.00398]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350, valid_loss=0.00398]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00398]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.00398]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00398]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.320, train_loss_epoch=8.320, valid_loss=0.00398]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.360, train_loss_epoch=8.360, valid_loss=0.00398]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.300, train_loss_epoch=8.300, valid_loss=0.00398]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.370, train_loss_epoch=8.370, valid_loss=0.00398]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.220, train_loss_epoch=8.220, valid_loss=0.00398]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.430, train_loss_epoch=8.430, valid_loss=0.00398]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00398]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.410, train_loss_epoch=8.410, valid_loss=0.00398]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.480, train_loss_epoch=8.480, valid_loss=0.00398]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.320, train_loss_epoch=8.320, valid_loss=0.00398]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.390, train_loss_epoch=8.390, valid_loss=0.00398]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.020, train_loss_epoch=8.020, valid_loss=0.00398]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.290, train_loss_epoch=8.290, valid_loss=0.00398]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.390, train_loss_epoch=8.390, valid_loss=0.00398]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00398]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00398]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.340, train_loss_epoch=8.340, valid_loss=0.00398]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.640, train_loss_epoch=8.640, valid_loss=0.00398]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.550, train_loss_epoch=8.550, valid_loss=0.00398]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.060, train_loss_epoch=8.060, valid_loss=0.00398]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00398]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00398]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.240, train_loss_epoch=8.240, valid_loss=0.00398]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.00398]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.310, train_loss_epoch=8.310, valid_loss=0.00398]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.250, train_loss_epoch=8.250, valid_loss=0.00398]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.00398]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.210, train_loss_epoch=8.210, valid_loss=0.00398]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00398]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.400, train_loss_epoch=8.400, valid_loss=0.00398]\n",
            "Epoch 897: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s, v_num=0, train_loss_step=8.200, train_loss_epoch=8.200, valid_loss=0.00398]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.200, train_loss_epoch=8.200, valid_loss=0.00398]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.210, train_loss_epoch=8.210, valid_loss=0.00398]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.210, valid_loss=0.00398]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 99.28it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00394]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.00394]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.540, train_loss_epoch=8.540, valid_loss=0.00394]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.460, train_loss_epoch=8.460, valid_loss=0.00394]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.040, train_loss_epoch=8.040, valid_loss=0.00394]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350, valid_loss=0.00394]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.560, train_loss_epoch=8.560, valid_loss=0.00394]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.710, train_loss_epoch=7.710, valid_loss=0.00394]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00394]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.450, train_loss_epoch=8.450, valid_loss=0.00394]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.270, train_loss_epoch=8.270, valid_loss=0.00394]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.260, train_loss_epoch=8.260, valid_loss=0.00394]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350, valid_loss=0.00394]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.050, train_loss_epoch=8.050, valid_loss=0.00394]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.630, train_loss_epoch=8.630, valid_loss=0.00394]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.570, train_loss_epoch=8.570, valid_loss=0.00394]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.00394]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.020, train_loss_epoch=8.020, valid_loss=0.00394]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.00394]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.490, train_loss_epoch=8.490, valid_loss=0.00394]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.00394]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.970, train_loss_epoch=7.970, valid_loss=0.00394]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00394]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.420, train_loss_epoch=8.420, valid_loss=0.00394]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.410, train_loss_epoch=8.410, valid_loss=0.00394]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=0.00394]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.920, train_loss_epoch=7.920, valid_loss=0.00394]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.320, train_loss_epoch=8.320, valid_loss=0.00394]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.050, train_loss_epoch=8.050, valid_loss=0.00394]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00394]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.120, train_loss_epoch=8.120, valid_loss=0.00394]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.660, train_loss_epoch=8.660, valid_loss=0.00394]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.160, train_loss_epoch=8.160, valid_loss=0.00394]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.320, train_loss_epoch=8.320, valid_loss=0.00394]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.00394]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.00394]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00394]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.210, train_loss_epoch=8.210, valid_loss=0.00394]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.00394]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.00394]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.520, train_loss_epoch=8.520, valid_loss=0.00394]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.00394]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.370, train_loss_epoch=8.370, valid_loss=0.00394]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.790, train_loss_epoch=7.790, valid_loss=0.00394]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.300, train_loss_epoch=8.300, valid_loss=0.00394]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.240, train_loss_epoch=8.240, valid_loss=0.00394]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.290, train_loss_epoch=8.290, valid_loss=0.00394]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00394]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00394]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00394]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.00394]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.320, train_loss_epoch=8.320, valid_loss=0.00394]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=0.00394]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.00394]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.200, train_loss_epoch=8.200, valid_loss=0.00394]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.210, train_loss_epoch=8.210, valid_loss=0.00394]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.00394]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.410, train_loss_epoch=8.410, valid_loss=0.00394]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.270, train_loss_epoch=8.270, valid_loss=0.00394]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.040, train_loss_epoch=8.040, valid_loss=0.00394]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.050, train_loss_epoch=8.050, valid_loss=0.00394]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.250, train_loss_epoch=8.250, valid_loss=0.00394]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.200, train_loss_epoch=8.200, valid_loss=0.00394]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.170, train_loss_epoch=8.170, valid_loss=0.00394]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.130, train_loss_epoch=8.130, valid_loss=0.00394]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.220, train_loss_epoch=8.220, valid_loss=0.00394]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.890, train_loss_epoch=7.890, valid_loss=0.00394]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=0.00394]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00394]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.140, train_loss_epoch=8.140, valid_loss=0.00394]\n",
            "Epoch 969: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s, v_num=0, train_loss_step=8.400, train_loss_epoch=8.400, valid_loss=0.00394]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.400, train_loss_epoch=8.400, valid_loss=0.00394]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00394]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.100, train_loss_epoch=8.100, valid_loss=0.00394]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.990, train_loss_epoch=7.990, valid_loss=0.00394]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00394]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=0.00394]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.290, train_loss_epoch=8.290, valid_loss=0.00394]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.020, train_loss_epoch=8.020, valid_loss=0.00394]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.050, train_loss_epoch=8.050, valid_loss=0.00394]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.100, train_loss_epoch=8.100, valid_loss=0.00394]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930, valid_loss=0.00394]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.00394]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.280, train_loss_epoch=8.280, valid_loss=0.00394]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.00394]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.300, train_loss_epoch=8.300, valid_loss=0.00394]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.310, train_loss_epoch=8.310, valid_loss=0.00394]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00394]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.110, train_loss_epoch=8.110, valid_loss=0.00394]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.00394]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=7.880, valid_loss=0.00394]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.220, train_loss_epoch=8.220, valid_loss=0.00394]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.00394]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.680, train_loss_epoch=7.680, valid_loss=0.00394]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.940, train_loss_epoch=7.940, valid_loss=0.00394]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.890, train_loss_epoch=7.890, valid_loss=0.00394]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.120, train_loss_epoch=8.120, valid_loss=0.00394]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.150, train_loss_epoch=8.150, valid_loss=0.00394]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.650, train_loss_epoch=7.650, valid_loss=0.00394]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.00394]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.00394]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=8.090, valid_loss=0.00394]\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.27it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=7.880, valid_loss=0.00399]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.060, train_loss_epoch=8.060, valid_loss=0.00399]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=0.00399]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.170, train_loss_epoch=8.170, valid_loss=0.00399]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=0.00399]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.00399]\n",
            "Epoch 1005: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.00399]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.250, train_loss_epoch=8.250, valid_loss=0.00399]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.380, train_loss_epoch=8.380, valid_loss=0.00399]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00399]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.910, train_loss_epoch=7.910, valid_loss=0.00399]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.00399]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.020, train_loss_epoch=8.020, valid_loss=0.00399]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.270, train_loss_epoch=8.270, valid_loss=0.00399]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930, valid_loss=0.00399]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.130, train_loss_epoch=8.130, valid_loss=0.00399]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.010, train_loss_epoch=8.010, valid_loss=0.00399]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.170, train_loss_epoch=8.170, valid_loss=0.00399]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.890, train_loss_epoch=7.890, valid_loss=0.00399]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.860, train_loss_epoch=7.860, valid_loss=0.00399]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.290, train_loss_epoch=8.290, valid_loss=0.00399]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.00399]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00399]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.00399]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.160, train_loss_epoch=8.160, valid_loss=0.00399]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.00399]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.00399]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.00399]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.810, train_loss_epoch=7.810, valid_loss=0.00399]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00399]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.210, train_loss_epoch=8.210, valid_loss=0.00399]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.960, train_loss_epoch=7.960, valid_loss=0.00399]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00399]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.010, train_loss_epoch=8.010, valid_loss=0.00399]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.960, train_loss_epoch=7.960, valid_loss=0.00399]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.970, train_loss_epoch=7.970, valid_loss=0.00399]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.890, train_loss_epoch=7.890, valid_loss=0.00399]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.150, train_loss_epoch=8.150, valid_loss=0.00399]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=0.00399]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00399]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.810, train_loss_epoch=7.810, valid_loss=0.00399]\n",
            "Epoch 1040:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.040, train_loss_epoch=8.040, valid_loss=0.00399]\n",
            "Epoch 1041:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.00399]\n",
            "Epoch 1042:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.710, train_loss_epoch=7.710, valid_loss=0.00399]\n",
            "Epoch 1043:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.00399]\n",
            "Epoch 1044:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.820, train_loss_epoch=7.820, valid_loss=0.00399]\n",
            "Epoch 1045:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.060, train_loss_epoch=8.060, valid_loss=0.00399]\n",
            "Epoch 1046:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.920, train_loss_epoch=7.920, valid_loss=0.00399]\n",
            "Epoch 1047:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.00399]\n",
            "Epoch 1048:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.160, train_loss_epoch=8.160, valid_loss=0.00399]\n",
            "Epoch 1049:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.00399]\n",
            "Epoch 1050:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.830, train_loss_epoch=7.830, valid_loss=0.00399]\n",
            "Epoch 1051:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.150, train_loss_epoch=8.150, valid_loss=0.00399]\n",
            "Epoch 1052:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00399]\n",
            "Epoch 1053:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=0.00399]\n",
            "Epoch 1054:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.00399]\n",
            "Epoch 1055:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.010, train_loss_epoch=8.010, valid_loss=0.00399]\n",
            "Epoch 1056:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.160, train_loss_epoch=8.160, valid_loss=0.00399]\n",
            "Epoch 1057:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.00399]\n",
            "Epoch 1058:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.150, train_loss_epoch=8.150, valid_loss=0.00399]\n",
            "Epoch 1059:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00399]\n",
            "Epoch 1060:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=7.880, valid_loss=0.00399]\n",
            "Epoch 1061:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00399]\n",
            "Epoch 1062:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.970, train_loss_epoch=7.970, valid_loss=0.00399]\n",
            "Epoch 1063:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.00399]\n",
            "Epoch 1063: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00399]\n",
            "Epoch 1064:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00399]\n",
            "Epoch 1065:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.910, train_loss_epoch=7.910, valid_loss=0.00399]\n",
            "Epoch 1066:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.710, train_loss_epoch=7.710, valid_loss=0.00399]\n",
            "Epoch 1067:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00399]\n",
            "Epoch 1068:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.350, train_loss_epoch=7.350, valid_loss=0.00399]\n",
            "Epoch 1069:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.990, train_loss_epoch=7.990, valid_loss=0.00399]\n",
            "Epoch 1070:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.00399]\n",
            "Epoch 1070: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s, v_num=0, train_loss_step=7.970, train_loss_epoch=7.740, valid_loss=0.00399]\n",
            "Epoch 1071:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.970, train_loss_epoch=7.970, valid_loss=0.00399]\n",
            "Epoch 1072:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.860, train_loss_epoch=7.860, valid_loss=0.00399]\n",
            "Epoch 1073:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.00399]\n",
            "Epoch 1074:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.860, train_loss_epoch=7.860, valid_loss=0.00399]\n",
            "Epoch 1075:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.00399]\n",
            "Epoch 1076:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.230, train_loss_epoch=8.230, valid_loss=0.00399]\n",
            "Epoch 1077:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00399]\n",
            "Epoch 1078:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=0.00399]\n",
            "Epoch 1079:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.060, train_loss_epoch=8.060, valid_loss=0.00399]\n",
            "Epoch 1080:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.770, train_loss_epoch=7.770, valid_loss=0.00399]\n",
            "Epoch 1081:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.110, train_loss_epoch=8.110, valid_loss=0.00399]\n",
            "Epoch 1082:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930, valid_loss=0.00399]\n",
            "Epoch 1083:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=7.880, valid_loss=0.00399]\n",
            "Epoch 1084:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.00399]\n",
            "Epoch 1085:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.00399]\n",
            "Epoch 1086:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.060, train_loss_epoch=8.060, valid_loss=0.00399]\n",
            "Epoch 1087:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.130, train_loss_epoch=8.130, valid_loss=0.00399]\n",
            "Epoch 1088:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.100, train_loss_epoch=8.100, valid_loss=0.00399]\n",
            "Epoch 1089:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00399]\n",
            "Epoch 1090:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.770, train_loss_epoch=7.770, valid_loss=0.00399]\n",
            "Epoch 1091:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=7.880, valid_loss=0.00399]\n",
            "Epoch 1092:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.070, train_loss_epoch=8.070, valid_loss=0.00399]\n",
            "Epoch 1093:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.550, train_loss_epoch=7.550, valid_loss=0.00399]\n",
            "Epoch 1094:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.00399]\n",
            "Epoch 1095:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00399]\n",
            "Epoch 1096:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.00399]\n",
            "Epoch 1097:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.00399]\n",
            "Epoch 1098:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00399]\n",
            "Epoch 1098: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.00399]\n",
            "Epoch 1099:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.00399]\n",
            "Epoch 1099: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.410, valid_loss=0.00399]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.22it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \n",
            "Epoch 1100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.980, train_loss_epoch=7.980, valid_loss=0.004]\n",
            "Epoch 1101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.004]\n",
            "Epoch 1102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.940, train_loss_epoch=7.940, valid_loss=0.004]\n",
            "Epoch 1103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=0.004]\n",
            "Epoch 1104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.004]\n",
            "Epoch 1105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.004]\n",
            "Epoch 1106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.940, train_loss_epoch=7.940, valid_loss=0.004]\n",
            "Epoch 1107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.960, train_loss_epoch=7.960, valid_loss=0.004]\n",
            "Epoch 1108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.004]\n",
            "Epoch 1109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.550, train_loss_epoch=7.550, valid_loss=0.004]\n",
            "Epoch 1110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.060, train_loss_epoch=8.060, valid_loss=0.004]\n",
            "Epoch 1111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.810, train_loss_epoch=7.810, valid_loss=0.004]\n",
            "Epoch 1112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=0.004]\n",
            "Epoch 1113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.004]\n",
            "Epoch 1114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.004]\n",
            "Epoch 1115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.220, train_loss_epoch=8.220, valid_loss=0.004]\n",
            "Epoch 1116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.810, train_loss_epoch=7.810, valid_loss=0.004]\n",
            "Epoch 1117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.100, train_loss_epoch=8.100, valid_loss=0.004]\n",
            "Epoch 1118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.430, train_loss_epoch=7.430, valid_loss=0.004]\n",
            "Epoch 1119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.004]\n",
            "Epoch 1120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.004]\n",
            "Epoch 1121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.004]\n",
            "Epoch 1122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.004]\n",
            "Epoch 1123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.080, train_loss_epoch=8.080, valid_loss=0.004]\n",
            "Epoch 1123: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.004]\n",
            "Epoch 1124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.004]\n",
            "Epoch 1125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.820, train_loss_epoch=7.820, valid_loss=0.004]\n",
            "Epoch 1126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.920, train_loss_epoch=7.920, valid_loss=0.004]\n",
            "Epoch 1127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.004]\n",
            "Epoch 1128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.930, train_loss_epoch=7.930, valid_loss=0.004]\n",
            "Epoch 1129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.700, train_loss_epoch=7.700, valid_loss=0.004]\n",
            "Epoch 1130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.090, train_loss_epoch=8.090, valid_loss=0.004]\n",
            "Epoch 1131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.680, train_loss_epoch=7.680, valid_loss=0.004]\n",
            "Epoch 1132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.920, train_loss_epoch=7.920, valid_loss=0.004]\n",
            "Epoch 1133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.910, train_loss_epoch=7.910, valid_loss=0.004]\n",
            "Epoch 1134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.004]\n",
            "Epoch 1135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.004]\n",
            "Epoch 1136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.004]\n",
            "Epoch 1136: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.580, valid_loss=0.004]\n",
            "Epoch 1136: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.004]\n",
            "Epoch 1137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.004]\n",
            "Epoch 1138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.004]\n",
            "Epoch 1139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=0.004]\n",
            "Epoch 1140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.870, train_loss_epoch=7.870, valid_loss=0.004]\n",
            "Epoch 1141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.120, train_loss_epoch=8.120, valid_loss=0.004]\n",
            "Epoch 1142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.880, train_loss_epoch=7.880, valid_loss=0.004]\n",
            "Epoch 1143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=0.004]\n",
            "Epoch 1144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.004]\n",
            "Epoch 1145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.004]\n",
            "Epoch 1146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.790, train_loss_epoch=7.790, valid_loss=0.004]\n",
            "Epoch 1147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.004]\n",
            "Epoch 1148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.540, train_loss_epoch=7.540, valid_loss=0.004]\n",
            "Epoch 1149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.004]\n",
            "Epoch 1150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=7.310, valid_loss=0.004]\n",
            "Epoch 1151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.004]\n",
            "Epoch 1152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.970, train_loss_epoch=7.970, valid_loss=0.004]\n",
            "Epoch 1153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.004]\n",
            "Epoch 1154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.790, train_loss_epoch=7.790, valid_loss=0.004]\n",
            "Epoch 1155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.004]\n",
            "Epoch 1156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.004]\n",
            "Epoch 1157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.500, train_loss_epoch=7.500, valid_loss=0.004]\n",
            "Epoch 1158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.860, train_loss_epoch=7.860, valid_loss=0.004]\n",
            "Epoch 1159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.004]\n",
            "Epoch 1160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.004]\n",
            "Epoch 1161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.004]\n",
            "Epoch 1162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.650, train_loss_epoch=7.650, valid_loss=0.004]\n",
            "Epoch 1163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.820, train_loss_epoch=7.820, valid_loss=0.004]\n",
            "Epoch 1164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.820, train_loss_epoch=7.820, valid_loss=0.004]\n",
            "Epoch 1165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.004]\n",
            "Epoch 1166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.570, train_loss_epoch=7.570, valid_loss=0.004]\n",
            "Epoch 1167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.440, train_loss_epoch=7.440, valid_loss=0.004]\n",
            "Epoch 1168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.900, train_loss_epoch=7.900, valid_loss=0.004]\n",
            "Epoch 1169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.004]\n",
            "Epoch 1170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.480, train_loss_epoch=7.480, valid_loss=0.004]\n",
            "Epoch 1171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.004]\n",
            "Epoch 1172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.004]\n",
            "Epoch 1173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.340, train_loss_epoch=7.340, valid_loss=0.004]\n",
            "Epoch 1174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.004]\n",
            "Epoch 1175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.570, train_loss_epoch=7.570, valid_loss=0.004]\n",
            "Epoch 1176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.380, train_loss_epoch=7.380, valid_loss=0.004]\n",
            "Epoch 1177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=0.004]\n",
            "Epoch 1178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=0.004]\n",
            "Epoch 1179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.710, train_loss_epoch=7.710, valid_loss=0.004]\n",
            "Epoch 1180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.750, train_loss_epoch=7.750, valid_loss=0.004]\n",
            "Epoch 1181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.004]\n",
            "Epoch 1182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.004]\n",
            "Epoch 1183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.750, train_loss_epoch=7.750, valid_loss=0.004]\n",
            "Epoch 1184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.004]\n",
            "Epoch 1185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.820, train_loss_epoch=7.820, valid_loss=0.004]\n",
            "Epoch 1186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.330, train_loss_epoch=7.330, valid_loss=0.004]\n",
            "Epoch 1187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.570, train_loss_epoch=7.570, valid_loss=0.004]\n",
            "Epoch 1188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.110, train_loss_epoch=8.110, valid_loss=0.004]\n",
            "Epoch 1189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.860, train_loss_epoch=7.860, valid_loss=0.004]\n",
            "Epoch 1190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.004]\n",
            "Epoch 1191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=0.004]\n",
            "Epoch 1192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.430, train_loss_epoch=7.430, valid_loss=0.004]\n",
            "Epoch 1193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.004]\n",
            "Epoch 1194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.790, train_loss_epoch=7.790, valid_loss=0.004]\n",
            "Epoch 1195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.230, train_loss_epoch=7.230, valid_loss=0.004]\n",
            "Epoch 1196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.350, train_loss_epoch=7.350, valid_loss=0.004]\n",
            "Epoch 1197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.360, train_loss_epoch=7.360, valid_loss=0.004]\n",
            "Epoch 1198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.370, train_loss_epoch=7.370, valid_loss=0.004]\n",
            "Epoch 1199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.530, train_loss_epoch=7.530, valid_loss=0.004]\n",
            "Epoch 1199: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.530, valid_loss=0.004]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 117.00it/s]\u001b[A\n",
            "Epoch 1200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.00383]\n",
            "Epoch 1201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.340, train_loss_epoch=7.340, valid_loss=0.00383]\n",
            "Epoch 1202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.780, train_loss_epoch=7.780, valid_loss=0.00383]\n",
            "Epoch 1203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.530, train_loss_epoch=7.530, valid_loss=0.00383]\n",
            "Epoch 1204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00383]\n",
            "Epoch 1205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.950, train_loss_epoch=7.950, valid_loss=0.00383]\n",
            "Epoch 1206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00383]\n",
            "Epoch 1207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=0.00383]\n",
            "Epoch 1208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=0.00383]\n",
            "Epoch 1209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=0.00383]\n",
            "Epoch 1210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.00383]\n",
            "Epoch 1211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.180, train_loss_epoch=7.180, valid_loss=0.00383]\n",
            "Epoch 1212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00383]\n",
            "Epoch 1213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.00383]\n",
            "Epoch 1214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.00383]\n",
            "Epoch 1215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.00383]\n",
            "Epoch 1216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.370, train_loss_epoch=7.370, valid_loss=0.00383]\n",
            "Epoch 1217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.00383]\n",
            "Epoch 1218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.650, train_loss_epoch=7.650, valid_loss=0.00383]\n",
            "Epoch 1219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.590, train_loss_epoch=7.590, valid_loss=0.00383]\n",
            "Epoch 1220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.00383]\n",
            "Epoch 1221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.250, train_loss_epoch=7.250, valid_loss=0.00383]\n",
            "Epoch 1222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.00383]\n",
            "Epoch 1223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00383]\n",
            "Epoch 1224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.00383]\n",
            "Epoch 1225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00383]\n",
            "Epoch 1226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.500, train_loss_epoch=7.500, valid_loss=0.00383]\n",
            "Epoch 1227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.00383]\n",
            "Epoch 1228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.480, train_loss_epoch=7.480, valid_loss=0.00383]\n",
            "Epoch 1229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.550, train_loss_epoch=7.550, valid_loss=0.00383]\n",
            "Epoch 1230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.00383]\n",
            "Epoch 1231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.300, train_loss_epoch=7.300, valid_loss=0.00383]\n",
            "Epoch 1232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.440, train_loss_epoch=7.440, valid_loss=0.00383]\n",
            "Epoch 1232: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.00383]\n",
            "Epoch 1233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.00383]\n",
            "Epoch 1234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.00383]\n",
            "Epoch 1235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.650, train_loss_epoch=7.650, valid_loss=0.00383]\n",
            "Epoch 1236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=0.00383]\n",
            "Epoch 1237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.00383]\n",
            "Epoch 1238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.720, train_loss_epoch=7.720, valid_loss=0.00383]\n",
            "Epoch 1239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460, valid_loss=0.00383]\n",
            "Epoch 1240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.00383]\n",
            "Epoch 1241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00383]\n",
            "Epoch 1242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.380, train_loss_epoch=7.380, valid_loss=0.00383]\n",
            "Epoch 1243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.00383]\n",
            "Epoch 1244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.470, train_loss_epoch=7.470, valid_loss=0.00383]\n",
            "Epoch 1245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.340, train_loss_epoch=7.340, valid_loss=0.00383]\n",
            "Epoch 1246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.00383]\n",
            "Epoch 1247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.910, train_loss_epoch=7.910, valid_loss=0.00383]\n",
            "Epoch 1248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.710, train_loss_epoch=7.710, valid_loss=0.00383]\n",
            "Epoch 1249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=7.310, valid_loss=0.00383]\n",
            "Epoch 1250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.00383]\n",
            "Epoch 1251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00383]\n",
            "Epoch 1252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00383]\n",
            "Epoch 1253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.340, train_loss_epoch=7.340, valid_loss=0.00383]\n",
            "Epoch 1254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.500, train_loss_epoch=7.500, valid_loss=0.00383]\n",
            "Epoch 1255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.610, train_loss_epoch=7.610, valid_loss=0.00383]\n",
            "Epoch 1256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00383]\n",
            "Epoch 1257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00383]\n",
            "Epoch 1258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00383]\n",
            "Epoch 1259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.650, train_loss_epoch=7.650, valid_loss=0.00383]\n",
            "Epoch 1260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.790, train_loss_epoch=7.790, valid_loss=0.00383]\n",
            "Epoch 1261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.00383]\n",
            "Epoch 1262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.300, train_loss_epoch=7.300, valid_loss=0.00383]\n",
            "Epoch 1263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.00383]\n",
            "Epoch 1264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00383]\n",
            "Epoch 1265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.120, train_loss_epoch=7.120, valid_loss=0.00383]\n",
            "Epoch 1266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.300, train_loss_epoch=7.300, valid_loss=0.00383]\n",
            "Epoch 1267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00383]\n",
            "Epoch 1268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.00383]\n",
            "Epoch 1269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00383]\n",
            "Epoch 1270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.740, train_loss_epoch=7.740, valid_loss=0.00383]\n",
            "Epoch 1271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.570, train_loss_epoch=7.570, valid_loss=0.00383]\n",
            "Epoch 1271: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s, v_num=0, train_loss_step=7.210, train_loss_epoch=7.570, valid_loss=0.00383]\n",
            "Epoch 1272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.210, train_loss_epoch=7.210, valid_loss=0.00383]\n",
            "Epoch 1273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.550, train_loss_epoch=7.550, valid_loss=0.00383]\n",
            "Epoch 1274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.710, train_loss_epoch=7.710, valid_loss=0.00383]\n",
            "Epoch 1275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.240, train_loss_epoch=7.240, valid_loss=0.00383]\n",
            "Epoch 1276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.470, train_loss_epoch=7.470, valid_loss=0.00383]\n",
            "Epoch 1277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.350, train_loss_epoch=7.350, valid_loss=0.00383]\n",
            "Epoch 1278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.440, train_loss_epoch=7.440, valid_loss=0.00383]\n",
            "Epoch 1279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.00383]\n",
            "Epoch 1280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.200, train_loss_epoch=7.200, valid_loss=0.00383]\n",
            "Epoch 1281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.00383]\n",
            "Epoch 1282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.510, train_loss_epoch=7.510, valid_loss=0.00383]\n",
            "Epoch 1283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.270, train_loss_epoch=7.270, valid_loss=0.00383]\n",
            "Epoch 1284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.00383]\n",
            "Epoch 1285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.400, train_loss_epoch=7.400, valid_loss=0.00383]\n",
            "Epoch 1286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.00383]\n",
            "Epoch 1287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.280, train_loss_epoch=7.280, valid_loss=0.00383]\n",
            "Epoch 1288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.470, train_loss_epoch=7.470, valid_loss=0.00383]\n",
            "Epoch 1289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00383]\n",
            "Epoch 1290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.00383]\n",
            "Epoch 1291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520, valid_loss=0.00383]\n",
            "Epoch 1292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.00383]\n",
            "Epoch 1293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00383]\n",
            "Epoch 1294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.510, train_loss_epoch=7.510, valid_loss=0.00383]\n",
            "Epoch 1295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00383]\n",
            "Epoch 1296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.00383]\n",
            "Epoch 1297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.00383]\n",
            "Epoch 1298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.730, train_loss_epoch=7.730, valid_loss=0.00383]\n",
            "Epoch 1299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.00383]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 22:02:38,280\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m `Trainer.fit` stopped: `max_steps=1300.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, v_num=0, train_loss_step=7.450, train_loss_epoch=7.450, valid_loss=0.00383]\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.450, valid_loss=0.00383]\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.50it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=67858)\u001b[0m \r                                                                      \u001b[A\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.450, valid_loss=0.00394]\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00394]\rEpoch 1299: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s, v_num=0, train_loss_step=7.320, train_loss_epoch=7.320, valid_loss=0.00394]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=70873)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 2025-06-15 22:02:52.533301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m E0000 00:00:1750024972.565123   70965 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m E0000 00:00:1750024972.574026   70965 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 2025-06-15 22:02:52.607746: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 3 | blocks       | ModuleList    | 7.9 M  | train\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 7.9 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 7.9 M     Total params\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 31.706    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.10, train_loss_epoch=40.10]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.70, train_loss_epoch=31.70]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.70, train_loss_epoch=26.70]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.50, train_loss_epoch=26.50]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.20, train_loss_epoch=25.20]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.10, train_loss_epoch=26.10]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.90, train_loss_epoch=23.90]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=24.40, train_loss_epoch=24.40]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.10, train_loss_epoch=22.10]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.00, train_loss_epoch=22.00]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.00, train_loss_epoch=21.00]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.40, train_loss_epoch=20.40]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.30, train_loss_epoch=20.30]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.40, train_loss_epoch=21.40]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.20, train_loss_epoch=20.20]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.40, train_loss_epoch=19.40]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.70, train_loss_epoch=18.70]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.70, train_loss_epoch=19.70]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.20, train_loss_epoch=18.20]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.90, train_loss_epoch=17.90]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.40, train_loss_epoch=17.40]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.70, train_loss_epoch=16.70]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.60, train_loss_epoch=16.60]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40]\n",
            "Epoch 37: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.10, train_loss_epoch=15.10]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.00, train_loss_epoch=16.00]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.80, train_loss_epoch=14.80]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.30, train_loss_epoch=14.30]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.10, train_loss_epoch=14.10]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.60, train_loss_epoch=14.60]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.70, train_loss_epoch=13.70]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.20, train_loss_epoch=13.20]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 55: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.10, train_loss_epoch=12.10]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.80, train_loss_epoch=11.80]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.30, train_loss_epoch=11.30]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.80, train_loss_epoch=10.80]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.560, train_loss_epoch=9.560]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.350, train_loss_epoch=9.350]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.670, train_loss_epoch=9.670]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.20, train_loss_epoch=10.20]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.730, train_loss_epoch=9.730]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.890, train_loss_epoch=9.890]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.850, train_loss_epoch=9.850]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.40, train_loss_epoch=10.40]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.920, train_loss_epoch=8.920]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.610, train_loss_epoch=9.610]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.270, train_loss_epoch=9.270]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.190, train_loss_epoch=9.190]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.120, train_loss_epoch=9.120]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.670, train_loss_epoch=9.670]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.820, train_loss_epoch=8.820]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.030, train_loss_epoch=9.030]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.180, train_loss_epoch=9.180]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.920, train_loss_epoch=8.920]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.830, train_loss_epoch=9.830]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=0, train_loss_step=9.080, train_loss_epoch=8.510]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 106.54it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.080, train_loss_epoch=9.080, valid_loss=0.0037]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.840, train_loss_epoch=8.840, valid_loss=0.0037]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.910, train_loss_epoch=7.910, valid_loss=0.0037]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.0037]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.0037]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.570, train_loss_epoch=8.570, valid_loss=0.0037]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.270, train_loss_epoch=8.270, valid_loss=0.0037]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.170, train_loss_epoch=8.170, valid_loss=0.0037]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.410, train_loss_epoch=8.410, valid_loss=0.0037]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.610, train_loss_epoch=8.610, valid_loss=0.0037]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.730, train_loss_epoch=8.730, valid_loss=0.0037]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.210, train_loss_epoch=8.210, valid_loss=0.0037]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.650, train_loss_epoch=8.650, valid_loss=0.0037]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.760, train_loss_epoch=8.760, valid_loss=0.0037]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.820, train_loss_epoch=7.820, valid_loss=0.0037]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.180, train_loss_epoch=8.180, valid_loss=0.0037]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=0.0037]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.670, train_loss_epoch=8.670, valid_loss=0.0037]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.0037]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.050, train_loss_epoch=8.050, valid_loss=0.0037]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.630, train_loss_epoch=8.630, valid_loss=0.0037]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.0037]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.510, train_loss_epoch=8.510, valid_loss=0.0037]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.670, train_loss_epoch=7.670, valid_loss=0.0037]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.910, train_loss_epoch=7.910, valid_loss=0.0037]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.0037]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.770, train_loss_epoch=7.770, valid_loss=0.0037]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.0037]\n",
            "Epoch 127: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.0037]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.0037]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.0037]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.450, train_loss_epoch=8.450, valid_loss=0.0037]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.330, train_loss_epoch=7.330, valid_loss=0.0037]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460, valid_loss=0.0037]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.010, train_loss_epoch=8.010, valid_loss=0.0037]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.0037]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.270, train_loss_epoch=7.270, valid_loss=0.0037]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.000, train_loss_epoch=7.000, valid_loss=0.0037]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.490, train_loss_epoch=7.490, valid_loss=0.0037]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.080, train_loss_epoch=7.080, valid_loss=0.0037]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.690, train_loss_epoch=7.690, valid_loss=0.0037]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.750, train_loss_epoch=7.750, valid_loss=0.0037]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.850, train_loss_epoch=6.850, valid_loss=0.0037]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.850, train_loss_epoch=7.850, valid_loss=0.0037]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.910, train_loss_epoch=6.910, valid_loss=0.0037]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.970, train_loss_epoch=6.970, valid_loss=0.0037]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.230, train_loss_epoch=7.230, valid_loss=0.0037]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.390, train_loss_epoch=7.390, valid_loss=0.0037]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.0037]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.680, train_loss_epoch=7.680, valid_loss=0.0037]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.990, train_loss_epoch=6.990, valid_loss=0.0037]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.0037]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.0037]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.440, train_loss_epoch=7.440, valid_loss=0.0037]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.0037]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.160, train_loss_epoch=7.160, valid_loss=0.0037]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.020, train_loss_epoch=7.020, valid_loss=0.0037]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.140, train_loss_epoch=7.140, valid_loss=0.0037]\n",
            "Epoch 156: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=6.740, train_loss_epoch=7.140, valid_loss=0.0037]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.740, train_loss_epoch=6.740, valid_loss=0.0037]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.010, train_loss_epoch=7.010, valid_loss=0.0037]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.870, train_loss_epoch=6.870, valid_loss=0.0037]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460, valid_loss=0.0037]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.890, train_loss_epoch=6.890, valid_loss=0.0037]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.980, train_loss_epoch=6.980, valid_loss=0.0037]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.0037]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.650, train_loss_epoch=6.650, valid_loss=0.0037]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.550, train_loss_epoch=6.550, valid_loss=0.0037]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.490, train_loss_epoch=6.490, valid_loss=0.0037]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.630, train_loss_epoch=6.630, valid_loss=0.0037]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.840, train_loss_epoch=6.840, valid_loss=0.0037]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.680, train_loss_epoch=6.680, valid_loss=0.0037]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.540, train_loss_epoch=6.540, valid_loss=0.0037]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.850, train_loss_epoch=6.850, valid_loss=0.0037]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.080, train_loss_epoch=6.080, valid_loss=0.0037]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460, valid_loss=0.0037]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.540, train_loss_epoch=6.540, valid_loss=0.0037]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.030, train_loss_epoch=6.030, valid_loss=0.0037]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.0037]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.230, train_loss_epoch=6.230, valid_loss=0.0037]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.500, train_loss_epoch=6.500, valid_loss=0.0037]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.370, train_loss_epoch=6.370, valid_loss=0.0037]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.170, train_loss_epoch=6.170, valid_loss=0.0037]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.270, train_loss_epoch=6.270, valid_loss=0.0037]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.0037]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.0037]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.240, train_loss_epoch=6.240, valid_loss=0.0037]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.660, train_loss_epoch=6.660, valid_loss=0.0037]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.340, train_loss_epoch=6.340, valid_loss=0.0037]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=0.0037]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.040, train_loss_epoch=6.040, valid_loss=0.0037]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=7.310, valid_loss=0.0037]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.300, train_loss_epoch=6.300, valid_loss=0.0037]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.860, train_loss_epoch=6.860, valid_loss=0.0037]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000, valid_loss=0.0037]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.310, train_loss_epoch=6.310, valid_loss=0.0037]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.060, train_loss_epoch=7.060, valid_loss=0.0037]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.310, train_loss_epoch=6.310, valid_loss=0.0037]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.030, train_loss_epoch=6.030, valid_loss=0.0037]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.490, train_loss_epoch=6.490, valid_loss=0.0037]\n",
            "Epoch 197: 100%|██████████| 1/1 [00:00<00:00,  1.36it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.0037]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.0037]        \n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.0037]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.190, train_loss_epoch=6.190, valid_loss=0.0037]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.190, valid_loss=0.0037]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 84.11it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=0.00232]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000, valid_loss=0.00232]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.130, train_loss_epoch=6.130, valid_loss=0.00232]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.380, train_loss_epoch=6.380, valid_loss=0.00232]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930, valid_loss=0.00232]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.250, train_loss_epoch=6.250, valid_loss=0.00232]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460, valid_loss=0.00232]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.310, train_loss_epoch=6.310, valid_loss=0.00232]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.00232]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.910, train_loss_epoch=5.910, valid_loss=0.00232]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.730, train_loss_epoch=6.730, valid_loss=0.00232]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=0.00232]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.340, train_loss_epoch=6.340, valid_loss=0.00232]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.080, train_loss_epoch=6.080, valid_loss=0.00232]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.340, train_loss_epoch=6.340, valid_loss=0.00232]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.900, train_loss_epoch=5.900, valid_loss=0.00232]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.740, train_loss_epoch=5.740, valid_loss=0.00232]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.480, train_loss_epoch=6.480, valid_loss=0.00232]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.140, train_loss_epoch=6.140, valid_loss=0.00232]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.920, train_loss_epoch=6.920, valid_loss=0.00232]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=6.440, valid_loss=0.00232]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.190, train_loss_epoch=6.190, valid_loss=0.00232]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.00232]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.790, train_loss_epoch=5.790, valid_loss=0.00232]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.00232]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.830, train_loss_epoch=6.830, valid_loss=0.00232]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.050, train_loss_epoch=6.050, valid_loss=0.00232]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.290, train_loss_epoch=7.290, valid_loss=0.00232]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.640, train_loss_epoch=5.640, valid_loss=0.00232]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.00232]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.260, train_loss_epoch=6.260, valid_loss=0.00232]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.490, train_loss_epoch=6.490, valid_loss=0.00232]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.300, train_loss_epoch=6.300, valid_loss=0.00232]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000, valid_loss=0.00232]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.860, train_loss_epoch=6.860, valid_loss=0.00232]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.920, valid_loss=0.00232]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.00232]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=0.00232]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=0.00232]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.930, train_loss_epoch=5.930, valid_loss=0.00232]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.950, train_loss_epoch=5.950, valid_loss=0.00232]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00232]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.560, train_loss_epoch=5.560, valid_loss=0.00232]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960, valid_loss=0.00232]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=0.00232]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.890, train_loss_epoch=5.890, valid_loss=0.00232]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.720, train_loss_epoch=5.720, valid_loss=0.00232]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960, valid_loss=0.00232]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.120, valid_loss=0.00232]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00232]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.750, train_loss_epoch=5.750, valid_loss=0.00232]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.210, train_loss_epoch=6.210, valid_loss=0.00232]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.700, train_loss_epoch=5.700, valid_loss=0.00232]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.920, train_loss_epoch=5.920, valid_loss=0.00232]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00232]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.560, train_loss_epoch=5.560, valid_loss=0.00232]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.00232]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.00232]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.440, train_loss_epoch=5.440, valid_loss=0.00232]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.770, train_loss_epoch=5.770, valid_loss=0.00232]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.720, train_loss_epoch=5.720, valid_loss=0.00232]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.00232]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.510, train_loss_epoch=5.510, valid_loss=0.00232]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.450, train_loss_epoch=5.450, valid_loss=0.00232]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620, valid_loss=0.00232]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.220, train_loss_epoch=5.220, valid_loss=0.00232]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620, valid_loss=0.00232]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.610, train_loss_epoch=5.610, valid_loss=0.00232]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.980, train_loss_epoch=4.980, valid_loss=0.00232]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.970, train_loss_epoch=4.970, valid_loss=0.00232]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.570, train_loss_epoch=4.570, valid_loss=0.00232]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.750, train_loss_epoch=4.750, valid_loss=0.00232]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.720, train_loss_epoch=4.720, valid_loss=0.00232]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.630, train_loss_epoch=4.630, valid_loss=0.00232]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=0.00232]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.390, train_loss_epoch=4.390, valid_loss=0.00232]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.300, train_loss_epoch=4.300, valid_loss=0.00232]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.480, train_loss_epoch=4.480, valid_loss=0.00232]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.460, train_loss_epoch=4.460, valid_loss=0.00232]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320, valid_loss=0.00232]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220, valid_loss=0.00232]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.240, train_loss_epoch=4.240, valid_loss=0.00232]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=0.00232]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.210, train_loss_epoch=4.210, valid_loss=0.00232]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.310, train_loss_epoch=4.310, valid_loss=0.00232]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=0.00232]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=0.00232]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.180, train_loss_epoch=4.180, valid_loss=0.00232]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=0.00232]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00232]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070, valid_loss=0.00232]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.170, train_loss_epoch=4.170, valid_loss=0.00232]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.010, train_loss_epoch=4.010, valid_loss=0.00232]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.800, train_loss_epoch=3.800, valid_loss=0.00232]\n",
            "Epoch 293: 100%|██████████| 1/1 [00:00<00:00,  2.13it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=3.950, valid_loss=0.00232]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=3.950, valid_loss=0.00232]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.050, train_loss_epoch=4.050, valid_loss=0.00232]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.170, train_loss_epoch=4.170, valid_loss=0.00232]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.150, train_loss_epoch=4.150, valid_loss=0.00232]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.920, train_loss_epoch=3.920, valid_loss=0.00232]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.250, train_loss_epoch=4.250, valid_loss=0.00232]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=4.250, valid_loss=0.00232]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 103.98it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=3.970, valid_loss=0.00184]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.160, train_loss_epoch=4.160, valid_loss=0.00184]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870, valid_loss=0.00184]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=0.00184]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00184]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780, valid_loss=0.00184]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.010, train_loss_epoch=4.010, valid_loss=0.00184]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780, valid_loss=0.00184]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.130, train_loss_epoch=4.130, valid_loss=0.00184]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.000, train_loss_epoch=4.000, valid_loss=0.00184]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00184]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.930, train_loss_epoch=3.930, valid_loss=0.00184]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.800, train_loss_epoch=3.800, valid_loss=0.00184]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00184]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00184]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.810, train_loss_epoch=3.810, valid_loss=0.00184]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.110, train_loss_epoch=4.110, valid_loss=0.00184]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=3.900, valid_loss=0.00184]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00184]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.850, valid_loss=0.00184]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00184]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.140, train_loss_epoch=4.140, valid_loss=0.00184]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.770, train_loss_epoch=3.770, valid_loss=0.00184]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.910, train_loss_epoch=3.910, valid_loss=0.00184]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=0.00184]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.920, train_loss_epoch=3.920, valid_loss=0.00184]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.020, train_loss_epoch=4.020, valid_loss=0.00184]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=0.00184]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.950, train_loss_epoch=3.950, valid_loss=0.00184]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.990, train_loss_epoch=3.990, valid_loss=0.00184]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.800, train_loss_epoch=3.800, valid_loss=0.00184]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=0.00184]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00184]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.720, train_loss_epoch=3.720, valid_loss=0.00184]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.810, train_loss_epoch=3.810, valid_loss=0.00184]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.880, train_loss_epoch=3.880, valid_loss=0.00184]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00184]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=0.00184]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.030, train_loss_epoch=4.030, valid_loss=0.00184]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=0.00184]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.800, train_loss_epoch=3.800, valid_loss=0.00184]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.980, train_loss_epoch=3.980, valid_loss=0.00184]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.850, valid_loss=0.00184]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00184]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.780, train_loss_epoch=3.780, valid_loss=0.00184]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00184]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.050, train_loss_epoch=4.050, valid_loss=0.00184]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.840, train_loss_epoch=3.840, valid_loss=0.00184]\n",
            "Epoch 347: 100%|██████████| 1/1 [00:01<00:00,  0.93it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=3.970, valid_loss=0.00184]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.970, train_loss_epoch=3.970, valid_loss=0.00184]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820, valid_loss=0.00184]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.090, train_loss_epoch=4.090, valid_loss=0.00184]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.00184]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.120, train_loss_epoch=4.120, valid_loss=0.00184]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=0.00184]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.990, train_loss_epoch=3.990, valid_loss=0.00184]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00184]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00184]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.930, train_loss_epoch=3.930, valid_loss=0.00184]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00184]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.850, train_loss_epoch=3.850, valid_loss=0.00184]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960, valid_loss=0.00184]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00184]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.580, train_loss_epoch=3.580, valid_loss=0.00184]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=0.00184]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830, valid_loss=0.00184]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.710, train_loss_epoch=3.710, valid_loss=0.00184]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.750, train_loss_epoch=3.750, valid_loss=0.00184]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560, valid_loss=0.00184]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.860, train_loss_epoch=3.860, valid_loss=0.00184]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00184]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.570, train_loss_epoch=3.570, valid_loss=0.00184]\n",
            "Epoch 370: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.570, valid_loss=0.00184]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=0.00184]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400, valid_loss=0.00184]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00184]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.560, train_loss_epoch=3.560, valid_loss=0.00184]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=0.00184]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540, valid_loss=0.00184]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00184]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00184]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.570, train_loss_epoch=3.570, valid_loss=0.00184]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.00184]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.370, train_loss_epoch=3.370, valid_loss=0.00184]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00184]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.640, train_loss_epoch=3.640, valid_loss=0.00184]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00184]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=0.00184]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.890, train_loss_epoch=3.890, valid_loss=0.00184]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.790, train_loss_epoch=3.790, valid_loss=0.00184]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=0.00184]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00184]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=0.00184]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.00184]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.730, train_loss_epoch=3.730, valid_loss=0.00184]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00184]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00184]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00184]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00184]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.630, train_loss_epoch=3.630, valid_loss=0.00184]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=0.00184]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=3.430, valid_loss=0.00184]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.05it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.430, valid_loss=0.00184]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 35.87it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00207]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00207]\n",
            "Epoch 400: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=0.00207]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.740, train_loss_epoch=3.740, valid_loss=0.00207]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00207]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.690, train_loss_epoch=3.690, valid_loss=0.00207]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00207]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=0.00207]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700, valid_loss=0.00207]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.640, train_loss_epoch=3.640, valid_loss=0.00207]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.490, train_loss_epoch=3.490, valid_loss=0.00207]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.490, train_loss_epoch=3.490, valid_loss=0.00207]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.590, train_loss_epoch=3.590, valid_loss=0.00207]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.600, train_loss_epoch=3.600, valid_loss=0.00207]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00207]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.450, train_loss_epoch=3.450, valid_loss=0.00207]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=0.00207]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00207]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00207]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470, valid_loss=0.00207]\n",
            "Epoch 417: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00207]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00207]        \n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520, valid_loss=0.00207]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00207]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.420, train_loss_epoch=3.420, valid_loss=0.00207]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.470, train_loss_epoch=3.470, valid_loss=0.00207]\n",
            "Epoch 421: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=0.00207]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=0.00207]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00207]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=0.00207]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400, valid_loss=0.00207]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.00207]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00207]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.00207]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.370, train_loss_epoch=3.370, valid_loss=0.00207]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00207]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400, valid_loss=0.00207]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00207]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.760, train_loss_epoch=3.760, valid_loss=0.00207]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=0.00207]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00207]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00207]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610, valid_loss=0.00207]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=0.00207]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.600, train_loss_epoch=3.600, valid_loss=0.00207]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620, valid_loss=0.00207]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.590, train_loss_epoch=3.590, valid_loss=0.00207]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.660, train_loss_epoch=3.660, valid_loss=0.00207]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00207]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.500, train_loss_epoch=3.500, valid_loss=0.00207]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.710, train_loss_epoch=3.710, valid_loss=0.00207]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00207]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540, valid_loss=0.00207]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.310, train_loss_epoch=3.310, valid_loss=0.00207]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.360, train_loss_epoch=3.360, valid_loss=0.00207]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380, valid_loss=0.00207]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400, valid_loss=0.00207]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00207]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510, valid_loss=0.00207]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00207]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440, valid_loss=0.00207]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00207]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00207]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00207]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00207]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.320, train_loss_epoch=3.320, valid_loss=0.00207]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480, valid_loss=0.00207]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00207]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00207]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00207]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00207]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00207]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00207]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00207]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.00207]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.00207]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00207]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.00207]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00207]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00207]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00207]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00207]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.00207]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00207]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00207]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00207]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00207]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00207]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.00207]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00207]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00207]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00207]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00207]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00207]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.00207]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.00207]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00207]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00207]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00207]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00207]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00207]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00207]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00207]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.240, train_loss_epoch=3.240, valid_loss=0.00207]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00207]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  2.03it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.330, valid_loss=0.00207]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.08it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.00164]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00164]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00164]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.00164]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00164]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.00164]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00164]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.00164]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00164]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00164]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00164]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00164]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00164]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00164]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00164]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00164]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00164]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00164]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.00164]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00164]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00164]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.00164]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00164]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.00164]\n",
            "Epoch 523: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00164]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00164]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.00164]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.00164]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00164]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.260, train_loss_epoch=3.260, valid_loss=0.00164]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00164]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.00164]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.00164]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00164]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.460, train_loss_epoch=3.460, valid_loss=0.00164]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.00164]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00164]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00164]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00164]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00164]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00164]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00164]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00164]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00164]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00164]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00164]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00164]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00164]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00164]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00164]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00164]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00164]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00164]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00164]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00164]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00164]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00164]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00164]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00164]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00164]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00164]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00164]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00164]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.00164]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00164]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00164]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00164]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00164]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00164]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00164]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00164]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00164]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00164]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00164]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00164]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00164]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00164]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00164]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00164]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00164]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00164]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00164]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00164]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00164]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00164]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00164]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00164]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00164]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00164]\n",
            "Epoch 587: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00164]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00164]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00164]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00164]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00164]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00164]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00164]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00164]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00164]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00164]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00164]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00164]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00164]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.090, valid_loss=0.00164]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 102.67it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0017]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0017]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0017]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0017]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0017]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.0017]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0017]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0017]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0017]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.0017]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0017]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0017]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.0017]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0017]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0017]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0017]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0017]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.0017]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0017]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0017]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0017]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0017]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0017]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0017]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.0017]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0017]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0017]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0017]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0017]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0017]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.0017]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.0017]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.0017]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0017]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.0017]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0017]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0017]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.0017]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.0017]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.0017]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0017]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0017]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0017]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0017]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0017]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.0017]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.0017]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0017]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.0017]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0017]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.0017]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.0017]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.0017]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0017]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.0017]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0017]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0017]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.0017]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0017]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.0017]\n",
            "Epoch 662: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.060, valid_loss=0.0017]\n",
            "Epoch 662: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0017]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0017]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.0017]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.0017]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Epoch 666: 100%|██████████| 1/1 [00:00<00:00,  1.84it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0017]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.0017]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0017]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0017]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.0017]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.0017]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0017]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.0017]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0017]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.0017]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.0017]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0017]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0017]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.0017]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.0017]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.0017]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0017]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0017]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.0017]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.0017]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.0017]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.0017]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.0017]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.0017]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.0017]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.0017]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.0017]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.0017]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0017]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.0017]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.0017]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=2.050, valid_loss=0.0017]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 107.69it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00163]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00163]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00163]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00163]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00163]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00163]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00163]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00163]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00163]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00163]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00163]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00163]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00163]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00163]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00163]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00163]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00163]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00163]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00163]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00163]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00163]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00163]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 727: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00163]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00163]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00163]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00163]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00163]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00163]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00163]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00163]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00163]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00163]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.800, train_loss_epoch=1.800, valid_loss=0.00163]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00163]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00163]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00163]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00163]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00163]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00163]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00163]\n",
            "Epoch 756: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00163]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.860, train_loss_epoch=1.860, valid_loss=0.00163]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00163]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00163]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00163]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.890, train_loss_epoch=1.890, valid_loss=0.00163]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00163]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00163]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.00163]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00163]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00163]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00163]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00163]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00163]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00163]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00163]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00163]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00163]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00163]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00163]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00163]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.100, train_loss_epoch=2.100, valid_loss=0.00163]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.040, train_loss_epoch=2.040, valid_loss=0.00163]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00163]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00163]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00163]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00163]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00163]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00163]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00163]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00163]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.910, train_loss_epoch=1.910, valid_loss=0.00163]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00163]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00163]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00163]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.810, train_loss_epoch=1.810, valid_loss=0.00163]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00163]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00163]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00163]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 22:10:11,821\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m `Trainer.fit` stopped: `max_steps=800.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=70873)\u001b[0m \rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00163]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=2.060, valid_loss=0.00163]\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 109.24it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=70873)\u001b[0m \r                                                                       \u001b[A\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=2.060, valid_loss=0.00147]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00147]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.79it/s, v_num=0, train_loss_step=1.950, train_loss_epoch=1.950, valid_loss=0.00147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=72801)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 2025-06-15 22:10:26.296737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m E0000 00:00:1750025426.332942   72893 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m E0000 00:00:1750025426.344945   72893 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 2025-06-15 22:10:26.385717: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 3 | blocks       | ModuleList    | 7.9 M  | train\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 7.9 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 7.9 M     Total params\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 31.706    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.60, train_loss_epoch=33.60]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=98.40, train_loss_epoch=98.40]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.08e+4, train_loss_epoch=4.08e+4]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=711.0, train_loss_epoch=711.0]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=99.90, train_loss_epoch=99.90]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=809.0, train_loss_epoch=809.0]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=107.0, train_loss_epoch=107.0]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=452.0, train_loss_epoch=452.0]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=304.0, train_loss_epoch=304.0]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=286.0, train_loss_epoch=286.0]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=93.40, train_loss_epoch=93.40]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=65.70, train_loss_epoch=65.70]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=47.50, train_loss_epoch=47.50]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=40.60, train_loss_epoch=40.60]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=45.20, train_loss_epoch=45.20]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=38.10]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.40, train_loss_epoch=37.40]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=37.30, train_loss_epoch=37.30]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.10, train_loss_epoch=38.10]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.70, train_loss_epoch=35.70]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.00, train_loss_epoch=34.00]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.90, train_loss_epoch=35.90]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.40, train_loss_epoch=38.40]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=35.10, train_loss_epoch=35.10]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.40, train_loss_epoch=33.40]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=32.70]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.40, train_loss_epoch=33.40]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.80, train_loss_epoch=31.80]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.80, train_loss_epoch=34.80]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.30, train_loss_epoch=34.30]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.00, train_loss_epoch=34.00]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=32.70]\n",
            "Epoch 36: 100%|██████████| 1/1 [00:00<00:00,  2.17it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=32.70]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=32.70]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=31.50]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.00, train_loss_epoch=33.00]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.50, train_loss_epoch=32.50]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.10, train_loss_epoch=33.10]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.20, train_loss_epoch=32.20]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=33.10, train_loss_epoch=33.10]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.80, train_loss_epoch=32.80]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.40, train_loss_epoch=32.40]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.00, train_loss_epoch=34.00]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.60, train_loss_epoch=32.60]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.70, train_loss_epoch=32.70]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.90, train_loss_epoch=32.90]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.10, train_loss_epoch=32.10]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.60, train_loss_epoch=31.60]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.70, train_loss_epoch=31.70]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.60, train_loss_epoch=31.60]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30]\n",
            "Epoch 73: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.80, train_loss_epoch=32.80]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.90, train_loss_epoch=31.90]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.90, train_loss_epoch=27.90]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.70, train_loss_epoch=27.70]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.70]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 80.80it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  1.47it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0134]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0134]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0134]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0134]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20, valid_loss=0.0134]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0134]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0134]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0134]\n",
            "Epoch 108: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=28.10, valid_loss=0.0134]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0134]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0134]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0134]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0134]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0134]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0134]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0134]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0134]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0134]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0134]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20, valid_loss=0.0134]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0134]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0134]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0134]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0134]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0134]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0134]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0134]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0134]\n",
            "Epoch 132: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0134]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0134]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0134]\n",
            "Epoch 134: 100%|██████████| 1/1 [00:00<00:00,  2.08it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0134]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0134]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0134]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0134]        \n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0134]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0134]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0134]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0134]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0134]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0134]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0134]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.40, train_loss_epoch=27.40, valid_loss=0.0134]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0134]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0134]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0134]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0134]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0134]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0134]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0134]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0134]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 155: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0134]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0134]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0134]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0134]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0134]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0134]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0134]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0134]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00, valid_loss=0.0134]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0134]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0134]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0134]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0134]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0134]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0134]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0134]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0134]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0134]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0134]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0134]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0134]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0134]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0134]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0134]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0134]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0134]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0134]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0134]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30, valid_loss=0.0134]\n",
            "Epoch 187: 100%|██████████| 1/1 [00:00<00:00,  1.41it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0134]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0134]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0134]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0134]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0134]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0134]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0134]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0134]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0134]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.60, train_loss_epoch=27.60, valid_loss=0.0134]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0134]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0134]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0134]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=29.10, valid_loss=0.0134]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 112.70it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0133]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0133]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0133]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0133]\n",
            "Epoch 204: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0133]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0133]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0133]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0133]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0133]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0133]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0133]\n",
            "Epoch 210: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=29.80, valid_loss=0.0133]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20, valid_loss=0.0133]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0133]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0133]\n",
            "Epoch 213: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0133]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0133]\n",
            "Epoch 214: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0133]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0133]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0133]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0133]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0133]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0133]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0133]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0133]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0133]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0133]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0133]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0133]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0133]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0133]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0133]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0133]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0133]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0133]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0133]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0133]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0133]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0133]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0133]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0133]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0133]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0133]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0133]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0133]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0133]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0133]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0133]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0133]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0133]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0133]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0133]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0133]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0133]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0133]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0133]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0133]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0133]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0133]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0133]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0133]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0133]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0133]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0133]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0133]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0133]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0133]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0133]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0133]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0133]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0133]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0133]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0133]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0133]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0133]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0133]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0133]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0133]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0133]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0133]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0133]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0133]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0133]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0133]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0133]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0133]\n",
            "Epoch 286: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.50, valid_loss=0.0133]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0133]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0133]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0133]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0133]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0133]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.30, train_loss_epoch=27.30, valid_loss=0.0133]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0133]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0133]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20, valid_loss=0.0133]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 297: 100%|██████████| 1/1 [00:00<00:00,  1.34it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=29.40, valid_loss=0.0133]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0133]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=31.50, valid_loss=0.0133]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=31.50, valid_loss=0.0133]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 83.34it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.00, train_loss_epoch=32.00, valid_loss=0.0132]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20, valid_loss=0.0132]\n",
            "Epoch 309: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0132]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]        \n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30, valid_loss=0.0132]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.70, train_loss_epoch=27.70, valid_loss=0.0132]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.90, train_loss_epoch=27.90, valid_loss=0.0132]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00, valid_loss=0.0132]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 104.35it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.80, train_loss_epoch=31.80, valid_loss=0.0132]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 486: 100%|██████████| 1/1 [00:00<00:00,  2.12it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 498: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 73.18it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.30, train_loss_epoch=27.30, valid_loss=0.0132]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.70, train_loss_epoch=27.70, valid_loss=0.0132]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.70, train_loss_epoch=27.70, valid_loss=0.0132]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.90, train_loss_epoch=26.90, valid_loss=0.0132]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20, valid_loss=0.0132]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40, valid_loss=0.0132]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0132]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0132]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0132]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.20, train_loss_epoch=31.20, valid_loss=0.0132]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0132]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.90, train_loss_epoch=27.90, valid_loss=0.0132]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 78.31it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.60, train_loss_epoch=31.60, valid_loss=0.0132]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.70, train_loss_epoch=31.70, valid_loss=0.0132]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.80, train_loss_epoch=31.80, valid_loss=0.0132]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20, valid_loss=0.0132]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 629: 100%|██████████| 1/1 [00:00<00:00,  1.97it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]        \n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40, valid_loss=0.0132]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.60, train_loss_epoch=27.60, valid_loss=0.0132]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 669: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 669: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00, valid_loss=0.0132]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00, valid_loss=0.0132]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.90, train_loss_epoch=27.90, valid_loss=0.0132]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=31.50, valid_loss=0.0132]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  1.96it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 110.63it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.90, train_loss_epoch=27.90, valid_loss=0.0132]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0132]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.10, train_loss_epoch=31.10, valid_loss=0.0132]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 716: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20, valid_loss=0.0132]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30, valid_loss=0.0132]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 735: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 736: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.50, train_loss_epoch=27.50, valid_loss=0.0132]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30, valid_loss=0.0132]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.50, train_loss_epoch=28.50, valid_loss=0.0132]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.50, train_loss_epoch=30.50, valid_loss=0.0132]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.40, train_loss_epoch=28.40, valid_loss=0.0132]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20, valid_loss=0.0132]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.80, train_loss_epoch=30.80, valid_loss=0.0132]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30, valid_loss=0.0132]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.20, train_loss_epoch=28.20, valid_loss=0.0132]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.90, train_loss_epoch=27.90, valid_loss=0.0132]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 788: 100%|██████████| 1/1 [00:00<00:00,  1.90it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 790: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.00, train_loss_epoch=31.00, valid_loss=0.0132]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:00<00:00,  1.23it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.19it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00, valid_loss=0.0132]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.10, train_loss_epoch=28.10, valid_loss=0.0132]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.90, train_loss_epoch=30.90, valid_loss=0.0132]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40, valid_loss=0.0132]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.50, train_loss_epoch=31.50, valid_loss=0.0132]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.20, train_loss_epoch=30.20, valid_loss=0.0132]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.40, train_loss_epoch=30.40, valid_loss=0.0132]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.80, train_loss_epoch=27.80, valid_loss=0.0132]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.30, train_loss_epoch=31.30, valid_loss=0.0132]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.00, train_loss_epoch=30.00, valid_loss=0.0132]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.10, train_loss_epoch=30.10, valid_loss=0.0132]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.90, train_loss_epoch=28.90, valid_loss=0.0132]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.00, train_loss_epoch=29.00, valid_loss=0.0132]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.60, train_loss_epoch=30.60, valid_loss=0.0132]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.50, train_loss_epoch=29.50, valid_loss=0.0132]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.40, train_loss_epoch=31.40, valid_loss=0.0132]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.80, train_loss_epoch=27.80, valid_loss=0.0132]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 878: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60, valid_loss=0.0132]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.00, train_loss_epoch=28.00, valid_loss=0.0132]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.90, train_loss_epoch=29.90, valid_loss=0.0132]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.80, train_loss_epoch=31.80, valid_loss=0.0132]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80, valid_loss=0.0132]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.30, train_loss_epoch=29.30, valid_loss=0.0132]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.60, train_loss_epoch=29.60, valid_loss=0.0132]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30, valid_loss=0.0132]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.10, train_loss_epoch=29.10, valid_loss=0.0132]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.70, train_loss_epoch=31.70, valid_loss=0.0132]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.70, train_loss_epoch=30.70, valid_loss=0.0132]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=30.30, train_loss_epoch=30.30, valid_loss=0.0132]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.70, train_loss_epoch=29.70, valid_loss=0.0132]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.70, train_loss_epoch=28.70, valid_loss=0.0132]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 22:18:49,936\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, v_num=0, train_loss_step=29.80, train_loss_epoch=29.80, valid_loss=0.0132]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.80, valid_loss=0.0132]\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 52.58it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=72801)\u001b[0m \r                                                                      \u001b[A\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.80, valid_loss=0.0132]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\rEpoch 899: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s, v_num=0, train_loss_step=29.20, train_loss_epoch=29.20, valid_loss=0.0132]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=72801)\u001b[0m `Trainer.fit` stopped: `max_steps=900.0` reached.\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 2025-06-15 22:19:03.116054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m E0000 00:00:1750025943.176031   75083 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m E0000 00:00:1750025943.192720   75083 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 2025-06-15 22:19:03.242310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 3 | blocks       | ModuleList    | 4.3 M  | train\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 4.3 M     Trainable params\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 4.3 M     Total params\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 17.149    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=154.0, train_loss_epoch=154.0]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.70, train_loss_epoch=14.70]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.550, train_loss_epoch=9.550]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=190.0, train_loss_epoch=190.0]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.010, train_loss_epoch=9.010]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.200, train_loss_epoch=7.200]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.890, train_loss_epoch=8.890]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.560, train_loss_epoch=8.560]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.230, train_loss_epoch=6.230]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=6.780]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.670, train_loss_epoch=4.670]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.510, train_loss_epoch=7.510]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.620, train_loss_epoch=6.620]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.350, train_loss_epoch=8.350]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.630, train_loss_epoch=6.630]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700]\n",
            "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=3.700]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.520, train_loss_epoch=7.520]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.380, train_loss_epoch=5.380]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.430, train_loss_epoch=4.430]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.900, train_loss_epoch=3.900]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.140, train_loss_epoch=5.140]\n",
            "Epoch 25: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.510, train_loss_epoch=4.510]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.220, train_loss_epoch=4.220]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.480, train_loss_epoch=3.480]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.170, train_loss_epoch=4.170]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.620, train_loss_epoch=3.620]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.830, train_loss_epoch=3.830]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.440, train_loss_epoch=3.440]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.300, train_loss_epoch=3.300]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.520, train_loss_epoch=3.520]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.280, train_loss_epoch=4.280]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.460, train_loss_epoch=5.460]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.400, train_loss_epoch=5.400]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.610, train_loss_epoch=3.610]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.060, train_loss_epoch=4.060]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.870, train_loss_epoch=3.870]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.380, train_loss_epoch=3.380]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.340, train_loss_epoch=3.340]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.010, train_loss_epoch=4.010]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.700, train_loss_epoch=3.700]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.540, train_loss_epoch=3.540]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.960, train_loss_epoch=3.960]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.400, train_loss_epoch=3.400]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.270, train_loss_epoch=3.270]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.430, train_loss_epoch=3.430]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.820, train_loss_epoch=3.820]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.510, train_loss_epoch=3.510]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=2.960]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 130.37it/s]\u001b[A\n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.0293]\n",
            "Epoch 100: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.0293]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.0293]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.0293]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0293]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0293]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.0293]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.0293]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.0293]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.250, train_loss_epoch=3.250, valid_loss=0.0293]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.370, train_loss_epoch=3.370, valid_loss=0.0293]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.0293]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.0293]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0293]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0293]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0293]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0293]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.0293]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.0293]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0293]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0293]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.0293]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.0293]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.0293]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.170, train_loss_epoch=3.170, valid_loss=0.0293]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.0293]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.160, train_loss_epoch=3.160, valid_loss=0.0293]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.0293]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.0293]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0293]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.0293]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.670, train_loss_epoch=3.670, valid_loss=0.0293]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.0293]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.100, train_loss_epoch=3.100, valid_loss=0.0293]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.0293]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.230, train_loss_epoch=3.230, valid_loss=0.0293]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.0293]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0293]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.0293]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.0293]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.0293]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.0293]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.350, train_loss_epoch=3.350, valid_loss=0.0293]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.0293]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0293]        \n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0293]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.0293]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.590, train_loss_epoch=3.590, valid_loss=0.0293]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0293]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.0293]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.140, train_loss_epoch=3.140, valid_loss=0.0293]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0293]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0293]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.0293]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0293]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0293]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0293]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.0293]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0293]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0293]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.180, train_loss_epoch=3.180, valid_loss=0.0293]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0293]\n",
            "Epoch 159: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0293]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0293]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.0293]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0293]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.120, train_loss_epoch=3.120, valid_loss=0.0293]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.0293]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0293]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0293]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.200, train_loss_epoch=3.200, valid_loss=0.0293]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0293]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0293]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0293]\n",
            "Epoch 170: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0293]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0293]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0293]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.0293]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.0293]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.030, train_loss_epoch=3.030, valid_loss=0.0293]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.020, train_loss_epoch=3.020, valid_loss=0.0293]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.0293]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0293]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.0293]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0293]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0293]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.0293]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0293]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.0293]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0293]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.0293]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0293]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0293]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0293]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.0293]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0293]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0293]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0293]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0293]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.0293]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0293]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0293]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0293]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.0293]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.760, valid_loss=0.0293]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 138.54it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0182]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0182]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0182]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0182]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0182]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0182]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0182]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0182]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0182]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0182]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0182]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0182]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.0182]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0182]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0182]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0182]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.980, train_loss_epoch=2.980, valid_loss=0.0182]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0182]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0182]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.0182]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0182]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0182]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.0182]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0182]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0182]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0182]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0182]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0182]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.0182]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0182]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0182]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.0182]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0182]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0182]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.0182]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0182]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.0182]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.0182]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.0182]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.0182]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0182]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0182]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0182]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0182]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0182]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0182]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0182]\n",
            "Epoch 246: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0182]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0182]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0182]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0182]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0182]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0182]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0182]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0182]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0182]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0182]\n",
            "Epoch 255: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.400, valid_loss=0.0182]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0182]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0182]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0182]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0182]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0182]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0182]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0182]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0182]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0182]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0182]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0182]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0182]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0182]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.0182]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.0182]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0182]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.0182]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0182]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.0182]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0182]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0182]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.0182]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0182]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0182]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0182]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0182]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0182]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.0182]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0182]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0182]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0182]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0182]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.0182]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0182]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0182]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0182]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.0182]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0182]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0182]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.0182]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0182]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0182]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0182]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0182]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.500, valid_loss=0.0182]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.81it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.0131]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0131]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0131]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0131]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0131]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0131]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0131]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0131]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0131]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0131]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0131]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0131]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0131]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0131]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.0131]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0131]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0131]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0131]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.0131]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0131]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0131]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0131]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.0131]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0131]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.0131]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0131]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0131]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0131]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0131]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0131]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.0131]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0131]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0131]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0131]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0131]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0131]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0131]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0131]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0131]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0131]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0131]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0131]\n",
            "Epoch 341: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.0131]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.990, train_loss_epoch=2.990, valid_loss=0.0131]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0131]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0131]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0131]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0131]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0131]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0131]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0131]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0131]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0131]\n",
            "Epoch 351: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.650, valid_loss=0.0131]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0131]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0131]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0131]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.0131]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0131]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0131]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0131]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0131]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.010, train_loss_epoch=3.010, valid_loss=0.0131]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0131]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0131]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.0131]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0131]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0131]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0131]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.0131]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0131]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0131]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0131]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0131]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0131]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0131]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0131]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0131]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0131]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0131]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.0131]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0131]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0131]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0131]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0131]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.0131]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0131]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0131]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0131]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0131]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0131]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.0131]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0131]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0131]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0131]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0131]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0131]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0131]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0131]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0131]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.0131]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0131]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.510, valid_loss=0.0131]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 146.28it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0141]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0141]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0141]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0141]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.0141]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0141]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0141]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0141]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0141]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0141]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0141]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0141]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0141]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0141]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0141]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0141]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0141]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0141]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0141]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0141]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0141]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0141]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0141]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0141]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0141]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.0141]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0141]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0141]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0141]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0141]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0141]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0141]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.0141]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0141]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.0141]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0141]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0141]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0141]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0141]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0141]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0141]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0141]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0141]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0141]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0141]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0141]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0141]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.0141]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0141]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0141]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0141]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0141]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0141]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0141]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.0141]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0141]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0141]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0141]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0141]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0141]\n",
            "Epoch 459: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.250, valid_loss=0.0141]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0141]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0141]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0141]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0141]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0141]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0141]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0141]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0141]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0141]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0141]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0141]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0141]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0141]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.0141]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0141]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0141]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0141]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.0141]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0141]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0141]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0141]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0141]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0141]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0141]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.0141]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0141]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0141]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0141]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.0141]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.0141]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0141]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0141]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0141]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0141]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0141]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0141]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0141]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.0141]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0141]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0141]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:00<00:00,  1.64it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.630, valid_loss=0.0141]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.68it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0128]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0128]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0128]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0128]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0128]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0128]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0128]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0128]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0128]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.0128]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0128]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.0128]\n",
            "Epoch 511: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0128]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0128]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0128]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0128]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0128]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0128]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0128]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0128]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0128]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.0128]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0128]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0128]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0128]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0128]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0128]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.090, train_loss_epoch=2.090, valid_loss=0.0128]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.0128]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0128]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0128]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0128]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0128]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0128]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0128]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0128]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0128]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0128]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0128]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0128]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.0128]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0128]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.0128]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0128]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.0128]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0128]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0128]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0128]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0128]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0128]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.0128]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0128]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.0128]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0128]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 554: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0128]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.0128]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.0128]\n",
            "Epoch 557: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0128]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0128]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0128]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0128]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0128]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.0128]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0128]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0128]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0128]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0128]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0128]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0128]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.0128]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0128]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0128]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0128]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0128]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0128]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0128]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0128]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0128]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0128]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0128]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0128]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.0128]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0128]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.0128]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.0128]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.940, train_loss_epoch=2.940, valid_loss=0.0128]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0128]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0128]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0128]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0128]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0128]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m =2.240, train_loss_epoch=2.240, valid_loss=0.0128]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0128]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0128]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0128]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0128]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0128]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0128]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0128]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:00<00:00,  1.57it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.450, valid_loss=0.0128]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.75it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0128]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0128]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0128]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.0128]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.0128]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0128]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0128]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0128]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0128]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0128]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.0128]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0128]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.0128]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0128]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.0128]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0128]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.0128]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0128]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0128]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.0128]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0128]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0128]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.0128]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0128]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0128]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0128]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0128]\n",
            "Epoch 627: 100%|██████████| 1/1 [00:00<00:00,  1.63it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0128]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0128]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0128]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0128]\n",
            "Epoch 630: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0128]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0128]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0128]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0128]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0128]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0128]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0128]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0128]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0128]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0128]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0128]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0128]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.0128]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0128]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.0128]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0128]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0128]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0128]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.0128]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0128]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0128]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0128]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0128]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.0128]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0128]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0128]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0128]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0128]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.950, train_loss_epoch=2.950, valid_loss=0.0128]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0128]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0128]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.0128]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0128]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0128]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.0128]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0128]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0128]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0128]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0128]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.090, train_loss_epoch=3.090, valid_loss=0.0128]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0128]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0128]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0128]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.0128]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0128]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0128]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0128]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0128]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0128]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0128]\n",
            "Epoch 681: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0128]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0128]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.0128]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0128]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0128]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0128]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0128]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0128]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0128]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.0128]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.0128]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0128]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.0128]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.080, train_loss_epoch=3.080, valid_loss=0.0128]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0128]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0128]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0128]        \n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0128]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0128]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.0128]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=1.970, valid_loss=0.0128]\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 88.98it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.0129]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0129]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0129]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.0129]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0129]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.0129]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.0129]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0129]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.0129]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0129]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.0129]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0129]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.0129]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0129]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0129]\n",
            "Epoch 714: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0129]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.0129]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.0129]\n",
            "Epoch 716: 100%|██████████| 1/1 [00:00<00:00,  2.39it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0129]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.0129]\n",
            "Epoch 717: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.590, valid_loss=0.0129]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.0129]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0129]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0129]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0129]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.0129]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0129]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.0129]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0129]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0129]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0129]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0129]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.0129]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0129]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.0129]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0129]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.0129]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.0129]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.0129]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0129]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0129]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0129]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.0129]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0129]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0129]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0129]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0129]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0129]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0129]\n",
            "Epoch 745: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0129]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.0129]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0129]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.0129]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.0129]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.0129]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.0129]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0129]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0129]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0129]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0129]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0129]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0129]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.0129]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.0129]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0129]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0129]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.0129]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.0129]\n",
            "Epoch 763: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.770, valid_loss=0.0129]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.0129]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.0129]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0129]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0129]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.0129]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.890, train_loss_epoch=2.890, valid_loss=0.0129]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.0129]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0129]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.0129]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.0129]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.0129]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.0129]\n",
            "Epoch 775: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0129]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.0129]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.0129]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0129]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.0129]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.0129]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.0129]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.0129]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.0129]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.0129]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.0129]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0129]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0129]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.0129]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.0129]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.0129]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.0129]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.0129]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.0129]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.0129]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.0129]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.0129]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.0129]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.280, train_loss_epoch=2.280, valid_loss=0.0129]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-15 22:25:22,256\tINFO tensorboardx.py:308 -- Removed the following hyperparameter values when logging to tensorboard: {'hist_exog_list': ('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7'), 'loss': ('__ref_ph', 'de895953'), 'n_freq_downsample': (180, 60, 1), 'n_pool_kernel_size': (2, 2, 1), 'valid_loss': ('__ref_ph', '004b9a7a')}\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m `Trainer.fit` stopped: `max_steps=800.0` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.0129]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.10it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.600, valid_loss=0.0129]\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \rValidation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \rValidation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \rValidation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \rValidation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 132.68it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=75000)\u001b[0m \r                                                                       \u001b[A\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.600, valid_loss=0.0128]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.02it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0128]\rEpoch 799: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s, v_num=0, train_loss_step=2.960, train_loss_epoch=2.960, valid_loss=0.0128]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_train_tune pid=76677)\u001b[0m /usr/local/lib/python3.11/dist-packages/ray/tune/integration/pytorch_lightning.py:198: `ray.tune.integration.pytorch_lightning.TuneReportCallback` is deprecated. Use `ray.tune.integration.pytorch_lightning.TuneReportCheckpointCallback` instead.\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m Seed set to 78\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m GPU available: False, used: False\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m TPU available: False, using: 0 TPU cores\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m HPU available: False, using: 0 HPUs\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 2025-06-15 22:25:37.353519: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m E0000 00:00:1750026337.386959   76777 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m E0000 00:00:1750026337.396333   76777 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 2025-06-15 22:25:37.427401: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m \n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m   | Name         | Type          | Params | Mode \n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 0 | loss         | MAE           | 0      | train\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 1 | padder_train | ConstantPad1d | 0      | train\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 2 | scaler       | TemporalNorm  | 0      | train\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 3 | blocks       | ModuleList    | 11.6 M | train\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m -------------------------------------------------------\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 11.6 M    Trainable params\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 0         Non-trainable params\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 11.6 M    Total params\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 46.264    Total estimated model params size (MB)\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 34        Modules in train mode\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m 0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] \n",
            "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.40, train_loss_epoch=34.40]\n",
            "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=36.50, train_loss_epoch=36.50]\n",
            "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=38.30, train_loss_epoch=38.30]\n",
            "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=31.80, train_loss_epoch=31.80]\n",
            "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=34.70, train_loss_epoch=34.70]\n",
            "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=32.60, train_loss_epoch=32.60]\n",
            "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=29.40, train_loss_epoch=29.40]\n",
            "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=27.80, train_loss_epoch=27.80]\n",
            "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.80, train_loss_epoch=28.80]\n",
            "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.30, train_loss_epoch=28.30]\n",
            "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=28.60, train_loss_epoch=28.60]\n",
            "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.90, train_loss_epoch=26.90]\n",
            "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=26.30, train_loss_epoch=26.30]\n",
            "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=25.30, train_loss_epoch=25.30]\n",
            "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.80, train_loss_epoch=23.80]\n",
            "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.10, train_loss_epoch=23.10]\n",
            "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=23.50, train_loss_epoch=23.50]\n",
            "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.40, train_loss_epoch=22.40]\n",
            "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.60, train_loss_epoch=21.60]\n",
            "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.80, train_loss_epoch=21.80]\n",
            "Epoch 21:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.10, train_loss_epoch=21.10]\n",
            "Epoch 22:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=21.40, train_loss_epoch=21.40]\n",
            "Epoch 23:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=22.70, train_loss_epoch=22.70]\n",
            "Epoch 24:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=20.00, train_loss_epoch=20.00]\n",
            "Epoch 25:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 26:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.90, train_loss_epoch=19.90]\n",
            "Epoch 27:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 28:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.20, train_loss_epoch=19.20]\n",
            "Epoch 29:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.80, train_loss_epoch=18.80]\n",
            "Epoch 30:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=19.50, train_loss_epoch=19.50]\n",
            "Epoch 31:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.30, train_loss_epoch=18.30]\n",
            "Epoch 32:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=18.50, train_loss_epoch=18.50]\n",
            "Epoch 33:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.10, train_loss_epoch=17.10]\n",
            "Epoch 34:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.60, train_loss_epoch=17.60]\n",
            "Epoch 35:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.20, train_loss_epoch=17.20]\n",
            "Epoch 36:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.40, train_loss_epoch=16.40]\n",
            "Epoch 37:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.90, train_loss_epoch=16.90]\n",
            "Epoch 38:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=17.00, train_loss_epoch=17.00]\n",
            "Epoch 39:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=16.30, train_loss_epoch=16.30]\n",
            "Epoch 40:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.80, train_loss_epoch=15.80]\n",
            "Epoch 41:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]\n",
            "Epoch 42:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.50, train_loss_epoch=15.50]\n",
            "Epoch 43:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.40, train_loss_epoch=15.40]\n",
            "Epoch 44:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.30, train_loss_epoch=15.30]\n",
            "Epoch 45:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.60, train_loss_epoch=15.60]\n",
            "Epoch 46:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.40, train_loss_epoch=14.40]\n",
            "Epoch 47:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.20, train_loss_epoch=14.20]\n",
            "Epoch 48:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=15.00, train_loss_epoch=15.00]\n",
            "Epoch 49:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 50:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=14.00, train_loss_epoch=14.00]\n",
            "Epoch 51:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 52:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.30, train_loss_epoch=13.30]\n",
            "Epoch 53:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.90, train_loss_epoch=13.90]\n",
            "Epoch 54:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 55:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.70, train_loss_epoch=12.70]\n",
            "Epoch 56:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.90, train_loss_epoch=12.90]\n",
            "Epoch 57:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.00, train_loss_epoch=13.00]\n",
            "Epoch 58:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=13.10, train_loss_epoch=13.10]\n",
            "Epoch 59:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.40, train_loss_epoch=12.40]\n",
            "Epoch 60:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.60, train_loss_epoch=12.60]\n",
            "Epoch 61:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.20, train_loss_epoch=12.20]\n",
            "Epoch 62:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=12.00, train_loss_epoch=12.00]\n",
            "Epoch 63:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90]\n",
            "Epoch 64:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 65:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70]\n",
            "Epoch 66:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10]\n",
            "Epoch 67:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.50, train_loss_epoch=11.50]\n",
            "Epoch 68:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.90, train_loss_epoch=11.90]\n",
            "Epoch 69:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10]\n",
            "Epoch 70:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 71:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.60, train_loss_epoch=10.60]\n",
            "Epoch 72:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 73:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 74:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.10, train_loss_epoch=10.10]\n",
            "Epoch 75:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.60, train_loss_epoch=11.60]\n",
            "Epoch 76:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 77:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.50, train_loss_epoch=10.50]\n",
            "Epoch 78:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.70, train_loss_epoch=11.70]\n",
            "Epoch 79:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.00, train_loss_epoch=10.00]\n",
            "Epoch 80:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.10, train_loss_epoch=11.10]\n",
            "Epoch 81:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=11.40, train_loss_epoch=11.40]\n",
            "Epoch 82:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.940, train_loss_epoch=9.940]\n",
            "Epoch 82: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=9.940]\n",
            "Epoch 83:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.90, train_loss_epoch=10.90]\n",
            "Epoch 84:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=10.30, train_loss_epoch=10.30]\n",
            "Epoch 85:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.930, train_loss_epoch=9.930]\n",
            "Epoch 86:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.470, train_loss_epoch=9.470]\n",
            "Epoch 87:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=9.150]\n",
            "Epoch 88:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.760, train_loss_epoch=9.760]\n",
            "Epoch 89:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.520, train_loss_epoch=9.520]\n",
            "Epoch 90:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.550, train_loss_epoch=8.550]\n",
            "Epoch 91:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.710, train_loss_epoch=8.710]\n",
            "Epoch 92:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.950, train_loss_epoch=8.950]\n",
            "Epoch 93:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.870, train_loss_epoch=8.870]\n",
            "Epoch 94:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.040, train_loss_epoch=9.040]\n",
            "Epoch 95:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.150, train_loss_epoch=9.150]\n",
            "Epoch 96:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.600, train_loss_epoch=8.600]\n",
            "Epoch 97:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.690, train_loss_epoch=8.690]\n",
            "Epoch 98:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.270, train_loss_epoch=8.270]\n",
            "Epoch 99:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.520, train_loss_epoch=8.520]\n",
            "Epoch 99: 100%|██████████| 1/1 [00:01<00:00,  0.89it/s, v_num=0, train_loss_step=9.030, train_loss_epoch=8.520]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.32it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m \n",
            "Epoch 100:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=9.030, train_loss_epoch=9.030, valid_loss=0.00401]\n",
            "Epoch 101:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.440, train_loss_epoch=8.440, valid_loss=0.00401]\n",
            "Epoch 102:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.490, train_loss_epoch=8.490, valid_loss=0.00401]\n",
            "Epoch 103:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.480, train_loss_epoch=8.480, valid_loss=0.00401]\n",
            "Epoch 104:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.330, train_loss_epoch=8.330, valid_loss=0.00401]\n",
            "Epoch 105:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.580, train_loss_epoch=8.580, valid_loss=0.00401]\n",
            "Epoch 106:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.550, train_loss_epoch=8.550, valid_loss=0.00401]\n",
            "Epoch 107:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.310, train_loss_epoch=8.310, valid_loss=0.00401]\n",
            "Epoch 108:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.530, train_loss_epoch=8.530, valid_loss=0.00401]\n",
            "Epoch 109:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.840, train_loss_epoch=8.840, valid_loss=0.00401]\n",
            "Epoch 110:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.000, train_loss_epoch=8.000, valid_loss=0.00401]\n",
            "Epoch 111:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.340, train_loss_epoch=8.340, valid_loss=0.00401]\n",
            "Epoch 111: 100%|██████████| 1/1 [00:01<00:00,  0.87it/s, v_num=0, train_loss_step=8.420, train_loss_epoch=8.340, valid_loss=0.00401]\n",
            "Epoch 112:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.420, train_loss_epoch=8.420, valid_loss=0.00401]\n",
            "Epoch 113:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.630, train_loss_epoch=7.630, valid_loss=0.00401]\n",
            "Epoch 114:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.480, train_loss_epoch=8.480, valid_loss=0.00401]\n",
            "Epoch 115:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.890, train_loss_epoch=7.890, valid_loss=0.00401]\n",
            "Epoch 116:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.320, train_loss_epoch=8.320, valid_loss=0.00401]\n",
            "Epoch 117:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.800, train_loss_epoch=7.800, valid_loss=0.00401]\n",
            "Epoch 118:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.400, train_loss_epoch=8.400, valid_loss=0.00401]\n",
            "Epoch 119:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.030, train_loss_epoch=8.030, valid_loss=0.00401]\n",
            "Epoch 120:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.120, train_loss_epoch=8.120, valid_loss=0.00401]\n",
            "Epoch 121:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.510, train_loss_epoch=7.510, valid_loss=0.00401]\n",
            "Epoch 122:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=8.430, train_loss_epoch=8.430, valid_loss=0.00401]\n",
            "Epoch 123:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.00401]\n",
            "Epoch 124:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.750, train_loss_epoch=7.750, valid_loss=0.00401]\n",
            "Epoch 125:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.480, train_loss_epoch=7.480, valid_loss=0.00401]\n",
            "Epoch 126:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00401]\n",
            "Epoch 127:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.020, train_loss_epoch=7.020, valid_loss=0.00401]\n",
            "Epoch 128:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.410, train_loss_epoch=7.410, valid_loss=0.00401]\n",
            "Epoch 129:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.170, train_loss_epoch=7.170, valid_loss=0.00401]\n",
            "Epoch 130:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.370, train_loss_epoch=7.370, valid_loss=0.00401]\n",
            "Epoch 131:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460, valid_loss=0.00401]\n",
            "Epoch 132:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.060, train_loss_epoch=7.060, valid_loss=0.00401]\n",
            "Epoch 133:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.580, train_loss_epoch=7.580, valid_loss=0.00401]\n",
            "Epoch 134:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.300, train_loss_epoch=7.300, valid_loss=0.00401]\n",
            "Epoch 135:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.760, train_loss_epoch=7.760, valid_loss=0.00401]\n",
            "Epoch 136:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.090, train_loss_epoch=7.090, valid_loss=0.00401]\n",
            "Epoch 137:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.560, train_loss_epoch=7.560, valid_loss=0.00401]\n",
            "Epoch 138:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.840, train_loss_epoch=7.840, valid_loss=0.00401]\n",
            "Epoch 139:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.510, train_loss_epoch=7.510, valid_loss=0.00401]\n",
            "Epoch 140:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.00401]\n",
            "Epoch 141:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.780, train_loss_epoch=6.780, valid_loss=0.00401]\n",
            "Epoch 142:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.600, train_loss_epoch=7.600, valid_loss=0.00401]\n",
            "Epoch 143:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.480, train_loss_epoch=7.480, valid_loss=0.00401]\n",
            "Epoch 144:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.910, train_loss_epoch=6.910, valid_loss=0.00401]\n",
            "Epoch 145:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.710, train_loss_epoch=6.710, valid_loss=0.00401]\n",
            "Epoch 146:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.010, train_loss_epoch=7.010, valid_loss=0.00401]\n",
            "Epoch 147:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.440, train_loss_epoch=6.440, valid_loss=0.00401]\n",
            "Epoch 148:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.820, train_loss_epoch=6.820, valid_loss=0.00401]\n",
            "Epoch 149:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.650, train_loss_epoch=6.650, valid_loss=0.00401]\n",
            "Epoch 150:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.420, train_loss_epoch=6.420, valid_loss=0.00401]\n",
            "Epoch 151:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.660, train_loss_epoch=6.660, valid_loss=0.00401]\n",
            "Epoch 152:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.700, train_loss_epoch=6.700, valid_loss=0.00401]\n",
            "Epoch 153:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.620, train_loss_epoch=7.620, valid_loss=0.00401]\n",
            "Epoch 154:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.640, train_loss_epoch=7.640, valid_loss=0.00401]\n",
            "Epoch 155:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.950, train_loss_epoch=6.950, valid_loss=0.00401]\n",
            "Epoch 156:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.310, train_loss_epoch=7.310, valid_loss=0.00401]\n",
            "Epoch 157:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.110, train_loss_epoch=6.110, valid_loss=0.00401]\n",
            "Epoch 158:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.460, train_loss_epoch=7.460, valid_loss=0.00401]\n",
            "Epoch 159:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.790, train_loss_epoch=6.790, valid_loss=0.00401]\n",
            "Epoch 160:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.330, train_loss_epoch=7.330, valid_loss=0.00401]\n",
            "Epoch 161:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.600, train_loss_epoch=6.600, valid_loss=0.00401]\n",
            "Epoch 162:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.440, train_loss_epoch=7.440, valid_loss=0.00401]\n",
            "Epoch 163:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.760, train_loss_epoch=6.760, valid_loss=0.00401]\n",
            "Epoch 164:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.280, train_loss_epoch=7.280, valid_loss=0.00401]\n",
            "Epoch 165:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.860, train_loss_epoch=6.860, valid_loss=0.00401]\n",
            "Epoch 166:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.010, train_loss_epoch=7.010, valid_loss=0.00401]\n",
            "Epoch 167:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.470, train_loss_epoch=7.470, valid_loss=0.00401]\n",
            "Epoch 168:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.380, train_loss_epoch=7.380, valid_loss=0.00401]\n",
            "Epoch 169:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.840, train_loss_epoch=6.840, valid_loss=0.00401]\n",
            "Epoch 170:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.080, train_loss_epoch=7.080, valid_loss=0.00401]\n",
            "Epoch 171:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.620, train_loss_epoch=6.620, valid_loss=0.00401]\n",
            "Epoch 172:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.600, train_loss_epoch=6.600, valid_loss=0.00401]\n",
            "Epoch 173:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.960, train_loss_epoch=6.960, valid_loss=0.00401]\n",
            "Epoch 174:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.790, train_loss_epoch=7.790, valid_loss=0.00401]\n",
            "Epoch 175:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.930, train_loss_epoch=6.930, valid_loss=0.00401]\n",
            "Epoch 176:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.00401]\n",
            "Epoch 177:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.150, train_loss_epoch=7.150, valid_loss=0.00401]\n",
            "Epoch 178:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.560, train_loss_epoch=6.560, valid_loss=0.00401]\n",
            "Epoch 179:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.070, train_loss_epoch=7.070, valid_loss=0.00401]\n",
            "Epoch 180:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.640, train_loss_epoch=6.640, valid_loss=0.00401]\n",
            "Epoch 181:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.280, train_loss_epoch=7.280, valid_loss=0.00401]\n",
            "Epoch 182:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.590, train_loss_epoch=6.590, valid_loss=0.00401]\n",
            "Epoch 183:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.390, train_loss_epoch=6.390, valid_loss=0.00401]\n",
            "Epoch 184:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.660, train_loss_epoch=7.660, valid_loss=0.00401]\n",
            "Epoch 185:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.420, train_loss_epoch=7.420, valid_loss=0.00401]\n",
            "Epoch 186:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.060, train_loss_epoch=7.060, valid_loss=0.00401]\n",
            "Epoch 187:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.760, train_loss_epoch=6.760, valid_loss=0.00401]\n",
            "Epoch 188:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=7.370, train_loss_epoch=7.370, valid_loss=0.00401]\n",
            "Epoch 189:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.670, train_loss_epoch=6.670, valid_loss=0.00401]\n",
            "Epoch 190:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.660, train_loss_epoch=6.660, valid_loss=0.00401]\n",
            "Epoch 191:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.880, train_loss_epoch=6.880, valid_loss=0.00401]\n",
            "Epoch 192:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.500, train_loss_epoch=6.500, valid_loss=0.00401]\n",
            "Epoch 193:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.770, train_loss_epoch=6.770, valid_loss=0.00401]\n",
            "Epoch 194:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.650, train_loss_epoch=6.650, valid_loss=0.00401]\n",
            "Epoch 195:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.460, train_loss_epoch=6.460, valid_loss=0.00401]\n",
            "Epoch 196:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.330, train_loss_epoch=6.330, valid_loss=0.00401]\n",
            "Epoch 197:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.00401]\n",
            "Epoch 198:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.760, train_loss_epoch=6.760, valid_loss=0.00401]\n",
            "Epoch 199:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.070, train_loss_epoch=6.070, valid_loss=0.00401]\n",
            "Epoch 199: 100%|██████████| 1/1 [00:01<00:00,  0.87it/s, v_num=0, train_loss_step=6.420, train_loss_epoch=6.070, valid_loss=0.00401]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.37it/s]\u001b[A\n",
            "Epoch 200:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.420, train_loss_epoch=6.420, valid_loss=0.00248]\n",
            "Epoch 201:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.980, train_loss_epoch=5.980, valid_loss=0.00248]\n",
            "Epoch 202:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.00248]\n",
            "Epoch 203:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.00248]\n",
            "Epoch 204:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.010, train_loss_epoch=6.010, valid_loss=0.00248]\n",
            "Epoch 205:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.100, train_loss_epoch=6.100, valid_loss=0.00248]\n",
            "Epoch 206:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.900, train_loss_epoch=5.900, valid_loss=0.00248]\n",
            "Epoch 207:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.00248]\n",
            "Epoch 208:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.150, train_loss_epoch=6.150, valid_loss=0.00248]\n",
            "Epoch 209:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.060, train_loss_epoch=6.060, valid_loss=0.00248]\n",
            "Epoch 210:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.250, train_loss_epoch=6.250, valid_loss=0.00248]\n",
            "Epoch 211:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.670, train_loss_epoch=6.670, valid_loss=0.00248]\n",
            "Epoch 212:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.680, train_loss_epoch=5.680, valid_loss=0.00248]\n",
            "Epoch 213:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.380, train_loss_epoch=6.380, valid_loss=0.00248]\n",
            "Epoch 214:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.900, train_loss_epoch=5.900, valid_loss=0.00248]\n",
            "Epoch 215:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.280, train_loss_epoch=6.280, valid_loss=0.00248]\n",
            "Epoch 216:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.440, train_loss_epoch=5.440, valid_loss=0.00248]\n",
            "Epoch 217:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.880, train_loss_epoch=5.880, valid_loss=0.00248]\n",
            "Epoch 218:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.120, train_loss_epoch=6.120, valid_loss=0.00248]\n",
            "Epoch 219:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.850, train_loss_epoch=5.850, valid_loss=0.00248]\n",
            "Epoch 220:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.520, train_loss_epoch=5.520, valid_loss=0.00248]\n",
            "Epoch 221:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.390, train_loss_epoch=5.390, valid_loss=0.00248]\n",
            "Epoch 222:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.890, train_loss_epoch=5.890, valid_loss=0.00248]\n",
            "Epoch 223:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.410, train_loss_epoch=5.410, valid_loss=0.00248]\n",
            "Epoch 224:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.970, train_loss_epoch=5.970, valid_loss=0.00248]\n",
            "Epoch 225:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00248]\n",
            "Epoch 226:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.760, train_loss_epoch=5.760, valid_loss=0.00248]\n",
            "Epoch 227:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.640, train_loss_epoch=5.640, valid_loss=0.00248]\n",
            "Epoch 228:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.170, train_loss_epoch=5.170, valid_loss=0.00248]\n",
            "Epoch 229:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.510, train_loss_epoch=5.510, valid_loss=0.00248]\n",
            "Epoch 230:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00248]\n",
            "Epoch 231:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.560, train_loss_epoch=5.560, valid_loss=0.00248]\n",
            "Epoch 232:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.480, train_loss_epoch=5.480, valid_loss=0.00248]\n",
            "Epoch 233:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=0.00248]\n",
            "Epoch 234:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.030, train_loss_epoch=6.030, valid_loss=0.00248]\n",
            "Epoch 235:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.620, train_loss_epoch=5.620, valid_loss=0.00248]\n",
            "Epoch 236:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.550, train_loss_epoch=5.550, valid_loss=0.00248]\n",
            "Epoch 237:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.680, train_loss_epoch=5.680, valid_loss=0.00248]\n",
            "Epoch 238:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=0.00248]\n",
            "Epoch 239:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.710, train_loss_epoch=5.710, valid_loss=0.00248]\n",
            "Epoch 240:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.270, train_loss_epoch=5.270, valid_loss=0.00248]\n",
            "Epoch 241:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.820, train_loss_epoch=5.820, valid_loss=0.00248]\n",
            "Epoch 242:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=0.00248]\n",
            "Epoch 243:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.450, train_loss_epoch=5.450, valid_loss=0.00248]\n",
            "Epoch 244:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.550, train_loss_epoch=5.550, valid_loss=0.00248]\n",
            "Epoch 245:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780, valid_loss=0.00248]\n",
            "Epoch 246:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00248]\n",
            "Epoch 247:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.330, train_loss_epoch=5.330, valid_loss=0.00248]\n",
            "Epoch 248:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00248]\n",
            "Epoch 249:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.00248]\n",
            "Epoch 250:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.710, train_loss_epoch=4.710, valid_loss=0.00248]\n",
            "Epoch 251:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.840, train_loss_epoch=5.840, valid_loss=0.00248]\n",
            "Epoch 252:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.920, train_loss_epoch=4.920, valid_loss=0.00248]\n",
            "Epoch 253:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.800, train_loss_epoch=5.800, valid_loss=0.00248]\n",
            "Epoch 254:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00248]\n",
            "Epoch 255:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.780, train_loss_epoch=5.780, valid_loss=0.00248]\n",
            "Epoch 256:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.730, train_loss_epoch=5.730, valid_loss=0.00248]\n",
            "Epoch 257:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.260, train_loss_epoch=6.260, valid_loss=0.00248]\n",
            "Epoch 258:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.490, valid_loss=0.00248]\n",
            "Epoch 259:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.900, train_loss_epoch=5.900, valid_loss=0.00248]\n",
            "Epoch 260:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.960, train_loss_epoch=5.960, valid_loss=0.00248]\n",
            "Epoch 261:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.770, train_loss_epoch=5.770, valid_loss=0.00248]\n",
            "Epoch 262:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.000, train_loss_epoch=6.000, valid_loss=0.00248]\n",
            "Epoch 263:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.090, train_loss_epoch=6.090, valid_loss=0.00248]\n",
            "Epoch 264:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.140, train_loss_epoch=5.140, valid_loss=0.00248]\n",
            "Epoch 265:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=6.520, train_loss_epoch=6.520, valid_loss=0.00248]\n",
            "Epoch 266:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.810, train_loss_epoch=5.810, valid_loss=0.00248]\n",
            "Epoch 267:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.990, train_loss_epoch=5.990, valid_loss=0.00248]\n",
            "Epoch 268:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.850, train_loss_epoch=5.850, valid_loss=0.00248]\n",
            "Epoch 269:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.690, train_loss_epoch=5.690, valid_loss=0.00248]\n",
            "Epoch 270:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.670, train_loss_epoch=5.670, valid_loss=0.00248]\n",
            "Epoch 271:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.300, train_loss_epoch=5.300, valid_loss=0.00248]\n",
            "Epoch 272:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.580, train_loss_epoch=5.580, valid_loss=0.00248]\n",
            "Epoch 273:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=0.00248]\n",
            "Epoch 274:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.660, train_loss_epoch=5.660, valid_loss=0.00248]\n",
            "Epoch 275:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=4.840, valid_loss=0.00248]\n",
            "Epoch 276:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090, valid_loss=0.00248]\n",
            "Epoch 277:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.280, train_loss_epoch=5.280, valid_loss=0.00248]\n",
            "Epoch 277: 100%|██████████| 1/1 [00:01<00:00,  0.91it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=0.00248]\n",
            "Epoch 278:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.200, train_loss_epoch=5.200, valid_loss=0.00248]\n",
            "Epoch 279:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.180, train_loss_epoch=5.180, valid_loss=0.00248]\n",
            "Epoch 280:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.540, train_loss_epoch=5.540, valid_loss=0.00248]\n",
            "Epoch 281:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.210, train_loss_epoch=5.210, valid_loss=0.00248]\n",
            "Epoch 282:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.650, train_loss_epoch=4.650, valid_loss=0.00248]\n",
            "Epoch 283:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.140, train_loss_epoch=5.140, valid_loss=0.00248]\n",
            "Epoch 284:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.070, train_loss_epoch=5.070, valid_loss=0.00248]\n",
            "Epoch 285:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.160, train_loss_epoch=5.160, valid_loss=0.00248]\n",
            "Epoch 286:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.150, train_loss_epoch=5.150, valid_loss=0.00248]\n",
            "Epoch 287:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.500, train_loss_epoch=5.500, valid_loss=0.00248]\n",
            "Epoch 288:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.840, train_loss_epoch=5.840, valid_loss=0.00248]\n",
            "Epoch 289:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.300, train_loss_epoch=5.300, valid_loss=0.00248]\n",
            "Epoch 290:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.430, train_loss_epoch=5.430, valid_loss=0.00248]\n",
            "Epoch 291:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.930, train_loss_epoch=4.930, valid_loss=0.00248]\n",
            "Epoch 292:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.690, train_loss_epoch=5.690, valid_loss=0.00248]\n",
            "Epoch 293:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.490, train_loss_epoch=5.490, valid_loss=0.00248]\n",
            "Epoch 294:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.550, train_loss_epoch=5.550, valid_loss=0.00248]\n",
            "Epoch 295:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.590, train_loss_epoch=5.590, valid_loss=0.00248]\n",
            "Epoch 296:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.130, train_loss_epoch=5.130, valid_loss=0.00248]\n",
            "Epoch 297:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.810, train_loss_epoch=4.810, valid_loss=0.00248]\n",
            "Epoch 298:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.990, train_loss_epoch=4.990, valid_loss=0.00248]\n",
            "Epoch 299:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.190, valid_loss=0.00248]\n",
            "Epoch 299: 100%|██████████| 1/1 [00:01<00:00,  0.91it/s, v_num=0, train_loss_step=5.260, train_loss_epoch=5.190, valid_loss=0.00248]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\u001b[36m(_train_tune pid=76677)\u001b[0m \n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 69.67it/s]\u001b[A\n",
            "Epoch 300:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.260, train_loss_epoch=5.260, valid_loss=0.00403]\n",
            "Epoch 301:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.180, train_loss_epoch=5.180, valid_loss=0.00403]\n",
            "Epoch 302:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.700, train_loss_epoch=4.700, valid_loss=0.00403]\n",
            "Epoch 303:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=0.00403]\n",
            "Epoch 304:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.750, train_loss_epoch=4.750, valid_loss=0.00403]\n",
            "Epoch 305:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.910, train_loss_epoch=4.910, valid_loss=0.00403]\n",
            "Epoch 306:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.680, train_loss_epoch=4.680, valid_loss=0.00403]\n",
            "Epoch 307:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.910, train_loss_epoch=4.910, valid_loss=0.00403]\n",
            "Epoch 308:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.570, train_loss_epoch=4.570, valid_loss=0.00403]\n",
            "Epoch 309:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=0.00403]\n",
            "Epoch 310:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.600, train_loss_epoch=4.600, valid_loss=0.00403]\n",
            "Epoch 311:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.490, train_loss_epoch=4.490, valid_loss=0.00403]\n",
            "Epoch 312:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.600, train_loss_epoch=4.600, valid_loss=0.00403]\n",
            "Epoch 313:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.330, train_loss_epoch=4.330, valid_loss=0.00403]\n",
            "Epoch 314:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.530, train_loss_epoch=4.530, valid_loss=0.00403]\n",
            "Epoch 315:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.710, train_loss_epoch=4.710, valid_loss=0.00403]\n",
            "Epoch 316:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.590, train_loss_epoch=4.590, valid_loss=0.00403]\n",
            "Epoch 317:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.750, train_loss_epoch=4.750, valid_loss=0.00403]\n",
            "Epoch 318:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.140, train_loss_epoch=5.140, valid_loss=0.00403]\n",
            "Epoch 319:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.620, train_loss_epoch=4.620, valid_loss=0.00403]\n",
            "Epoch 320:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.220, train_loss_epoch=5.220, valid_loss=0.00403]\n",
            "Epoch 321:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.520, train_loss_epoch=4.520, valid_loss=0.00403]\n",
            "Epoch 322:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.250, train_loss_epoch=5.250, valid_loss=0.00403]\n",
            "Epoch 323:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.530, train_loss_epoch=4.530, valid_loss=0.00403]\n",
            "Epoch 324:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.350, train_loss_epoch=5.350, valid_loss=0.00403]\n",
            "Epoch 325:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.760, train_loss_epoch=4.760, valid_loss=0.00403]\n",
            "Epoch 326:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.170, train_loss_epoch=5.170, valid_loss=0.00403]\n",
            "Epoch 327:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.560, train_loss_epoch=5.560, valid_loss=0.00403]\n",
            "Epoch 328:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.310, train_loss_epoch=5.310, valid_loss=0.00403]\n",
            "Epoch 329:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.400, train_loss_epoch=5.400, valid_loss=0.00403]\n",
            "Epoch 330:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.670, train_loss_epoch=4.670, valid_loss=0.00403]\n",
            "Epoch 331:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.120, train_loss_epoch=5.120, valid_loss=0.00403]\n",
            "Epoch 332:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.770, train_loss_epoch=4.770, valid_loss=0.00403]\n",
            "Epoch 333:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.880, train_loss_epoch=4.880, valid_loss=0.00403]\n",
            "Epoch 334:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.920, train_loss_epoch=4.920, valid_loss=0.00403]\n",
            "Epoch 335:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.020, train_loss_epoch=5.020, valid_loss=0.00403]\n",
            "Epoch 336:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.950, train_loss_epoch=4.950, valid_loss=0.00403]\n",
            "Epoch 337:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.190, train_loss_epoch=5.190, valid_loss=0.00403]\n",
            "Epoch 338:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.760, train_loss_epoch=4.760, valid_loss=0.00403]\n",
            "Epoch 339:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.060, train_loss_epoch=5.060, valid_loss=0.00403]\n",
            "Epoch 340:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.620, train_loss_epoch=4.620, valid_loss=0.00403]\n",
            "Epoch 341:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=0.00403]\n",
            "Epoch 342:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.470, train_loss_epoch=4.470, valid_loss=0.00403]\n",
            "Epoch 343:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.420, train_loss_epoch=4.420, valid_loss=0.00403]\n",
            "Epoch 344:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.640, train_loss_epoch=4.640, valid_loss=0.00403]\n",
            "Epoch 345:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.320, train_loss_epoch=4.320, valid_loss=0.00403]\n",
            "Epoch 346:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.690, train_loss_epoch=4.690, valid_loss=0.00403]\n",
            "Epoch 347:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.290, train_loss_epoch=4.290, valid_loss=0.00403]\n",
            "Epoch 348:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.750, train_loss_epoch=4.750, valid_loss=0.00403]\n",
            "Epoch 349:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.400, train_loss_epoch=4.400, valid_loss=0.00403]\n",
            "Epoch 350:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.490, train_loss_epoch=4.490, valid_loss=0.00403]\n",
            "Epoch 351:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.110, train_loss_epoch=5.110, valid_loss=0.00403]\n",
            "Epoch 352:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.660, train_loss_epoch=4.660, valid_loss=0.00403]\n",
            "Epoch 353:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.670, train_loss_epoch=4.670, valid_loss=0.00403]\n",
            "Epoch 354:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.500, train_loss_epoch=4.500, valid_loss=0.00403]\n",
            "Epoch 355:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.670, train_loss_epoch=4.670, valid_loss=0.00403]\n",
            "Epoch 356:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.930, train_loss_epoch=4.930, valid_loss=0.00403]\n",
            "Epoch 357:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.290, train_loss_epoch=4.290, valid_loss=0.00403]\n",
            "Epoch 358:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.790, train_loss_epoch=4.790, valid_loss=0.00403]\n",
            "Epoch 359:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.380, train_loss_epoch=4.380, valid_loss=0.00403]\n",
            "Epoch 360:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.350, train_loss_epoch=4.350, valid_loss=0.00403]\n",
            "Epoch 361:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.520, train_loss_epoch=4.520, valid_loss=0.00403]\n",
            "Epoch 362:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.280, train_loss_epoch=4.280, valid_loss=0.00403]\n",
            "Epoch 363:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.400, train_loss_epoch=4.400, valid_loss=0.00403]\n",
            "Epoch 364:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.840, train_loss_epoch=4.840, valid_loss=0.00403]\n",
            "Epoch 365:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.780, train_loss_epoch=4.780, valid_loss=0.00403]\n",
            "Epoch 366:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.930, train_loss_epoch=4.930, valid_loss=0.00403]\n",
            "Epoch 367:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=5.090, train_loss_epoch=5.090, valid_loss=0.00403]\n",
            "Epoch 368:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.020, train_loss_epoch=4.020, valid_loss=0.00403]\n",
            "Epoch 369:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.330, train_loss_epoch=4.330, valid_loss=0.00403]\n",
            "Epoch 370:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.520, train_loss_epoch=4.520, valid_loss=0.00403]\n",
            "Epoch 371:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.680, train_loss_epoch=3.680, valid_loss=0.00403]\n",
            "Epoch 372:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.070, train_loss_epoch=4.070, valid_loss=0.00403]\n",
            "Epoch 373:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.000, train_loss_epoch=4.000, valid_loss=0.00403]\n",
            "Epoch 374:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.390, train_loss_epoch=3.390, valid_loss=0.00403]\n",
            "Epoch 375:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=4.330, train_loss_epoch=4.330, valid_loss=0.00403]\n",
            "Epoch 376:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.220, train_loss_epoch=3.220, valid_loss=0.00403]\n",
            "Epoch 377:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.710, train_loss_epoch=3.710, valid_loss=0.00403]\n",
            "Epoch 378:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00403]\n",
            "Epoch 379:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.320, train_loss_epoch=3.320, valid_loss=0.00403]\n",
            "Epoch 380:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.650, train_loss_epoch=3.650, valid_loss=0.00403]\n",
            "Epoch 381:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.330, train_loss_epoch=3.330, valid_loss=0.00403]\n",
            "Epoch 382:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.210, train_loss_epoch=3.210, valid_loss=0.00403]\n",
            "Epoch 383:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.550, train_loss_epoch=3.550, valid_loss=0.00403]\n",
            "Epoch 384:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.190, train_loss_epoch=3.190, valid_loss=0.00403]\n",
            "Epoch 384: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00403]\n",
            "Epoch 385:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.150, train_loss_epoch=3.150, valid_loss=0.00403]\n",
            "Epoch 386:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00403]\n",
            "Epoch 387:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.280, train_loss_epoch=3.280, valid_loss=0.00403]\n",
            "Epoch 388:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00403]\n",
            "Epoch 389:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00403]\n",
            "Epoch 390:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.070, train_loss_epoch=3.070, valid_loss=0.00403]\n",
            "Epoch 391:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00403]\n",
            "Epoch 392:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.050, train_loss_epoch=3.050, valid_loss=0.00403]\n",
            "Epoch 393:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00403]\n",
            "Epoch 394:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00403]\n",
            "Epoch 395:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00403]\n",
            "Epoch 396:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00403]\n",
            "Epoch 397:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00403]\n",
            "Epoch 398:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00403]\n",
            "Epoch 399:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.110, train_loss_epoch=3.110, valid_loss=0.00403]\n",
            "Epoch 399: 100%|██████████| 1/1 [00:01<00:00,  0.88it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=3.110, valid_loss=0.00403]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 90.41it/s]\u001b[A\n",
            "Epoch 400:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00187]\n",
            "Epoch 401:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00187]\n",
            "Epoch 402:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00187]\n",
            "Epoch 403:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00187]\n",
            "Epoch 404:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00187]\n",
            "Epoch 405:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00187]\n",
            "Epoch 406:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00187]\n",
            "Epoch 407:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00187]\n",
            "Epoch 408:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00187]\n",
            "Epoch 409:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00187]\n",
            "Epoch 410:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00187]\n",
            "Epoch 411:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00187]\n",
            "Epoch 412:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00187]\n",
            "Epoch 413:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00187]\n",
            "Epoch 414:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00187]\n",
            "Epoch 415:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00187]\n",
            "Epoch 416:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00187]\n",
            "Epoch 417:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00187]\n",
            "Epoch 418:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00187]\n",
            "Epoch 419:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00187]\n",
            "Epoch 420:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00187]\n",
            "Epoch 421:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.970, train_loss_epoch=2.970, valid_loss=0.00187]\n",
            "Epoch 422:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00187]\n",
            "Epoch 423:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.900, train_loss_epoch=2.900, valid_loss=0.00187]\n",
            "Epoch 424:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00187]\n",
            "Epoch 425:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.000, train_loss_epoch=3.000, valid_loss=0.00187]\n",
            "Epoch 426:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.730, train_loss_epoch=2.730, valid_loss=0.00187]\n",
            "Epoch 427:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00187]\n",
            "Epoch 428:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00187]\n",
            "Epoch 429:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00187]\n",
            "Epoch 430:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00187]\n",
            "Epoch 431:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00187]\n",
            "Epoch 432:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.840, train_loss_epoch=2.840, valid_loss=0.00187]\n",
            "Epoch 433:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00187]\n",
            "Epoch 434:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00187]\n",
            "Epoch 435:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00187]\n",
            "Epoch 436:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00187]\n",
            "Epoch 437:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00187]\n",
            "Epoch 438:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00187]\n",
            "Epoch 439:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.860, train_loss_epoch=2.860, valid_loss=0.00187]\n",
            "Epoch 440:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00187]\n",
            "Epoch 441:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00187]\n",
            "Epoch 442:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00187]\n",
            "Epoch 443:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00187]\n",
            "Epoch 444:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00187]\n",
            "Epoch 445:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.780, train_loss_epoch=2.780, valid_loss=0.00187]\n",
            "Epoch 446:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00187]\n",
            "Epoch 447:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00187]\n",
            "Epoch 448:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00187]\n",
            "Epoch 449:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00187]\n",
            "Epoch 450:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00187]\n",
            "Epoch 451:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.830, train_loss_epoch=2.830, valid_loss=0.00187]\n",
            "Epoch 452:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00187]\n",
            "Epoch 453:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.820, train_loss_epoch=2.820, valid_loss=0.00187]\n",
            "Epoch 454:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.880, train_loss_epoch=2.880, valid_loss=0.00187]\n",
            "Epoch 455:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00187]\n",
            "Epoch 456:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00187]\n",
            "Epoch 457:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00187]\n",
            "Epoch 458:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00187]\n",
            "Epoch 459:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00187]\n",
            "Epoch 460:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.770, train_loss_epoch=2.770, valid_loss=0.00187]\n",
            "Epoch 461:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00187]\n",
            "Epoch 462:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00187]\n",
            "Epoch 463:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00187]\n",
            "Epoch 464:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00187]\n",
            "Epoch 465:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00187]\n",
            "Epoch 466:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00187]\n",
            "Epoch 467:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00187]\n",
            "Epoch 468:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00187]\n",
            "Epoch 469:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00187]\n",
            "Epoch 470:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00187]\n",
            "Epoch 471:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00187]\n",
            "Epoch 472:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00187]\n",
            "Epoch 473:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00187]\n",
            "Epoch 474:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00187]\n",
            "Epoch 475:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00187]\n",
            "Epoch 476:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00187]\n",
            "Epoch 477:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00187]\n",
            "Epoch 478:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00187]\n",
            "Epoch 479:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00187]\n",
            "Epoch 480:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00187]\n",
            "Epoch 481:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00187]\n",
            "Epoch 482:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00187]\n",
            "Epoch 483:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00187]\n",
            "Epoch 484:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00187]\n",
            "Epoch 485:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00187]\n",
            "Epoch 486:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00187]\n",
            "Epoch 487:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00187]\n",
            "Epoch 488:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.00187]\n",
            "Epoch 489:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00187]\n",
            "Epoch 490:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00187]\n",
            "Epoch 491:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00187]\n",
            "Epoch 492:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00187]\n",
            "Epoch 493:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00187]\n",
            "Epoch 494:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00187]\n",
            "Epoch 495:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00187]\n",
            "Epoch 496:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00187]\n",
            "Epoch 497:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00187]\n",
            "Epoch 498:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00187]\n",
            "Epoch 499:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00187]\n",
            "Epoch 499: 100%|██████████| 1/1 [00:01<00:00,  0.64it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.420, valid_loss=0.00187]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 89.77it/s]\u001b[A\n",
            "Epoch 500:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00173]\n",
            "Epoch 501:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00173]\n",
            "Epoch 502:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00173]\n",
            "Epoch 502: 100%|██████████| 1/1 [00:01<00:00,  0.87it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 503:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 504:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 505:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.720, train_loss_epoch=2.720, valid_loss=0.00173]\n",
            "Epoch 506:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00173]\n",
            "Epoch 507:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00173]\n",
            "Epoch 508:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00173]\n",
            "Epoch 509:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00173]\n",
            "Epoch 510:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 511:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00173]\n",
            "Epoch 512:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00173]\n",
            "Epoch 512: 100%|██████████| 1/1 [00:01<00:00,  0.89it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00173]\n",
            "Epoch 513:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00173]\n",
            "Epoch 514:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 515:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00173]\n",
            "Epoch 516:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00173]\n",
            "Epoch 517:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00173]\n",
            "Epoch 518:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00173]\n",
            "Epoch 519:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00173]\n",
            "Epoch 520:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00173]\n",
            "Epoch 521:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.640, train_loss_epoch=2.640, valid_loss=0.00173]\n",
            "Epoch 522:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00173]\n",
            "Epoch 523:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00173]\n",
            "Epoch 524:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00173]\n",
            "Epoch 525:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00173]\n",
            "Epoch 526:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00173]\n",
            "Epoch 527:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00173]\n",
            "Epoch 528:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00173]\n",
            "Epoch 529:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00173]\n",
            "Epoch 530:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 531:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00173]\n",
            "Epoch 532:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.570, train_loss_epoch=2.570, valid_loss=0.00173]\n",
            "Epoch 533:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00173]\n",
            "Epoch 534:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00173]\n",
            "Epoch 535:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.520, train_loss_epoch=2.520, valid_loss=0.00173]\n",
            "Epoch 536:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00173]\n",
            "Epoch 537:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.680, train_loss_epoch=2.680, valid_loss=0.00173]\n",
            "Epoch 538:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00173]\n",
            "Epoch 539:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.750, train_loss_epoch=2.750, valid_loss=0.00173]\n",
            "Epoch 540:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00173]\n",
            "Epoch 541:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.630, train_loss_epoch=2.630, valid_loss=0.00173]\n",
            "Epoch 542:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00173]\n",
            "Epoch 543:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00173]\n",
            "Epoch 544:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00173]\n",
            "Epoch 545:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 545: 100%|██████████| 1/1 [00:01<00:00,  0.62it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 546:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00173]\n",
            "Epoch 547:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00173]\n",
            "Epoch 548:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00173]\n",
            "Epoch 549:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.870, train_loss_epoch=2.870, valid_loss=0.00173]\n",
            "Epoch 550:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00173]\n",
            "Epoch 551:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00173]\n",
            "Epoch 552:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00173]\n",
            "Epoch 553:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.480, train_loss_epoch=2.480, valid_loss=0.00173]\n",
            "Epoch 554:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00173]\n",
            "Epoch 555:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00173]\n",
            "Epoch 556:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00173]\n",
            "Epoch 557:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00173]\n",
            "Epoch 558:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.410, train_loss_epoch=2.410, valid_loss=0.00173]\n",
            "Epoch 559:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00173]\n",
            "Epoch 560:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00173]\n",
            "Epoch 561:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00173]\n",
            "Epoch 562:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.760, train_loss_epoch=2.760, valid_loss=0.00173]\n",
            "Epoch 563:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00173]\n",
            "Epoch 564:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.810, train_loss_epoch=2.810, valid_loss=0.00173]\n",
            "Epoch 565:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00173]\n",
            "Epoch 566:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00173]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:01<00:00,  0.54it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00173]\n",
            "Epoch 566: 100%|██████████| 1/1 [00:01<00:00,  0.53it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00173]\n",
            "Epoch 567:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.910, train_loss_epoch=2.910, valid_loss=0.00173]\n",
            "Epoch 568:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00173]\n",
            "Epoch 569:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.790, train_loss_epoch=2.790, valid_loss=0.00173]\n",
            "Epoch 570:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.670, train_loss_epoch=2.670, valid_loss=0.00173]\n",
            "Epoch 571:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.850, train_loss_epoch=2.850, valid_loss=0.00173]\n",
            "Epoch 572:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.700, train_loss_epoch=2.700, valid_loss=0.00173]\n",
            "Epoch 573:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00173]\n",
            "Epoch 574:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00173]\n",
            "Epoch 575:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.440, train_loss_epoch=2.440, valid_loss=0.00173]\n",
            "Epoch 576:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.710, train_loss_epoch=2.710, valid_loss=0.00173]\n",
            "Epoch 577:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00173]\n",
            "Epoch 578:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.690, train_loss_epoch=2.690, valid_loss=0.00173]\n",
            "Epoch 579:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00173]\n",
            "Epoch 580:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.550, train_loss_epoch=2.550, valid_loss=0.00173]\n",
            "Epoch 581:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00173]\n",
            "Epoch 582:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00173]\n",
            "Epoch 583:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00173]\n",
            "Epoch 584:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00173]\n",
            "Epoch 585:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00173]\n",
            "Epoch 586:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00173]\n",
            "Epoch 587:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00173]\n",
            "Epoch 588:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00173]\n",
            "Epoch 588: 100%|██████████| 1/1 [00:01<00:00,  0.82it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.330, valid_loss=0.00173]\n",
            "Epoch 589:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00173]\n",
            "Epoch 590:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00173]\n",
            "Epoch 591:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00173]\n",
            "Epoch 592:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00173]\n",
            "Epoch 592: 100%|██████████| 1/1 [00:01<00:00,  0.88it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00173]\n",
            "Epoch 593:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00173]\n",
            "Epoch 594:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00173]\n",
            "Epoch 595:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00173]\n",
            "Epoch 596:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00173]\n",
            "Epoch 597:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00173]\n",
            "Epoch 598:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00173]\n",
            "Epoch 599:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00173]\n",
            "Epoch 599: 100%|██████████| 1/1 [00:01<00:00,  0.88it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.200, valid_loss=0.00173]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.81it/s]\u001b[A\n",
            "Epoch 600:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00139]\n",
            "Epoch 601:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00139]\n",
            "Epoch 602:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.230, train_loss_epoch=2.230, valid_loss=0.00139]\n",
            "Epoch 603:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00139]\n",
            "Epoch 604:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.350, train_loss_epoch=2.350, valid_loss=0.00139]\n",
            "Epoch 605:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00139]\n",
            "Epoch 606:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00139]\n",
            "Epoch 607:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00139]\n",
            "Epoch 608:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.400, train_loss_epoch=2.400, valid_loss=0.00139]\n",
            "Epoch 609:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00139]\n",
            "Epoch 610:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00139]\n",
            "Epoch 611:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00139]\n",
            "Epoch 612:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00139]\n",
            "Epoch 613:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00139]\n",
            "Epoch 614:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00139]\n",
            "Epoch 615:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00139]\n",
            "Epoch 616:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00139]\n",
            "Epoch 616: 100%|██████████| 1/1 [00:01<00:00,  0.81it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.310, valid_loss=0.00139]\n",
            "Epoch 617:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00139]\n",
            "Epoch 618:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.470, train_loss_epoch=2.470, valid_loss=0.00139]\n",
            "Epoch 619:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00139]\n",
            "Epoch 620:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.450, train_loss_epoch=2.450, valid_loss=0.00139]\n",
            "Epoch 621:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.610, train_loss_epoch=2.610, valid_loss=0.00139]\n",
            "Epoch 622:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00139]\n",
            "Epoch 623:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.740, train_loss_epoch=2.740, valid_loss=0.00139]\n",
            "Epoch 624:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00139]\n",
            "Epoch 625:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00139]\n",
            "Epoch 626:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00139]\n",
            "Epoch 627:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.580, train_loss_epoch=2.580, valid_loss=0.00139]\n",
            "Epoch 628:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.930, train_loss_epoch=2.930, valid_loss=0.00139]\n",
            "Epoch 629:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.320, train_loss_epoch=2.320, valid_loss=0.00139]\n",
            "Epoch 630:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=3.040, train_loss_epoch=3.040, valid_loss=0.00139]\n",
            "Epoch 631:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.560, train_loss_epoch=2.560, valid_loss=0.00139]\n",
            "Epoch 632:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=0.00139]\n",
            "Epoch 633:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.600, train_loss_epoch=2.600, valid_loss=0.00139]\n",
            "Epoch 634:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.490, train_loss_epoch=2.490, valid_loss=0.00139]\n",
            "Epoch 635:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.800, train_loss_epoch=2.800, valid_loss=0.00139]\n",
            "Epoch 636:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00139]\n",
            "Epoch 637:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00139]\n",
            "Epoch 638:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.620, train_loss_epoch=2.620, valid_loss=0.00139]\n",
            "Epoch 639:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.660, train_loss_epoch=2.660, valid_loss=0.00139]\n",
            "Epoch 640:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.540, train_loss_epoch=2.540, valid_loss=0.00139]\n",
            "Epoch 641:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.590, train_loss_epoch=2.590, valid_loss=0.00139]\n",
            "Epoch 642:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00139]\n",
            "Epoch 643:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.650, train_loss_epoch=2.650, valid_loss=0.00139]\n",
            "Epoch 644:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00139]\n",
            "Epoch 645:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00139]\n",
            "Epoch 646:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00139]\n",
            "Epoch 647:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00139]\n",
            "Epoch 648:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00139]\n",
            "Epoch 649:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.270, train_loss_epoch=2.270, valid_loss=0.00139]\n",
            "Epoch 650:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00139]\n",
            "Epoch 651:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00139]\n",
            "Epoch 652:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.530, train_loss_epoch=2.530, valid_loss=0.00139]\n",
            "Epoch 653:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00139]\n",
            "Epoch 654:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.290, train_loss_epoch=2.290, valid_loss=0.00139]\n",
            "Epoch 655:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00139]\n",
            "Epoch 656:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.420, train_loss_epoch=2.420, valid_loss=0.00139]\n",
            "Epoch 657:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.00139]\n",
            "Epoch 658:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.370, train_loss_epoch=2.370, valid_loss=0.00139]\n",
            "Epoch 659:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00139]\n",
            "Epoch 660:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00139]\n",
            "Epoch 661:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00139]\n",
            "Epoch 662:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00139]\n",
            "Epoch 663:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.390, train_loss_epoch=2.390, valid_loss=0.00139]\n",
            "Epoch 664:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.460, train_loss_epoch=2.460, valid_loss=0.00139]\n",
            "Epoch 665:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.330, train_loss_epoch=2.330, valid_loss=0.00139]\n",
            "Epoch 666:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00139]\n",
            "Epoch 667:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00139]\n",
            "Epoch 668:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00139]\n",
            "Epoch 669:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.510, train_loss_epoch=2.510, valid_loss=0.00139]\n",
            "Epoch 670:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00139]\n",
            "Epoch 671:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.170, train_loss_epoch=2.170, valid_loss=0.00139]\n",
            "Epoch 672:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00139]\n",
            "Epoch 673:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.380, train_loss_epoch=2.380, valid_loss=0.00139]\n",
            "Epoch 674:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00139]\n",
            "Epoch 675:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.300, train_loss_epoch=2.300, valid_loss=0.00139]\n",
            "Epoch 676:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00139]\n",
            "Epoch 677:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00139]\n",
            "Epoch 678:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00139]\n",
            "Epoch 679:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00139]\n",
            "Epoch 680:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.360, train_loss_epoch=2.360, valid_loss=0.00139]\n",
            "Epoch 681:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.110, train_loss_epoch=2.110, valid_loss=0.00139]\n",
            "Epoch 682:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00139]\n",
            "Epoch 683:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00139]\n",
            "Epoch 684:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00139]\n",
            "Epoch 685:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.990, train_loss_epoch=1.990, valid_loss=0.00139]\n",
            "Epoch 686:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00139]\n",
            "Epoch 687:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00139]\n",
            "Epoch 688:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00139]\n",
            "Epoch 689:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.200, train_loss_epoch=2.200, valid_loss=0.00139]\n",
            "Epoch 690:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.260, train_loss_epoch=2.260, valid_loss=0.00139]\n",
            "Epoch 691:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00139]\n",
            "Epoch 692:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.160, train_loss_epoch=2.160, valid_loss=0.00139]\n",
            "Epoch 693:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.430, train_loss_epoch=2.430, valid_loss=0.00139]\n",
            "Epoch 694:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.980, train_loss_epoch=1.980, valid_loss=0.00139]\n",
            "Epoch 695:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00139]\n",
            "Epoch 696:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.340, train_loss_epoch=2.340, valid_loss=0.00139]\n",
            "Epoch 697:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.500, train_loss_epoch=2.500, valid_loss=0.00139]\n",
            "Epoch 698:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00139]\n",
            "Epoch 699:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.240, train_loss_epoch=2.240, valid_loss=0.00139]\n",
            "Epoch 699: 100%|██████████| 1/1 [00:01<00:00,  0.88it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.240, valid_loss=0.00139]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 95.05it/s]\u001b[A\n",
            "Epoch 700:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00248]\n",
            "Epoch 701:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00248]\n",
            "Epoch 702:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00248]\n",
            "Epoch 703:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00248]\n",
            "Epoch 704:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.120, train_loss_epoch=2.120, valid_loss=0.00248]\n",
            "Epoch 705:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00248]\n",
            "Epoch 706:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.250, train_loss_epoch=2.250, valid_loss=0.00248]\n",
            "Epoch 707:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.960, train_loss_epoch=1.960, valid_loss=0.00248]\n",
            "Epoch 708:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.930, train_loss_epoch=1.930, valid_loss=0.00248]\n",
            "Epoch 709:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00248]\n",
            "Epoch 710:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.080, train_loss_epoch=2.080, valid_loss=0.00248]\n",
            "Epoch 711:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.970, train_loss_epoch=1.970, valid_loss=0.00248]\n",
            "Epoch 712:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.150, train_loss_epoch=2.150, valid_loss=0.00248]\n",
            "Epoch 713:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00248]\n",
            "Epoch 714:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00248]\n",
            "Epoch 715:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.190, train_loss_epoch=2.190, valid_loss=0.00248]\n",
            "Epoch 716:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00248]\n",
            "Epoch 717:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.310, train_loss_epoch=2.310, valid_loss=0.00248]\n",
            "Epoch 718:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.000, train_loss_epoch=2.000, valid_loss=0.00248]\n",
            "Epoch 719:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.140, train_loss_epoch=2.140, valid_loss=0.00248]\n",
            "Epoch 720:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00248]\n",
            "Epoch 721:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00248]\n",
            "Epoch 722:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.060, train_loss_epoch=2.060, valid_loss=0.00248]\n",
            "Epoch 723:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00248]\n",
            "Epoch 724:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.030, train_loss_epoch=2.030, valid_loss=0.00248]\n",
            "Epoch 725:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.130, train_loss_epoch=2.130, valid_loss=0.00248]\n",
            "Epoch 726:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00248]\n",
            "Epoch 727:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.220, train_loss_epoch=2.220, valid_loss=0.00248]\n",
            "Epoch 728:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.050, train_loss_epoch=2.050, valid_loss=0.00248]\n",
            "Epoch 729:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.180, train_loss_epoch=2.180, valid_loss=0.00248]\n",
            "Epoch 730:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.020, train_loss_epoch=2.020, valid_loss=0.00248]\n",
            "Epoch 731:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.210, train_loss_epoch=2.210, valid_loss=0.00248]\n",
            "Epoch 732:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.070, train_loss_epoch=2.070, valid_loss=0.00248]\n",
            "Epoch 733:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=2.010, train_loss_epoch=2.010, valid_loss=0.00248]\n",
            "Epoch 734:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.940, train_loss_epoch=1.940, valid_loss=0.00248]\n",
            "Epoch 735:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.900, train_loss_epoch=1.900, valid_loss=0.00248]\n",
            "Epoch 736:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.870, train_loss_epoch=1.870, valid_loss=0.00248]\n",
            "Epoch 737:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.840, train_loss_epoch=1.840, valid_loss=0.00248]\n",
            "Epoch 738:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00248]\n",
            "Epoch 739:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.780, train_loss_epoch=1.780, valid_loss=0.00248]\n",
            "Epoch 740:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.740, train_loss_epoch=1.740, valid_loss=0.00248]\n",
            "Epoch 741:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00248]\n",
            "Epoch 742:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00248]\n",
            "Epoch 743:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00248]\n",
            "Epoch 744:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00248]\n",
            "Epoch 745:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.670, train_loss_epoch=1.670, valid_loss=0.00248]\n",
            "Epoch 746:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00248]\n",
            "Epoch 747:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00248]\n",
            "Epoch 748:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00248]\n",
            "Epoch 749:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00248]\n",
            "Epoch 750:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00248]\n",
            "Epoch 751:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00248]\n",
            "Epoch 752:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00248]\n",
            "Epoch 753:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.680, train_loss_epoch=1.680, valid_loss=0.00248]\n",
            "Epoch 754:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.610, train_loss_epoch=1.610, valid_loss=0.00248]\n",
            "Epoch 755:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00248]\n",
            "Epoch 756:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00248]\n",
            "Epoch 757:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 758:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00248]\n",
            "Epoch 759:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00248]\n",
            "Epoch 760:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 761:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00248]\n",
            "Epoch 762:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00248]\n",
            "Epoch 763:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00248]\n",
            "Epoch 764:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00248]\n",
            "Epoch 765:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 766:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00248]\n",
            "Epoch 767:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00248]\n",
            "Epoch 768:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00248]\n",
            "Epoch 769:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00248]\n",
            "Epoch 770:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.590, train_loss_epoch=1.590, valid_loss=0.00248]\n",
            "Epoch 771:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00248]\n",
            "Epoch 772:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00248]\n",
            "Epoch 773:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 774:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00248]\n",
            "Epoch 775:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 776:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.00248]\n",
            "Epoch 777:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00248]\n",
            "Epoch 778:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00248]\n",
            "Epoch 779:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00248]\n",
            "Epoch 780:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00248]\n",
            "Epoch 781:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.00248]\n",
            "Epoch 782:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 783:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00248]\n",
            "Epoch 784:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00248]\n",
            "Epoch 785:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00248]\n",
            "Epoch 786:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.310, train_loss_epoch=1.310, valid_loss=0.00248]\n",
            "Epoch 787:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00248]\n",
            "Epoch 788:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00248]\n",
            "Epoch 789:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00248]\n",
            "Epoch 790:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 791:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00248]\n",
            "Epoch 792:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00248]\n",
            "Epoch 793:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00248]\n",
            "Epoch 794:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00248]\n",
            "Epoch 795:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00248]\n",
            "Epoch 796:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00248]\n",
            "Epoch 797:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00248]\n",
            "Epoch 798:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00248]\n",
            "Epoch 799:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00248]\n",
            "Epoch 799: 100%|██████████| 1/1 [00:01<00:00,  0.82it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.440, valid_loss=0.00248]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 44.19it/s]\u001b[A\n",
            "Epoch 800:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00192]\n",
            "Epoch 801:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00192]\n",
            "Epoch 802:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 803:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00192]\n",
            "Epoch 804:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00192]\n",
            "Epoch 805:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00192]\n",
            "Epoch 806:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 807:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00192]\n",
            "Epoch 808:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 809:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 810:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=0.00192]\n",
            "Epoch 811:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00192]\n",
            "Epoch 812:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=0.00192]\n",
            "Epoch 813:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 814:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 815:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00192]\n",
            "Epoch 816:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00192]\n",
            "Epoch 817:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00192]\n",
            "Epoch 818:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00192]\n",
            "Epoch 819:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00192]\n",
            "Epoch 820:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00192]\n",
            "Epoch 821:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00192]\n",
            "Epoch 822:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00192]\n",
            "Epoch 823:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00192]\n",
            "Epoch 824:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00192]\n",
            "Epoch 825:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 826:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00192]\n",
            "Epoch 827:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00192]\n",
            "Epoch 828:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00192]\n",
            "Epoch 829:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 830:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Epoch 831:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00192]\n",
            "Epoch 832:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00192]\n",
            "Epoch 833:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00192]\n",
            "Epoch 834:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=0.00192]\n",
            "Epoch 835:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 836:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00192]\n",
            "Epoch 837:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00192]\n",
            "Epoch 838:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 839:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00192]\n",
            "Epoch 840:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 841:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 842:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 843:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00192]\n",
            "Epoch 844:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 845:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00192]\n",
            "Epoch 846:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 847:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 848:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00192]\n",
            "Epoch 849:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00192]\n",
            "Epoch 850:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00192]\n",
            "Epoch 851:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00192]\n",
            "Epoch 851: 100%|██████████| 1/1 [00:01<00:00,  0.82it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 852:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 853:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00192]\n",
            "Epoch 854:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00192]\n",
            "Epoch 855:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00192]\n",
            "Epoch 856:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 857:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 858:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 859:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00192]\n",
            "Epoch 860:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00192]\n",
            "Epoch 861:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Epoch 862:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00192]\n",
            "Epoch 863:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Epoch 864:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00192]\n",
            "Epoch 865:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00192]\n",
            "Epoch 866:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 867:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=0.00192]\n",
            "Epoch 868:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 869:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00192]\n",
            "Epoch 870:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Epoch 871:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00192]\n",
            "Epoch 872:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.00192]\n",
            "Epoch 873:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00192]\n",
            "Epoch 874:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.00192]\n",
            "Epoch 875:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 876:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Epoch 877:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00192]\n",
            "Epoch 878:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 879:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 880:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.00192]\n",
            "Epoch 881:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 882:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00192]\n",
            "Epoch 883:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Epoch 884:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 885:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00192]\n",
            "Epoch 886:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00192]\n",
            "Epoch 887:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00192]\n",
            "Epoch 888:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 889:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 890:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 891:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 892:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00192]\n",
            "Epoch 893:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00192]\n",
            "Epoch 894:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00192]\n",
            "Epoch 895:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.00192]\n",
            "Epoch 896:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00192]\n",
            "Epoch 897:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.00192]\n",
            "Epoch 898:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00192]\n",
            "Epoch 899:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Epoch 899: 100%|██████████| 1/1 [00:01<00:00,  0.61it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.410, valid_loss=0.00192]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 92.03it/s]\u001b[A\n",
            "Epoch 900:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00184]\n",
            "Epoch 901:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00184]\n",
            "Epoch 902:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00184]\n",
            "Epoch 903:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00184]\n",
            "Epoch 904:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.420, train_loss_epoch=1.420, valid_loss=0.00184]\n",
            "Epoch 905:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00184]\n",
            "Epoch 906:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00184]\n",
            "Epoch 907:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.00184]\n",
            "Epoch 908:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00184]\n",
            "Epoch 909:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00184]\n",
            "Epoch 910:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00184]\n",
            "Epoch 911:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.00184]\n",
            "Epoch 912:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.00184]\n",
            "Epoch 913:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00184]\n",
            "Epoch 914:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.330, train_loss_epoch=1.330, valid_loss=0.00184]\n",
            "Epoch 915:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00184]\n",
            "Epoch 916:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00184]\n",
            "Epoch 917:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.00184]\n",
            "Epoch 918:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00184]\n",
            "Epoch 919:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.300, train_loss_epoch=1.300, valid_loss=0.00184]\n",
            "Epoch 920:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.00184]\n",
            "Epoch 921:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.00184]\n",
            "Epoch 922:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00184]\n",
            "Epoch 923:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.240, train_loss_epoch=1.240, valid_loss=0.00184]\n",
            "Epoch 924:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.00184]\n",
            "Epoch 925:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.00184]\n",
            "Epoch 926:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.340, train_loss_epoch=1.340, valid_loss=0.00184]\n",
            "Epoch 927:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00184]\n",
            "Epoch 928:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00184]\n",
            "Epoch 929:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00184]\n",
            "Epoch 930:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00184]\n",
            "Epoch 931:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=0.00184]\n",
            "Epoch 932:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00184]\n",
            "Epoch 933:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00184]\n",
            "Epoch 934:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00184]\n",
            "Epoch 935:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00184]\n",
            "Epoch 936:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00184]\n",
            "Epoch 937:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00184]\n",
            "Epoch 938:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00184]\n",
            "Epoch 939:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00184]\n",
            "Epoch 940:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.360, train_loss_epoch=1.360, valid_loss=0.00184]\n",
            "Epoch 941:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00184]\n",
            "Epoch 942:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00184]\n",
            "Epoch 943:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00184]\n",
            "Epoch 944:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00184]\n",
            "Epoch 945:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00184]\n",
            "Epoch 946:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00184]\n",
            "Epoch 947:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.710, train_loss_epoch=1.710, valid_loss=0.00184]\n",
            "Epoch 948:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.460, train_loss_epoch=1.460, valid_loss=0.00184]\n",
            "Epoch 948: 100%|██████████| 1/1 [00:01<00:00,  0.81it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00184]\n",
            "Epoch 949:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00184]\n",
            "Epoch 950:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00184]\n",
            "Epoch 950: 100%|██████████| 1/1 [00:01<00:00,  0.77it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00184]\n",
            "Epoch 951:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00184]\n",
            "Epoch 952:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00184]\n",
            "Epoch 953:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00184]\n",
            "Epoch 953: 100%|██████████| 1/1 [00:01<00:00,  0.64it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00184]\n",
            "Epoch 954:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00184]\n",
            "Epoch 955:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00184]\n",
            "Epoch 956:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00184]\n",
            "Epoch 957:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00184]\n",
            "Epoch 958:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00184]\n",
            "Epoch 959:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00184]\n",
            "Epoch 960:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00184]\n",
            "Epoch 961:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00184]\n",
            "Epoch 962:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00184]\n",
            "Epoch 963:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00184]\n",
            "Epoch 964:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00184]\n",
            "Epoch 965:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.430, train_loss_epoch=1.430, valid_loss=0.00184]\n",
            "Epoch 966:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.410, train_loss_epoch=1.410, valid_loss=0.00184]\n",
            "Epoch 967:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00184]\n",
            "Epoch 968:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.00184]\n",
            "Epoch 969:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00184]\n",
            "Epoch 970:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00184]\n",
            "Epoch 971:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00184]\n",
            "Epoch 972:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00184]\n",
            "Epoch 973:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00184]\n",
            "Epoch 974:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00184]\n",
            "Epoch 975:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00184]\n",
            "Epoch 976:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.380, train_loss_epoch=1.380, valid_loss=0.00184]\n",
            "Epoch 977:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00184]\n",
            "Epoch 978:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00184]\n",
            "Epoch 979:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00184]\n",
            "Epoch 980:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00184]\n",
            "Epoch 981:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00184]\n",
            "Epoch 982:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00184]\n",
            "Epoch 983:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00184]\n",
            "Epoch 984:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00184]\n",
            "Epoch 985:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00184]\n",
            "Epoch 986:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00184]\n",
            "Epoch 987:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00184]\n",
            "Epoch 988:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00184]\n",
            "Epoch 989:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.570, train_loss_epoch=1.570, valid_loss=0.00184]\n",
            "Epoch 990:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.620, train_loss_epoch=1.620, valid_loss=0.00184]\n",
            "Epoch 991:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00184]\n",
            "Epoch 992:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00184]\n",
            "Epoch 993:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00184]\n",
            "Epoch 994:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00184]\n",
            "Epoch 994: 100%|██████████| 1/1 [00:01<00:00,  0.81it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00184]\n",
            "Epoch 995:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00184]\n",
            "Epoch 996:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.540, train_loss_epoch=1.540, valid_loss=0.00184]\n",
            "Epoch 997:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00184]\n",
            "Epoch 998:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00184]\n",
            "Epoch 999:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.510, train_loss_epoch=1.510, valid_loss=0.00184]\n",
            "Epoch 999: 100%|██████████| 1/1 [00:01<00:00,  0.84it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.510, valid_loss=0.00184]\n",
            "Validation: |          | 0/? [00:00<?, ?it/s]\u001b[A\n",
            "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 96.86it/s]\u001b[A\n",
            "Epoch 1000:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00182]\n",
            "Epoch 1001:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.600, train_loss_epoch=1.600, valid_loss=0.00182]\n",
            "Epoch 1002:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.580, train_loss_epoch=1.580, valid_loss=0.00182]\n",
            "Epoch 1003:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00182]\n",
            "Epoch 1004:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00182]\n",
            "Epoch 1005:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00182]\n",
            "Epoch 1005: 100%|██████████| 1/1 [00:01<00:00,  0.82it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00182]\n",
            "Epoch 1006:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.630, train_loss_epoch=1.630, valid_loss=0.00182]\n",
            "Epoch 1007:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00182]\n",
            "Epoch 1008:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00182]\n",
            "Epoch 1009:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00182]\n",
            "Epoch 1010:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.720, train_loss_epoch=1.720, valid_loss=0.00182]\n",
            "Epoch 1011:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.700, train_loss_epoch=1.700, valid_loss=0.00182]\n",
            "Epoch 1012:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00182]\n",
            "Epoch 1013:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.560, train_loss_epoch=1.560, valid_loss=0.00182]\n",
            "Epoch 1014:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00182]\n",
            "Epoch 1015:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.530, train_loss_epoch=1.530, valid_loss=0.00182]\n",
            "Epoch 1016:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00182]\n",
            "Epoch 1017:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00182]\n",
            "Epoch 1018:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00182]\n",
            "Epoch 1019:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.640, train_loss_epoch=1.640, valid_loss=0.00182]\n",
            "Epoch 1020:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.500, train_loss_epoch=1.500, valid_loss=0.00182]\n",
            "Epoch 1021:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00182]\n",
            "Epoch 1022:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00182]\n",
            "Epoch 1022: 100%|██████████| 1/1 [00:01<00:00,  0.84it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00182]\n",
            "Epoch 1023:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00182]\n",
            "Epoch 1024:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00182]\n",
            "Epoch 1025:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00182]\n",
            "Epoch 1026:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.550, train_loss_epoch=1.550, valid_loss=0.00182]\n",
            "Epoch 1027:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.470, train_loss_epoch=1.470, valid_loss=0.00182]\n",
            "Epoch 1028:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.490, train_loss_epoch=1.490, valid_loss=0.00182]\n",
            "Epoch 1029:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.400, train_loss_epoch=1.400, valid_loss=0.00182]\n",
            "Epoch 1030:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.480, train_loss_epoch=1.480, valid_loss=0.00182]\n",
            "Epoch 1031:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00182]\n",
            "Epoch 1032:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00182]\n",
            "Epoch 1033:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.320, train_loss_epoch=1.320, valid_loss=0.00182]\n",
            "Epoch 1034:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.450, train_loss_epoch=1.450, valid_loss=0.00182]\n",
            "Epoch 1035:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.390, train_loss_epoch=1.390, valid_loss=0.00182]\n",
            "Epoch 1036:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.520, train_loss_epoch=1.520, valid_loss=0.00182]\n",
            "Epoch 1037:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.370, train_loss_epoch=1.370, valid_loss=0.00182]\n",
            "Epoch 1038:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.440, train_loss_epoch=1.440, valid_loss=0.00182]\n",
            "Epoch 1039:   0%|          | 0/1 [00:00<?, ?it/s, v_num=0, train_loss_step=1.260, train_loss_epoch=1.260, valid_loss=0.00182]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Junta os últimos 'input_size' pontos do treino com os dados de teste\n",
        "predictions_input_df = pd.concat([train.tail(input_size), test])"
      ],
      "metadata": {
        "id": "TqcMG75sna1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria janelas deslizantes do DataFrame para fazer predições\n",
        "inputs_for_predicions_list = [\n",
        "    predictions_input_df.iloc[i:i + input_size]\n",
        "    for i in range(0, len(predictions_input_df) - input_size + 1, horizon)\n",
        "]"
      ],
      "metadata": {
        "id": "A7SAD1mE0fFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecasts_list = []\n",
        "for input_df in inputs_for_predicions_list:\n",
        "    forecast = nf.predict(df=input_df)\n",
        "    forecasts_list.append(forecast)"
      ],
      "metadata": {
        "id": "FrKMTQYA0hrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forecasts_output = pd.concat(forecasts_list)\n",
        "forecasts_output"
      ],
      "metadata": {
        "id": "we9e10kN3nk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = test[['unique_id', 'ds', 'y']]\n",
        "ground_truth"
      ],
      "metadata": {
        "id": "zRcnIwFS3wx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exogenous_results = pd.merge(\n",
        "    ground_truth,\n",
        "    forecasts_output,\n",
        "    on=['unique_id', 'ds'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "exogenous_results"
      ],
      "metadata": {
        "id": "qPz1nr0Y30m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"nhits_bayesopt\"\n",
        "version = \"v1\"\n",
        "exogenous_results.to_csv(f\"{ROOT}/results/{file_name}_{version}.csv\", index=False, mode='x')"
      ],
      "metadata": {
        "id": "0qDOnrJR4BGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# Espaço de busca da otimizaçao bayseana\n",
        "##########################################\n",
        "\n",
        "# from statsforecast.models import AutoNHITS\n",
        "from ray.tune.search.sample import Categorical, LogUniform\n",
        "\n",
        "# Get the config dictionary with the Ray Tune sampler objects\n",
        "config = AutoNHITS.get_default_config(h=horizon, backend='ray')\n",
        "\n",
        "print(\"Inspecting the AutoNHITS Default Search Space Programmatically:\\n\")\n",
        "\n",
        "# Iterate through the hyperparameters and their sampler objects\n",
        "for param, sampler in config.items():\n",
        "    print(f\"Hyperparameter: '{param}'\")\n",
        "\n",
        "    if isinstance(sampler, Categorical):\n",
        "        # This object is created by tune.choice([...])\n",
        "        print(f\"  -> Type: Categorical Choice\")\n",
        "        print(f\"  -> Values: {sampler.categories}\\n\")\n",
        "\n",
        "    elif isinstance(sampler, LogUniform):\n",
        "        # This object is created by tune.loguniform(...)\n",
        "        print(f\"  -> Type: Log-Uniform Float\")\n",
        "        print(f\"  -> Lower Bound: {sampler.lower}\")\n",
        "        print(f\"  -> Upper Bound: {sampler.upper}\\n\")\n",
        "\n",
        "    else:\n",
        "        # This handles any fixed values that are not Ray Tune samplers\n",
        "        print(f\"  -> Type: Fixed Value\")\n",
        "        print(f\"  -> Value: {sampler}\\n\")"
      ],
      "metadata": {
        "id": "I-TqW2xJ6Ml3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################\n",
        "# Salvar os parametros de cada etapa da otimizaçao.\n",
        "####################################################\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "bayesopt_logs = nf.models[0].results.get_dataframe()\n",
        "bayesopt_logs.to_csv(f\"{ROOT}/results/nhits_bayesopt_logs-{version}.csv\", index=False, mode='x')\n",
        "\n",
        "# bayesopt_logs"
      ],
      "metadata": {
        "id": "UdT-96jHJPeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bayesopt_logs = pd.read_csv(f\"{ROOT}/results/nhits_bayesopt_logs-{version}.csv\")"
      ],
      "metadata": {
        "id": "8Yj7JQpuX4vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################\n",
        "# Pegar os hiper-parâmetros selecionados\n",
        "########################################\n",
        "\n",
        "(\n",
        "    bayesopt_logs\n",
        "    .loc[\n",
        "        bayesopt_logs['loss'] == bayesopt_logs['loss'].min(), [column for column in bayesopt_logs.columns if column.startswith(\"config/\")]\n",
        "    ]\n",
        "    .rename(columns={column: column.replace('config/', '') for column in bayesopt_logs.columns})\n",
        "    .to_dict(orient='records')\n",
        ")"
      ],
      "metadata": {
        "id": "LLFAeWbiLcuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23e03d12-6cdb-4ac5-e719-1562cef17f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'h': 187,\n",
              "  'n_pool_kernel_size': '(16, 8, 1)',\n",
              "  'n_freq_downsample': '(1, 1, 1)',\n",
              "  'learning_rate': 0.0022705464489066,\n",
              "  'scaler_type': 'standard',\n",
              "  'max_steps': 1300.0,\n",
              "  'batch_size': 64,\n",
              "  'windows_batch_size': 512,\n",
              "  'loss': 'MAE()',\n",
              "  'random_seed': 78,\n",
              "  'input_size': 187,\n",
              "  'step_size': 1,\n",
              "  'exclude_insample_y': True,\n",
              "  'hist_exog_list': \"('pressure_1', 'pressure_2', 'pressure_3', 'pressure_4', 'pressure_5', 'pressure_6', 'pressure_7')\",\n",
              "  'early_stop_patience_steps': 10,\n",
              "  'val_check_steps': 100,\n",
              "  'valid_loss': 'MAE()'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar modelo\n",
        "model_dir = f\"{ROOT}/models/BayesOptNHITS_{version}/\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "nf.save(path=model_dir)"
      ],
      "metadata": {
        "id": "6XbEWzZOOARM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance"
      ],
      "metadata": {
        "id": "u0AkvCO6ZXRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "tpi_Kd8ubcjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = \"/content/drive/MyDrive/dl-project\"\n",
        "file_name = \"nhits_bayesopt\"\n",
        "version = \"v1\"\n",
        "exogenous_results = pd.read_csv(f\"{ROOT}/results/{file_name}_{version}.csv\")"
      ],
      "metadata": {
        "id": "LM09SFsiXTGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exogenous_results[['y', 'AutoNHITS']].plot(figsize=(15, 5));"
      ],
      "metadata": {
        "id": "1dC_BorG4Xyw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "8779e088-2ada-4ca0-cefd-9375caad754d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = joblib.load(f\"{ROOT}/data/scaler.joblib\")"
      ],
      "metadata": {
        "id": "7e6NpCaRbX-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############\n",
        "# Métricas\n",
        "############"
      ],
      "metadata": {
        "id": "aNGWxxkjRJYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################\n",
        "# Retornar para a escala original\n",
        "##################################\n",
        "\n",
        "n_rows = len(exogenous_results)\n",
        "dummy_df = pd.DataFrame(\n",
        "    data={\n",
        "        'pressure_1': [0]*n_rows,\n",
        "        'pressure_2': [0]*n_rows,\n",
        "        'pressure_3': [0]*n_rows,\n",
        "        'pressure_4': [0]*n_rows,\n",
        "        'pressure_5': [0]*n_rows,\n",
        "        'pressure_6': [0]*n_rows,\n",
        "        'pressure_7': [0]*n_rows,\n",
        "        'gas_flow_rate': [0]*n_rows,\n",
        "        'liquid_flow_rate': [0]*n_rows\n",
        "    }\n",
        ")\n",
        "\n",
        "model_outputs_columns = [\n",
        "    'y', # y_true\n",
        "    'AutoNHITS'\n",
        "]\n",
        "\n",
        "\n",
        "original_scale_predictons = {}\n",
        "for column in model_outputs_columns:\n",
        "    dummy_df['liquid_flow_rate'] = exogenous_results[column]\n",
        "    reverse_df = scaler.inverse_transform(dummy_df)\n",
        "    original_scale_predictons[column] = reverse_df['liquid_flow_rate']\n",
        "\n",
        "\n",
        "original_scale_df = pd.concat(\n",
        "    [\n",
        "        exogenous_results[['unique_id', 'ds']],\n",
        "        pd.DataFrame(original_scale_predictons)\n",
        "    ],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "original_scale_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uK2SjqwYdDWZ",
        "outputId": "2ca0ad30-73c0-4b15-f571-d68e8d89f98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      unique_id    ds           y   AutoNHITS\n",
              "0     slug_flow  1501   91.592333   92.994329\n",
              "1     slug_flow  1502   96.149750   97.616388\n",
              "2     slug_flow  1503  101.114667  101.869979\n",
              "3     slug_flow  1504  105.843333  106.228489\n",
              "4     slug_flow  1505  111.156667  111.918246\n",
              "...         ...   ...         ...         ...\n",
              "1495  slug_flow  2996   22.713000   22.752119\n",
              "1496  slug_flow  2997   22.696038   22.445265\n",
              "1497  slug_flow  2998   22.470111   22.468313\n",
              "1498  slug_flow  2999   22.205667   22.299579\n",
              "1499  slug_flow  3000   22.160000   21.963461\n",
              "\n",
              "[1500 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73d0be85-b165-40a6-92de-7f06bc97b2fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>ds</th>\n",
              "      <th>y</th>\n",
              "      <th>AutoNHITS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>1501</td>\n",
              "      <td>91.592333</td>\n",
              "      <td>92.994329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>1502</td>\n",
              "      <td>96.149750</td>\n",
              "      <td>97.616388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>1503</td>\n",
              "      <td>101.114667</td>\n",
              "      <td>101.869979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>1504</td>\n",
              "      <td>105.843333</td>\n",
              "      <td>106.228489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>1505</td>\n",
              "      <td>111.156667</td>\n",
              "      <td>111.918246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>2996</td>\n",
              "      <td>22.713000</td>\n",
              "      <td>22.752119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1496</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>2997</td>\n",
              "      <td>22.696038</td>\n",
              "      <td>22.445265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>2998</td>\n",
              "      <td>22.470111</td>\n",
              "      <td>22.468313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1498</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>2999</td>\n",
              "      <td>22.205667</td>\n",
              "      <td>22.299579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1499</th>\n",
              "      <td>slug_flow</td>\n",
              "      <td>3000</td>\n",
              "      <td>22.160000</td>\n",
              "      <td>21.963461</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1500 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73d0be85-b165-40a6-92de-7f06bc97b2fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-73d0be85-b165-40a6-92de-7f06bc97b2fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-73d0be85-b165-40a6-92de-7f06bc97b2fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e164498b-a8f6-4325-bab7-3377565df9a9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e164498b-a8f6-4325-bab7-3377565df9a9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e164498b-a8f6-4325-bab7-3377565df9a9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_e92f5d59-0843-4b9c-9a1b-4b000d06e545\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('original_scale_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e92f5d59-0843-4b9c-9a1b-4b000d06e545 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('original_scale_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "original_scale_df",
              "summary": "{\n  \"name\": \"original_scale_df\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"unique_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"slug_flow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 433,\n        \"min\": 1501,\n        \"max\": 3000,\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          2617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.42728942899546,\n        \"min\": -81.09550000000002,\n        \"max\": 291.73,\n        \"num_unique_values\": 1492,\n        \"samples\": [\n          22.42892307692305\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AutoNHITS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.841951891599656,\n        \"min\": -85.1191335649456,\n        \"max\": 307.187589931,\n        \"num_unique_values\": 1498,\n        \"samples\": [\n          22.466886428559988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "original_scale_df[['y', 'AutoNHITS']].plot(figsize=(15, 5));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "n2DF2jiadtHH",
        "outputId": "150308a1-4e36-4930-a3ad-129e3e2c46ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = original_scale_df['y']\n",
        "y_pred = original_scale_df['AutoNHITS']"
      ],
      "metadata": {
        "id": "x4NFUWCRYvmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"RMSE: {math.sqrt(mean_squared_error(y_true, y_pred))}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_true, y_pred)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IqLOVCLY2x4",
        "outputId": "7b8c1281-5b27-45db-ce95-145adf4b180d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2.448190732459234\n",
            "MAE: 1.1568633336300047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ebWgyyT4d9GL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}